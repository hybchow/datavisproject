{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A comparative study in Diabetes Diagnosis through Multilayer Perceptron and Support Vector Machine\n",
    "\n",
    "\n",
    "## Abstract\n",
    "Multilayer Perceptron (MLP) and Support Vector Machine (SVM) algorithms yielded similar test AUCs and accuracies on the Pima Indian Diabetes dataset. MLP’s higher specificity of 89% compared to SVM (78%) makes MLP more suitable for practical use, as there is a high cost associated with the incorrect classification of a large number of non-diabetes patients.\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "Early diagnosis and treatment of diabetes are essential to avoid complications such as blindness, kidney failure, heart attacks, stroke and lower limb amputation[1]. In this work, we compared and critically evaluated the use of Multilayer Perceptron (MLP) and Support Vector Machine (SVM) to aid the diagnosis of diabetes using the [Pima Indian Diabetes database](https://www.kaggle.com/uciml/pima-indians-diabetes-database). PyTorch and Scikit-learn packages were used to build the models. This investigation was implemented on a machine with Intel Core i5 processor running at 2.3 GHz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP)\n",
    "\n",
    "MLP is a class of feed-forward artificial neural network consisting of fully connected neurons in an input layer, one or more hidden layers and an output layer[2]. During training, data are repeatedly passed into MLP and each neuron passes to the next layer a signal that is a function of sum of the inputs. An error signal which is calculated by the difference between the actual and the predicted output is back propagated through the network such that the weight of each neuron can be adjusted to minimize the error (loss).\n",
    "Advantages of MLP are that it works on non-linearly separable data and does not require prior knowledge or assumption on the data distribution. A disadvantage of MLP is that it is prone to overfitting. Nonetheless, this may be reduced by the application of dropout, batch normalization and early stopping[3,4]. Another disadvantage is that it is technically challenging, computationally expensive and time-consuming to build and train MLP models. Variations in architecture, activation function, learning rate, dropout rate, batch size and other parameters can produce significant difference in predictive power. Furthermore, MLP may yield a solution that is a local minimum instead of the global minimum[5], depending on the choice of initial weights, learning rate and momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Classifier (SVM)\n",
    "\n",
    "In the context of binary classification, SVM is an algorithm that separates two classes by maximizing the margin between data points and the optimal decision boundary in a feature space[6]. A kernel can be applied to transform input data into a higher dimensional feature space to enable computation of a decision boundary.\n",
    "SVM has the advantage of yielding global and unique solution. In addition, the computation time and cost are relatively low, as only the examples closest to the decision boundary (support vectors) determine the optimal decision boundary. A disadvantage of SVM is that it assumes the data is linearly separable, which is not always appropriate. Furthermore, the selection of kernel requires either prior knowledge on the distribution of the data or trial-and-error. Underfitting occurs when the decision boundary does not effectively separate the data points into two classes in the selected transformed space. In addition, any noise near the decision boundary would have a significant impact to the model. Nonetheless, regularization can be incorporated into SVM by separating the two classes with a large margin, enhancing its immunity to noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "1. MLP yields a higher Area Under the Receiver Operation Curve (AUC) score than SVM. SVM assumes that the data is linearly separable, but this is not the case for the dataset. MLP does not have such an assumption. This is supported by the literature -– MLP achieved an accuracy of 0.82 [7], whereas SVM attained a lower accuracy of 0.78 [8]. \n",
    "2. Randomized search for MLP requires a longer time than for SVM. SVM only considers a small number of data points closest to the decision boundary, whereas training MLP involves numerous iterations of complex computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The Pima Indian Diabetes database was obtained from [Kaggle](https://www.kaggle.com/uciml/pima-indians-diabetes-database) [9] (originally from UCI). The dataset originally contained 8 numeric (continuous) features of 768 Pima Indian females aged 21 or above. A total of 268 females were diagnosed with diabetes and 500 females were not. Six features, namely ‘Pregnancies’ (number of previous pregnancies), ‘Glucose’ (2-hour plasma glucose concentration in an oral glucose tolerance test), ‘BloodPressure’ (diastolic blood pressure), ‘BMI’ (body mass index), ‘DiabetesPedigreeFunction’ (diabetes pedigree function) and ‘Age’ (age in years) were used for analysis. Missing values were encoded as zero and distributed randomly in the columns ‘SkinThickness’ (tricep skinfold thickness), ‘Insulin’ (2-hour serum insulin), ‘Glucose’, ‘BloodPressure’ and ‘BMI’. Removing the columns ‘SkinThickness’ and ‘Insulin’ and imputing the remainder with mean yielded highest accuracy in our experiment and were implemented (see Appendix).\n",
    "\n",
    "Details of pre-processing and exploration of the dataset can be found in Diabetes-Preprocessing.ipynb.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "The following training and evaluation methodology were adopted.\n",
    "1. Divided data into training and test sets in 80:20 ratio using stratified sampling such that equal\n",
    "proportions of diabetes patients and non-diabetes patients were in both sets.\n",
    "2. Applied Synthetic Minority Over-sampling Technique (SMOTE) on the minority non-diabetes\n",
    "class in the training set such that both classes became equal in size and the bias towards the\n",
    "majority class was eliminated during training [10].\n",
    "3. Standardized the features in both training and test sets to zero mean and unit variance.\n",
    "4. Selected the best model for each algorithm based on AUC using randomized search on the\n",
    "hyperparameters on the training data. Stratified five-fold cross-validation was used to reduce bias and increase generalizability of the models. Using AUC is more appropriate than accuracy, because AUC is less sensitive to differences in target class proportions in the training and test sets. For MLP, Early Stopping was applied to reduce overfitting such that the training stopped when there was no improvement in validation accuracy (determined using a random selection of 20% of the training data that was unseen during training) in the last 5 epochs or when a maximum of 100 epochs were completed.\n",
    "5. Measured the time required to perform randomized search for each algorithm across five scoring functions (accuracy, precision, recall, F1 score and AUC) on a Macbook Pro equipped with a 2.3GHz Intel Core i5 processor with Python’s Time module.\n",
    "6. Evaluated and compared the algorithms based on AUC on the test data and the time required for the randomized search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture and Parameters for MLP\n",
    "\n",
    "The MLP contained 6 input neurons, one or two hidden layers and two output neurons. Rectified linear unit (RELu) activation function was applied in the input and hidden layers. Softmax was used in the output layer to give predicted probabilities for each class. Stochastic gradient decent algorithm was used to update the weights of neurons. The optimal combination of the number of neurons, optimizer momentum, learning rate, dropout rate for input and hidden layers, and batch size in MLP with one or two hidden layers were selected using stratified 5-fold cross validated Randomized Search based on AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture and Parameters for SVM\n",
    "\n",
    "The optimal kernel, regularization parameter C, and for polynomial and RBF kernels, the kernel coefficient gamma, were determined using stratified 5-fold cross validated Randomized Search based on AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Pre-processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \\\n",
    "plot_roc_curve, roc_curve, plot_confusion_matrix, classification_report, precision_recall_curve, plot_precision_recall_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from time import time\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EarlyStopping\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python==3.7.9 (default, Aug 31 2020, 07:22:35) \n",
      "[Clang 10.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "# Version of Python used\n",
    "print('Python==' + str(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas==1.1.1\n",
      "matplotlib==3.3.1\n",
      "numpy==1.19.1\n",
      "seaborn==0.11.0\n",
      "missingno==0.4.2\n",
      "statsmodels==0.12.0\n",
      "scikit-learn==0.24.1\n",
      "torch==1.7.1\n",
      "skorch==0.9.0\n",
      "imbalanced-learn==0.8.0\n"
     ]
    }
   ],
   "source": [
    "# Version numbers of libraries used\n",
    "print('pandas==' + str(pd.__version__))\n",
    "print('matplotlib==' + str(sys.modules[plt.__package__].__version__))\n",
    "print('numpy==' + str(np.__version__))\n",
    "print('seaborn==' + str(sns.__version__))\n",
    "print('missingno==' + str(msno.__version__))\n",
    "print('statsmodels==' + str(sys.modules[add_constant.__module__[:add_constant.__module__.index(\".\")]].__version__))\n",
    "print('scikit-learn==' + str(sys.modules[StandardScaler.__module__[:StandardScaler.__module__.index(\".\")]].__version__))\n",
    "print('torch==' + str(torch.__version__))\n",
    "print('skorch==' + str(sys.modules[NeuralNetClassifier.__module__[:NeuralNetClassifier.__module__.index(\".\")]].__version__))\n",
    "print('imbalanced-learn==' + str(sys.modules[SMOTE.__module__[:SMOTE.__module__.index(\".\")]].__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note these built-in modules of Python 3 'pickle', 'collections', 'time' were also used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "data = pd.read_csv('processed_diabetes.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 768 rows and 7 columns.\n"
     ]
    }
   ],
   "source": [
    "# Size of dataset\n",
    "print('The dataset has %.0f rows and %.0f columns.'%(data.shape[0],data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and Transform Pre-processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   int64\n",
       "Glucose                     float64\n",
       "BloodPressure               float64\n",
       "BMI                         float64\n",
       "DiabetesPedigreeFunction    float64\n",
       "Age                           int64\n",
       "Outcome                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect data types of the columns\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.865672</td>\n",
       "      <td>142.165573</td>\n",
       "      <td>75.147324</td>\n",
       "      <td>35.384757</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>37.067164</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.741239</td>\n",
       "      <td>29.541750</td>\n",
       "      <td>11.945712</td>\n",
       "      <td>6.595065</td>\n",
       "      <td>0.372354</td>\n",
       "      <td>10.968254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.750000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>30.900000</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>38.775000</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure         BMI  \\\n",
       "count   268.000000  268.000000     268.000000  268.000000   \n",
       "mean      4.865672  142.165573      75.147324   35.384757   \n",
       "std       3.741239   29.541750      11.945712    6.595065   \n",
       "min       0.000000   78.000000      30.000000   22.900000   \n",
       "25%       1.750000  119.000000      68.000000   30.900000   \n",
       "50%       4.000000  140.000000      74.000000   34.250000   \n",
       "75%       8.000000  167.000000      82.000000   38.775000   \n",
       "max      17.000000  199.000000     114.000000   67.100000   \n",
       "\n",
       "       DiabetesPedigreeFunction         Age  Outcome  \n",
       "count                268.000000  268.000000    268.0  \n",
       "mean                   0.550500   37.067164      1.0  \n",
       "std                    0.372354   10.968254      0.0  \n",
       "min                    0.088000   21.000000      1.0  \n",
       "25%                    0.262500   28.000000      1.0  \n",
       "50%                    0.449000   36.000000      1.0  \n",
       "75%                    0.728000   44.000000      1.0  \n",
       "max                    2.420000   70.000000      1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize summary statistics for diabetes patients\n",
    "data[data.Outcome==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.298000</td>\n",
       "      <td>110.710121</td>\n",
       "      <td>70.935397</td>\n",
       "      <td>30.888434</td>\n",
       "      <td>0.429734</td>\n",
       "      <td>31.190000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.017185</td>\n",
       "      <td>24.717060</td>\n",
       "      <td>11.931033</td>\n",
       "      <td>6.504779</td>\n",
       "      <td>0.299085</td>\n",
       "      <td>11.667655</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>0.229750</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>107.500000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>0.561750</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>57.300000</td>\n",
       "      <td>2.329000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure         BMI  \\\n",
       "count   500.000000  500.000000     500.000000  500.000000   \n",
       "mean      3.298000  110.710121      70.935397   30.888434   \n",
       "std       3.017185   24.717060      11.931033    6.504779   \n",
       "min       0.000000   44.000000      24.000000   18.200000   \n",
       "25%       1.000000   93.000000      63.500000   25.750000   \n",
       "50%       2.000000  107.500000      72.000000   30.400000   \n",
       "75%       5.000000  125.000000      78.000000   35.300000   \n",
       "max      13.000000  197.000000     122.000000   57.300000   \n",
       "\n",
       "       DiabetesPedigreeFunction         Age  Outcome  \n",
       "count                500.000000  500.000000    500.0  \n",
       "mean                   0.429734   31.190000      0.0  \n",
       "std                    0.299085   11.667655      0.0  \n",
       "min                    0.078000   21.000000      0.0  \n",
       "25%                    0.229750   23.000000      0.0  \n",
       "50%                    0.336000   27.000000      0.0  \n",
       "75%                    0.561750   37.000000      0.0  \n",
       "max                    2.329000   81.000000      0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize summary statistics for non-diabetes patients\n",
    "data[data.Outcome==0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into predictors and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 6)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "## Split data into predictors and target \n",
    "X = data.iloc[:,:-1].values\n",
    "y = data.iloc[:,-1].values\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 6)\n",
      "(614,)\n",
      "(154, 6)\n",
      "(154,)\n"
     ]
    }
   ],
   "source": [
    "## Split data into training set and test set in 80:20 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the number of data in the two target classes in training set\n",
    "train_class_count = pd.DataFrame(y_train)\n",
    "plt.bar(range(len(train_class_count.value_counts())), train_class_count.value_counts())\n",
    "plt.xticks([0,1])\n",
    "plt.title(\"Number of people without diabetes (labelled as 0) and with diabetes (labelled as 1) in training data\")\n",
    "plt.ylabel(\"Number of people\")\n",
    "plt.xlabel(\"With diabetes or not\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the number of data in the two target classes in test set\n",
    "test_class_count = pd.DataFrame(y_test)\n",
    "plt.bar(range(len(test_class_count.value_counts())), test_class_count.value_counts())\n",
    "plt.xticks([0,1])\n",
    "plt.title(\"Number of people without diabetes (labelled as 0) and with diabetes (labelled as 1) in test data\")\n",
    "plt.ylabel(\"Number of people\")\n",
    "plt.xlabel(\"With diabetes or not\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set and test set have the same distribution of target classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Synthetic Minority Over-sampling Technique (SMOTE) to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 6)\n",
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTE(sampling_strategy='minority', random_state=1)\n",
    "X_train_smote, y_train_smote = smt.fit_resample(X_train, y_train)\n",
    "print(X_train_smote.shape)\n",
    "print(y_train_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 400, 0: 400})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of data in the target classes after resampling\n",
    "Counter(y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both target classes contain 400 examples after performing oversampling on the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 100, 1: 54})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of examples in each target class in the test set remained unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply standardization on predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale each feature to values between 0 and 1\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 6)\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform all features in augmented training data \n",
    "X_train_smote = scaler.fit_transform(X_train_smote)\n",
    "print(X_train_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154, 6)\n"
     ]
    }
   ],
   "source": [
    "# Transform all features in test data \n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.287859e-16</td>\n",
       "      <td>6.864648e-16</td>\n",
       "      <td>4.816286e-16</td>\n",
       "      <td>1.221245e-15</td>\n",
       "      <td>1.571659e-17</td>\n",
       "      <td>-1.640216e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000626e+00</td>\n",
       "      <td>1.000626e+00</td>\n",
       "      <td>1.000626e+00</td>\n",
       "      <td>1.000626e+00</td>\n",
       "      <td>1.000626e+00</td>\n",
       "      <td>1.000626e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.208217e+00</td>\n",
       "      <td>-2.671495e+00</td>\n",
       "      <td>-3.778196e+00</td>\n",
       "      <td>-2.202427e+00</td>\n",
       "      <td>-1.224557e+00</td>\n",
       "      <td>-1.132306e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.112203e-01</td>\n",
       "      <td>-7.500742e-01</td>\n",
       "      <td>-6.146475e-01</td>\n",
       "      <td>-6.461541e-01</td>\n",
       "      <td>-7.135986e-01</td>\n",
       "      <td>-7.794140e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.172275e-01</td>\n",
       "      <td>-1.313116e-01</td>\n",
       "      <td>-5.178323e-02</td>\n",
       "      <td>-7.044464e-02</td>\n",
       "      <td>-2.897687e-01</td>\n",
       "      <td>-2.439629e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.651142e-01</td>\n",
       "      <td>6.502833e-01</td>\n",
       "      <td>6.156215e-01</td>\n",
       "      <td>5.609786e-01</td>\n",
       "      <td>4.921753e-01</td>\n",
       "      <td>6.443799e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.840722e+00</td>\n",
       "      <td>2.376305e+00</td>\n",
       "      <td>3.251912e+00</td>\n",
       "      <td>5.062655e+00</td>\n",
       "      <td>5.674862e+00</td>\n",
       "      <td>4.197751e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pregnancies       Glucose  BloodPressure           BMI  \\\n",
       "count  8.000000e+02  8.000000e+02   8.000000e+02  8.000000e+02   \n",
       "mean   1.287859e-16  6.864648e-16   4.816286e-16  1.221245e-15   \n",
       "std    1.000626e+00  1.000626e+00   1.000626e+00  1.000626e+00   \n",
       "min   -1.208217e+00 -2.671495e+00  -3.778196e+00 -2.202427e+00   \n",
       "25%   -9.112203e-01 -7.500742e-01  -6.146475e-01 -6.461541e-01   \n",
       "50%   -3.172275e-01 -1.313116e-01  -5.178323e-02 -7.044464e-02   \n",
       "75%    6.651142e-01  6.502833e-01   6.156215e-01  5.609786e-01   \n",
       "max    3.840722e+00  2.376305e+00   3.251912e+00  5.062655e+00   \n",
       "\n",
       "       DiabetesPedigreeFunction           Age  \n",
       "count              8.000000e+02  8.000000e+02  \n",
       "mean               1.571659e-17 -1.640216e-15  \n",
       "std                1.000626e+00  1.000626e+00  \n",
       "min               -1.224557e+00 -1.132306e+00  \n",
       "25%               -7.135986e-01 -7.794140e-01  \n",
       "50%               -2.897687e-01 -2.439629e-01  \n",
       "75%                4.921753e-01  6.443799e-01  \n",
       "max                5.674862e+00  4.197751e+00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect distribution of features after scaling\n",
    "pd.DataFrame(X_train_smote, columns = data.columns[:-1]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 6)\n",
      "(154, 6)\n",
      "(800,)\n",
      "(154,)\n"
     ]
    }
   ],
   "source": [
    "# Convert features to 'float32' and target to 'int64'\n",
    "X_train_smote = np.array(X_train_smote).astype('float32')\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "y_train_smote = np.array(y_train_smote).astype('int64')\n",
    "y_test = np.array(y_test).astype('int64')\n",
    "\n",
    "print(X_train_smote.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train_smote.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Support Vector Machine (SVM) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare between 5 and 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in this section is adapted based on https://towardsdatascience.com/\n",
    "#     machine-learning-classifiers-comparison-with-python-33149aecdbca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SVM model with a linear kernel\n",
    "svc_linear = SVC(kernel='linear', random_state=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for storing mean performance metrics scores\n",
    "scoring = {'accuracy':make_scorer(accuracy_score), \n",
    "           'precision':make_scorer(precision_score),\n",
    "           'recall':make_scorer(recall_score), \n",
    "           'f1_score':make_scorer(f1_score),\n",
    "           'AUC': 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             5 fold   10 fold Best Score\n",
      "Accuracy   0.740000  0.736250     5 fold\n",
      "Precision  0.747876  0.749116    10 fold\n",
      "Recall     0.725000  0.715000     5 fold\n",
      "F1 Score   0.735956  0.729958     5 fold\n",
      "AUC        0.833656  0.832812     5 fold\n",
      "             5 fold   10 fold Minimum standard deviation\n",
      "Accuracy   0.029738  0.042371                     5 fold\n",
      "Precision  0.032752  0.051374                     5 fold\n",
      "Recall     0.035355  0.061441                     5 fold\n",
      "F1 Score   0.030293  0.044993                     5 fold\n",
      "AUC        0.028039  0.046983                     5 fold\n"
     ]
    }
   ],
   "source": [
    "# Create function that performs cross-validation and evaluates each classifier\n",
    "def models_evaluation(X_train, y_train):\n",
    "    \n",
    "    # Perform cross-validation on each classifier\n",
    "    cv_svc_linear_5fold = cross_validate(svc_linear, X_train, y_train, cv=5, scoring=scoring)\n",
    "    cv_svc_linear_10fold = cross_validate(svc_linear, X_train, y_train, cv=10, scoring=scoring)\n",
    "   \n",
    "    \n",
    "    # Create 'mean_scores_table' DataFrame with mean performance metric scores for each classifier\n",
    "    mean_scores_table = pd.DataFrame({'5 fold':[cv_svc_linear_5fold['test_accuracy'].mean(),\n",
    "                                                         cv_svc_linear_5fold['test_precision'].mean(),\n",
    "                                                         cv_svc_linear_5fold['test_recall'].mean(),\n",
    "                                                         cv_svc_linear_5fold['test_f1_score'].mean(),\n",
    "                                                         cv_svc_linear_5fold['test_AUC'].mean()],\n",
    "                                       '10 fold':[cv_svc_linear_10fold['test_accuracy'].mean(),\n",
    "                                                            cv_svc_linear_10fold['test_precision'].mean(),\n",
    "                                                            cv_svc_linear_10fold['test_recall'].mean(),\n",
    "                                                            cv_svc_linear_10fold['test_f1_score'].mean(),\n",
    "                                                            cv_svc_linear_10fold['test_AUC'].mean()]},\n",
    "                                       index=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'])\n",
    "    \n",
    "    # Add 'Best Score' column to 'mean_scores_table'\n",
    "    mean_scores_table['Best Score'] = mean_scores_table.idxmax(axis=1)  \n",
    "\n",
    "    # Create 'std_scores_table' DataFrame with standard deviation of performance metric scores for each classifier\n",
    "    std_scores_table = pd.DataFrame({'5 fold':[cv_svc_linear_5fold['test_accuracy'].std(),\n",
    "                                                         cv_svc_linear_5fold['test_precision'].std(),\n",
    "                                                         cv_svc_linear_5fold['test_recall'].std(),\n",
    "                                                         cv_svc_linear_5fold['test_f1_score'].std(),\n",
    "                                                         cv_svc_linear_5fold['test_AUC'].std()],\n",
    "                                     '10 fold':[cv_svc_linear_10fold['test_accuracy'].std(),\n",
    "                                                            cv_svc_linear_10fold['test_precision'].std(),\n",
    "                                                            cv_svc_linear_10fold['test_recall'].std(),\n",
    "                                                            cv_svc_linear_10fold['test_f1_score'].std(),\n",
    "                                                            cv_svc_linear_10fold['test_AUC'].std()]},\n",
    "                                     index=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'])\n",
    "   \n",
    "    # Add 'Minimum standard deviation' column to 'std_scores_table'\n",
    "    std_scores_table['Minimum standard deviation'] = std_scores_table.idxmin(axis=1)  \n",
    "\n",
    "    # Return DataFrames with mean and standard deviation performance metrics scores for each classifier\n",
    "    return mean_scores_table, std_scores_table\n",
    "                     \n",
    "# Evaluate classifiers on training data\n",
    "mean_scores_table, std_scores_table = models_evaluation(X_train_smote, y_train_smote)\n",
    "\n",
    "# Display the average cross-validation scores \n",
    "print(mean_scores_table)\n",
    "\n",
    "# Display the average cross-validation scores \n",
    "print(std_scores_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x1872 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot bar graphs to show the mean and standard deviation of performance metrics of 5-fold and 10-fold cross-validated SVM models\n",
    "x_labels = ['5-fold cross-validation',\n",
    "            '10-fold cross-validation']\n",
    "n_bars = len(mean_scores_table.iloc[0,:-1])\n",
    "xval = np.arange(n_bars)\n",
    "ax = plt.figure(figsize = (6,26))\n",
    "for k in range(len(mean_scores_table)):\n",
    "   ax = plt.subplot(5,1,k+1)\n",
    "   for j in xval:\n",
    "      plt.barh([j], mean_scores_table.iloc[k,j], xerr=std_scores_table.iloc[k,j], alpha=0.6, align='center')\n",
    "   plt.title('%s for SVC models with different number of cross validation folds'%mean_scores_table.index[k])\n",
    "   plt.xlabel('%s'%mean_scores_table.index[k])\n",
    "   ax.set_yticks(xval)\n",
    "   ax.invert_yaxis()\n",
    "   ax.set_yticklabels(x_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of ten-fold cross-validation was suggested in the paper \"A Study of Cross􏰇-Validation and Bootstrap for Accuracy Estimation and Model Selection\" by Ron Kohavi\n",
    "http://robotics.stanford.edu/%7Eronnyk/accEst.pdf. \n",
    "\n",
    "Based on the above experiment, five-fold and ten-fold cross-validated models yielded similar performance in terms of accuracy, precision, recall, F1 score and Area Under the receiver operation Curve (AUC). However, five-fold cross-validated model yielded smaller standard deviations for these performance metrics. This was probably because the test set became too small when 10 folds were used and any extreme values included in the test set would have an significant impact on the performance of each fold, leading to the greater variations in performance of the models in the folds.\n",
    "\n",
    "We will use five-fold cross-validation in this study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare between linear, polynomial (degree 2 or 3), radial basis function (RBF) and sigmoid kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in this section is adapted based on https://towardsdatascience.com/\n",
    "#    machine-learning-classifiers-comparison-with-python-33149aecdbca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM models with different kernels\n",
    "svc_poly2 = SVC(kernel='poly', degree=2, random_state=1)\n",
    "svc_poly3 = SVC(kernel='poly', degree=3, random_state=1)\n",
    "svc_rbf = SVC(kernel='rbf', random_state=1)\n",
    "svc_sigmoid = SVC(kernel='sigmoid', random_state=1)\n",
    "dummy_model = DummyClassifier(strategy='stratified', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Linear kernel  Polynomial (degree 2) kernel  \\\n",
      "Accuracy        0.738750                      0.588750   \n",
      "Precision       0.747097                      0.630245   \n",
      "Recall          0.722500                      0.435000   \n",
      "F1 Score        0.734300                      0.512862   \n",
      "AUC             0.833594                      0.636563   \n",
      "\n",
      "           Polynomial (degree 3) kernel  Radial basis function kernel  \\\n",
      "Accuracy                       0.723750                      0.797500   \n",
      "Precision                      0.750289                      0.772165   \n",
      "Recall                         0.685000                      0.845000   \n",
      "F1 Score                       0.713208                      0.806204   \n",
      "AUC                            0.816875                      0.859781   \n",
      "\n",
      "           Sigmoid kernel  Dummy classifier                    Best Score  \n",
      "Accuracy         0.662500          0.455000  Radial basis function kernel  \n",
      "Precision        0.666234          0.453846  Radial basis function kernel  \n",
      "Recall           0.650000          0.442500  Radial basis function kernel  \n",
      "F1 Score         0.657146          0.448101  Radial basis function kernel  \n",
      "AUC              0.743875          0.455000  Radial basis function kernel  \n",
      "           Linear kernel  Polynomial (degree 2) kernel  \\\n",
      "Accuracy        0.031721                      0.007289   \n",
      "Precision       0.033994                      0.020004   \n",
      "Recall          0.038243                      0.041382   \n",
      "F1 Score        0.032784                      0.025548   \n",
      "AUC             0.027981                      0.032193   \n",
      "\n",
      "           Polynomial (degree 3) kernel  Radial basis function kernel  \\\n",
      "Accuracy                       0.029948                      0.036785   \n",
      "Precision                      0.058530                      0.034358   \n",
      "Recall                         0.039051                      0.055114   \n",
      "F1 Score                       0.016231                      0.038197   \n",
      "AUC                            0.023330                      0.025351   \n",
      "\n",
      "           Sigmoid kernel  Dummy classifier    Minimum standard deviation  \n",
      "Accuracy         0.027951          0.010000  Polynomial (degree 2) kernel  \n",
      "Precision        0.021594          0.010256              Dummy classifier  \n",
      "Recall           0.058095          0.010000              Dummy classifier  \n",
      "F1 Score         0.036208          0.010127              Dummy classifier  \n",
      "AUC              0.030180          0.010000              Dummy classifier  \n"
     ]
    }
   ],
   "source": [
    "# Create function that performs cross-validation and evaluates each classifier\n",
    "def models_evaluation(X_train, y_train):\n",
    "    \n",
    "    # Perform cross-validation on each classifier\n",
    "    cv_svc_linear = cross_validate(svc_linear, X_train, y_train, cv=5, scoring=scoring, return_train_score=True)\n",
    "    cv_svc_poly2 = cross_validate(svc_poly2, X_train, y_train, cv=5, scoring=scoring, return_train_score=True)\n",
    "    cv_svc_poly3 = cross_validate(svc_poly3, X_train, y_train, cv=5, scoring=scoring, return_train_score=True)\n",
    "    cv_svc_rbf = cross_validate(svc_rbf, X_train, y_train, cv=5, scoring=scoring, return_train_score=True)\n",
    "    cv_svc_sigmoid = cross_validate(svc_sigmoid, X_train, y_train, cv=5, scoring=scoring, return_train_score=True)\n",
    "    cv_dummy_model = cross_validate(dummy_model, X_train, y_train, cv=5, scoring=scoring, return_train_score=True)\n",
    "    \n",
    "    # Create 'mean_scores_table' DataFrame with mean performance metric scores for each classifier\n",
    "    mean_scores_table = pd.DataFrame({'Linear kernel':[cv_svc_linear['test_accuracy'].mean(),\n",
    "                                                         cv_svc_linear['test_precision'].mean(),\n",
    "                                                         cv_svc_linear['test_recall'].mean(),\n",
    "                                                         cv_svc_linear['test_f1_score'].mean(),\n",
    "                                                         cv_svc_linear['test_AUC'].mean()],\n",
    "                                       'Polynomial (degree 2) kernel':[cv_svc_poly2['test_accuracy'].mean(),\n",
    "                                                            cv_svc_poly2['test_precision'].mean(),\n",
    "                                                            cv_svc_poly2['test_recall'].mean(),\n",
    "                                                            cv_svc_poly2['test_f1_score'].mean(),\n",
    "                                                            cv_svc_poly2['test_AUC'].mean()],\n",
    "                                      'Polynomial (degree 3) kernel':[cv_svc_poly3['test_accuracy'].mean(),\n",
    "                                                            cv_svc_poly3['test_precision'].mean(),\n",
    "                                                            cv_svc_poly3['test_recall'].mean(),\n",
    "                                                            cv_svc_poly3['test_f1_score'].mean(),\n",
    "                                                            cv_svc_poly3['test_AUC'].mean()],\n",
    "                                       'Radial basis function kernel':[cv_svc_rbf['test_accuracy'].mean(),\n",
    "                                                            cv_svc_rbf['test_precision'].mean(),\n",
    "                                                            cv_svc_rbf['test_recall'].mean(),\n",
    "                                                            cv_svc_rbf['test_f1_score'].mean(),\n",
    "                                                            cv_svc_rbf['test_AUC'].mean()],\n",
    "                                       'Sigmoid kernel':[cv_svc_sigmoid['test_accuracy'].mean(),\n",
    "                                                         cv_svc_sigmoid['test_precision'].mean(),\n",
    "                                                         cv_svc_sigmoid['test_recall'].mean(),\n",
    "                                                         cv_svc_sigmoid['test_f1_score'].mean(),\n",
    "                                                        cv_svc_sigmoid['test_AUC'].mean()],\n",
    "                                     'Dummy classifier':[cv_dummy_model['test_accuracy'].mean(),\n",
    "                                                         cv_dummy_model['test_precision'].mean(),\n",
    "                                                         cv_dummy_model['test_recall'].mean(),\n",
    "                                                         cv_dummy_model['test_f1_score'].mean(),\n",
    "                                                        cv_dummy_model['test_AUC'].mean()]},\n",
    "                                      index=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'])\n",
    "    \n",
    "    # Add 'Best Score' column to 'mean_scores_table'\n",
    "    mean_scores_table['Best Score'] = mean_scores_table.idxmax(axis=1)  \n",
    "\n",
    "    # Create 'std_scores_table' DataFrame with standard deviation of performance metric scores for each classifier\n",
    "    std_scores_table = pd.DataFrame({'Linear kernel':[cv_svc_linear['test_accuracy'].std(),\n",
    "                                                         cv_svc_linear['test_precision'].std(),\n",
    "                                                         cv_svc_linear['test_recall'].std(),\n",
    "                                                         cv_svc_linear['test_f1_score'].std(),\n",
    "                                                         cv_svc_linear['test_AUC'].std()],\n",
    "                                       'Polynomial (degree 2) kernel':[cv_svc_poly2['test_accuracy'].std(),\n",
    "                                                            cv_svc_poly2['test_precision'].std(),\n",
    "                                                            cv_svc_poly2['test_recall'].std(),\n",
    "                                                            cv_svc_poly2['test_f1_score'].std(),\n",
    "                                                            cv_svc_poly2['test_AUC'].std()],\n",
    "                                       'Polynomial (degree 3) kernel':[cv_svc_poly3['test_accuracy'].std(),\n",
    "                                                            cv_svc_poly3['test_precision'].std(),\n",
    "                                                            cv_svc_poly3['test_recall'].std(),\n",
    "                                                            cv_svc_poly3['test_f1_score'].std(),\n",
    "                                                            cv_svc_poly3['test_AUC'].std()],\n",
    "                                       'Radial basis function kernel':[cv_svc_rbf['test_accuracy'].std(),\n",
    "                                                            cv_svc_rbf['test_precision'].std(),\n",
    "                                                            cv_svc_rbf['test_recall'].std(),\n",
    "                                                            cv_svc_rbf['test_f1_score'].std(),\n",
    "                                                            cv_svc_rbf['test_AUC'].std()],\n",
    "                                       'Sigmoid kernel':[cv_svc_sigmoid['test_accuracy'].std(),\n",
    "                                                         cv_svc_sigmoid['test_precision'].std(),\n",
    "                                                         cv_svc_sigmoid['test_recall'].std(),\n",
    "                                                         cv_svc_sigmoid['test_f1_score'].std(),\n",
    "                                                         cv_svc_sigmoid['test_AUC'].std()],\n",
    "                                     'Dummy classifier':[cv_dummy_model['test_accuracy'].std(),\n",
    "                                                         cv_dummy_model['test_precision'].std(),\n",
    "                                                         cv_dummy_model['test_recall'].std(),\n",
    "                                                         cv_dummy_model['test_f1_score'].std(),\n",
    "                                                        cv_dummy_model['test_AUC'].std()]},\n",
    "                                      index=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'])\n",
    "   \n",
    "    # Add 'Minimum standard deviation' column to 'std_scores_table'\n",
    "    std_scores_table['Minimum standard deviation'] = std_scores_table.idxmin(axis=1)  \n",
    "\n",
    "    # Return DataFrames with mean and standard deviation performance metrics scores for each classifier\n",
    "    return mean_scores_table, std_scores_table\n",
    "    \n",
    "                                       \n",
    "# Evaluate the classifiers \n",
    "mean_scores_table, std_scores_table = models_evaluation(X_train_smote, y_train_smote)\n",
    "\n",
    "# Display the average cross-validation scores\n",
    "print(mean_scores_table)\n",
    "\n",
    "# Display the standard deviations of the cross-validation scores\n",
    "print(std_scores_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAXCCAYAAAAPZgRQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAADubUlEQVR4nOzdebxd093H8c+3ETIgxFRRkVbEFBrEVFPSqrZmpUUVQSkt6ikPLW0E1apOWqqKh9CaqoYaaiquqYKESGLWoqYiSCQSIcnv+WOty85xzr3n3tx7z91836/Xed09rL3Xb+9z7vnttfY+eysiMDMzs/L6RKMDMDMzs4XjZG5mZlZyTuZmZmYl52RuZmZWck7mZmZmJedkbmZmVnJO5mYfEZIOkfSKpJmSlml0PN2RpCZJ36qzbEga3ElxHCvp3Bbmj5J090Ksf6ykn+ThLSQ9UZi3uqSHJM2QdLik3pKulTRd0uXtrbOzFLelwXE8K2nrRsdRi5O5fSzkL/E3JS3W6Fg6g6SewK+BbSJi8Yh4vQPWubmkf+Yv+Tck3SNpQ0mbSnpb0hJVlnlI0qGSBuVk+GDF/GUlvSvp2YWNr8wi4qcR8S2Awr5apJPquisiVi9MOhpoioglIuJ3wG7ACsAyEfG1zoihFkkjJL3QlXV+VDmZ20eepEHAFkAAO3Zx3Z3yBV3FCkAv4JG2LqjkExXTlgSuA04H+gMrAScAcyLiXuAFYNeKZYYCawGXFCb3zdObfQN4pq0xWodahQU/J6sAT0bE3LauqAs/3wtNUo9Gx9CZnMzt42AfYBwwFti3OEPSypKulPSapNclnVGYd6Ckx3J35KOS1s/TF+h+rejSHCHpBUnHSPovcL6kpSVdl+t4Mw9/qrB8f0nnS3opz786T58iaYdCuZ6SpkoaVrENQ4DmbtRpkm7L0z8n6YHcsn5A0ucKyzRJOlnSPcAs4DMV+2wIQERcEhHzImJ2RNwcEZPy/Avyfq3cz9dX9Ar8qWKf7wNcSAvy/v2OpKfyvj9J0qqS7pX0lqS/SFq0UP5ASU/n3oNrJA0ozPuipMfzPjgDUEVd++f3+E1JN0lapUZM2+bPwAxJL0o6qka55yRtkIe/mbdlrTz+rcJ7O0bSn/Nid+a/05ROkWxaWN8vc2zPSPpKC/tsPUkP5vguIx3YNc97v/WbPxsjgTNyXZcAo4Hd8/gBre2XvE3flfQU8FSetr2kiZKmKfXmrFso/6ykoyRNyu/DZZJ6SeoL3AAMyHXPLL53NbZzCUm3S/qdkjUk3ZLf+yckfb1QdqykP0j6u6S3gZG1YiksU3M7KuLYSNL4/Hl8RdKvW4q7S0SEX359pF/A08B3gA2A94AV8vQewMPAb4C+pC/AzfO8rwEvAhuSEsBgYJU8L4DBhfWPBX6Sh0cAc4GfA4sBvYFlSK3YPsASwOXA1YXlrwcuA5YGegJb5elHA5cVyu0ETK6xjYNyXIvk8f7Am8DewCLAnnl8mTy/CfgPsHae37NifUsCr5OS9leApSvmr5z35cA8/glSa33ningGAc/nfb0m6aBja+DZFt6vAK7JMawNzAFuJR1w9AMeBfbNZT8PTAXWz/v7dODOPG9Z4C1SN3JP4H/ye/OtPH/n/NlYM++DHwH/rIhjcB5+GdgiDy8NrF8j9guBI/Pw2cC/gEMK8/4nD48B/lztvcvTRuX9e2Ded4cALwGqUueiwHN5+3rm7X2PBT+TLxTKNzXvg8pY2rBfbiF9xnrnff8qsHGOdV/gWWCxXP5Z4H5gQF7mMeDgarHV2KdjgZ+Q/o/uL2xXX9Jna78c5/r5s7B2YbnpwGakz2evVmKpZzu2zsP3Anvn4cWBTRr9PeeWuX2kSdqc1I34l4iYQPpy/UaevRHpn/p/I+LtiHgnIpovOvoWcGpEPBDJ0xHxXJ3VzgeOj4g5kVq0r0fEFRExKyJmACcDW+X4ViQly4Mj4s2IeC8i7sjr+TOwrVKXN6TE/Kc6Y9gOeCoi/hQRcyPiEuBxYIdCmbER8Uie/15x4Yh4C9ic9MV9DvBabvWukOc/D9wBfDMv8gXSl+X1FXG8wAcJfF9aaZUX/Dwi3oqIR4ApwM0R8e+ImE5qza2Xy+0FnBcRD0bEHOCHwKZKp1a2BR6NiL/m7TsN+G+hjm8DP4uIxyJ1Mf8UGFajdf4esJakJfP79GCVMpD2yVZ5eAvgZ4XxrfL8ej0XEedExDzSQdWKpNMplTYhJfHT8ufnr8ADbainUj375WcR8UZEzCYdcPwxIu6L1ItzAekAbJNC+d9FxEsR8QZwLTCsjTENIO27yyPiR3na9qSDwvPzZ/hB4ArSwUyzv0XEPRExPyLeaSWWeraj2XvAYEnLRsTMiBjXxu3pcE7m9lG3LykRTM3jF/NBt+/KpC/MaucKVyYl/vZ4rfDFgaQ+kv6Yu2DfInWrLqV0Dm9l4I2IeLNyJRHxEnAPsKukpUhJ/6I6YxhAaq0VPUc6993s+ZZWkL/MR0XEp4CheZ2nFYoUu9r3Bi6uPCjILiS1NPckHaDU45XC8Owq44vn4QW2MyJmknoUVsrzni/MCxbc5lWA3+Yu1WnAG6RemOI+arYr6eDgOUl3FLvCK9wBbCHpk6TW3WXAZvngoh8wseYWf9j7Bx4RMSsPLl6l3ADgxbx9zeo98Kymnv1SuR+PbC6fl1k5x9WseBA1i+rb0ZLtSL0AZ1XUu3FFvXsBn6wRZ2ux1LMdzQ4gnYp6XOkU1vZt3J4OV5qLF8zaSlJv4OtAD6Xz15C6YpeS9FnSP/pASYtUSejPA6vWWPUsUpd5s0+SWqDNKh9FeCSwOrBxRPxX6Zz3Q6QvyOeB/pKWiohpVeq6gNRLsAhwb0S8WGt7K7xE+nIqGgjc2EKcNUXE45LGklptza4EzpQ0Evgqqcu0miuAM4AJEfGcpNXqrbcOC2xnPg+7DOkUycukL+PmeSqOk/b9yRHR6gFSRDwA7KT0q4FDgb9UrKu53NOSZgGHk7r7Z+TP3kHA3RExv9rqW93Klr0MrCRJhYQ+kPYfjNazX4oxN5c/uR111bvt55BOb/xd0pcj4u1c7x0R8cUOWD+0YTsi4ilgT6ULR78K/FXSMjmuhnDL3D7Kdgbmka6wHpZfawJ3kVqU95O+CE+R1DdflLNZXvZc4ChJG+QLbQYXuhknAt+Q1EPSl/mgG7WWJUityWmS+gPHN8+IiJdJ3cZnKl0o11PSloVlryady/se9XdRA/wdGCLpG5IWkbR73g/X1bNwvrDoSOUL9SStTGpZv9+dmL+4/gqcT+rhGF9tXbnc50kHJR3tYmA/ScOUfnb4U+C+iHiW1OW/tqSvKl11fTgLttrOAn4oaW0ASf0kfeinWZIWlbSXpH655+Et0ueqljtICb+5S72pYrzSa6RTM5UXIdbrXtK1AIfn9/qrpFNI7VXXfik4BzhY0sb5f6WvpO1U5aeLVbwCLCOpXx1lDyWdsrkuH6hfR/qM753/b3oq/XRyzTrWtVDboXRx43L54GxantzSZ6LTOZnbR9m+wPkR8Z+I+G/zi9RK3IvUMt6BdHHbf0it690BIuJy0rnti4EZpKTaP6/3e3m5aXk9V7cSx2mkLsKppGR4Y8X8vUnn4B4nXYBzRPOMfE7yCuDTpJZwXSJdUb49qVfgddLFdNsXTje0ZgbpQqD7lK4EHkc6d31kRbkLSC3jFg80ImJ8RLS3pdjSem8FfkzaRy+TelP2yPOmki5kPIW0D1YjnbZoXvYq0oWKl+bTH1NIpzKq2Rt4Npc7mA+uFajmDtIB3J01xiu3YRbps3ZP7t6tdo62poh4l9Q6HEW6yHF32vBZqbK+tuwX8kHcgaT/qzdJF8+NqrOux0k/Zfx33vaaV7PnXoeDSC3ov5H+Z7Yhvd8vkbrPmy88bbM2bseXgUckzQR+C+xRPLXWCFrwNIuZdTeSRgNDIqKlBGJmH2M+Z27WjeVu+QNILUMzs6rczW7WTUk6kNSleENEVO2iNTMDd7ObmZmVnlvmZmZmJedz5tYQyy67bAwaNKjRYZiZlcqECROmRsRyldOdzK0hBg0axPjxVX+WbGZmNUiqenc/d7ObmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWcn5dq7WEC9Om80Pr5zc6DDM7CPsZ19dp9EhdBm3zM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7JvBNJmlll2sGS9uniOJ6VtGwX1tckaXhX1Wdm9nHnB610sYg4qzPXL0mAImJ+B6xrkYiY2wFhmZlZJ3Iy72KSxgAzI+KXkpqA+4CRwFLAARFxl6QewCnACGAx4PcR8UdJiwN/A5YGegI/ioi/SRoE3ADcDmwK7Aw8V6Xu3sBVwBXAxcDpwDqkz8GYvK5RwHZAL6CvpAuBHYE+wKrAVRFxdF7fNsAJOcZ/AftFxId6I8zMOsJFo/dvU/l7f9e3TeWbmpraVL47cTd74y0SERsBRwDH52kHANMjYkNgQ+BASZ8G3gF2iYj1SQcAv8otcYDVgQsjYr2I+FAiBxYHrgUujohzgOOA23IdI4FfSGr+5G8K7BsRn8/jw4DdSYl/d0kr5277HwFb53jGA99vaUMlHSRpvKTxs6a/WfcOMjOzlrll3nhX5r8TgEF5eBtgXUm75fF+wGrAC8BPJW0JzAdWAlbIZZ6LiHEt1PM34NSIuKhQx46SjsrjvYCBefiWiHijsOytETEdQNKjwCqknoS1gHvy8cSiwL0tbWhEnA2cDbDi4LWjpbJmZpX2OvG8NpX/OD3P3Mm88ebkv/P44P0QcFhE3FQsmLvAlwM2iIj3JD1LSsIAb7dSzz3AVyRdHBGR69g1Ip6oqGPjKuuaUxhujlOkpL9nK/WamVknczd793QTcIikngCShuQu8H7AqzmRjyS1kOs1GngdOLNQx2HN3fSS1mtjjOOAzSQNzsv3kTSkjeswM7MO4GTeufpIeqHwavGccsG5wKPAg5KmAH8ktYYvAoZLGg/sBTzexniOAHpJOhU4iXQR3aRcx0ltWVFEvAaMAi6RNImU3NdoYzxmZtYBlHpczbrWioPXjlGnXtroMMzsI+yjeM5c0oSI+NB9PNwyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5P2jFGmKlpXp/JO/OZGbWCG6Zm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZx/Z26NMf15uPZ7jY7C7ONrh982OgLrQG6Zm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVXKvJXNI8SRMlTZF0uaQ+LZQdJemMjg2xPpJOlLR1K2XGStqtxrzTJG1ZZfoISdd1VJwLQ9IvJD0uaZKkqyQtlaevI2lsjWW69D3pTvvLzOzjop6W+eyIGBYRQ4F3gYM7OaZ2iYjREfGP9iwrqT+wSUTc2cFhVdbTYyFXcQswNCLWBZ4EfggQEZOBT0kauJDrX0AHxGtmZl2grd3sdwGDJfWXdHVuIY6TtG6xkKQlJD0jqWceX1LSs5J6SmqS9HNJ90t6UtIWuUwvSedLmizpIUkj8/RRua5r8zoPlfT9XGZcTsQLtLoljZb0QO5NOFuSWtmu3YAbC/F/ObeA7wa+WpjeV9J5ed0PSdopT+8j6S95f1wm6T5Jw/O8mbnX4D5gU0nfzNs+UdIfmxOmpG0k3SvpwdwDsnhlkBFxc0TMzaPjgE8VZl8L7NHSRkraLtexbK368vs0Om/71/L4CbncZElrtLQvzKz7GnHsFR+8Rox4/2XlV3cyl7QI8BVgMnAC8FBuIR4LXFgsGxEzgCZguzxpD+CKiHgvjy8SERsBRwDH52nfzcuuA+wJXCCpV543FPgGsBFwMjArItYD7gX2qRLuGRGxYe5N6A1s38rmbQZMyNvZCzgH2AHYAvhkodxxwG0RsSEwEviFpL7Ad4A38/44CdigsExfYEpEbAy8DuwObBYRw4B5wF6SlgV+BGwdEesD44HvtxLz/sANhfHxOd6qJO0C/ADYNk9qqb53ImLziLg0j0/N5f4AHNXKvqhJ0kGSxksa/9r02a1snpmZ1aue55n3ljQxD98F/B9wH7ArQETcJmkZSf0qljsXOBq4GtgPOLAw78r8dwIwKA9vDpye1/m4pOeAIXne7fkAYYak6aRWKKQDiwV6BbKRko4G+gD9gUcKy1SzIvBaHl4DeCYingKQ9GfgoDxvG2BHSc0JrRcwMMf+2xz7FEmTCuueB1yRh79ASvQP5M6C3sCrwCbAWsA9efqipAOVqiQdB8wFLipMfhUYUGORkcBwYJuIeEvS9q3Ud1nF8sX3q7mnota+qCkizgbOBhi+2grRUlkz63hNP931gxE/z/wjpZ5kPju3It9Xo9t6gS/niLhH0iBJWwE9ImJKYfac/HdeIYaWusLnFIbnF8bnU7ENuWV9JjA8Ip6XNIaUaFoyu6JMrUQjYNeIeKKizpZifyci5hWWvyAiflix/A7ALRGxZytxImlfUk/DFyKiGGevvB3V/Bv4DOngaHyOo6X63q4Yr/V+VdsXK7S2DWZm1rHa+9O0O4G9IF29TOqGfatKuQuBS4Dz27jOIaRW3hMtLlFdc1Kems8DV716vcJjwOA8/DjwaUmr5vFiwrsJOKw5eUtaL0+/G/h6nrYWsE6Nem4FdpO0fC7bX9IqpPPfm0kanKf3yftgAZK+DBwD7BgRsypmDwGmVC6TPUdqUV8oae1662tFrX1hZmZdrL3JfAwwPHcnnwLsW6PcRcDSpITemjOBHpImk7p5R0XEnFaW+ZCImEY65z2Z1MX/QB2LXQ+MyMu/Q+pWvz5fBPZcodxJQE9gkqQpebw59uXy/jgGmARMrxLbo6Rz1TfnsrcAK0bEa8Ao4JI8fRypu7/SGcASwC35ArqzCvNG5u2oKreg9wIuB5ass76W1NoXZmbWxbRgT20HrzxdXb5TROzdaZV0kJy4t88HA21dtgfQMyLeyS36W4EhEfFuB4dZq/7FgDuAzQtXu3drw1dbIcb/usWL782sM/mceSlJmhARwyun13POvL0Vnk66+n3b1sp2E0eSuvantWPZPsDtSj/FE3BIVyXybCDwg7IkcjMz61idlswj4rDOWndniIj7FmLZGaSrxRsiX3n/VKPqNzOzxvK92c3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzEqu035nbtaifiv7DlRmZh3ELXMzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OS8+/MrSFeevslTrj3hEaHYWYfAcdvenyjQ2g4t8zNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzEqu1WQuaZ6kiZKmSLpcUp8Wyo6SdEbHhlgfSSdK2rqVMmMl7VZj3mmStqwyfYSk6zoqzoUh6SRJk/L7cbOkAXn6OpLG1limS9+T7rS/zMw+Luppmc+OiGERMRR4Fzi4k2Nql4gYHRH/aM+ykvoDm0TEnR0cVmU9PRZyFb+IiHUjYhhwHTAaICImA5+SNHAh17+ADojXzMy6QFufmnYXsG5OfucBnwFmAQdFxKTmQpKWACYBQyLiPUlL5vHVgFuA+4CRwFLAARFxl6RewB+A4cBc4PsRcbukUcDOQA9gKPArYFFgb2AOsG1EvJFbptdFxF8ljQZ2AHoD/wS+HRHRwnbtBtxYiP/LwGnAVODBwvS+wOnAOqR9NyYi/pZ7K8YCawCPAYOA70bEeEkzgV8DXwKOlDQIODxvw33AdyJinqRtgBOAxYB/AftFxMxikBHxVmG0L1DcpmuBPYBTa22kpO2AH+V9s361+iQ9S3pvtwHOkHQKcEFepifwtYh4vNa+qFW3mVlbnP/d8+sue/uSt7dp3U1NTW2Mpvur+5y5pEWArwCTSUngoYhYFzgWuLBYNiJmAE3AdnnSHsAVEfFeHl8kIjYCjgCan1333bzsOsCewAU5wUNK4t8ANgJOBmZFxHrAvcA+VcI9IyI2zL0JvYHtW9m8zYAJeTt7AeeQktcWwCcL5Y4DbouIDUkHI7/ISe07wJt5f5wEbFBYpi8wJSI2Bl4Hdgc2y63recBekpYlJdmtI2J9YDzw/WqBSjpZ0vPAXuSWeTY+x1uVpF2AHwDb5kkt1fdORGweEZfm8am53B+Ao1rZFzVJOkjSeEnjZ705q6WiZmbWBvW0zHtLmpiH7wL+j9Si3BUgIm6TtIykfhXLnQscDVwN7AccWJh3Zf47gdSKBdic1NIjt/yeA4bkebfnA4QZkqaTWqGQDizWrRLzSElHA32A/sAjhWWqWRF4LQ+vATwTEU8BSPozcFCetw2wo6TmhNYLGJhj/22OfYqk93spSAn7ijz8BVKif0ASpAONV4FNgLWAe/L0RUkHKh8SEccBx0n6IXAoHxwMvQoMqLF9I0k9HttExFuStm+lvssqli++X19tZV/UFBFnA2cDDFhzQEs9JWb2Mbff7/eru6yfZ15fMp+dW5HvU84AFRb4co6IeyQNkrQV0CMiphRmz8l/5xViqLbOyvIA8wvj86nYhtyyPhMYHhHPSxpDSjQtmV1RplaiEbBrRDxRUWdLsb8TEfMKy18QET+sWH4H4JaI2LOVOIsuBq7ng2Tei7Qd1fybdEpkCKkVrlbqe7tivNb7VW1frFDvBpiZWcdo70/T7iR18yJpBKkb9q0q5S4ELgHqOflRXOcQUivviRaXqK45KU+VtDjpfHhrHgMG5+HHgU9LWjWPFxPeTcBhzclb0np5+t3A1/O0tUjnkau5FdhN0vK5bH9JqwDjgM0kDc7T++R9sABJqxVGd8yxNhsCTKG650gt6gslrV1vfa2otS/MzKyLtTeZjwGG5+7kU4B9a5S7CFialNBbcybQQ9JkUjfvqIiY08oyHxIR00jnvCeTuvgfqGOx64ERefl3SN3q10u6m5QIm51EughskqQpebw59uXy/jiGdLHf9CqxPUo6V31zLnsLsGJEvAaMAi7J08eRuvsrnZJ/IjiJ1M39vcK8kXk7qsot6L2Ay4El66yvJbX2hZmZdTG1fJH3Qq48/aZ7p4jYu9Mq6SA5cW+fDwbaumwPoGdEvJNb9LeSruR/t4PDrFX/YsAdwOYRMbcr6lxYA9YcEN8+79uNDsPMPgI+TufMJU2IiOGV09v607S2VHg66er3bVsr200cSeran9aOZfsAt0vqSTqXfEhXJfJsIPCDsiRyMzPrWJ2WzCPisM5ad2eIiPsWYtkZpKvFGyJfef9Uo+o3M7PG8r3ZzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSq7Tfmdu1pIBfQd8rO7aZGbWmdwyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzn/ztwa4r2XXuLl0f6duZmV04onntDoEBbglrmZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWcm1O5lLmidpoqQpkq6VtFQbl2+SNDwP/7215SU9K2nZKtNntqXeGuseLul3bSh/uKTHJF20sHUX1jlI0jfaG1Mr617ofdTG+qq+V2Zm1jkWpmU+OyKGRcRQ4A3gu+1dUURsGxHTFiKWhRIR4yPi8DYs8h1g24jYqwPDGAS8n8zbEVOHk+QH8ZiZlUBHfVnfC6wLIGkj4DSgNzAb2C8inpDUGzgfWAt4LM8nL/MsMDwipkq6GlgZ6AX8NiLObq1ySb8CRgJvAntExGuSDgQOAhYFngb2johZkr4GHA/MA6ZHxJaSRgBHRcT2krYCfptXHcCWETGjUNdZwGeAaySdB/QDZkbEL/P8KcD2ufgNwN3A54AXgZ0iYrakwcBZwHI5jq8BpwBrSpoIXAA8VIipP3BerncWcFBETJI0BhiYpw8ETouImq353Fq+FvgJcH+OYWCefURE3JPXOYB0cDFV0pO16pD0TeDwvI/vA74TEfNq1W9m1t3seuEF7Vpu0TvvaNdyTU1N7VquNQt9zlxSD+ALwDV50uOkBLgeMBr4aZ5+CDArItYFTgY2qLHK/SNiA2A4cLikZVoJoS/wYESsD9xBStQAV0bEhhHxWdLBwwF5+mjgS3n6jlXWdxTw3YgYBmxBOiB5X0QcDLwEjIyI37QS22rA7yNibWAasGueflGe/llSon8Z+AFwV+7tqFzvCcBDed8dC1xYmLcG8CVgI+B4ST2rBSJpBeB6YHREXE86YPlNRGyY4zq3UHwD0oFHc0/Bh+qQtCawO7BZ3lfzgBZ7KiQdJGm8pPGvz5rVUlEzM2uDhWmZ986tyEHABOCWPL0fcIGk1Ugt2+bksiXwO4DcqpxUY72HS9olD69MSoivtxDHfOCyPPxn4Mo8PFTST4ClgMWBm/L0e4Cxkv5SKFt0D/DrfD78yoh4oYW6W/NMREzMwxOAQZKWAFaKiKsAIuIdAEktrWdz8oFARNwmaRlJ/fK86yNiDjBH0qvACkBlzD2BW0kHKc2Hk1sDaxXqXTLHBnBNRBQPYqrV8QVS0n8gr6M38GpLG5F7Wc4G+OyAAdFSWTOzrnDFPvu2a7mP0vPMZ+cW2Sqkbtbmc+YnAbfnc+k7kLrLm7X4BZ67u7cGNs2t1ocqlq9Hcx1jgUMjYh1Sy7YXvN+y/hHpQGFiZcs/Ik4BvkVKTuMkrdFKfXNZcD8W451TGJ5HOnhqMWvXUG2Z5u2sVke1GCeQWtfNPkHaz8Pya6XC6YS3K5avtR0XFJZfPSLG1Lc5ZmbWkRa6mz0ippPOmx6Vu3j7kc4PA4wqFL2T3A0raSj5HHuFfsCb+dz2GsAmdYTwCWC3PPwN0jlqgCWAl3NM73f/Slo1Iu6LiNHAVFJSp2L+5Ij4OTCe1MXckmeB9fOy6wOfbqlwRLwFvCBp57zMYpL6ADNyzNUU990IYGpeT70C2B9YQ9IP8rSbgUObC0ga1ob1QWrp7yZp+bx8f0mrtHEdZmbWATrkd+YR8RDwMLAHcCrwM0n3AD0Kxf4ALJ67148mXYBV6UZgkVzmJGBcHdW/DawtaQLweeDEPP3HpIuybiGdx2/2C0mT84Vqd+a4i47IP7d7mHS+/IZW6r8C6J9PORwCPFlHzHuTTidMAv4JfBKYBMyV9LCk/6koPwYYnsufArS5XyhfmLYHMFLSd0gHYMMlTZL0KHBwG9f3KKmH4+Yc1y3Aim2Ny8zMFp4ifOrSut5nBwyIG791YKPDMDNrl0adM5c0ISKGV073HeDMzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOQW5hGoZu3Wc8CAbvcIQTOzsnLL3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs4/TbOGmPHGO9x+0eONDsPMusjIvdZodAgfaW6Zm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJN5O0g6TtIjkiZJmihp4zz9XElrdXLdf5e0VJXpYyQdVWX6WEm7dWZM9cRhZmadxw9aaSNJmwLbA+tHxBxJywKLAkTEtzq7/ojYtrPrAJAkQBExvyvqMzOz9nPLvO1WBKZGxByAiJgaES8BSGqSNDwPHyDpyTztHEln5OljJf1B0u2S/i1pK0nnSXpM0tjmSiTtKWmypCmSfl6Y/mw+gGjuIXhC0j+A1VsLXNJJuf5PSPpfSQ/k3oUT8vxBOY4zgQeBLfL4Obkn4mZJvXPZVSXdKGmCpLsk+ZFIZmYN4pZ5290MjJb0JPAP4LKIuKNYQNIA4MfA+sAM4Dbg4UKRpYHPAzsC1wKbAd8CHpA0DHgV+DmwAfAmcLOknSPi6kIdGwB7AOuR3scHgQm1gpZ0KtAP2A/4IrAasBEg4BpJWwL/IR0U7BcR35E0KJfbMyIOlPQXYFfgz8DZwMER8VQ+zXBm3iYz+5j4n5/sU3fZpc7pU3fZpqamdkTz8eaWeRtFxExSkj0IeA24TNKoimIbAXdExBsR8R5wecX8ayMigMnAKxExOXdnPwIMAjYEmiLitYiYC1wEbFmxji2AqyJiVkS8BVzTQtg/BpaKiG/nerfJr4dIBwFrkJI2wHMRMa6w7DMRMTEPTwAGSVoc+BxwuaSJwB9JPRYtknSQpPGSxk9/683WipuZWZ3cMm+HiJgHNAFNkiYD+wJjC0XUyirm5L/zC8PN44sAc+sNpc5yDwAbSOofEW/k+H4WEX8sFsot8bdrxAowD+hNOgicFhHD6qw/BRtxNqlFz+qfGVpv7GbWTf3mRxfWXXbkXj4T15ncMm8jSatLWq0waRjwXEWx+4GtJC0taRFS13Rb3JeXX1ZSD2BP4I6KMncCu0jqLWkJYIcW1ncjcApwfS57E7B/bmEjaSVJy9cbXO4JeEbS1/LykvTZepc3M7OO5ZZ52y0OnJ5/HjYXeJrU5f6+iHhR0k9JSfkl4FFger0VRMTLkn4I3E5qRf89Iv5WUeZBSZcBE0kHE3e1ss7LcyK/BtgWuBi4N120zkzgm6SWd732Av4g6UdAT+BSFrwuwMzMuojSKVTraJIWj4iZuWV+FXBeRFzV6Li6i9U/MzTOOumvjQ7DzLqIu9k7hqQJETG8crq72TvPmHxx2BTgGeDqhkZjZmYfWe5m7yQR4bugmZlZl3DL3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErON42xhliify/f3tHMrIO4ZW5mZlZyTuZmZmYl52RuZmZWck7mZmZmJedkbmZmVnJO5mZmZiXnn6ZZQ7z12qvccvYZjQ7DrE2+eNChjQ7BrCq3zM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczAFJ8yRNlPSIpIclfV9SKfaNpEGSpnTg+k6UtHUe3iLvk4mSVpL0146qx8zMOo6fmpbMjohhAJKWBy4G+gHHNzKoRoiI0YXRvYBfRsT5eXy3etcjqUdEzOvQ4MzMrCon8woR8aqkg4AHJI0B9gWGR8ShAJKuIyW4Jkkzgd8DWwNvAscCpwIDgSMi4hpJo4CdgR7AUOBXwKLA3sAcYFtgaeDyiFg/17EacGlEbFCMTdJg4CxgOWAe8LX8t3n+IOBPQN886dCI+KekFYHLgCVJ7/khwD+B/wOGAwGcFxG/kTQWuA5YCvg68KXcUj8OuC4ihkrqAZwCjAAWA34fEX+UNIJ0APQyMAxYqw273qzbOepXv11gfOmLF+ycampq6sJozGpzMq8iIv6du9mXb6VoX6ApIo6RdBXwE+CLpCR2AXBNLjcUWA/oBTwNHBMR60n6DbBPRJwmabqkYRExEdgPGFulvouAUyLiKkm9SKdJijG+CnwxIt7JBwSXkJL1N4CbIuLknIj7kJLtShExFEDSUhX74FxJm5MS+F/zgUKzA4DpEbGhpMWAeyTdnOdtBAyNiGcqg88HSQcBLN9/6Rq71MzM2srJvDbVUeZd4MY8PBmYExHvSZoMDCqUuz0iZgAzJE0Hri0ss24ePhfYT9L3gd1JSfGDYKQlSMn3KoCIeCdPLxbrCZwhaRipxT4kT38AOE9ST+DqiJgo6d/AZySdDlwP3Ez9tgHWldTc7d4PWC3vj/urJfIc89nA2QBDVhkYbajPrCF+eeT3Fhj/4kGHNigSs5aV4iKvribpM6Rk+CowlwX3U6/C8HsR0ZyU5pO6zYmI+Sx4oDSnMDy/MF4sdwXwFWB7YEJEvF4ZVh2h/w/wCvBZUot80RzPncCWwIvAnyTtExFv5nJNwHdJBxP1EnBYRAzLr09HRPPBwNttWI+ZmXUAJ/MKkpYjnZc+IyfqZ4Fhkj4haWUqWswdJbe0bwL+AJxfZf5bwAuSds5xLiapT0WxfsDL+WBib9J5eiStArwaEeeQzpOvL2lZ4BMRcQXwY2D9NoR7E3BIbukjaYikvq0sY2ZmncTd7ElvSRNJ3dRzSReR/TrPuwd4htQlPgV4sBPjuAj4KrW7vPcG/ijpROA90gVw8wvzzwSukPQ14HY+aCWPAP5X0nvATGAfYCXg/MJP8H7YhjjPJZ1GeFCpn/810kV+ZmbWAPqgl9gaTdJRQL+I+HGjY+lsQ1YZGL8/7uhGh2HWJj5nbo0maUJEDK+c7pZ5N5Gvhl8V+HyjYzEzs3JxMu8mImKXRsdgZmbl5AvgzMzMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs6/M7eGWHK55X03LTOzDuKWuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnCKi0THYx5CkGcATjY6jimWBqY0OogrH1XbdNTbH1TbdNS5oTGyrRMRylRN9b3ZrlCciYnijg6gkabzjql93jQu6b2yOq226a1zQvWJzN7uZmVnJOZmbmZmVnJO5NcrZjQ6gBsfVNt01Lui+sTmutumucUE3is0XwJmZmZWcW+ZmZmYl52RuZmZWck7m1mkkfVnSE5KelvSDKvMl6Xd5/iRJ63ej2NaQdK+kOZKO6kZx7ZX31SRJ/5T02W4S1045pomSxkvavDvEVSi3oaR5knbrirjqiU3SCEnT8z6bKGl0d4irENtESY9IuqM7xCXpfwv7akp+P/t3g7j6SbpW0sN5f+3X2TFVFRF++dXhL6AH8C/gM8CiwMPAWhVltgVuAARsAtzXjWJbHtgQOBk4qhvF9Tlg6Tz8la7YZ3XGtTgfXIOzLvB4d4irUO424O/Abt3ovRwBXNcV8bQxrqWAR4GBeXz57hBXRfkdgNu6Q1zAscDP8/BywBvAol35vkaEW+bWaTYCno6If0fEu8ClwE4VZXYCLoxkHLCUpBW7Q2wR8WpEPAC81wXxtCWuf0bEm3l0HPCpbhLXzMjfZkBfoCuurK3nMwZwGHAF8GoXxNTW2LpaPXF9A7gyIv4D6X+hm8RVtCdwSTeJK4AlJIl0UPsGMLcLYluAk7l1lpWA5wvjL+RpbS3TGRpVb2vaGtcBpJ6NzlZXXJJ2kfQ4cD2wf3eIS9JKwC7AWV0QT1G97+WmuXv2Bklrd5O4hgBLS2qSNEHSPt0kLgAk9QG+TDpA6w5xnQGsCbwETAa+FxHzuyC2Bfh2rtZZVGVaZWutnjKdoVH1tqbuuCSNJCXzrjg3XVdcEXEVcJWkLYGTgK27QVynAcdExLzUcOoy9cT2IOk+2zMlbQtcDazWDeJaBNgA+ALQG7hX0riIeLLBcTXbAbgnIt7oxHia1RPXl4CJwOeBVYFbJN0VEW91cmwLcMvcOssLwMqF8U+RjlzbWqYzNKre1tQVl6R1gXOBnSLi9e4SV7OIuBNYVdKy3SCu4cClkp4FdgPOlLRzJ8dVV2wR8VZEzMzDfwd6dpN99gJwY0S8HRFTgTuBzr7Qsi2fsT3omi52qC+u/UinJSIingaeAdboovg+0NUn6f36eLxIR/f/Bj7NBxeOrF1RZjsWvADu/u4SW6HsGLruArh69tlA4Gngc93svRzMBxfArQ+82DzeHd7HXH4sXXcBXD377JOFfbYR8J/usM9IXca35rJ9gCnA0EbHlcv1I52T7tuN3sc/AGPy8Ar5s79sV8RXfLmb3TpFRMyVdChwE+mK0PMi4hFJB+f5Z5GuLt6WlJxmkY5wu0Vskj4JjAeWBOZLOoJ0FWundZ3Vuc9GA8uQWpgAc6OTn9pUZ1y7AvtIeg+YDewe+dutwXE1RJ2x7QYcImkuaZ/t0R32WUQ8JulGYBIwHzg3IqY0Oq5cdBfg5oh4uzPjaWNcJwFjJU0mNUyOidSj0aV8O1czM7OS8zlzMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3s9LKt5ANSV1/kw6zbsTJ3MzKbE/gbtJdwTqFpB6dtW6zjuJkbmalJGlxYDPSPer3yNN6SPqlpMn5+eqH5ekb5ue/PyzpfklLSBol6YzC+q6TNCIPz5R0oqT7SA9DGS3pgfwc7bPzE7KQNFjSP/J6H5S0qqQ/SdqpsN6LJO3YVfvFPp6czM2srHYm3UP8SeANSesDB5FuvbleRKwLXCRpUeAy0tOsPkt6AMzsVtbdF5gSERtHxN3AGRGxYUQMJT18ZPtc7iLg93m9nwNeJt03fz8ASf3y9L931EabVeNkbmZltSfp+dLkv3uSEvVZETEXINKTtVYHXo70fHoiPeCktedNz2PBR2yOlHRfvmXn54G1JS0BrBTpaXFExDsRMSsi7gAGS1o+x3RFHfWZLRTfm93MSkfSMqSkOlRSkO6bHcAEqj9qt9p9q+eyYIOmV2H4nYiYl+vqBZwJDI+I5yWNyWVbeqbqn4C9SN3/XfFsd/uYc8vczMpoN+DCiFglIgZFxMqkR08+CBwsaREASf2Bx4EBkjbM05bI858Fhkn6hKSVSU8uq6Y5yU/N5+l3g9TCB15ofqSqpMUk9cllxwJH5HKPdNhWm9XgZG5mZbQncFXFtCuAAaRHiU6S9DDwjYh4F9gdOD1Pu4WUoO8hHQBMBn5JOhD4kIiYBpyTy10NPFCYvTdwuKRJwD9JjzUlIl4BHgPOX8jtNKuLn5pmZtbBcgt9MrB+RExvdDz20eeWuZlZB5K0Nalr/3QncusqbpmbmZmVnFvmZmZmJedkbraQJO0l6eY6yp0l6cedUL8knS/pTUn3d/T6PyryPdwH11FuhKQXOjGOGyTt28L8sZJ+shDrfzZ39SPpWEnnFubtIun5fIe79SStLukhSTMkHd7eOjtLcVsaGMOg/Nnp1j/ldjK3j7T8ZTA7f3m9kpPe4h1ZR0RcFBHb1FHu4Ig4qSPrzjYHvgh8KiJq/byqTSQdIOnx/CX/iqTr80+6fijpzirll5X0rqSh+TapIenXFWV2ztPHdkSMZRURX4mICwDyvrq7E+v6aUR8qzDpl8ChEbF4RDwEHA00RcQSEfG7zoqjGkljJP25K+v8KHMyt4+DHSJicWB9YEPgR5UFuvtRdytWAZ6NiLfbumC17Za0FfBTYM+IWAJYE/hLnv0n4HOSPl2x2B7A5IiYksf/Bexesf59gCfbGqN1qFWAR1oYr1tZ/mfKEufCcjK3j42IeBG4ARgK73e7flfSU8BTedr2kiZKmqb0YI51m5eXtLKkKyW9Jul15Yd0FFtXucv7N5JelTRd6WEfzfUt0H0q6UBJT0t6Q9I1kgYU5oWkgyU9lbvPfy/pQ3cck3QA6V7gm+behxPqXPcC211hQ+De3HIjIt6IiAsiYkZEvADcRvp9ddE+wAWF8f+Sfpr1pVxnf9I9yq+p8fa8370t6ei8/17OrfltJT2Zt+XYQvnFJJ0m6aX8Ok3SYoX5/5vX8ZKk/SvqWkzpgSz/yT0PZ0nqXSOuYyS9mHspnpD0hSplPp0/M5/I4+dKerUw/8+SjsjDTZK+JWlN4Cw+eO+mFVa5dO4NmaF0G9lVW9hve0t6Ln8mj6uYNybXvZikmaQ75T0s6V+SbgNGAmfk+oe0tF8K788xkv4LnK90w50f5PW9Lukv+b0udk/vm9c3tTk+SV8GjiUd8M1U+v1/iyStIekZSc0P1Wnpf/XZHOck4G2lB+JUjSWXr7kdVeIYJenf+b15RtJercXeJSLCL78+si/SXb62zsMrk1ohJ+XxIN1ApD/p4RnrA68CG5O+9PbNyy+Wxx8GfkN6CEcvYPO8nlHA3Xn4S6Rbii5Fut3nmsCKed5Y4Cd5+PPA1FznYsDpwJ2FuAO4Lq9nIPAa8OUa2/h+/W1Y9/vbXWV9W5AeRHIC6alki1XM3wt4qjC+OvAusFwxHuAbwGV52neAPwI/AcbW2I4RpFusjgZ6Agfm7b4YWAJYG3gH+EwufyIwDlgeWI5005bm9/bLwCukA7e+eR0BDM7zTyMdWPTP674W+FkhjhcK2/Y8MCCPDwJWrRH/f4AN8vATwL+BNQvz1svDTcC3qr13hc/JG6Q70i1CepjLpTXqXAuYCWyZ3+tf533Y/JkfA/y54r0fXBh/P5Y698tc4Oe5rt6ku9yNAz6Vp/0RuKSwr4J0w53ewGeBOYV9skBsLf3/kj7L/wG2z9Nr/q8WlptI+p/vXUcs9WzHIqTP0lvA6nneisDajf6eiwgnc78+2q/8Tz0TmAY8R7rHdu88L4DPF8r+gZwMCtOeALYCNiUllkWq1DGKD5L550ldyZsAn6goN5YPkvn/AacW5i0OvAcMKsS2eWH+X4Af1NjG9+tvw7o/X21dhWW+Qvoin5b336+BHnlen/yF9rk8fjLwt8p48pfmK0C//EW5Ga0n89mFepbIsW5cKDMB2DkP/wvYtjDvS6TTDQDnAacU5g3J6xpMOsh6m0JSzu/vM4U4mpP5YFLS2Bro2co++xPwfdJd4J4ATgUOJj3FbVrz54H6kvm5hfFtgcdr1DmaQqInJZt3aUcyr3O/vAv0Ksx/DPhCYXxF0mdtET5Igp8qzL8f2KNabC38/54AvACMrOd/tbDc/oV5rcVSz3Y0J/NpwK5UORBu5Mvd7PZxsHNELBXpPt7fiYji4y+fLwyvAhyZu+2m5W7PlUm3CF0ZeC5aefpVRNwGnAH8HnhF6dnXS1YpOoB0cNG83EzgdWClQpn/FoZnkZJyPepZ9/OVCxVFxA0RsQOphbYTKel8K8+bBVwO7CNJpJb6BVXWMRu4nnSNwrIRcU8dsb8e+QEnfPCY0lcK82fzwX5YYDvz8IDCvOcr5jVbjnRAMqHwPt+Yp1duw9OkVtsY4FVJl6pwyqLCHaSEtyVwJylRbpVfd0XE/BrLVVPve7/Adka6buL1NtRTVM9+eS0i3imMrwJcVSj/GOmJcysUyrT3c9zsYOCfEXF7Rb21/lebVfuM14qlnu1o3r+755hezqdC1mjj9nQKJ3P7uIvC8PPAyTnxN7/6RMQled5A1XExTUT8LiI2IHULDwH+t0qxl0hfIABI6gssA7y4ENvSlnVH5ULVRMT8iLiVdJ58aGHWBcDXSVfRL0E6JVDNhcCRpFZrR1tgO0mnI17Kwy+TvtyL85pNJR0UrF14n/tFukjyQyLi4ojYPNcVpG7mau4gnaIYkYfvJvVGbJXHq66+xvR6LbCdSreRXaad66pnv1TG+zzwlYr/mV6Rrk9pTb3bfjDpf+83FfXW+l9t6/qb11fXdkTETRHxRVLr/XFS133DOZmbfeAc0hO3NlbSV9J2Ss+tvp/0xXlKnt5L0maVK5C0YV6+J6nL8h3SEX6li4H9JA1Tumjrp8B9EfFsB2zHQq1b0k6S9pC0dN4PG5ES0rhCsbtI3Y1nk7p5362xujtICf/09m1Kiy4BfiRpOUnLkrqcm3/q9BdglKS1coI7vnmh3EI+B/iN0jPHkbSSpC9VVqD0O+zP5/34DinZVXs/iYin8vxvkq5ReIvUq7ArtZP5K8CnJC3axm1v9ldge0mb53WcSDu/19uyXwrOAk6WtEouv5ykneqs8hVgkPJFgy2YQboGYktJp+RpLf2vtkdd2yFpBUk75gPkOaRTUFU/D13Nydwsi4jxpIuuzgDeBJ4mdS+Tu353IJ1D/Q/pHN7uVVazJOmL5k1S1+7rpN/2VtZ1K/Bj0pO+XgZWJf28qyO2Y2HX/SZpPzxFOjf+Z+AXEXFRoY4gtbpXyX9rxRIRcWtEvNHW7ajDT4DxwCTSlfMP5mlExA2ki7luI72Pt1Use0yePk7SW8A/SBe7VVoMOIXUav0v6WK7Y6uUa3YH6VTBfwrjAh6qUf420kWZ/5U0tYX1VhXp8arfJR3AvUx67xbmhjf17pdmvyVdMHezpBmkA76N66zr8vz3dUlVn1jXLNKT674IfEXSSS39r7ZTvdvxCVJP00ukixS3Il3c2XC+N7uZmVnJuWVuZmZWck7mZmZmJedkbmZmVnJO5mZmZiX3sbgBvXU/yy67bAwaNKjRYZiZlcqECROmRsSHbnDkZG4NMWjQIMaPH9/oMMzMSkXSc9Wmu5vdzMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOR8BzhriBenzeaHV05udBhmZu/72VfXaXQI7eaWuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZdyJJM6tMO1jSPl0cx7OSlu3C+pokDe+q+szMPu78oJUuFhFndeb6JQlQRMzvgHUtEhFzOyAsMzPrRE7mXUzSGGBmRPxSUhNwHzASWAo4ICLuktQDOAUYASwG/D4i/ihpceBvwNJAT+BHEfE3SYOAG4DbgU2BnYHnqtTdG7gKuAK4GDgdWIf0ORiT1zUK2A7oBfSVdCGwI9AHWBW4KiKOzuvbBjghx/gvYL+I+FBvhJlZV7to9P5tXube3/VtV11NTU3tWq4juZu98RaJiI2AI4Dj87QDgOkRsSGwIXCgpE8D7wC7RMT6pAOAX+WWOMDqwIURsV5EfCiRA4sD1wIXR8Q5wHHAbbmOkcAvJDV/kjcF9o2Iz+fxYcDupMS/u6SVc7f9j4Ctczzjge+3tKGSDpI0XtL4WdPfrHsHmZlZy9wyb7wr898JwKA8vA2wrqTd8ng/YDXgBeCnkrYE5gMrASvkMs9FxLgW6vkbcGpEXFSoY0dJR+XxXsDAPHxLRLxRWPbWiJgOIOlRYBVST8JawD35eGJR4N6WNjQizgbOBlhx8NrRUlkzs4Wx14nntXmZMj/P3Mm88ebkv/P44P0QcFhE3FQsmLvAlwM2iIj3JD1LSsIAb7dSzz3AVyRdHBGR69g1Ip6oqGPjKuuaUxhujlOkpL9nK/WamVknczd793QTcIikngCShuQu8H7AqzmRjyS1kOs1GngdOLNQx2HN3fSS1mtjjOOAzSQNzsv3kTSkjeswM7MO4GTeufpIeqHwavGccsG5wKPAg5KmAH8ktYYvAoZLGg/sBTzexniOAHpJOhU4iXQR3aRcx0ltWVFEvAaMAi6RNImU3NdoYzxmZtYBlHpczbrWioPXjlGnXtroMMzM3leGc+aSJkTEh+7j4Za5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWcn5QSvWECst1bsUd1syMysDt8zNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzr8zt8aY/jxc+71GR2FmnWGH3zY6go8dt8zNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzEqu1WQuaZ6kiZKmSLpcUp8Wyo6SdEbHhlgfSSdK2rqVMmMl7VZj3mmStqwyfYSk6zoqzoUh6ReSHpc0SdJVkpbK09eRNLbGMl36nnSn/WVm9nFRT8t8dkQMi4ihwLvAwZ0cU7tExOiI+Ed7lpXUH9gkIu7s4LAq6+mxkKu4BRgaEesCTwI/BIiIycCnJA1cyPUvoAPiNTOzLtDWp6bdBaybk995wGeAWcBBETGpuZCkJYBJwJCIeE/Sknl8NVJCug8YCSwFHBARd0nqBfwBGA7MBb4fEbdLGgXsDPQAhgK/AhYF9gbmANtGxBu5ZXpdRPxV0mhgB6A38E/g2xERLWzXbsCNhfi/DJwGTAUeLEzvC5wOrEPad2Mi4m+5t2IssAbwGDAI+G5EjJc0E/g18CXgSEmDgMPzNtwHfCci5knaBjgBWAz4F7BfRMwsBhkRNxdGx+W4m10L7AGcWmsjJW0H/Cjvm/Wr1SfpWdJ7uw1whqRTgAvyMj2Br0XE47X2Ra26zeyjY8SxV7Rc4FcPtzi7qamp44IxoA3nzCUtAnwFmExKAg/lFuKxwIXFshExA2gCtsuT9gCuiIj38vgiEbERcARwfJ723bzsOsCewAU5wUNK4t8ANgJOBmZFxHrAvcA+VcI9IyI2zL0JvYHtW9m8zYAJeTt7AeeQktcWwCcL5Y4DbouIDUkHI7/ISe07wJt5f5wEbFBYpi8wJSI2Bl4Hdgc2i4hhwDxgL0nLkpLs1hGxPjAe+H4rMe8P3FAYH5/jrUrSLsAPgG3zpJbqeyciNo+IS/P41FzuD8BRreyLmiQdJGm8pPGvTZ/dyuaZmVm96mmZ95Y0MQ/fBfwfqUW5K0BE3CZpGUn9KpY7FzgauBrYDziwMO/K/HcCqRULsDmppUdu+T0HDMnzbs8HCDMkTSe1QiEdWKxbJeaRko4G+gD9gUcKy1SzIvBaHl4DeCYingKQ9GfgoDxvG2BHSc0JrRcwMMf+2xz7FEnv91KQEnbzYewXSIn+AUmQDjReBTYB1gLuydMXJR2oVCXpOFLvxUWFya8CA2osMpLU47FNRLwlaftW6rusYvni+/XVPFxrX9QUEWcDZwMMX22FlnpKzKwba/rpri0X8PPMu1w9yXx2bkW+TzkDVFjgyzki7pE0SNJWQI+ImFKYPSf/nVeIodo6K8sDzC+Mz6diG3LL+kxgeEQ8L2kMKdG0ZHZFmVqJRsCuEfFERZ0txf5ORMwrLH9BRPywYvkdgFsiYs9W4kTSvqSehi9UnDrolbejmn+TTokMIbXC1Up9b1eM13q/qu2LFVrbBjMz61jt/WnancBekK5eJnXDvlWl3IXAJcD5bVznEFIr74kWl6iuOSlPlbQ4C55XruUxYHAefhz4tKRV83gx4d0EHNacvCWtl6ffDXw9T1uLdB65mluB3SQtn8v2l7QK6fz3ZpIG5+l98j5YQD6XfwywY0TMqpg9BJhSuUz2HKlFfaGkteutrxW19oWZmXWx9ibzMcDw3J18CrBvjXIXAUuTEnprzgR6SJpM6uYdFRFzWlnmQyJiGumc92RSF/8DdSx2PTAiL/8OqVv9ekl3kxJhs5NIF4FNkjQljzfHvlzeH8eQLvabXiW2R0nnqm/OZW8BVoyI14BRwCV5+jhSd3+lM4AlgFvyzwXPKswbmbejqtyC3gu4HFiyzvpaUmtfmJlZF1PLF3kv5MrTb7p3ioi9O62SDpIT9/b5YKCty/YAekbEO7lFfyvpSv53OzjMWvUvBtwBbB4Rc7uizoU1fLUVYvyv92h0GGbWGXzOvNNImhARwyunt/WnaW2p8HTS1e/btla2mziS1LU/rR3L9gFul9STdC75kK5K5NlA4AdlSeRmZtaxOi2ZR8RhnbXuzhAR9y3EsjNIV4s3RL7y/qlG1W9mZo3le7ObmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyXXaTWPMWtRvZd/y0cysg7hlbmZmVnJO5mZmZiXnZG5mZlZyTuZmZmYl52RuZmZWck7mZmZmJeefpllDvPT2S5xw7wmNDsPM7EOO3/T4RofQZm6Zm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVXKvJXNI8SRMlTZF0uaQ+LZQdJemMjg2xPpJOlLR1K2XGStqtxrzTJG1ZZfoISdd1VJwLQ9JJkibl9+NmSQPy9HUkja2xTJe+J91pf5mZfVzU0zKfHRHDImIo8C5wcCfH1C4RMToi/tGeZSX1BzaJiDs7OKzKenos5Cp+ERHrRsQw4DpgNEBETAY+JWngQq5/AR0Qr5mZdYG2drPfBQyW1F/S1bmVOE7SusVCkpaQ9Iyknnl8SUnPSuopqUnSzyXdL+lJSVvkMr0knS9psqSHJI3M00fluq7N6zxU0vdzmXE5ES/Q6pY0WtIDuTfhbElqZbt2A24sxP9lSY9Luhv4amF6X0nn5XU/JGmnPL2PpL/k/XGZpPskDc/zZuZeg/uATSV9M2/7REl/bE6YkraRdK+kB3MPyOKVQUbEW4XRvkAUxq8F9mhpIyVtl+tYtlZ9+X0anbf9a3n8hFxusqQ1WtoXZmbW9ep+BKqkRYCvkJLeCcBDEbGzpM8DFwLDmstGxAxJTcB2wNWkJHNFRLyX8+oiEbGRpG2B44Gtge/mZdfJCeNmSUPyKocC6wG9gKeBYyJiPUm/AfYBTqsI94yIODHH/Sdge1Kyq2Uz4K+5fC/gHODzua7LCuWOA26LiP0lLQXcL+kfwCHAmxGxrqShwMTCMn2BKRExWtKawDHAZnlfnAnsJenvwI+ArSPibUnHAN8HTqwMVNLJeZunAyMLs8YDPwBOrbaBknbJ69wW6NFKfe9ExOZ5uVOAqRGxvqTvAEcB32phX5iZdbrzv3t+p6379iVv77R1NzU1dcp662mZ95Y0kZQs/gP8H7A58CeAiLgNWEZSv4rlzgX2y8P7AcU9f2X+OwEYlIeL63wceA5oTua3R8SMiHiNlMSaE/PkwvJFI3PreDIpKa/dyjauCLyWh9cAnomIpyIigD8Xym0D/CDvjybSwcXAHPulOfYpwKTCMvOAK/LwF4ANgAfyOr4AfAbYBFgLuCdP3xdYpVqgEXFcRKwMXAQcWpj1KjCgxvaNJB1EbBcRb9ZR32UVy1d7v2rti5okHSRpvKTxs96c1VJRMzNrg3pa5rPzOdr31ei2jgVGIu6RNEjSVkCPnOSazcl/5xViaKkrfE5heH5hfD4V25Bb1mcCwyPieUljSImmJbMrykSNcgJ2jYgnKupsKfZ3ImJeYfkLIuKHFcvvANwSEXu2EmfRxcD1pJ4NSPHPrlH236SDhiGkgzK1Ut/bFeO13q9q+2KFWgFHxNnA2QAD1hxQax+bmbVqv9/v13qhdjp+0+NbL9TNtPenaXcCe0G6epnUDftWlXIXApewYKu8nnUOIbXynmhxieqak/LUfB646tXrFR4DBufhx4FPS1o1jxcT3k3AYc3JW9J6efrdwNfztLWAdWrUcyuwm6Tlc9n+klYBxgGbSRqcp/cpnGJ4n6TVCqM75libDQGmUN1zpHP/F0pau976WlFrX5iZWRdrbzIfAwyXNAk4hdRNW81FwNKkhN6aM4EeuWv8MmBURMxpZZkPiYhppHPek0nn6x+oY7HrgRF5+XeAg4Dr80VgzxXKnQT0BCZJmpLHm2NfLu+PY0jd7NOrxPYo6Vz1zbnsLcCK+fTBKOCSPH0cqbu/0ilKF/VNInVzf68wb2TejqpyC3ov4HJgyTrra0mtfWFmZl1M6bRwJ608XV2+U0Ts3WmVdJCcuLfPBwNtXbYH0DMi3skt+luBIRHxbgeHWav+xYA7gM0jYm5X1LmwBqw5IL593rcbHYaZ2Yd05252SRMiYnjl9LqvZm9HhaeTrn7ftrPq6GBHkrr2p7Vj2T7A7Uo/xRNwSFcl8mwg8IOyJHIzM+tYnZbMI+Kwzlp3Z4iI+xZi2RnAh46UukpEPAU81aj6zcyssXxvdjMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMyu5TrtpjFlLBvQd0K1vmWhmViZumZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWcf2duDfHeSy/x8mj/ztzMymfFE09odAgf4pa5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJtTuZS5onaaKkKZKulbRUG5dvkjQ8D/+9teUlPStp2SrTZ7al3hrrHi7pd20of7ikxyRdtLB1F9Y5SNI32htTK+te6H3UxvqqvldmZtY5FqZlPjsihkXEUOAN4LvtXVFEbBsR0xYiloUSEeMj4vA2LPIdYNuI2KsDwxgEvJ/M2xFTh5PkB/GYmZVAR31Z3wusCyBpI+A0oDcwG9gvIp6Q1Bs4H1gLeCzPJy/zLDA8IqZKuhpYGegF/DYizm6tckm/AkYCbwJ7RMRrkg4EDgIWBZ4G9o6IWZK+BhwPzAOmR8SWkkYAR0XE9pK2An6bVx3AlhExo1DXWcBngGsknQf0A2ZGxC/z/CnA9rn4DcDdwOeAF4GdImK2pMHAWcByOY6vAacAa0qaCFwAPFSIqT9wXq53FnBQREySNAYYmKcPBE6LiJqt+dxavhb4CXB/jmFgnn1ERNyT1zmAdHAxVdKTteqQ9E3g8LyP7wO+ExHzatVvZtbd7HrhBW1eZtE772hXXU1NTe1arh4Lfc5cUg/gC8A1edLjpAS4HjAa+GmefggwKyLWBU4GNqixyv0jYgNgOHC4pGVaCaEv8GBErA/cQUrUAFdGxIYR8VnSwcMBefpo4Et5+o5V1ncU8N2IGAZsQTogeV9EHAy8BIyMiN+0EttqwO8jYm1gGrBrnn5Rnv5ZUqJ/GfgBcFfu7ahc7wnAQ3nfHQtcWJi3BvAlYCPgeEk9qwUiaQXgemB0RFxPOmD5TURsmOM6t1B8A9KBR3NPwYfqkLQmsDuwWd5X84AWeyokHSRpvKTxr8+a1VJRMzNrg4VpmffOrchBwATgljy9H3CBpNVILdvm5LIl8DuA3KqcVGO9h0vaJQ+vTEqIr7cQx3zgsjz8Z+DKPDxU0k+ApYDFgZvy9HuAsZL+UihbdA/w63w+/MqIeKGFulvzTERMzMMTgEGSlgBWioirACLiHQBJLa1nc/KBQETcJmkZSf3yvOsjYg4wR9KrwApAZcw9gVtJBynNh5RbA2sV6l0yxwZwTUQUD2Kq1fEFUtJ/IK+jN/BqSxuRe1nOBvjsgAHRUlkzs65wxT77tnmZj9rzzGfnFtkqpG7W5nPmJwG353PpO5C6y5u1+AWeu7u3BjbNrdaHKpavR3MdY4FDI2IdUsu2F7zfsv4R6UBhYmXLPyJOAb5FSk7jJK3RSn1zWXA/FuOdUxieRzp4ajFr11BtmebtrFZHtRgnkFrXzT5B2s/D8mulwumEtyuWr7UdFxSWXz0ixtS3OWZm1pEWups9IqaTzpselbt4+5HODwOMKhS9k9wNK2ko+Rx7hX7Am/nc9hrAJnWE8Algtzz8DdI5aoAlgJdzTO93/0paNSLui4jRwFRSUqdi/uSI+DkwntTF3JJngfXzsusDn26pcES8Bbwgaee8zGKS+gAzcszVFPfdCGBqXk+9AtgfWEPSD/K0m4FDmwtIGtaG9UFq6e8mafm8fH9Jq7RxHWZm1gE65HfmEfEQ8DCwB3Aq8DNJ9wA9CsX+ACyeu9ePJl2AVelGYJFc5iRgXB3Vvw2sLWkC8HngxDz9x6SLsm4hncdv9gtJk/OFanfmuIuOyD+3e5h0vvyGVuq/AuifTzkcAjxZR8x7k04nTAL+CXwSmATMlfSwpP+pKD8GGJ7LnwK0uV8oX5i2BzBS0ndIB2DDJU2S9ChwcBvX9yiph+PmHNctwIptjcvMzBaeInzq0rreZwcMiBu/dWCjwzAza7NGnjOXNCEihldO9x3gzMzMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzEquo55nbtYmPQcM6JZPHjIzKyO3zM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOvzO3hpjxxjvcftHjjQ7DzLqRkXut0egQSsstczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMybwdJx0l6RNIkSRMlbZynnytprU6u+++SlqoyfYyko6pMHytpt86MqZ44zMys8/hBK20kaVNge2D9iJgjaVlgUYCI+FZn1x8R23Z2HQCSBCgi5ndFfWZm1n5O5m23IjA1IuYARMTU5hmSmoCjImK8pAOAY4CXgKeAORFxqKSxwGxgDWAVYD9gX2BT4L6IGJXXtSdwLCDg+og4Jk9/FhgeEVMlHQfsAzwPvAZMaClwSScBKwP7A0cCXwcWA66KiOMlDQJuAG7P8Rwh6SzgbuBzwIvAThExW9KqwO+B5YBZwIER4cegmVlN//OTfVqcv9Q5fVpdR1NTUwdF89Hibva2uxlYWdKTks6UtFVlAUkDgB8DmwBfJCXuoqWBzwP/A1wL/AZYG1hH0rC8/M9zmWHAhpJ2rqhjA2APYD3gq8CGLQUt6VRgedLBw9bAasBGef0bSNoyF10duDAi1gOey+V+HxFrA9OAXXO5s4HDImID4CjgzJbqzzEcJGm8pPHT33qzteJmZlYnt8zbKCJm5kS6BTASuEzSDyJibKHYRsAdEfEGgKTLgSGF+ddGREiaDLwSEZNzuUeAQaQWe1NEvJanXwRsCVxdWMcWpBb1rFzmmhbC/jGp1X9QLrsNsA3wUJ6/OClp/wd4LiLGFZZ9JiIm5uEJwCBJi5Na6pen3nggtfBbFBFnkw4CWP0zQ6O18mb20fKbH13Y4nw/z7z9nMzbISLmAU1AU07I+wJjC0VUZbGiOfnv/MJw8/giwNx6Q6mz3AOk1nf/fIAh4GcR8cdiodzN/naNWAHmAb1JPTrTImJYnfWbmVkncjd7G0laXdJqhUnDSN3RRfcDW0laWtIifNA1Xa/78vLLSuoB7AncUVHmTmAXSb0lLQHs0ML6bgROAa7PZW8C9s8tbCStJGn5eoOLiLeAZyR9LS8vSZ+td3kzM+tYbpm33eLA6fnnYXOBp4GDigUi4kVJPyUl5ZeAR4Hp9VYQES9L+iHpQjQBf4+Iv1WUeVDSZcBE0sHEXa2s8/KcyK8BtgUuBu7N3eQzgW+SWt712gv4g6QfAT2BS4GH27C8mZl1EEX41GVnkLR4Pr++CHAVcF5EXNXouLqL1T8zNM466a+NDsPMuhGfM2+dpAkRMbxyurvZO88YSROBKcAzLHjxmpmZWYdxN3sniQjfBc3MzLqEW+ZmZmYl52RuZmZWck7mZmZmJedkbmZmVnJO5mZmZiXnZG5mZlZyTuZmZmYl59+ZW0Ms0b+X7/ZkZtZB3DI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOf/O3Brirdde5Zazz2h0GGYL7YsHHdroEMzcMjczMys7J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknc0DSPEkTJT0i6WFJ35dUin0jaZCkKR24vhMlbZ2Ht8j7ZKKklST9taPqMTOzjuMHrSSzI2IYgKTlgYuBfsDxjQyqESJidGF0L+CXEXF+Ht+t3vVI6hER8zo0ODMzq8rJvEJEvCrpIOABSWOAfYHhEXEogKTrSAmuSdJM4PfA1sCbwLHAqcBA4IiIuEbSKGBnoAcwFPgVsCiwNzAH2BZYGrg8ItbPdawGXBoRGxRjkzQYOAtYDpgHfC3/bZ4/CPgT0DdPOjQi/ilpReAyYEnSe34I8E/g/4DhQADnRcRvJI0FrgOWAr4OfCm31I8DrouIoZJ6AKcAI4DFgN9HxB8ljSAdAL0MDAPWasOuNyuFo3712wXGl754wQ6rpqamLozGLHEyryIi/p272ZdvpWhfoCkijpF0FfAT4IukJHYBcE0uNxRYD+gFPA0cExHrSfoNsE9EnCZpuqRhETER2A8YW6W+i4BTIuIqSb1Ip0mKMb4KfDEi3skHBJeQkvU3gJsi4uSciPuQku1KETEUQNJSFfvgXEmbkxL4X/OBQrMDgOkRsaGkxYB7JN2c520EDI2IZyqDzwdJBwEs33/pGrvUzMzaysm8NtVR5l3gxjw8GZgTEe9JmgwMKpS7PSJmADMkTQeuLSyzbh4+F9hP0veB3UlJ8YNgpCVIyfcqgIh4J08vFusJnCFpGKnFPiRPfwA4T1JP4OqImCjp38BnJJ0OXA/cTP22AdaV1Nzt3g9YLe+P+6sl8hzz2cDZAENWGRhtqM+s2/jlkd9bYNzPM7fuoBQXeXU1SZ8hJcNXgbksuJ96FYbfi4jmpDSf1G1ORMxnwQOlOYXh+YXxYrkrgK8A2wMTIuL1yrDqCP1/gFeAz5Ja5IvmeO4EtgReBP4kaZ+IeDOXawK+SzqYqJeAwyJiWH59OiKaDwbebsN6zMysAziZV5C0HOm89Bk5UT8LDJP0CUkrU9Fi7ii5pX0T8Afg/Crz3wJekLRzjnMxSX0qivUDXs4HE3uTztMjaRXg1Yg4h3SefH1JywKfiIgrgB8D67ch3JuAQ3JLH0lDJPVtZRkzM+sk7mZPekuaSOqmnku6iOzXed49wDOkLvEpwIOdGMdFwFep3eW9N/BHSScC75EugJtfmH8mcIWkrwG380EreQTwv5LeA2YC+wArAecXfoL3wzbEeS7pNMKDSv38r5Eu8jMzswbQB73E1miSjgL6RcSPGx1LZxuyysD4/XFHNzoMs4Xmc+bWlSRNiIjhldPdMu8m8tXwqwKfb3QsZmZWLk7m3URE7NLoGMzMrJx8AZyZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJ+Xfm1hBLLre875xlZtZB3DI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5RUSjY7CPIUkzgCcaHUcNywJTGx1EC7pzfN05Nuje8Tm29uvO8XV0bKtExHKVE/2gFWuUJyJieKODqEbS+O4aG3Tv+LpzbNC943Ns7ded4+uq2NzNbmZmVnJO5mZmZiXnZG6NcnajA2hBd44Nund83Tk26N7xObb2687xdUlsvgDOzMys5NwyNzMzKzknc+s0kr4s6QlJT0v6QZX5kvS7PH+SpPW7WXxrSLpX0hxJR3Wz2PbK+2ySpH9K+mw3i2+nHNtESeMlbd5dYiuU21DSPEm7dVVs9cQnaYSk6XnfTZQ0urvEVohvoqRHJN3RXWKT9L+FfTYlv7f9u1F8/SRdK+nhvO/269AAIsIvvzr8BfQA/gV8BlgUeBhYq6LMtsANgIBNgPu6WXzLAxsCJwNHdbPYPgcsnYe/0g333eJ8cBpvXeDx7hJbodxtwN+B3brZvhsBXNdVMbUxtqWAR4GBeXz57hJbRfkdgNu62b47Fvh5Hl4OeANYtKNicMvcOstGwNMR8e+IeBe4FNiposxOwIWRjAOWkrRid4kvIl6NiAeA97ooprbE9s+IeDOPjgM+1c3imxn5WwvoC3TVxTn1fO4ADgOuAF7toria1RtfI9QT2zeAKyPiP5D+R7pRbEV7Apd0SWRJPfEFsIQkkQ523wDmdlQATubWWVYCni+Mv5CntbVMZ2lk3a1pa2wHkHo4ukpd8UnaRdLjwPXA/t0lNkkrAbsAZ3VRTEX1vreb5u7YGySt3TWh1RXbEGBpSU2SJkjapxvFBoCkPsCXSQdrXaWe+M4A1gReAiYD34uI+R0VgO8AZ51FVaZVts7qKdNZGll3a+qOTdJIUjLvsnPS1BlfRFwFXCVpS+AkYOvODoz6YjsNOCYi5qVGUpeqJ74HSbfsnClpW+BqYLXODoz6YlsE2AD4AtAbuFfSuIh4shvE1mwH4J6IeKMT46lUT3xfAiYCnwdWBW6RdFdEvNURAbhlbp3lBWDlwvinSEekbS3TWRpZd2vqik3SusC5wE4R8XoXxQZt3HcRcSewqqRlOzsw6ottOHCppGeB3YAzJe3cBbFBHfFFxFsRMTMP/x3o2Y323QvAjRHxdkRMBe4EuuLiy7Z85vaga7vYob749iOdooiIeBp4BlijwyLoqgsE/Pp4vUhH8P8GPs0HF4SsXVFmOxa8AO7+7hRfoewYuvYCuHr23UDgaeBz3fS9HcwHF8CtD7zYPN7o2CrKj6VrL4CrZ999srDvNgL+0132Hamb+NZctg8wBRjaHWLL5fqRzkX37ar3tA377g/AmDy8Qv6fWLajYnA3u3WKiJgr6VDgJtKVnudFxCOSDs7zzyJdSbwtKSnNIh25dpv4JH0SGA8sCcyXdATpCtUO6RZbmNiA0cAypFYlwNzoogdN1BnfrsA+kt4DZgO7R/4W6waxNUyd8e0GHCJpLmnf7dFd9l1EPCbpRmASMB84NyKmdIfYctFdgJsj4u3Ojqkd8Z0EjJU0mdSAOSZS70aH8B3gzMzMSs7nzM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MxKKz8Zq/kpWZfnW3ku7DpPlFTzbnWSDu7C25ia1cU/TTOz0pI0MyIWz8MXARMi4teF+T0iYl7DAjTrIm6Zm9lHxV3A4Py87dslXQxMltRD0i8kPZCfsf7t5gUkHS1pcn6oySl52tjmZ5xLOkXSo3m5X+ZpY5Sfby9pmKRxef5VkpbO05sk/VzS/ZKelLRFV+8M+3jxHeDMrPQkLUJ6rvuNedJGpNuMPiPpIGB6RGwoaTHgHkk3k+6LvTOwcUTMktS/Yp39SXcUWyMiQtJSVaq+EDgsIu6QdCJwPHBEnrdIRGyUH5ZyPF3zoBn7mHLL3MzKrLekiaTb7v4H+L88/f6IeCYPb0O6texE4D7SbXBXIyXX8yNiFkB8+ClbbwHvAOdK+irplsPvk9QPWCoi7siTLgC2LBS5Mv+dAAxq/yaatc4tczMrs9kRMaw4Id+rvnhvbpFazzdVlPsyLTz2Nt9veyPS4z73AA4lPb6yXnPy33n4u9Y6mVvmZvZRdxPpwSU9ASQNkdQXuBnYv/kK+Crd7IsD/SI9hvQIYFhxfkRMB94snA/fG7gDswbw0aKZfdSdS+rmflCp2f4asHNE3ChpGDBe0rukp/gdW1huCeBvknqRWvf/U2Xd+wJn5QOCf9OFT/4zK/JP08zMzErO3exmZmYl52RuZmZWck7mZmZmJedkbtYA+Q5h38rDoyTd3ULZXSQ9L2mmpPW6LsryyHdt+0mdZZ9t6d7rCxnHXvmGNLXmj5D0wkKsf4ykP+fhgfkz0SOPryDpTkkzJP1KyfmS3pR0f3vr7CzFbWlwHO//L5aZk7l97OUv99n5i/G/OTEs3ui4Cn4JHBoRi0fEQwu7MklrS7o5f8lPkzRB0raSVpI0V9KqVZa5qnA705D0Sr7rWvP8RSS9KuljfUVtRFwUEds0j+d9NbiT6vpP/kw033v+IGAqsGREHAlsDnwR+FREbNQZMdQiaVDedv9iqos4mZslO+QHdgwD1gN+2NhwFrAK8Eh7FmxutVW4FrgFWAFYHjgceCsiXgRuJf1euriO/sC2pDucNZtGun1qs22BN9sTo3WYVYBH44OfKK0CPBsRb7ewTFVlSsJlirUzOZmbFUTEf0k3GRnWPE3SJpL+mVuxD0saUZjXP3dlvpRbulfn6UtLuk7Sa3n6dZI+1ZZYJC0maSbQA3hY0r/y9DVz1+A0SY9I2rGwzFhJf5D0d0lvAyMr1rks8GngnIh4N7/uiYjmbv4LqEjmpLufPRIRkwvT/gQUHwO6D+k+5S1tz7OS/lfpoSRvS/q/3DV8Q+4a/ofyg0py+R3z9k3L27tmYd56kh7My10G9Kqoa3ulR6NOy+/dujVi2kjSeElv5d6GX9cod4ekXfPw5rnVuW0e31rpVrELnDKRdGde/OHc67N7YX1H5p6MlyXV/G26pE/numdIugVYtjDv/davpLGk37wfnev6Nun39Zvm8RNa2y/5/TlG0iTg7bzelj77TZJOknRPju/m/PkCaN72abn+TWttY15XT0mXSLpC0qKSBuTh1yQ9I+nwQtkxkv4q6c+S3gJGtRJLi//DFXEMzvt7uqSp+bNVDhHhl18f6xfwLLB1Hv4UMBn4bR5fCXid1PL8BKnb8nVguTz/euAyYGmgJ7BVnr4MsCvQh3TzkcuBqwt1NgHfysOjgLtbiC+AwXm4J/A06eYmi5JuLzoDWD3PHwtMBzbL8faqWJeAp4DrSA8ZWaFifu+8/OaFafcCR1TEMxR4BVgqv17J06KV/TyO1COwEvAq8CCpJ2Qx4Dbg+Fx2COmWrF/M23x03u5F8+s50k1cegK7Ae8BP8nLrp/XvTHpQGjfXPdiVd7ve4G98/DiwCY1Yj8ROD0PHwv8C/h5YV7z52WB97L43uXxEcDcvExP0udqFrB0jXrvBX6d98+W+b3+c543KK9/kcJ7/5PCspWx1LNfJgIr589Ba5/9prwfhuTyTcAp1WKrsW1jgD/nZa/P8ffIdU0ARuf3+jOkG/J8qbDce6TP7ycKddeKpZ7taP5fvAQ4LpfrReH/oLu/3DI3S66WNAN4nvSFd3ye/k3g7xHx94iYHxG3kB7qsa2kFUldzQdHxJsR8V7kh25ExOsRcUVEzIqIGcDJwFYdEOcmpKRzSqRW9W2kxLxnoczfIrW250fEO8WFI31jjSR9cf8KeFnpoqnV8vzZpAOPfQDy9A2AiyvieIfUXb87qeV+TZ7WmtMj4pVIXfp3AfdFxEMRMQe4ipTYyeu9PiJuiYj3SNcN9AY+l/dBT+C0vM//CjxQqONA4I8RcV9EzIuIC0j3Sd+kSjzvkR6bumxEzIyIcTXivoMP3r8tgZ8VxreibbdxfQ84Mcf+d2AmsHplIUkDgQ2BH0fEnIi4k7TP26ue/fK7iHg+fw5qfvYL5c+PiCdz+b9QccvbOixJetLdv4D9Ip3/35CUaE/Mn/F/A+eQPmfN7o2Iq3Ncs1uJpZ7taPYe6fTEgIh4Jz7oser2nMzNkp0jYglSy2kNPujOXAX4Wu6emyZpGunCohVJLZg3IuJD54ol9ZH0R0nP5a7AO4GlVP0cdlsMAJ6PiPmFac+RWh/Nnm9pBRHxQkQcGhGrkrbvbRbsIr8A+LrSbUz3Bm6MiFerrOpCUtJvtYu94JXC8Owq480XHg4gbVdzzPNJ27VSnvdiPjBp9lxheBXgyIr3bOW8XKUDSK25x5Wed759jbjvBYZIWoGUJC4EVs5duRvxQbdyPV6PiLmF8Vl8sN1FA4A3Y8Fz3s9VKVevevbL8xXla332m/23MFxrO1qyCbAu6eC0eK5/QEW9x5J6dKrF2Vos9WxHs6NJvVf3K53i2b+N29MwvnDArCDSc6nHklqCO5O+NP4UEQdWls0t8/6SloqIaRWzjyS1tjaOiP8q3QP8IdIXxcJ4iZREPlFI6AOBJ4ubUe/KIuJ5Sb8ndS82T7tL0uvATqRWzdE1Fr+L9IUYwN3Ah66CXwgvAes0j0gSKfG8mOtbSZIKCWAgqXUH6T07OSJObq2SiHgK2FPSJ4CvAn+VtExFAiXS884nAN8DpkTEu5L+CXwf+FdETF2Yja3hZWBpSX0L8QykDe9vhXr2S3HdNT/7dag3xpuBScCtkkZExCu53mciYrUOWD+0YTsiXTNzIKRrI4B/SLozIp5uQ30N4Za52YedBnwxJ+A/AztI+pKkHpJ6Kf1W+FMR8TJwA3Cm0gVvPSU1P896CVJLc5rS1eDHV6mnPe4jtaSPzvWNAHYALq1n4RznCflCn0/kluX+pHPZRRcCPyedD6/atZsT6Q7AjhWt5I7wF2A7SV9QetrZkaQu4X+SWslzgcPzRVpfJbWOm50DHCxpYyV9JW0naYnKSiR9U9Jy+cBoWp48r7JcdgfpMajNXepNFePVvEI659tmEfEcqTv4hHxR2Oak/d1ede+XrOZnv466XgPmU8e2R8SppNM4t+bP4/3AW0oX4/XOdQ+VtGF9m9n+7ZD0tcL0N0kHDbU+D92Kk7lZhYh4jZTMfhwRz5NaqMeSvqCeB/6XD/539iadZ3ucdK79iDz9NNI53qmkRHljB8X2LrAj6Vz9VOBMYJ+IeLzOVbxLujjpH8BbwBRSkhxVUe5CUivwsnw+u1Y8j0REu34215KIeILUK3A6aTt3IP188N28D76aY36TdH79ysKy40mtqzPy/Kf58PY1+zLwiNKvBn4L7FF5nUHBHaSDtDtrjFczBrggd+9+vYVytXyDdMHaG6QDwnpPZ3xIG/cLdXz2W6prFuk6kXvytle7XqFY/iTgatLnsh/p/R4GPEN6/8/N09usjduxIXBf/jxcA3wvIp5pT71dzU9NMzMzKzm3zM3MzErOydzMzKzknMzNzMxKzsnczMys5Pw7c2uIZZddNgYNGtToMMzMSmXChAlTI2K5yulO5tYQgwYNYvz48Y0Ow8ysVCRVvQugu9nNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs53gLOGeHHabH545eRGh2FmDfCzr67T6BA+ctwyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSfzTiRpZpVpB0vap4vjeFbSsl1YX5Ok4V1Vn5nZx50ftNLFIuKszly/JAGKiPkdsK5FImJuB4RlZmadyC3zLiZpjKSj8nCTpJ9Lul/Sk5K2yNN7SPqFpAckTZL07Tx9cUm3SnpQ0mRJO+XpgyQ9JulM4EFg5Rp195Z0o6QDJfWVdF6u46HCukZJulzStcDNefzKvNxTkk4trG8bSffmeC6XtHin7jwzM6vKLfPGWyQiNpK0LXA8sDVwADA9IjaUtBhwj6SbgeeBXSLirdxtPk7SNXk9qwP7RcR3atSzOHApcGFEXCjpp8BtEbG/pKWA+yX9I5fdFFg3It6QNAoYBqwHzAGekHQ6MBv4EbB1RLwt6Rjg+8CJHbZnzKxbu2j0/u1a7t7f9W3zMk1NTe2q6+PCybzxrsx/JwCD8vA2wLqSdsvj/YDVgBeAn0raEpgPrASskMs8FxHjWqjnb8CpEXFRoY4dm3sJgF7AwDx8S0S8UVj21oiYDiDpUWAVYClgLdKBBsCiwL0tbaikg4CDAJZcdsWWipqZWRs4mTfenPx3Hh+8HwIOi4ibigVzK3k5YIOIeE/Ss6QkDPB2K/XcA3xF0sUREbmOXSPiiYo6Nq6yrjmF4eY4RUr6e7ZS7/si4mzgbIAVB68d9S5nZt3TXiee167lfvbVdTo4EvM58+7pJuAQST0BJA2R1JfUQn81J/KRpBZyvUYDrwNnFuo4LF8wh6T12hjjOGAzSYPz8n0kDWnjOszMrAM4mXeuPpJeKLy+X+dy5wKPAg9KmgL8kdQavggYLmk8sBfweBvjOQLolS9iOwnoCUzKdZzUlhVFxGvAKOASSZNIyX2NNsZjZmYdQKnH1axrrTh47Rh16qWNDsPMGsDd7O0naUJEfOg+Hm6Zm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJ+alp1hArLdXbt3Q0M+sgbpmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnH9nbo0x/Xm49nuNjsI+6nb4baMjMOsSbpmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZVcq8lc0jxJEyVNkXS5pD4tlB0l6YyODbE+kk6UtHUrZcZK2q3GvNMkbVll+ghJ13VUnAtD0i8kPS5pkqSrJC2Vp68jaWyNZbr0PelO+8vM7OOinpb57IgYFhFDgXeBgzs5pnaJiNER8Y/2LCupP7BJRNzZwWFV1tNjIVdxCzA0ItYFngR+CBARk4FPSRq4kOtfQAfEa2ZmXaCtT027C1g3J7/zgM8As4CDImJScyFJSwCTgCER8Z6kJfP4aqSEdB8wElgKOCAi7pLUC/gDMByYC3w/Im6XNArYGegBDAV+BSwK7A3MAbaNiDdyy/S6iPirpNHADkBv4J/AtyMiWtiu3YAbC/F/GTgNmAo8WJjeFzgdWIe078ZExN9yb8VYYA3gMWAQ8N2IGC9pJvBr4EvAkZIGAYfnbbgP+E5EzJO0DXACsBjwL2C/iJhZDDIibi6MjstxN7sW2AM4tdZGStoO+FHeN+tXq0/Ss6T3dhvgDEmnABfkZXoCX4uIx2vti1p1m7XXiGOvaP/Cv3q43Ys2NTW1v16zLlb3OXNJiwBfASaTksBDuYV4LHBhsWxEzACagO3ypD2AKyLivTy+SERsBBwBHJ+nfTcvuw6wJ3BBTvCQkvg3gI2Ak4FZEbEecC+wT5Vwz4iIDXNvQm9g+1Y2bzNgQt7OXsA5pOS1BfDJQrnjgNsiYkPSwcgvclL7DvBm3h8nARsUlukLTImIjYHXgd2BzSJiGDAP2EvSsqQku3VErA+MB77fSsz7AzcUxsfneKuStAvwA2DbPKml+t6JiM0j4tI8PjWX+wNwVCv7oiZJB0kaL2n8a9Nnt7J5ZmZWr3pa5r0lTczDdwH/R2pR7goQEbdJWkZSv4rlzgWOBq4G9gMOLMy7Mv+dQGrFAmxOaumRW37PAUPyvNvzAcIMSdNJrVBIBxbrVol5pKSjgT5Af+CRwjLVrAi8lofXAJ6JiKcAJP0ZOCjP2wbYUVJzQusFDMyx/zbHPkXS+70UpITd3LT4AinRPyAJ0oHGq8AmwFrAPXn6oqQDlaokHUfqvbioMPlVYECNRUaSejy2iYi3JG3fSn2XVSxffL++modr7YuaIuJs4GyA4aut0FJPidn7mn66a/sX9vPM7WOinmQ+O7ci36ecASos8OUcEfdIGiRpK6BHREwpzJ6T/84rxFBtnZXlAeYXxudTsQ25ZX0mMDwinpc0hpRoWjK7okytRCNg14h4oqLOlmJ/JyLmFZa/ICJ+WLH8DsAtEbFnK3EiaV9ST8MXKk4d9MrbUc2/SadEhpBa4Wqlvrcrxmu9X9X2xQqtbYOZmXWs9v407U5gL0hXL5O6Yd+qUu5C4BLg/DaucwiplfdEi0tU15yUp0panAXPK9fyGDA4Dz8OfFrSqnm8mPBuAg5rTt6S1svT7wa+nqetRTqPXM2twG6Sls9l+0tahXT+ezNJg/P0PnkfLCCfyz8G2DEiZlXMHgJMqVwme47Uor5Q0tr11teKWvvCzMy6WHuT+RhgeO5OPgXYt0a5i4ClSQm9NWcCPSRNJnXzjoqIOa0s8yERMY10znsyqYv/gToWux4YkZd/h9Stfr2ku0mJsNlJpIvAJkmaksebY18u749jSBf7Ta8S26Okc9U357K3ACtGxGvAKOCSPH0cqbu/0hnAEsAt+eeCZxXmjczbUVVuQe8FXA4sWWd9Lam1L8zMrIup5Yu8F3Ll6TfdO0XE3p1WSQfJiXv7fDDQ1mV7AD0j4p3cor+VdCX/ux0cZq36FwPuADaPiLldUefCGr7aCjH+13s0Ogz7qPM5c/uIkTQhIoZXTm/rT9PaUuHppKvft22tbDdxJKlrf1o7lu0D3C6pJ+lc8iFdlcizgcAPypLIzcysY3VaMo+Iwzpr3Z0hIu5biGVnkK4Wb4h85f1TjarfzMway/dmNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzP7f/buPN6u6f7/+OvdCEkMidRQUZEaQgmCUGpKSrVVY9HSFEGl5ip+htIIOqhWaYtqqkRaU5WooTUU10wlRBJTq4aavo0YQmSoxOf3x1qXnePcc89N7r3nbt7Px+M+soe19vrsfW7uZ6+199m75JzMzczMSs7J3MzMrOQ67HvmZjX1XsVP5zIzayfumZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWcv2duDfHyOy9z6v2nNjoMM1sEp2x+SqNDsMw9czMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzkms1mUuaL2mSpKmSrpLUq0bZEZLObd8Q6yPpNEnbtVJmrKQ9Wlh3jqStqywfKumG9opzUUg6XdLk/HncIqlfXr6epLEt1OnUz6QrHS8zs4+LenrmsyNicEQMAv4HHNzBMS2UiBgVEX9fmLqS+gKbRcRd7RxWZTvdFnETP4uI9SNiMHADMAogIqYAn5bUfxG3v4B2iNfMzDpBW9+adjewfk5+FwGrAbOAkRExubmQpKWBycDAiHhX0jJ5fk3gVuBBYBjQBzgwIu6W1AP4DTAEmAccHRF3SBoB7Ap0AwYBZwGLA/sAc4EdIuL13DO9ISL+LGkUsBPQE7gP+E5ERI392gO4qRD/l4FzgOnAw4XlSwK/BtYjHbvREfGXPFoxFlgbeAIYABwWERMkzQR+AXwJOEbSAODIvA8PAodGxHxJ2wOnAksA/wb2j4iZxSAj4q3C7JJAcZ+uB/YCzmxpJyV9FTg5H5uNqrUn6TnSZ7s9cK6kM4BLcp3uwJ4R8WRLx6Klts2sa7v4sIvbXOeOZe5YqLaampoWqp61rO5r5pIWA74CTCElgUciYn3g+8C4YtmIeBtoAr6aF+0FXB0R7+b5xSJiU+AooPkdeofluusBewOX5AQPKYl/E9gU+BEwKyI2BO4H9q0S7rkRsUkeTegJ7NjK7m0BTMz72QP4HSl5bQV8qlDuJOD2iNiEdDLys5zUDgXeyMfjdGDjQp0lgakR8TngNeAbwBa5dz0fGC5pOVKS3S4iNgImAEdXC1TSjyS9AAwn98yzCTneqiTtBpwA7JAX1WpvTkRsGRFX5PnpudxvgGNbORYtkjRS0gRJE2a9MatWUTMza4N6euY9JU3K03cDvyf1KHcHiIjbJX1SUu+KehcCxwHXAvsDBxXWXZP/nUjqxQJsSerpkXt+zwMD87o78gnC25JmkHqhkE4s1q8S8zBJxwG9gL7AY4U61awEvJqn1waejYh/AUj6IzAyr9se2FlSc0LrAfTPsf8yxz5V0vujFKSEfXWe3paU6B+SBOlEYxqwGbAOcG9evjjpROVDIuIk4CRJJwKH88HJ0DSgXwv7N4w04rF9RLwlacdW2ruyon7x8/paK8eiRRExBhgD0O+z/WqNlJhZJ9v/vP3bXMfvM+866knms3Mv8n3KGaDCAn+cI+JeSQMkbQN0i4iphdVz87/zCzFU22ZleYD3CvPvUbEPuWd9PjAkIl6QNJqUaGqZXVGmpUQjYPeIeKqizVqxz4mI+YX6l0TEiRX1dwJujYi9W4mz6DLgRj5I5j1I+1HNM6RLIgNJvXC10t47FfMtfV7VjsWK9e6AmZm1j4X9atpdpGFeJA0lDcO+VaXcOOByoJ6LMcVtDiT18p6qWaO65qQ8XdJSpOvhrXkCWCNPPwl8RtLqeb6Y8G4GjmhO3pI2zMvvAb6el61Duo5czW3AHpJWyGX7SloVeADYQtIaeXmvfAwWIGnNwuzOOdZmA4GpVPc8qUc9TtK69bbXipaOhZmZdbKFTeajgSF5OPkMYL8Wyl0KLEtK6K05H+gmaQppmHdERMxtpc6HRMSbpGveU0hD/A/VUe1GYGiuP4c0rH6jpHtIibDZ6aSbwCZLmprnm2NfPh+P40k3+82oEtvjpGvVt+SytwIrRcSrwAjg8rz8AdJwf6Uz8lcEJ5OGub9bWDcs70dVuQc9HLgKWKbO9mpp6ViYmVknU+2bvBdx4+k73btExD4d1kg7yYl7x3wy0Na63YDuETEn9+hvI93J/792DrOl9pcA7gS2jIh5ndHmour32X7xnYu+0+gwzGwR+Jp555M0MSKGVC5v61fT2tLgr0l3v+/QWtku4hjS0P6bC1G3F3CHpO6ka8mHdFYiz/oDJ5QlkZuZWfvqsGQeEUd01LY7QkQ8uAh13ybdLd4Q+c77fzWqfTMzayw/m93MzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzkOux75ma19Fuyn58eZWbWTtwzNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzl/z9wa4t2XX+aVUf6euZl1bSuddmqjQ6iLe+ZmZmYl52RuZmZWck7mZmZmJedkbmZmVnJO5mZmZiXnZG5mZlZyTuZmZmYl52RuZmZWck7mZmZmJedkbmZmVnJO5mZmZiW30Mlc0nxJkyRNlXS9pD5trN8kaUie/mtr9SU9J2m5KstntqXdFrY9RNKv2lD+SElPSLp0UdsubHOApG8ubEytbHuRj1Eb26v6WZmZWcdYlJ757IgYHBGDgNeBwxZ2QxGxQ0S8uQixLJKImBARR7ahyqHADhExvB3DGAC8n8wXIqZ2J8kv4jEzK4H2+mN9P7A+gKRNgXOAnsBsYP+IeEpST+BiYB3gibyeXOc5YEhETJd0LbAK0AP4ZUSMaa1xSWcBw4A3gL0i4lVJBwEjgcWBp4F9ImKWpD2BU4D5wIyI2FrSUODYiNhR0jbAL/OmA9g6It4utHUBsBpwnaSLgN7AzIj4eV4/FdgxF/8bcA/weeAlYJeImC1pDeACYPkcx57AGcBnJU0CLgEeKcTUF7gotzsLGBkRkyWNBvrn5f2BcyKixd587i1fD/wQ+EeOoX9efVRE3Ju32Y90cjFd0j9bakPSt4Aj8zF+EDg0Iua31L6ZWWfYfdwl7batxe+6s922BdDU1NSu22u2yNfMJXUDtgWuy4ueJCXADYFRwI/z8kOAWRGxPvAjYOMWNnlARGwMDAGOlPTJVkJYEng4IjYC7iQlaoBrImKTiNiAdPJwYF4+CvhSXr5zle0dCxwWEYOBrUgnJO+LiIOBl4FhEXF2K7GtCZwXEesCbwK75+WX5uUbkBL9K8AJwN15tKNyu6cCj+Rj931gXGHd2sCXgE2BUyR1rxaIpBWBG4FREXEj6YTl7IjYJMd1YaH4xqQTj+aRgg+1IemzwDeALfKxmg/UHKmQNFLSBEkTXps1q1ZRMzNrg0XpmffMvcgBwETg1ry8N3CJpDVJPdvm5LI18CuA3Kuc3MJ2j5S0W55ehZQQX6sRx3vAlXn6j8A1eXqQpB8CfYClgJvz8nuBsZL+VChbdC/wi3w9/JqIeLFG2615NiIm5emJwABJSwMrR8R4gIiYAyCp1na2JJ8IRMTtkj4pqXded2NEzAXmSpoGrAhUxtwduI10ktJ8mrkdsE6h3WVybADXRUTxJKZaG9uSkv5DeRs9gWm1diKPsowB2KBfv6hV1sxsYV29737ttq2Pw/vMZ+ce2aqkYdbma+anA3fka+k7kYbLm9X8A56Hu7cDNs+91kcq6tejuY2xwOERsR6pZ9sD3u9Zn0w6UZhU2fOPiDOAb5OS0wOS1m6lvXkseByL8c4tTM8nnTzVzNotqFaneT+rtVEtxomk3nWzT5CO8+D8s3LhcsI7FfVb2o9LCvXXiojR9e2OmZm1p0UeZo+IGaTrpsfmId7epOvDACMKRe8iD8NKGkS+xl6hN/BGvra9NrBZHSF8AtgjT3+TdI0aYGnglRzT+8O/klaPiAcjYhQwnZTUqVg/JSJ+CkwgDTHX8hywUa67EfCZWoUj4i3gRUm75jpLSOoFvJ1jrqZ47IYC0/N26hXAAcDakk7Iy24BDm8uIGlwG7YHqae/h6QVcv2+klZt4zbMzKwdtMv3zCPiEeBRYC/gTOAnku4FuhWK/QZYKg+vH0e6AavSTcBiuczpwAN1NP8OsK6kicAXgNPy8h+Qbsq6lXQdv9nPJE3JN6rdleMuOip/3e5R0vXyv7XS/tVA33zJ4RDgn3XEvA/pcsJk4D7gU8BkYJ6kRyV9r6L8aGBILn8G0OYxpHxj2l7AMEmHkk7AhkiaLOlx4OA2bu9x0gjHLTmuW4GV2hqXmZktOkX40qV1vg369Yubvn1Qo8MwM6upq10zlzQxIoZULvcT4MzMzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKrr3eZ27WJt379etyT1YyMysr98zNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzt8zt4Z4+/U53HHpk40Ow8wKhg1fu9Eh2EJyz9zMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczBeCpJMkPSZpsqRJkj6Xl18oaZ0ObvuvkvpUWT5a0rFVlo+VtEdHxlRPHGZm1nH8opU2krQ5sCOwUUTMlbQcsDhARHy7o9uPiB06ug0ASQIUEe91RntmZrbwnMzbbiVgekTMBYiI6c0rJDUBx0bEBEkHAscDLwP/AuZGxOGSxgKzgbWBVYH9gf2AzYEHI2JE3tbewPcBATdGxPF5+XPAkIiYLukkYF/gBeBVYGKtwCWdDqwCHAAcA3wdWAIYHxGnSBoA/A24I8dzlKQLgHuAzwMvAbtExGxJqwPnAcsDs4CDIsKvQTPrRN/74b7tur0+v+vVrtsDaGpqavdt2od5mL3tbgFWkfRPSedL2qaygKR+wA+AzYAvkhJ30bLAF4DvAdcDZwPrAutJGpzr/zSXGQxsImnXijY2BvYCNgS+BmxSK2hJZwIrkE4etgPWBDbN299Y0ta56FrAuIjYEHg+lzsvItYF3gR2z+XGAEdExMbAscD5tdrPMYyUNEHShBlvvdFacTMzq5N75m0UETNzIt0KGAZcKemEiBhbKLYpcGdEvA4g6SpgYGH99RERkqYA/42IKbncY8AAUo+9KSJezcsvBbYGri1sYytSj3pWLnNdjbB/QOr1j8xltwe2Bx7J65ciJe3/AM9HxAOFus9GxKQ8PREYIGkpUk/9qjQaD6Qefk0RMYZ0EsBaqw2K1sqbWW1nnzyuXbfn95mXl5P5QoiI+UAT0JQT8n7A2EIRValWNDf/+15hunl+MWBevaHUWe4hUu+7bz7BEPCTiPhtsVAeZn+nhVgB5gM9SSM6b0bE4DrbNzOzDuRh9jaStJakNQuLBpOGo4v+AWwjaVlJi/HB0HS9Hsz1l5PUDdgbuLOizF3AbpJ6Sloa2KnG9m4CzgBuzGVvBg7IPWwkrSxphXqDi4i3gGcl7ZnrS9IG9dY3M7P25Z552y0F/Dp/PWwe8DQwslggIl6S9GNSUn4ZeByYUW8DEfGKpBNJN6IJ+GtE/KWizMOSrgQmkU4m7m5lm1flRH4dsANwGXB/HiafCXyL1POu13DgN5JOBroDVwCPtqG+mZm1E0X40mVHkLRUvr6+GDAeuCgixjc6rq5irdUGxQWn/7nRYZhZga+Zd32SJkbEkMrlHmbvOKMlTQKmAs+y4M1rZmZm7cbD7B0kIvwUNDMz6xTumZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJ+aEx1hBL9+3hR0eambUT98zNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzk/NU0a4i3Xp3GrWPObXQY9jHyxZGHNzoEsw7jnrmZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mQOS5kuaJOkxSY9KOlpSKY6NpAGSprbj9k6TtF2e3iofk0mSVpb05/Zqx8zM2o9ftJLMjojBAJJWAC4DegOnNDKoRoiIUYXZ4cDPI+LiPL9HvduR1C0i5rdrcGZmVlUpep+dKSKmASOBw5WMkPT+670k3SBpaJ6eKemnkiZK+rukTSU1SXpG0s65zAhJ10q6XtKzkg7PPf9HJD0gqa+k1SU9XGhjTUkTK2OTtEZu51FJD0tavWL9AEl353UPS/p8Xr6SpLtyD3tq7nF3kzQ2z0+R9L1cdqykPSR9G/g6MErSpcURgFz3Z5IekjRZ0nfy8qGS7pB0GTClHT8WMzOrwT3zKiLimTzMvkIrRZcEmiLieEnjgR8CXwTWAS4BrsvlBgEbAj2Ap4HjI2JDSWcD+0bEOZJmSBocEZOA/YGxVdq7FDgjIsZL6kE6GSvGOA34YkTMkbQmcDkwBPgmcHNE/EhSN6AXMBhYOSIGAUjqU3EMLpS0JXBDRPxZ0oDC6gOBGRGxiaQlgHsl3ZLXbQoMiohnWzl2Zh3q2LN+ucD8spd9cJWoqampk6Mx61hO5i1THWX+B9yUp6cAcyPiXUlTgAGFcndExNvA25JmANcX6qyfpy8E9pd0NPANUlL8IBhpaVLyHQ8QEXPy8mKx7sC5kgYD84GBeflDwEWSugPXRsQkSc8Aq0n6NXAjcAv12x5YX1LzsHtvYM18PP7RUiKXNJI06sEKfZdtQ3NmZlaLk3kVklYjJcNpwDwWvBzRozD9bkREnn4PmAsQEe9JKh7buYXp9wrz7/HBZ3A16Rr97cDEiHitMqw6Qv8e8F9ggxzznBzPXZK2Br4K/EHSzyJinKQNgC8Bh5GG1A+oo43mWI6IiJsXWJguP7zTUqWIGAOMARi4av9oqZxZe/j5Md9dYP6LIw9vUCRmHc/XzCtIWh64ADg3J+rngMGSPiFpFSp6zO0l97RvBn4DXFxl/VvAi5J2zXEuIalXRbHewCsR8R6wD9Atl10VmBYRvwN+D2wkaTngExFxNfADYKM2hHszcEju6SNpoKQl21DfzMzakXvmSU9Jk0jD1POAPwC/yOvuBZ4lDYlPBR6utoF2cinwNVoe8t4H+K2k04B3gT1Jvftm5wNXS9oTuIMPeslDgf8n6V1gJrAvsDJwceEreCe2Ic4LSZcRHlYa538V2LUN9c3MrB3pg1FiazRJxwK9I+IHjY6low1ctX+cd9JxjQ7DPkY8zG4fBZImRsSQyuXumXcR+W741YEvNDoWMzMrFyfzLiIidmt0DGZmVk6+Ac7MzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzg+NsYZYZvkV/HhNM7N24p65mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWcIqLRMdjHkKS3gacaHUcXtRwwvdFBdFE+NtX5uLTso3ZsVo2I5SsX+tns1ihPRcSQRgfRFUma4GNTnY9NdT4uLfu4HBsPs5uZmZWck7mZmVnJOZlbo4xpdABdmI9Ny3xsqvNxadnH4tj4BjgzM7OSc8/czMys5JzMzczMSs7J3DqMpC9LekrS05JOqLJekn6V10+WtFEj4myEOo7N8HxMJku6T9IGjYizEVo7NoVym0iaL2mPzoyvkeo5NpKGSpok6TFJd3Z2jI1Sx/+p3pKul/RoPjb7NyLODhMR/vFPu/8A3YB/A6sBiwOPAutUlNkB+BsgYDPgwUbH3YWOzeeBZfP0V3xsqpa7HfgrsEej4+4qxwboAzwO9M/zKzQ67i50bL4P/DRPLw+8Dize6Njb68c9c+somwJPR8QzEfE/4Apgl4oyuwDjInkA6CNppc4OtAFaPTYRcV9EvJFnHwA+3ckxNko9vzcARwBXA9M6M7gGq+fYfBO4JiL+AxARH5fjU8+xCWBpSQKWIiXzeZ0bZsdxMreOsjLwQmH+xbysrWU+itq63weSRjA+Dlo9NpJWBnYDLujEuLqCen5vBgLLSmqSNFHSvp0WXWPVc2zOBT4LvAxMAb4bEe91Tngdz49ztY6iKssqvwdZT5mPorr3W9IwUjLfskMj6jrqOTbnAMdHxPzUyfrYqOfYLAZsDGwL9ATul/RARPyzo4NrsHqOzZeAScAXgNWBWyXdHRFvdXBsncLJ3DrKi8AqhflPk86I21rmo6iu/Za0PnAh8JWIeK2TYmu0eo7NEOCKnMiXA3aQNC8iru2UCBun3v9T0yPiHeAdSXcBGwAf9WRez7HZHzgj0kXzpyU9C6wN/KNzQuxYHma3jvIQsKakz0haHNgLuK6izHXAvvmu9s2AGRHxSmcH2gCtHhtJ/YFrgH0+Br2qolaPTUR8JiIGRMQA4M/AoR+DRA71/Z/6C7CVpMUk9QI+BzzRyXE2Qj3H5j+kEQskrQisBTzTqVF2IPfMrUNExDxJhwM3k+40vSgiHpN0cF5/AelO5B2Ap4FZpDPnj7w6j80o4JPA+bkHOi8+Bm9+qvPYfCzVc2wi4glJNwGTgfeACyNiauOi7hx1/t6cDoyVNIU0LH98RHxkXo3qx7mamZmVnIfZzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczD6S8hvVJkmamt+W1aedt/+cpOXy9Mz23LZZWzmZm9lH1eyIGBwRg0gv1Tis0QGZdRQnczP7OLif/OINSatLuim/iORuSWvn5StKGp/fd/2opM/n5dfmso9JGtnAfTBrkZ8AZ2YfaZK6kR7j+fu8aAxwcET8S9LngPNJL9/4FXBnROyW6yyVyx8QEa9L6gk8JOnqj9Gz8q0knMzN7KOqp6RJwABgIuktWUsBnweuKrxxbYn87xeAfQEiYj4wIy8/UtJueXoVYE3Aydy6FCdzM/uomh0RgyX1Bm4gXTMfC7wZEYPr2YCkocB2wOYRMUtSE9CjI4I1WxS+Zm5mH2kRMQM4EjgWmA08K2lPgPzGvg1y0duAQ/LybpKWAXoDb+REvjawWafvgFkdnMzN7CMvIh4BHiW9GnM4cKCkR4HHgF1yse8Cw/JbtSYC6wI3AYtJmkx669YDnR27WT381jQzM7OSc8/czMys5JzMzczMSs7J3KzkJP1Q0nRJ/9foWLqq/OjV7eooN0BSSOqQb/pIukDSD2qsHy3pj4uw/SZJ387TwyXdUli3haR/SZopadf8kJy7JL0t6ayFbbOjFPelwXGEpDUaHUdrnMztIy//IZ+d/4g1//TL68ZIekrSe5JGtLKdT0u6OifOGZKmtFano0laBTgGWCciPtVO29wlP9P8rbyvt+Ukt3c+lqoov5ikaZJ2lDQ0//G7pqLMBnl5U3vEWFYRcXBEnA7pa2+SXuzAti6NiO0Li04Dzo2IpSLiWmAkMB1YJiKO6ag4qpE0QtI9ndnmR52TuX1c7JT/iDX/vJyXPwocCjxcxzb+ALwArAp8kvSAkf+2Z5AL0SNcFXgtIqa1R1u5BzKOdILQG/gM6Qlp7wHjgT7ANhXVvgwE6c5vgFeBz0v6ZKHMfsA/2xqjtatVSXfvF+cfj4W4C7qjRi7aW/7q4cciz30sdtKsJRFxXkTcBsypo/gmwNiIeCci5kXEIxHxt+aVkraUdJ+kNyW90Nxrl9Rb0jhJr0p6XtLJzX9gcg/lXklnS3odGC1pCUk/l/QfSf/NQ7M9K4PJw8a3Av3yaMPYvHxnpeeIv5mHKj9bqPOcpOPzV63eqfJHeTDwbETcFsnbEXF1RPwnIuYAfyI/Ja1gX+DSiJiX5/8HXEv6Gljz41S/Dlza0oEtDG/vn4/dG5IOlrSJpMl5X84tlP9EPo7P51GBcUoPh2lev09e95qkkyra+oSkEyT9O6//k6S+LcQ1QtIzeSj6WUnDq5TpkUd+mt+gdrKkeUrfU2++DHJOnh6b55cE/sYHn937o0XA4nl/3s6f45Aax+2Lkp7MI0XnAiqse7/3K+nfwGrA9bmty0knWMfl+e1qHZfC53OgpP8At+flB0h6In9eN0tatdB+5M/wX3n9eTm5fha4ANg8t/1mS/tX2NZK+ffg2Dy/mT74v/ao0sN9mss2SfqRpHuBWcBqLcVSqNPiflTEsYOkx/Nn81JzPF1CRPjHPx/pH+A5YLtWytwDjGilzN+Be0lJqn/Fuv7A28DeQHdSz31wXjcO+AuwNOnRov8EDszrRgDzgCNIT2TsCZwDXAf0zXWuB37SQkxDgRcL8wOBd4Av5jiOA54GFi8ci0mkx5L2rLK91UgnNmcDw4ClKtZvAbzVXJfUe59d2NehwIukR6Y+mJftANwMfBtoamE/BpB69xeQnrC2fY7jWmAF0ktSpgHb5PIH5P1ajfQM9WuAP+R16wAzga1Jj2r9RT7G2+X1R5G+L/7pvP63wOUVcSwGLJn3da28biVg3RbivwvYPU/fAvwb+Eph3W55eizww2qfXV42Ou/3DkA34CfAAy20uVyOb4/8WX8v7+e3C79b97T0/6AYSxuOy7h8XHoCu+bP4LP5eJ0M3FfYXpCevNeH9P/jVeDL1WJrYf+aSL8zA0j/Z0bm5SuTHqe7A6lD+sU8v3yh3n9IzwlYLB+bWrHUsx9r5OlXgK3y9LLARo3++/Z+nI0OwD/+6eif/EdsJvBm/rm2Spl6kvmywBmkocr5pKS4SV53IjC+Sp1uwFzSNe3mZd8hJ7X8R+0/hXUiJePVC8s2J/WWq8U0lAWT+Q+APxXmPwG8BAwtHIsDWtnPzUg98FdJiWUshaQO/Av4Zp4+CHi0Wjy53FrAFaQHtdSTzFcuLHsN+EZh/mrgqDx9G3BoYd1awLv5j/Eo4IrCuiVJowXNyfwJYNvC+pUKdZvjaE7mbwK7U+XEpyL+00kvalkM+D/SA2jOIJ2YzAaWy+XG0noy/3thfh3SY2mrtbkvhUSff3deZOGTeT3HZbXC+r+RT0oLv2uzgFXzfABbFtb/CTihWmwt7F8T6UTsOWDvwvLjySduhWU3A/sV6p1Wsb5WLPXsR3My/w/p/+8ytWJvxI+H2e3jYteI6JN/dl2YDUTEGxFxQkSsC6xISubX5uG6VUi9sUrLAYsDzxeWPU9+HWf2QmF6eaAXMDEPIb5Juha9fJ1h9iu2FRHv5e231N6HRMQDEfH1iFge2IrUwy0OVY/jg6H2fYBLWtjUH4DDST388XXGX7wHYXaV+eY3mS2wn3l6MdLn0o/CPkbEOyz4YpRVgfGF4/sE6eRsxWIgud43gIOBVyTdqPy61CruJCXnjYAppMsf25BOjJ6OiOm1drpC8VsJs4Aeqn6NunI/g1Y+21bUc1xeqCj/y0L510knFMXftcp9WYq2GU46Gf1zRbt7Nreb296SdPJRLc7WYqlnP5rtThoReF7SnZI2b+P+dBgnc7OFkP84/5z0B7Uv6Y/H6lWKTif1borX4PqT/kC9v7mK8rNJw7nNJx+9I6LeP4IvF9sqnGi01F5NEfEQaQh7UGHxOGDb/IdsM+CyFqr/gXRz4V8jYla9bdZpgf0kHdN5pOT/CmmfAZDUi3TZo9kLpCHwPoWfHhFRPEYARMTNEfFFUqJ4EvhdC/HcRxod2I30GtXHc0xfJSX6atp841mFyv1UcX4h1HNcoqL8dyrK94yI++poq959H036P3GZ0r0Xze3+oaLdJSPijIXYfvP26tqPiHgoInYhXfq5ltTD7xKczO1jTdLiknqQzsS755uZqv6/kPRTSYOUvoq1NOmlHE9Herf1pcB2kr6e139S0uBIr9L8E/AjSUvnG2uOBqp+lzj3pH8HnC1phdzuypK+VOcu/Qn4qqRtJXUn3ZU+l5Rs6jkeW0o6qND22sDOFJ5JHhHPky5LXA7cGhFVv98eEc+SeqcnVVu/iC4HvifpM0qvNf0xcGWkm/D+DOyY92Vx0leyip/pBaTPY1UASctL2qWyAaXvYe+sdLPaXNKlmvnVgsknKxNJb2ZrTt73kYZkW0rm/wU+qcKNe210I7CupK/lnvuRwKJ8PbGu41JR/kRJ6+byvZVfYFOH/wKfzp9PLe8Ce5Iuefwh/9/8I7CTpC8pvRCnh9LX/D5dZ9sLtR/5b8VwSb0j4l3S/QpVfx8awcncPu5uIfWEPw+MydNbt1C2F2m4+E3gGVLPcGeAiPgPafjtGNIw3SRgg1zvCNJ18GdISfAy4KIaMR1PuiHnAUlvkW68W6uenYmIp4BvAb8m9Wh2In0t73/11M/7tjMwRdJM0hD/eODMinKXkPZ/XCvx3BMffA2wPV1E6vnfBTxLurZ/RG7zMVJSvYzUe32DdC252S9JNxjeIult0onK56q08QnS5/ky6TPdhjTS0JI7STdb/aMwv3SO8UMi4knSSckzeYi3X7VyLcmjQ3uSrs2/RnrP+r1t2UaFeo9Lc/vjgZ8CV+Tf06nAV+ps63bSvSf/J6nmJYj8u/s1Um/4ItIo0y7A90n3dbwA/D8WMp+1cT/2AZ7L5Q4m/V/rEvyiFTMzs5Jzz9zMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrORK8eYb++hZbrnlYsCAAY0Ow8ysVCZOnDg9P51xAU7m1hADBgxgwoQJjQ7DzKxUJD1fbbmH2c3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzk+As4Z46c3ZnHjNlEaHYWYfET/52nqNDqGh3DM3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5J/MOJGlmlWUHS9q3k+N4TtJyndhek6QhndWemdnHnV+00ski4oKO3L4kAYqI99phW4tFxLx2CMvMzDqQk3knkzQamBkRP5fUBDwIDAP6AAdGxN2SugFnAEOBJYDzIuK3kpYC/gIsC3QHTo6Iv0gaAPwNuAPYHNgVeL5K2z2B8cDVwGXAr4H1SL8Ho/O2RgBfBXoAS0oaB+wM9AJWB8ZHxHF5e9sDp+YY/w3sHxEfGo0wM2urS0cd0Kby9/9qyTaVb2pqalP5rs7D7I23WERsChwFnJKXHQjMiIhNgE2AgyR9BpgD7BYRG5FOAM7KPXGAtYBxEbFhRHwokQNLAdcDl0XE74CTgNtzG8OAn0lq/t+wObBfRHwhzw8GvkFK/N+QtEoetj8Z2C7HMwE4utaOShopaYKkCbNmvFH3ATIzs9rcM2+8a/K/E4EBeXp7YH1Je+T53sCawIvAjyVtDbwHrAysmMs8HxEP1GjnL8CZEXFpoY2dJR2b53sA/fP0rRHxeqHubRExA0DS48CqpJGEdYB78/nE4sD9tXY0IsYAYwBWWmPdqFXWzD7ehp92UZvKf9zfZ+5k3nhz87/z+eDzEHBERNxcLJiHwJcHNo6IdyU9R0rCAO+00s69wFckXRYRkdvYPSKeqmjjc1W2Nbcw3RynSEl/71baNTOzDuZh9q7pZuAQSd0BJA3MQ+C9gWk5kQ8j9ZDrNQp4DTi/0MYRzcP0kjZsY4wPAFtIWiPX7yVpYBu3YWZm7cDJvGP1kvRi4afmNeWCC4HHgYclTQV+S+oNXwoMkTQBGA482cZ4jgJ6SDoTOJ10E93k3MbpbdlQRLwKjAAulzSZlNzXbmM8ZmbWDpRGXM0610prrBsjzryi0WGY2UfEx+WauaSJEfGh53i4Z25mZlZyTuZmZmYl52RuZmZWck7mZmZmJedkbmZmVnJO5mZmZiXnZG5mZlZyTuZmZmYl52RuZmZWcn7RijXEyn16fmye2GRm1tHcMzczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5f8/cGmPGC3D9dxsdhVnj7PTLRkdgHyHumZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlVyryVzSfEmTJE2VdJWkXjXKjpB0bvuGWB9Jp0narpUyYyXt0cK6cyRtXWX5UEk3tFeci0LSzyQ9KWmypPGS+uTl60ka20KdTv1MutLxMjP7uKinZz47IgZHxCDgf8DBHRzTQomIURHx94WpK6kvsFlE3NXOYVW2020RN3ErMCgi1gf+CZwIEBFTgE9L6r+I219AO8RrZmadoK1vTbsbWD8nv4uA1YBZwMiImNxcSNLSwGRgYES8K2mZPL8mKSE9CAwD+gAHRsTdknoAvwGGAPOAoyPiDkkjgF2BbsAg4CxgcWAfYC6wQ0S8nnumN0TEnyWNAnYCegL3Ad+JiKixX3sANxXi/zJwDjAdeLiwfEng18B6pGM3OiL+kkcrxgJrA08AA4DDImKCpJnAL4AvAcdIGgAcmffhQeDQiJgvaXvgVGAJ4N/A/hExsxhkRNxSmH0gx93semAv4MyWdlLSV4GT87HZqFp7kp4jfbbbA+dKOgO4JNfpDuwZEU+2dCxaatvs42To969uvdBZj9a1raampkULxj4W6r5mLmkx4CvAFFISeCT3EL8PjCuWjYi3gSbgq3nRXsDVEfFunl8sIjYFjgJOycsOy3XXA/YGLskJHlIS/yawKfAjYFZEbAjcD+xbJdxzI2KTPJrQE9ixld3bApiY97MH8DtS8toK+FSh3EnA7RGxCelk5Gc5qR0KvJGPx+nAxoU6SwJTI+JzwGvAN4AtImIwMB8YLmk5UpLdLiI2AiYAR7cS8wHA3wrzE3K8VUnaDTgB2CEvqtXenIjYMiKuyPPTc7nfAMe2cixaJGmkpAmSJrw6Y3Yru2dmZvWqp2feU9KkPH038HtSj3J3gIi4XdInJfWuqHchcBxwLbA/cFBh3TX534mkXizAlqSeHrnn9zwwMK+7I58gvC1pBqkXCunEYv0qMQ+TdBzQC+gLPFaoU81KwKt5em3g2Yj4F4CkPwIj87rtgZ0lNSe0HkD/HPsvc+xTJb0/SkFK2M2n6duSEv1DkiCdaEwDNgPWAe7NyxcnnahUJekk0ujFpYXF04B+LVQZRhrx2D4i3pK0YyvtXVlRv/h5fS1Pt3QsWhQRY4AxAEPWXLHWSIlZqTX9ePfWC/l95taO6knms3Mv8n3KGaDCAn+cI+JeSQMkbQN0i4iphdVz87/zCzFU22ZleYD3CvPvUbEPuWd9PjAkIl6QNJqUaGqZXVGmpUQjYPeIeKqizVqxz4mI+YX6l0TEiRX1dwJujYi9W4kTSfuRRhq2rbh00CPvRzXPkC6JDCT1wtVKe+9UzLf0eVU7Fiu2tg9mZta+FvaraXcBwyHdvUwahn2rSrlxwOXAxW3c5kBSL++pmjWqa07K0yUtxYLXlVvyBLBGnn4S+Iyk1fN8MeHdDBzRnLwlbZiX3wN8PS9bh3QduZrbgD0krZDL9pW0Kun69xaS1sjLe+VjsIB8Lf94YOeImFWxeiAwtbJO9jypRz1O0rr1tteKlo6FmZl1soVN5qOBIXk4+QxgvxbKXQosS0rorTkf6CZpCmmYd0REzG2lzodExJuka95TSEP8D9VR7UZgaK4/hzSsfqOke0iJsNnppJvAJkuamuebY18+H4/jSTf7zagS2+Oka9W35LK3AitFxKvACODyvPwB0nB/pXOBpYFb89cFLyisG5b3o6rcgx4OXAUsU2d7tbR0LMzMrJOp9k3ei7jx9J3uXSJinw5rpJ3kxL1jPhloa91uQPeImJN79LeR7uT/XzuH2VL7SwB3AltGxLzOaHNRDVlzxZjwi70aHYZZ4/iauS0ESRMjYkjl8rZ+Na0tDf6adPf7Dq2V7SKOIQ3tv7kQdXsBd0jqTrqWfEhnJfKsP3BCWRK5mZm1rw5L5hFxREdtuyNExIOLUPdt0t3iDZHvvP9Xo9o3M7PG8rPZzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOQ67KExZjX1XsWPszQzayfumZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWcn5q2nWEC+/8zKn3n9qo8Mws5I4ZfNTGh1Cl+aeuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZybWazCXNlzRJ0lRJV0nqVaPsCEnntm+I9ZF0mqTtWikzVtIeLaw7R9LWVZYPlXRDe8W5KCSdLmly/jxukdQvL19P0tgW6nTqZ9KVjpeZ2cdFPT3z2RExOCIGAf8DDu7gmBZKRIyKiL8vTF1JfYHNIuKudg6rsp1ui7iJn0XE+hExGLgBGAUQEVOAT0vqv4jbX0A7xGtmZp2grW9NuxtYPye/i4DVgFnAyIiY3FxI0tLAZGBgRLwraZk8vyZwK/AgMAzoAxwYEXdL6gH8BhgCzAOOjog7JI0AdgW6AYOAs4DFgX2AucAOEfF67pneEBF/ljQK2AnoCdwHfCciosZ+7QHcVIj/y8A5wHTg4cLyJYFfA+uRjt3oiPhLHq0YC6wNPAEMAA6LiAmSZgK/AL4EHCNpAHBk3ocHgUMjYr6k7YFTgSWAfwP7R8TMYpAR8VZhdkmguE/XA3sBZ7a0k5K+Cpycj81G1dqT9Bzps90eOFfSGcAluU53YM+IeLKlY9FS22Zm9bj4sIurLr9jmTuqLm9qaurAaMqj7mvmkhYDvgJMISWBRyJifeD7wLhi2Yh4G2gCvpoX7QVcHRHv5vnFImJT4Cig+b12h+W66wF7A5fkBA8piX8T2BT4ETArIjYE7gf2rRLuuRGxSR5N6Ans2MrubQFMzPvZA/gdKXltBXyqUO4k4PaI2IR0MvKznNQOBd7Ix+N0YONCnSWBqRHxOeA14BvAFrl3PR8YLmk5UpLdLiI2AiYAR1cLVNKPJL0ADCf3zLMJOd6qJO0GnADskBfVam9ORGwZEVfk+em53G+AY1s5Fi2SNFLSBEkTZr0xq1ZRMzNrg3p65j0lTcrTdwO/J/UodweIiNslfVJS74p6FwLHAdcC+wMHFdZdk/+dSOrFAmxJ6umRe37PAwPzujvyCcLbkmaQeqGQTizWrxLzMEnHAb2AvsBjhTrVrAS8mqfXBp6NiH8BSPojMDKv2x7YWVJzQusB9M+x/zLHPlXS+6MUpIR9dZ7elpToH5IE6URjGrAZsA5wb16+OOlE5UMi4iTgJEknAofzwcnQNKBfC/s3jDTisX1EvCVpx1bau7KifvHz+lorx6JFETEGGAPQ77P9ao2UmNnH1P7n7V91ud9nXls9yXx27kW+TzkDVFjgj3NE3CtpgKRtgG4RMbWwem7+d34hhmrbrCwP8F5h/j0q9iH3rM8HhkTEC5JGkxJNLbMryrSUaATsHhFPVbRZK/Y5ETG/UP+SiDixov5OwK0RsXcrcRZdBtzIB8m8B2k/qnmGdElkIKkXrlbae6divqXPq9qxWLHeHTAzs/axsF9Nu4s0zIukoaRh2LeqlBsHXA5UvwjS8jYHknp5T9WsUV1zUp4uaSnS9fDWPAGskaefBD4jafU8X0x4NwNHNCdvSRvm5fcAX8/L1iFdR67mNmAPSSvksn0lrQo8AGwhaY28vFc+BguQtGZhducca7OBwFSqe57Uox4nad1622tFS8fCzMw62cIm89HAkDycfAawXwvlLgWWJSX01pwPdJM0hTTMOyIi5rZS50Mi4k3SNe8ppCH+h+qodiMwNNefQxpWv1HSPaRE2Ox00k1gkyVNzfPNsS+fj8fxpJv9ZlSJ7XHStepbctlbgZUi4lVgBHB5Xv4Aabi/0hn5K4KTScPc3y2sG5b3o6rcgx4OXAUsU2d7tbR0LMzMrJOp9k3ei7jx9J3uXSJinw5rpJ3kxL1jPhloa91uQPeImJN79LeR7uT/XzuH2VL7SwB3AltGxLzOaHNR9ftsv/jORd9pdBhmVhK+Zp5ImhgRQyqXt/WraW1p8Neku993aK1sF3EMaWj/zYWo2wu4Q1J30rXkQzorkWf9gRPKksjNzKx9dVgyj4gjOmrbHSEiHlyEum+T7hZviHzn/b8a1b6ZmTWWn81uZmZWck7mZmZmJedkbmZmVnJO5mZmZiXnZG5mZlZyTuZmZmYl52RuZmZWck7mZmZmJddhD40xq6Xfkv38eEYzs3binrmZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWcv5pmDfHuyy/zyih/Nc3Mymel005tdAgf4p65mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJLXQylzRf0iRJUyVdL6lPG+s3SRqSp//aWn1Jz0larsrymW1pt4VtD5H0qzaUP1LSE5IuXdS2C9scIOmbCxtTK9te5GPUxvaqflZmZtYxFqVnPjsiBkfEIOB14LCF3VBE7BARby5CLIskIiZExJFtqHIosENEDG/HMAYA7yfzhYip3Unyi3jMzEqgvYbZ7wdWBpC0qaT7JD2S/10rL+8p6QpJkyVdCfRsrlzsyUm6VtJESY9JGllP45LOkvSwpNskLZ+XHSTpIUmPSrpaUq+8fM88mvCopLvysqGSbsjT2+QRh0l5H5auaOsCYDXgOknfkzRa0rGF9VNzL3tA7r3/Lu/LLZJ65jJrSPp7juFhSasDZwBb5Xa/VxFT33xcJkt6QNL6efloSRflUY5nJNVM/pKWk3S/pK9KWj4fl4fyzxaFbY6RdAswrlYbkr4l6R855t9K6lbP52VmZu1rkXte+Q/4tsDv86Inga0jYp6k7YAfA7sDhwCzImL9nIwebmGTB0TE6znxPSTp6oh4rUYISwIPR8QxkkYBpwCHA9dExO9yjD8EDgR+DYwCvhQRL7UwtH8scFhE3CtpKWBOcWVEHCzpy8CwiJguaXSN2NYE9o6IgyT9KR+HPwKXAmdExHhJPUgnVScAx0bEjjnmoYXtnAo8EhG7SvoCMA4YnNetDQwDlgaekvSbiHi3MhBJKwLXASdHxK2SLgPOjoh7JPUHbgY+m4tvDGwZEbPz/n2oDWAN4BvAFhHxrqTzgeE5NjOzLm/3cZcsVL3F77pzodtsampa6Lq1LEoy7ylpEml4eCJwa17eG7hE0ppAAN3z8q2BXwFExGRJk1vY7pGSdsvTq5ASYq1k/h5wZZ7+I3BNnh6Uk3gfYClSsgK4Fxibk+s1fNi9wC+UrodfExEv1mi7Nc9GxKQ8PREYkHv6K0fEeICImAMgqdZ2tiSdCBARt0v6pKTeed2NETEXmCtpGrAiUBlzd+A20klK82/hdsA6hXaXKYxCXBcRswv1q7WxLSnpP5S30ROYVmsn8kjLSICVe/euVdTMzNpgUZL57IgYnJPKDaRr5r8CTgfuiIjdJA0Amgp1otYGc290O2DziJglqQno0ca4mtsYC+waEY9KGgEMhfd71p8DvgpMkjR4gcoRZ0i6EdgBeEDSdhHxZI325rHg5YpivHML0/NJCa9m1m5BtTrN+1nZRrXPdB7pZOJLQHMy/wTpOBeTdvNJxTsV9au1IeCSiDixjvhTwBFjgDEAG/TrV/N3wcyso129734LVW+l005t50gW3SJfM4+IGcCRwLGSupN65i/l1SMKRe8iDcMiaRCwfpXN9QbeyIl8bWCzOkL4BLBHnv4mcE+eXhp4Jcf0/o1qklaPiAcjYhQwndT7p2L9lIj4KTCBNMRcy3PARrnuRsBnahWOiLeAFyXtmussoXQ9/+0cczXFYzcUmJ63U68ADgDWlnRCXnYL6XIEebuD27A9SD39PSStkOv3lbRqG7dhZmbtoF1ugIuIR4BHgb2AM4GfSLoXKN4Q9RtgqTy8fhzwjyqbuglYLJc5HXigjubfAdaVNBH4AnBaXv4D4EHS8H+xZ/0zSVMkTSUlyUcrtndUvontUWA28LdW2r8a6JsvORwC/LOOmPchXU6YDNwHfAqYDMzLN8V9r6L8aGBILn8G0ObTyYiYT/p8hkk6lHQCNiTfVPc4cHAbt/c4cDJwS47rVmCltsZlZmaLThEe7bTOt0G/fnHTtw9qdBhmZm3WyGF2SRMjYkjlcj8BzszMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKbpHfZ262MLr369cl3zxkZlZG7pmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnL9nbg3x9utzuOPSJxsdhpl1gGHD1250CB877pmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck/lCkHSSpMckTZY0SdLn8vILJa3TwW3/VVKfKstHSzq2yvKxkvboyJjqicPMzDqOX7TSRpI2B3YENoqIuZKWAxYHiIhvd3T7EbFDR7cBIEmAIuK9zmjPzMwWnpN5260ETI+IuQARMb15haQm4NiImCDpQOB44GXgX8DciDhc0lhgNrA2sCqwP7AfsDnwYESMyNvaG/g+IODGiDg+L38OGBIR0yWdBOwLvAC8CkysFbik04FVgAOAY4CvA0sA4yPiFEkDgL8Bd+R4jpJ0AXAP8HngJWCXiJgtaXXgPGB5YBZwUET4NWhmHyHf++G+C1Wvz+96LVS9pqamhapnHmZfGLcAq0j6p6TzJW1TWUBSP+AHwGbAF0mJu2hZ4AvA94DrgbOBdYH1JA3O9X+aywwGNpG0a0UbGwN7ARsCXwM2qRW0pDOBFUgnD9sBawKb5u1vLGnrXHQtYFxEbAg8n8udFxHrAm8Cu+dyY4AjImJj4Fjg/Frt5xhGSpogacKMt95orbiZmdXJPfM2ioiZOZFuBQwDrpR0QkSMLRTbFLgzIl4HkHQVMLCw/vqICElTgP9GxJRc7jFgAKnH3hQRr+bllwJbA9cWtrEVqUc9K5e5rkbYPyD1+kfmstsD2wOP5PVLkZL2f4DnI+KBQt1nI2JSnp4IDJC0FKmnflUajQdSD7+miBhDOglgrdUGRWvlzayxzj553ELV8/vMO5+T+UKIiPlAE9CUE/J+wNhCEVWpVjQ3//teYbp5fjFgXr2h1FnuIVLvu28+wRDwk4j4bbFQHmZ/p4VYAeYDPUkjOm9GxOA62zczsw7kYfY2krSWpDULiwaThqOL/gFsI2lZSYvxwdB0vR7M9ZeT1A3YG7izosxdwG6SekpaGtipxvZuAs4AbsxlbwYOyD1sJK0saYV6g4uIt4BnJe2Z60vSBvXWNzOz9uWeedstBfw6fz1sHvA0MLJYICJekvRjUlJ+GXgcmFFvAxHxiqQTSTeiCfhrRPyloszDkq4EJpFOJu5uZZtX5UR+HbADcBlwfx4mnwl8i9Tzrtdw4DeSTga6A1cAj7ahvpmZtRNF+NJlR5C0VL6+vhgwHrgoIsY3Oq6uYq3VBsUFp/+50WGYWQfwNfOOI2liRAypXO5h9o4zWtIkYCrwLAvevGZmZtZuPMzeQSLCT0EzM7NO4Z65mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyfl75tYQS/ft4adEmZm1E/fMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7fM7eGeOvVadw65txGh2HWoi+OPLzRIZjVzT1zMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczIHJM2XNEnSY5IelXS0pFIcG0kDJE1tx+2dJmm7PL1VPiaTJK0s6c/t1Y6ZmbUfv2glmR0RgwEkrQBcBvQGTmlkUI0QEaMKs8OBn0fExXl+j3q3I6lbRMxv1+DMzKwqJ/MKETFN0kjgIUmjgf2AIRFxOICkG0gJrknSTOA8YDvgDeD7wJlAf+CoiLhO0ghgV6AbMAg4C1gc2AeYC+wALAtcFREb5TbWBK6IiI2LsUlaA7gAWB6YD+yZ/21ePwD4A7BkXnR4RNwnaSXgSmAZ0md+CHAf8HtgCBDARRFxtqSxwA1AH+DrwJdyT/0k4IaIGCSpG3AGMBRYAjgvIn4raSjpBOgVYDCwThsOvVlDHXvWLxeYX/ayBQeimpqaOjEas7ZxMq8iIp7Jw+wrtFJ0SaApIo6XNB74IfBFUhK7BLgulxsEbAj0AJ4Gjo+IDSWdDewbEedImiFpcERMAvYHxlZp71LgjIgYL6kH6TJJMcZpwBcjYk4+IbiclKy/CdwcET/KibgXKdmuHBGDACT1qTgGF0rakpTA/5xPFJodCMyIiE0kLQHcK+mWvG5TYFBEPFsZfD5JGgmwQt9lWzikZmbWVk7mLVMdZf4H3JSnpwBzI+JdSVOAAYVyd0TE28DbkmYA1xfqrJ+nLwT2l3Q08A1SUvwgGGlpUvIdDxARc/LyYrHuwLmSBpN67APz8oeAiyR1B66NiEmSngFWk/Rr4EbgFuq3PbC+pOZh997Amvl4/KNaIs8xjwHGAAxctX+0oT2zDvfzY767wLzfZ25lUoqbvDqbpNVIyXAaMI8Fj1OPwvS7EdGclN4jDZsTEe+x4InS3ML0e4X5Yrmrga8AOwITI+K1yrDqCP17wH+BDUg98sVzPHcBWwMvAX+QtG9EvJHLNQGHkU4m6iXgiIgYnH8+ExHNJwPvtGE7ZmbWDpzMK0hannRd+tycqJ8DBkv6hKRVqOgxt5fc074Z+A1wcZX1bwEvSto1x7mEpF4VxXoDr+STiX1I1+mRtCowLSJ+R7pOvpGk5YBPRMTVwA+AjdoQ7s3AIbmnj6SBkpZspY6ZmXUQD7MnPSVNIg1TzyPdRPaLvO5e4FnSkPhU4OEOjONS4Gu0POS9D/BbSacB75JugHuvsP584GpJewJ38EEveSjw/yS9C8wE9gVWBi4ufAXvxDbEeSHpMsLDSuP8r5Ju8jMzswbQB6PE1miSjgV6R8QPGh1LRxu4av8476TjGh2GWYt8zdy6IkkTI2JI5XL3zLuIfDf86sAXGh2LmZmVi5N5FxERuzU6BjMzKyffAGdmZlZyTuZmZmYl52RuZmZWck7mZmZmJedkbmZmVnJO5mZmZiXnZG5mZlZy/p65NcQyy6/gJ2yZmbUT98zNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOQUEY2OwT6GJL0NPNXoOKpYDpje6CAqdMWYwHG1VVeMqyvGBI6rllUjYvnKhX42uzXKUxExpNFBVJI0oavF1RVjAsfVVl0xrq4YEziuheFhdjMzs5JzMjczMys5J3NrlDGNDqAFXTGurhgTOK626opxdcWYwHG1mW+AMzMzKzn3zM3MzErOydzMzKzknMytw0j6sqSnJD0t6YQq6yXpV3n9ZEkbdZG41pZ0v6S5ko7tjJjqjGt4Pk6TJd0naYMuEtcuOaZJkiZI2rLRMRXKbSJpvqQ9OjqmeuKSNFTSjHysJkka1RXiKsQ2SdJjku7sCnFJ+n+FYzU1f5Z9u0BcvSVdL+nRfLz27+iYWhUR/vFPu/8A3YB/A6sBiwOPAutUlNkB+BsgYDPgwS4S1wrAJsCPgGO70PH6PLBsnv5KFzpeS/HB/TfrA082OqZCuduBvwJ7dJFjNRS4oTN+p9oYVx/gcaB/nl+hK8RVUX4n4PauEBfwfeCneXp54HVg8c78XCt/3DO3jrIp8HREPBMR/wOuAHapKLMLMC6SB4A+klZqdFwRMS0iHgLe7eBY2hrXfRHxRp59APh0F4lrZuS/asCSQEffVVvP7xbAEcDVwLQOjqetcXW2euL6JnBNRPwH0v+BLhJX0d7A5V0krgCWliTSyezrwLxOiK1FTubWUVYGXijMv5iXtbVMI+JqhLbGdSBpVKOj1RWXpN0kPQncCBzQ6JgkrQzsBlzQwbG0Ka5s8zw8+zdJ63aRuAYCy0pqkjRR0r5dJC4AJPUCvkw6OesKcZ0LfBZ4GZgCfDci3uuE2Frkx7laR1GVZZU9tnrKtLdGtFmPuuOSNIyUzDv82jR1xhUR44HxkrYGTge2a3BM5wDHR8T81HnqFPXE9TDp2dozJe0AXAus2QXiWgzYGNgW6AncL+mBiPhng+NqthNwb0S83oHxNKsnri8Bk4AvAKsDt0q6OyLe6uDYWuSeuXWUF4FVCvOfJp3FtrVMI+JqhLrikrQ+cCGwS0S81lXiahYRdwGrS1quwTENAa6Q9BywB3C+pF07MKa64oqItyJiZp7+K9C9g49VXXHlMjdFxDsRMR24C+joGyzb8ru1F50zxA71xbU/6bJERMTTwLPA2p0UX3WNvGDvn4/uD+lM/xngM3xwE8m6FWW+yoI3wP2jK8RVKDuazrsBrp7j1R94Gvh8F/sc1+CDG+A2Al5qnm/0Z5jLj6VzboCr51h9qnCsNgX+05HHqg1xfRa4LZftBUwFBjU6rlyuN+ma9JId/Rm24Xj9Bhidp1fMv/PLdUZ8Lf14mN06RETMk3Q4cDPp7tCLIuIxSQfn9ReQ7jLegZSgZpHOdhsel6RPAROAZYD3JB1Fupu1w4bQ6jxeo4BPknqZAPOig9/gVGdcuwP7SnoXmA18I/JfuQbG1OnqjGsP4BBJ80jHaq+OPFb1xhURT0i6CZgMvAdcGBFTGx1XLrobcEtEvNOR8bQxrtOBsZKmkDojx0ca0WgYP87VzMys5HzN3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzazU8pu0JhV+Bkj6pKQ7JM2UdG6NujtKeiQ/XvVxSd/pzNjN2ou/mmZmpSZpZkQsVbFsSWBDYBDp4SeHV6nXHXge2DQiXpS0BDAgIp5ahFhE+rva0Od028ePe+Zm9pET6bGk9wBzahRbmvS0r9dynbnNiVzSipLG5x77o5I+n5cfnd+rPTU/TIg8EvCEpPNJz15fJb+H+yGl97yf2oG7agY4mZtZ+fUsDLGPr7dSpJd2XAc8L+lyScMlNf9N/BVwZ0RsQHpE7WOSNiY9pfBzpMcPHyRpw1x+LdLrfDfM02uSHtc6GNg4v4DGrMP4ca5mVnazI2LwwlSMiG9LWo/0lrdjgS8CI0hvw9o3l5kPzJC0JTC++bGikq4BtiKfEETEA3mz2+efR/L8UqTkftfCxGhWDydzM/tYi4gpwBRJfyC9/WpEC0VrvUu1+NxwAT+JiN+2T4RmrfMwu5l9LElaStLQwqLBpBviIL1B7JBcrpukZUg9610l9co32O0G3F1l0zcDB0haKtdfWdIKHbITZpl75mb2kZTfZb4MsHh+l/n2EfF4sQhwnKTfkt5g9g4f9Mq/C4yRdCAwHzgkIu6XNBb4Ry5zYUQ8ImlAsd2IuEXSZ4H789vtZgLfAqa19z6aNfNX08zMzErOw+xmZmYl52RuZmZWck7mZmZmJedkbtaF5CeP3SXpbUlnNTqerkjSUEkv1ll2tKQ/dmAsMyWtVmP9c5K2W8htD5AUkhbL83+TtF9h/Q8lTZf0f3l+N0kv5Jg2bGm7jVC5Lw2MY4SkexoZQ0dxMjdrhaQmSW/kZ3dXLv92xbIFEo2SI/PjP9+R9KKkq/KDSqoZCUwHlomIY9oh9sUlnZXbnSnpWUln53U3SzqtSp1dJP2fpMUkjc1/hHeuKHNOXj5iUWMss4hYKiKeAcjH6ocd2NZXIuKS3NYqwDHAOhHxqVzk58DhOaZHWtpOR6j2f8E6l5O5WQ35a0dbAQHsXLt0Vb8kfc3pSKAvMBC4FvhqC+VXBR6PhfiaSQu9nhOBIaRHiy4NDOODJ5ONBfbJLwcp2ge4NCLm5fl/AsUe4WLAnsC/2xqjtZtVgdciYlrFsscWZmON7jHXqyxxNoKTuVlt+wIPkBLffrWLLkjSmsBhwN4RcXt+kcesiLg0Is6oUr65jeNyL3o7SUvkXvDL+eec5hGC5lEAScfnodaLq4SxCekRpC9H8lxEjMvrriWdYGxViGFZYEdgXGEb1wNb5HUAXwYmA/9XY99H5xGIP+ZLBlMkDZR0oqRpeTh4+0L5fpKuk/S6pKclHVRY1zP3et+Q9HjeJyrqXi3p1TzycGQLMfXI8bwm6U2lF6GsWKXc/pKuL8w/LelPhfkXJA3O0yFpDUkjgeF88NldX9jkYKUXrsyQdKWkHi3E103Sz/PQ+TNUnPA1936Vhu1vBfrlti6XNBPoBjwq6d+tHZf8+fw5H4+3gBGSekv6vaRXJL2kNIzfLZcfIemeHN8beXtfyet+RPodOletvHK20P7uSpcgBkn6hKQTJP07fzZ/ktQ3l2senj9Q0n+A22vFkuu0uB8VMUjS2fn3cUb+jAa1FntX5WRuVtu+wKX550vV/vjXsC3wYkT8o9WSQESMyO2cmYdK/w6cRHqpx2BgA1IP++RCtU+REvKqpCH6Sg8AR0s6VNJ60ge98IiYDfwp72OzrwNPRsSjhWVzSM8f3yvP78uCyb4lOwF/AJYljQbcTPqbszJwGlB83OnlwItAP2AP4MeSts3rTgFWzz9fYsFRgk+QTjYezdvdFjhK0peqxLMf0BtYBfgkcDDpYTGV7gS2yklmJaA7sEVubzXSs9YnFytExBgW/Ox2Kqz+OukE6DPA+rT8uNiDSCdSG5JGU/aoVij/XnwFeDm3tXfhFbAbRMTqdR6XXYA/A31y7JcA84A1cgzbA8Wh888BTwHLAWcCv5ekiDiJ9CS85iH+D71utkjS/sBPge0iYipp1GpXYBvS5/8GcF5FtW2Az5I+/xZjyeta249m2wNbk0bL+gDfIL9Br4yczM1aoPRijVWBP0XERNKw8jfbsIlPAq8sYhjDgdMiYlpEvAqcShoGb/YecEru9VdLTD8h/eEcDkwAXlLhJirSH749JfXM8/vmZZXGAftK6k36w3ptHbHfHRE35+H6q4DlgTMi4l3gCmCApD5K13+3BI6PiDkRMQm4sLCfXwd+FBGvR8QLpDeaNdsEWD4iTouI/+Xr17/jgxOPondJn8kaETE/IiZGxFuVhfI23iadQG1DOgl5SdLaef7uNr6v/Fd5ZOR1UoId3EK5rwPnRMQLuexP2tBGpXqOy/0RcW3el2VIJwhH5dfHTgPOrij/fET8Lr945hJgJaAtJ7cARwH/DxgaEU/nZd8BToqIFyNiLjAa2EMLDqmPznE1/45XjSWfbLe2H83eJV16Wpv0ALUnImJR/782jK8/mLVsP+CWiJie5y/Ly87O8/NIvbai7qQ/EpDO8ldaxBj68cHzwsnT/Qrzr0ZEi+/szn/szgPOywn7AOAiSf/If7zukfQqsIukf5CSwNeqbOceScuTRgVuiIjZ+tCl9g/5b2F6NjA9x9M8D6mX2w94PSLertjPIXm6H/BCxbpmq5KGm98sLOtG9Wem/4HUK79CUh/gj6Qk8m6VsncCQ0m9uzuBN0mJfPM83xbFyxGzWPDzK6q1n21Vz3F5oaJ8d+CVwuf6iYoy7+9HRMzK5Zaibf4f6eS0+G2EVYHxkoonSPNZ8EShGEetWPrWsR/N9W7PlwTOA/orvT732GoneGXgnrlZFTnxfR3YRunO7v8DvgdsIGmDXOw/wICKqp9hwZd1fFrSEBbey6Q/ds3652XN6r5RLiJmR8R5pGHMdQqrxpF65PuQTl7+W60+KfkdQ31D7G3xMtBX0tKFZf2Bl/L0K6QkXFzX7AXg2YjoU/hZOiJ2qGwkIt6NiFMjYh3g86Qh7X0ry2XNyXyrPH0nKZlvQ8vJfFGfjV1rP9uqnuMSFeXnAssVyi8TEevW2V69+749cLKk3Sva/kpFrD0i4qVCmXq336b9iIhfRcTGwLqk4fb/V2c7XY6TuVl1u5J6B+uQhkUHk67Z3c0HCeBKYH9Jm+abaQaSEv4VABHxL+B84HKlm9UWV7oJay9JJ9QZx+WkP37LS1oOGEVKqnWRdFRuu6fSV832Iw0tFr+6NI70Pu+DqD7E3uxXpPd9t+t7ufPQ+X3AT/LxWR84kHQdF9J1/RMlLSvp08ARher/AN5Sugmwp9JNZIMkLXCTHICkYfm+gW7AW6QRlPmV5bI7SXf+98y9yLtJ170/yYLHrui/QIvfOa/Dn4AjJX1a6WbDen9Hqqn7uADk4eVbgLMkLZPvF1hd0jZ1tlfvvj9GOo7n6YOvO14A/EjSqgD5d32XOttdQFv2Q9Imkj4nqTvpJTtzaPn3octzMjerbj/g4oj4T0T8X/MPcC4wXNJiEXEz6Q/uxcAM4K+kZDimsJ0jc53zSEO1/ya9OrN4t3MtPyRd654MTAEezsvqNRs4izQsOZ10d/3u+RoqABHxHCmZLkm60a2qfM36togOeTvT3qRRjpeB8aT7AG7N604ljXY8S/pD/YdCTPNJN9oNzuunk663967SxqdIN3y9BTxBSthVT4wi4p+kt53dneffAp4B7i1cKqj0e2AdpTvlr219lz/kd6Tr84+SPudrFmIbQJuPS7N9gcWBx0mjN3+m/stEvyRd535D0q9qFYx0c+WOwO/yXei/JP3e3SLpbdJNm5+rs91q6t2PZUjH/A3S79drpO/ql5LfmmZmZlZy7pmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWcn5oTHWEMstt1wMGDCg0WGYmZXKxIkTp0fE8pXLncytIQYMGMCECRMaHYaZWalIqvpkQA+zm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWcnwBnDfHSm7M58ZopjQ7DzKxVP/naeo0OoVXumZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTeQeSNLPKsoMl7dvJcTwnablObK9J0pDOas/M7OPOL1rpZBFxQUduX5IARcR77bCtxSJiXjuEZWZmHcjJvJNJGg3MjIifS2oCHgSGAX2AAyPibkndgDOAocASwHkR8VtJSwF/AZYFugMnR8RfJA0A/gbcAWwO7Ao8X6XtnsB44GrgMuDXwHqk34PReVsjgK8CPYAlJY0DdgZ6AasD4yPiuLy97YFTc4z/BvaPiA+NRpiZdUWXjjqgrnL3/2rJuso1NTUtQjSLxsPsjbdYRGwKHAWckpcdCMyIiE2ATYCDJH0GmAPsFhEbkU4Azso9cYC1gHERsWFEfCiRA0sB1wOXRcTvgJOA23Mbw4CfSWr+jd0c2C8ivpDnBwPfICX+b0haJQ/bnwxsl+OZABxda0cljZQ0QdKEWTPeqPsAmZlZbe6ZN941+d+JwIA8vT2wvqQ98nxvYE3gReDHkrYG3gNWBlbMZZ6PiAdqtPMX4MyIuLTQxs6Sjs3zPYD+efrWiHi9UPe2iJgBIOlxYFXSSMI6wL35fGJx4P5aOxoRY4AxACutsW7UKmtm1tGGn3ZRXeXK8D5zJ/PGm5v/nc8Hn4eAIyLi5mLBPAS+PLBxRLwr6TlSEgZ4p5V27gW+IumyiIjcxu4R8VRFG5+rsq25henmOEVK+nu30q6ZmXUwD7N3TTcDh0jqDiBpYB4C7w1My4l8GKmHXK9RwGvA+YU2jmgeppe0YRtjfADYQtIauX4vSQPbuA0zM2sHTuYdq5ekFws/Na8pF1wIPA48LGkq8FtSb/hSYIikCcBw4Mk2xnMU0EPSmcDppJvoJuc2Tm/LhiLiVWAEcLmkyaTkvnYb4zEzs3agNOJq1rlWWmPdGHHmFY0Ow8ysVV3pmrmkiRHxoed4uGduZmZWck7mZmZmJedkbmZmVnJO5mZmZiXnZG5mZlZyTuZmZmYl52RuZmZWck7mZmZmJedkbmZmVnJO5mZmZiXnt6ZZQ6zcp2eXekSimVmZuWduZmZWck7mZmZmJedkbmZmVnJO5mZmZiXnZG5mZlZyTuZmZmYl56+mWWPMeAGu/26jozCzZjv9stER2CJwz9zMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrORaTeaS5kuaJGmqpKsk9apRdoSkc9s3xPpIOk3Sdq2UGStpjxbWnSNp6yrLh0q6ob3iXBSSfibpSUmTJY2X1CcvX0/S2BbqdOpn0pWOl5nZx0U9PfPZETE4IgYB/wMO7uCYFkpEjIqIvy9MXUl9gc0i4q52DquynW6LuIlbgUERsT7wT+BEgIiYAnxaUv9F3P4C2iFeMzPrBG0dZr8bWENSX0nX5h7iA5LWLxaStLSkZyV1z/PLSHpOUndJTZJ+Kukfkv4paatcpoekiyVNkfSIpGF5+Yjc1vV5m4dLOjqXeSAn4gV63ZJGSXoojyaMkaRW9msP4KZC/F/OPeB7gK8Vli8p6aK87Uck7ZKX95L0p3w8rpT0oKQhed3MPGrwILC5pG/lfZ8k6bfNCVPS9pLul/RwHgFZqjLIiLglIubl2QeATxdWXw/sVWsnJX01t7FcS+3lz2lU3vc98/ypudwUSWvXOhZmZtb56n4FqqTFgK+Qkt6pwCMRsaukLwDjgMHNZSPibUlNwFeBa0lJ5uqIeDfn1cUiYlNJOwCnANsBh+W66+WEcYukgXmTg4ANgR7A08DxEbGhpLOBfYFzKsI9NyJOy3H/AdiRlOxasgXw51y+B/A74Au5rSsL5U4Cbo+IA/IQ9z8k/R04BHgjItaXNAiYVKizJDA1IkZJ+ixwPLBFPhbnA8Ml/RU4GdguIt6RdDxwNHBajZgPqIhtAnACcGa1wpJ2y9vcAejWSntzImLLXO8MYHpEbCTpUOBY4Ns1joWZdRFDv391/YXPerRN225qampbMNah6knmPSVNytN3A78HHgR2B4iI2yV9UlLvinoXAseRkvn+wEGFddfkfycCA/L0lsCv8zaflPQ80JzM74iIt4G3Jc3gg8Q8BVhgVCAbJuk4oBfQF3iM2sl8JeDVPL028GxE/AtA0h+BkXnd9sDOko7N8z2A/jn2X+bYp0qaXNj2fKD5f9S2wMbAQ/mkpicwDdgMWAe4Ny9fHLi/pWAlnQTMAy4tLJ4G9GuhyjBgCLB9RLwlacdW2ruyon7x82oeqWjpWLRI0kjysey//NK1ipqZWRvUk8xnR8Tg4oIWhq1jgZmIeyUNkLQN0C0iphZWz83/zi/EUGsofG5h+r3C/HtU7EPuWZ8PDImIFySNJiWaWmZXlIkWygnYPSKeqmizVuxzImJ+of4lEXFiRf2dgFsjYu9W4kTSfqSRhm0johhnj7wf1TwDrEY6OZqQ46jV3jsV8y19XtWOxYotxR4RY4AxAEPWXLGlY2xm7aTpx7vXX3inX3ZcINbhFvaraXcBwyHdvUwahn2rSrlxwOXAxW3c5kBSL++pmjWqa07K0/N14Kp3r1d4AlgjTz8JfEbS6nm+mPBuBo5oTt6SNszL7wG+npetA6zXQju3AXtIWiGX7StpVdL17y0krZGX9ypcYnifpC+Thul3johZFasHAlMr62TPk3rU4yStW297rWjpWJiZWSdb2GQ+GhiSh5PPAPZrodylwLKkhN6a84FukqaQhnlHRMTcVup8SES8SbrmPYU0xP9QHdVuBIbm+nNIQ8E35pvAni+UOx3oDkyWNDXPN8e+fD4exwOTgRlVYnucdK36llz2VmCliHgVGAFcnpc/QBrur3QusDRwa76B7oLCumF5P6rKPejhwFXAMnW2V0tLx8LMzDqZFhypbeeNp7vLd4mIfTqskXaSE/eO+WSgrXW7Ad0jYk7u0d8GDIyI/7VzmC21vwRwJ7Bl4W73Lm3ImivGhF/UvPnezDqTh9lLQdLEiBhSubzuu9kXosFfk+5+36Gj2mhnx5CG9t9ciLq9gDuUvoon4JDOSuRZf+CEsiRyMzNrXx2WzCPiiI7adkeIiAcXoe7bpLvFGyLfef+vRrVvZmaN5Wezm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWcl12ENjzGrqvYofH2lm1k7cMzczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5f8/cGuLld17m1PtPbXQYZmbvO2XzUxodwkJzz9zMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrORaTeaS5kuaJGmqpKsk9apRdoSkc9s3xPpIOk3Sdq2UGStpjxbWnSNp6yrLh0q6ob3iXBSSTpc0OX8et0jql5evJ2lsC3U69TPpSsfLzOzjop6e+eyIGBwRg4D/AQd3cEwLJSJGRcTfF6aupL7AZhFxVzuHVdlOt0XcxM8iYv2IGAzcAIwCiIgpwKcl9V/E7S+gHeI1M7NO0Na3pt0NrJ+T30XAasAsYGRETG4uJGlpYDIwMCLelbRMnl8TuBV4EBgG9AEOjIi7JfUAfgMMAeYBR0fEHZJGALsC3YBBwFnA4sA+wFxgh4h4PfdMb4iIP0saBewE9ATuA74TEVFjv/YAbirE/2XgHGA68HBh+ZLAr4H1SMdudET8JY9WjAXWBp4ABgCHRcQESTOBXwBfAo6RNAA4Mu/Dg8ChETFf0vbAqcASwL+B/SNiZjHIiHirMLskUNyn64G9gDNb2klJXwVOzsdmo2rtSXqO9NluD5wr6QzgklynO7BnRDzZ0rFoqW0zs0a7+LCLa66/Y5k7aq5vampqx2jaV93XzCUtBnwFmEJKAo9ExPrA94FxxbIR8TbQBHw1L9oLuDoi3s3zi0XEpsBRQPM75w7LddcD9gYuyQkeUhL/JrAp8CNgVkRsCNwP7Fsl3HMjYpM8mtAT2LGV3dsCmJj3swfwO1Ly2gr4VKHcScDtEbEJ6WTkZzmpHQq8kY/H6cDGhTpLAlMj4nPAa8A3gC1y73o+MFzScqQku11EbARMAI6uFqikH0l6ARhO7plnE3K8VUnaDTgB2CEvqtXenIjYMiKuyPPTc7nfAMe2cixaJGmkpAmSJsx6Y1atomZm1gb19Mx7SpqUp+8Gfk/qUe4OEBG3S/qkpN4V9S4EjgOuBfYHDiqsuyb/O5HUiwXYktTTI/f8ngcG5nV35BOEtyXNIPVCIZ1YrF8l5mGSjgN6AX2Bxwp1qlkJeDVPrw08GxH/ApD0R2BkXrc9sLOk5oTWA+ifY/9ljn2qpPdHKUgJ++o8vS0p0T8kCdKJxjRgM2Ad4N68fHHSicqHRMRJwEmSTgQO54OToWlAvxb2bxhpxGP7iHhL0o6ttHdlRf3i5/W1Vo5FiyJiDDAGoN9n+9UaKTEza3f7n7d/zfVlfp95Pcl8du5Fvk85A1RY4I9zRNwraYCkbYBuETG1sHpu/nd+IYZq26wsD/BeYf49KvYh96zPB4ZExAuSRpMSTS2zK8q0lGgE7B4RT1W0WSv2ORExv1D/kog4saL+TsCtEbF3K3EWXQbcyAfJvAdpP6p5hnRJZCCpF65W2nunYr6lz6vasVix3h0wM7P2sbBfTbuLNMyLpKGkYdi3qpQbB1wO1L5Q8eFtDiT18p6qWaO65qQ8XdJSpOvhrXkCWCNPPwl8RtLqeb6Y8G4GjmhO3pI2zMvvAb6el61Duo5czW3AHpJWyGX7SloVeADYQtIaeXmvfAwWIGnNwuzOOdZmA4GpVPc8qUc9TtK69bbXipaOhZmZdbKFTeajgSF5OPkMYL8Wyl0KLEtK6K05H+gmaQppmHdERMxtpc6HRMSbpGveU0hD/A/VUe1GYGiuP4c0rH6jpHtIibDZ6aSbwCZLmprnm2NfPh+P40k3+82oEtvjpGvVt+SytwIrRcSrwAjg8rz8AdJwf6Uz8lcEJ5OGub9bWDcs70dVuQc9HLgKWKbO9mpp6ViYmVknU+2bvBdx4+k73btExD4d1kg7yYl7x3wy0Na63YDuETEn9+hvI93J/792DrOl9pcA7gS2jIh5ndHmour32X7xnYu+0+gwzMzeV4Zr5pImRsSQyuVt/WpaWxr8Nenu9x1aK9tFHEMa2n9zIer2Au6Q1J10LfmQzkrkWX/ghLIkcjMza18dlswj4oiO2nZHiIgHF6Hu26S7xRsi33n/r0a1b2ZmjeVns5uZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZVch33P3KyWfkv2K8XTlszMysA9czMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5Lz98ytId59+WVeGeXvmZvZR8dKp53asLbdMzczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzK7mFTuaS5kuaJGmqpOsl9Wlj/SZJQ/L0X1urL+k5SctVWT6zLe22sO0hkn7VhvJHSnpC0qWL2nZhmwMkfXNhY2pl24t8jNrYXtXPyszMOsai9MxnR8TgiBgEvA4ctrAbiogdIuLNRYhlkUTEhIg4sg1VDgV2iIjh7RjGAOD9ZL4QMbU7SX4Rj5lZCbTXH+v7gfUBJG0KnAP0BGYD+0fEU5J6AhcD6wBP5PXkOs8BQyJiuqRrgVWAHsAvI2JMa41LOgsYBrwB7BURr0o6CBgJLA48DewTEbMk7QmcAswHZkTE1pKGAsdGxI6StgF+mTcdwNYR8XahrQuA1YDrJF0E9AZmRsTP8/qpwI65+N+Ae4DPAy8Bu0TEbElrABcAy+c49gTOAD4raRJwCfBIIaa+wEW53VnAyIiYLGk00D8v7w+cExEt9uZzb/l64IfAP3IM/fPqoyLi3rzNfqSTi+mS/tlSG5K+BRyZj/GDwKERMb+l9s3Mymj3cZfUVW7xu+5stUxTU9MiRlPdIl8zl9QN2Ba4Li96kpQANwRGAT/Oyw8BZkXE+sCPgI1b2OQBEbExMAQ4UtInWwlhSeDhiNgIuJOUqAGuiYhNImID0snDgXn5KOBLefnOVbZ3LHBYRAwGtiKdkLwvIg4GXgaGRcTZrcS2JnBeRKwLvAnsnpdfmpdvQEr0rwAnAHfn0Y7K7Z4KPJKP3feBcYV1awNfAjYFTpHUvVogklYEbgRGRcSNpBOWsyNikxzXhYXiG5NOPJpHCj7UhqTPAt8AtsjHaj5Qc6RC0khJEyRNeG3WrFpFzcysDRalZ94z9yIHABOBW/Py3sAlktYk9Wybk8vWwK8Acq9ycgvbPVLSbnl6FVJCfK1GHO8BV+bpPwLX5OlBkn4I9AGWAm7Oy+8Fxkr6U6Fs0b3AL/L18Gsi4sUabbfm2YiYlKcnAgMkLQ2sHBHjASJiDoCkWtvZknwiEBG3S/qkpN553Y0RMReYK2kasCJQGXN34DbSSUrzqeN2wDqFdpfJsQFcFxHFk5hqbWxLSvoP5W30BKbV2ok8yjIGYIN+/aJWWTOzruLqfferq1xZ32c+O/fIViUNszZfMz8duCNfS9+JNFzerOYf8DzcvR2wee61PlJRvx7NbYwFDo+I9Ug92x7wfs/6ZNKJwqTKnn9EnAF8m5ScHpC0divtzWPB41iMd25hej7p5Klm1m5BtTrN+1mtjWoxTiT1rpt9gnScB+eflQuXE96pqN/SflxSqL9WRIyub3fMzKw9LfIwe0TMIF03PTYP8fYmXR8GGFEoehd5GFbSIPI19gq9gTfyte21gc3qCOETwB55+puka9QASwOv5JjeH/6VtHpEPBgRo4DppKROxfopEfFTYAJpiLmW54CNct2NgM/UKhwRbwEvSto111lCUi/g7RxzNcVjNxSYnrdTrwAOANaWdEJedgtweHMBSYPbsD1IPf09JK2Q6/eVtGobt2FmZu2gXb5nHhGPAI8CewFnAj+RdC/QrVDsN8BSeXj9ONINWJVuAhbLZU4HHqij+XeAdSVNBL4AnJaX/4B0U9atpOv4zX4maUq+Ue2uHHfRUfnrdo+Srpf/rZX2rwb65ksOhwD/rCPmfUiXEyYD9wGfAiYD8yQ9Kul7FeVHA0Ny+TOA+sZ8CvKNaXsBwyQdSjoBGyJpsqTHgYPbuL3HSSMct+S4bgVWamtcZma26BThS5fW+Tbo1y9u+vZBjQ7DzKzddMY1c0kTI2JI5XI/Ac7MzKzknMzNzMxKzsnczMys5JzMzczMSs7J3MzMrOSczM3MzErOydzMzKzknMzNzMxKzsnczMys5NrrfeZmbdK9X7+GvmHIzOyjxD1zMzOzknMyNzMzKzknczMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzkvP3zK0h3n59Dndc+mSjwzCzEhg2fO1Gh9DluWduZmZWck7mZmZmJedkbmZmVnJO5mZmZiXnZG5mZlZyTuZmZmYl52RuZmZWck7mZmZmJedkbmZmVnJO5mZmZiXnZG5mZlZyTuYLQdJJkh6TNFnSJEmfy8svlLROB7f9V0l9qiwfLenYKsvHStqjI2OqJw4zM+s4ftFKG0naHNgR2Cgi5kpaDlgcICK+3dHtR8QOHd0GgCQBioj3OqM9MzNbeE7mbbcSMD0i5gJExPTmFZKagGMjYoKkA4HjgZeBfwFzI+JwSWOB2cDawKrA/sB+wObAgxExIm9rb+D7gIAbI+L4vPw5YEhETJd0ErAv8ALwKjCxVuCSTgdWAQ4AjgG+DiwBjI+IUyQNAP4G3JHjOUrSBcA9wOeBl4BdImK2pNWB84DlgVnAQRHh16CZWV2+98N96y7b53e96i7b1NS0ENGUn4fZ2+4WYBVJ/5R0vqRtKgtI6gf8ANgM+CIpcRctC3wB+B5wPXA2sC6wnqTBuf5Pc5nBwCaSdq1oY2NgL2BD4GvAJrWClnQmsALp5GE7YE1g07z9jSVtnYuuBYyLiA2B53O58yJiXeBNYPdcbgxwRERsDBwLnF+r/RzDSEkTJE2Y8dYbrRU3M7M6uWfeRhExMyfSrYBhwJWSToiIsYVimwJ3RsTrAJKuAgYW1l8fESFpCvDfiJiSyz0GDCD12Jsi4tW8/FJga+Dawja2IvWoZ+Uy19UI+wekXv/IXHZ7YHvgkbx+KVLS/g/wfEQ8UKj7bERMytMTgQGSliL11K9Ko/FA6uHXFBFjSCcBrLXaoGitvJl9dJ198ri6y/p95q1zMl8IETEfaAKackLeDxhbKKIq1Yrm5n/fK0w3zy8GzKs3lDrLPUTqfffNJxgCfhIRvy0WysPs77QQK8B8oCdpROfNiBhcZ/tmZtaBPMzeRpLWkrRmYdFg0nB00T+AbSQtK2kxPhiarteDuf5ykroBewN3VpS5C9hNUk9JSwM71djeTcAZwI257M3AAbmHjaSVJa1Qb3AR8RbwrKQ9c31J2qDe+mZm1r7cM2+7pYBf56+HzQOeBkYWC0TES5J+TErKLwOPAzPqbSAiXpF0IulGNAF/jYi/VJR5WNKVwCTSycTdrWzzqpzIrwN2AC4D7s/D5DOBb5F63vUaDvxG0slAd+AK4NE21Dczs3aiCF+67AiSlsrX1xcDxgMXRcT4RsfVVay12qC44PQ/NzoMMysBXzP/gKSJETGkcrmH2TvOaEmTgKnAsyx485qZmVm78TB7B4kIPwXNzMw6hXvmZmZmJedkbmZmVnJO5mZmZiXnZG5mZlZyTuZmZmYl52RuZmZWck7mZmZmJedkbmZmVnJ+aIw1xNJ9e/gRjWZm7cQ9czMzs5JzMjczMys5J3MzM7OSczI3MzMrOSdzMzOzknMyNzMzKzl/Nc0a4q1Xp3HrmHMbHYYZAF8ceXijQzBbJO6Zm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJO5mZlZyTmZm5mZlZyTuZmZWck5mZuZmZWck7mZmVnJOZmbmZmVnJM5IGm+pEmSHpP0qKSjJZXi2EgaIGlqO27vNEnb5emt8jGZJGllSX9ur3bMzKz9+EUryeyIGAwgaQXgMqA3cEojg2qEiBhVmB0O/DwiLs7ze9S7HUndImJ+uwZnZmZVOZlXiIhpkkYCD0kaDewHDImIwwEk3UBKcE2SZgLnAdsBbwDfB84E+gNHRcR1kkYAuwLdgEHAWcDiwD7AXGAHYFngqojYKLexJnBFRGxcjE3SGsAFwPLAfGDP/G/z+gHAH4Al86LDI+I+SSsBVwLLkD7zQ4D7gN8DQ4AALoqIsyWNBW4A+gBfB76Ue+onATdExCBJ3YAzgKHAEsB5EfFbSUNJJ0CvAIOBddpw6M06zbFn/XKB+WUv+2DQqampqZOjMVt0TuZVRMQzeZh9hVaKLgk0RcTxksYDPwS+SEpilwDX5XKDgA2BHsDTwPERsaGks4F9I+IcSTMkDY6IScD+wNgq7V0KnBER4yX1IF0mKcY4DfhiRMzJJwSXk5L1N4GbI+JHORH3IiXblSNiEICkPhXH4EJJW5IS+J/ziUKzA4EZEbGJpCWAeyXdktdtCgyKiGcrg88nSSMBVui7bAuH1MzM2srJvGWqo8z/gJvy9BRgbkS8K2kKMKBQ7o6IeBt4W9IM4PpCnfXz9IXA/pKOBr5BSoofBCMtTUq+4wEiYk5eXizWHThX0mBSj31gXv4QcJGk7sC1ETFJ0jPAapJ+DdwI3EL9tgfWl9Q87N4bWDMfj39US+Q55jHAGICBq/aPNrRn1q5+fsx3F5j3+8yt7Epxk1dnk7QaKRlOA+ax4HHqUZh+9/+3d7+hktV1HMffH7MNTVPTNUzddbNMQ1rZrKR/mD2olUINg7bcBamgfxJBZf/sQT6xJxFiZmUpRiDRmlmUEpRZ2WYpq66KtWnYlvgfNQVz3W8PzhFvw+6958qdOXN23i8Yds7M7y7f+TKXz/x+c+75VdWzobSDZtmcqtrB/39QemrO/R1zjueO2wisBd4N3FhVD42W1aH0TwP3AatpZuTL2nquA94G/Av4QZINVfVIO+5a4BM0Hya6CnBWVR3X3lZV1bMfBp5YxP8jSVoChvmIJMtpvpe+oA3qfwDHJdkjyeGMzJiXSjvTvgb4FnDJTp5/DNiW5NS2zhcl2Xtk2H7Ave2HifU039OTZCVwf1V9l+Z78jVJDgL2qKqNwDnAmkWUew3wsXamT5Kjkrx4gZ+RJI2Jy+yNvZJsplmm3k5zEtnX2+f+ANxNsyS+BbhpjHX8EHgvu17yXg98O8lXgadpToDbMef5C4GNSd4H/IbnZsknAp9N8jTwH2ADcChwyZw/wfvCIuq8mOZrhJvSrPM/QHOSnySpB3lulVh9S/IZYL+qOqfvWsbtqJUr6ptf+lzfZUiA35lrOJLcWFXHjz7uzHxKtGfDHwmc1HctkqRhMcynRFWd1ncNkqRh8gQ4SZIGzjCXJGngDHNJkgbOMJckaeAMc0mSBs4wlyRp4AxzSZIGzjCXJGngvGiMevGS5Qd7CU1JWiLOzCVJGjjDXJKkgTPMJUkaOMNckqSBM8wlSRo4w1ySpIEzzCVJGjjDXJKkgTPMJUkaOMNckqSBS1X1XYNmUJLHgTv7rmOKHQQ82HcRU8z+zM/+zG/I/VlZVctHH/Ta7OrLnVV1fN9FTKskf7E/u2Z/5md/5rc79sdldkmSBs4wlyRp4Axz9eU7fRcw5ezP/OzP/OzP/Ha7/ngCnCRJA+fMXJKkgTPMJUkaOMNcY5PkXUnuTLI1yed38nySnN8+f0uSNX3U2ZcO/flg25dbklyfZHUfdfZpoR7NGff6JM8kOX2S9fWtS3+SnJhkc5Lbkvx20jX2qcPv2H5Jfpbk5rY/Z/ZR55KoKm/elvwGvAD4O/AKYBlwM/CakTEnA78EApwA/KnvuqesP28CDmjvr52l/nTt0ZxxvwZ+AZzed93T1B9gf+B2YEV7fHDfdU9Zf74IfK29vxx4GFjWd+3P5+bMXOPyBmBrVd1VVf8FLgdOGRlzCnBZNTYB+yc5ZNKF9mTB/lTV9VX1SHu4CThswjX2rct7COAsYCNw/ySLmwJd+vMB4IqqugegqmapR136U8C+SQLsQxPm2ydb5tIwzDUuhwL/nHO8rX1ssWN2V4t97R+iWcWYJQv2KMmhwGnARROsa1p0eQ8dBRyQ5NokNybZMLHq+telPxcAxwD/Bm4FPlVVOyZT3tLycq4al+zksdG/g+wyZnfV+bUneTtNmL9lrBVNny49+gZwdlU900yuZkqX/uwJvA54B7AX8Mckm6rqr+Mubgp06c87gc3AScCRwK+S/K6qHhtzbUvOMNe4bAMOn3N8GM2n38WO2V11eu1JXgtcDKytqocmVNu06NKj44HL2yA/CDg5yfaqunIiFfar6+/Yg1X1BPBEkuuA1cAshHmX/pwJnFfNl+Zbk9wNHA3cMJkSl47L7BqXPwOvSrIqyTLg/cBVI2OuAja0Z7WfADxaVfdOutCeLNifJCuAK4D1MzKTGrVgj6pqVVUdUVVHAD8GPj4jQQ7dfsd+Crw1yZ5J9gbeCNwx4Tr70qU/99CsWpDkZcCrgbsmWuUScWausaiq7Uk+CVxDc1bp96vqtiQfbZ+/iObs45OBrcCTNJ+SZ0LH/nwFOBC4sJ15bq/dbKen+XTs0czq0p+quiPJ1cAtwA7g4qra0l/Vk9Px/XMucGmSW2mW5c+uqkFujerlXCVJGjiX2SVJGjjDXJKkgTPMJUkaOMNckqSBM8wlSRo4w1zSTElyWpJKcnR7fGKSn4+MufTZHdiSvDDJeUn+lmRLkhuSrO2jdmlXDHNJs2Yd8Huai4h0cS5wCHBsVR0LvAfYd0y1Sc+LYS5pZiTZB3gzzbXuFwzz9qppHwHOqqqnAKrqvqr60VgLlRbJMJc0S04Frm4vj/twkjULjH8lcM8QN97QbDHMJc2SdTT7WtP+u45d79Tn5TE1GF6bXdJMSHIgzVaXxyYpmut1F3AZcMDI8JcCD9LsG7Aiyb5V9fgk65UWw5m5pFlxOnBZVa1sd1o7HLibJrhfnuQYgCQrabYJ3VxVTwLfA85vd94iySFJzujnJUg7Z5hLmhXrgJ+MPLaR5kS4M4BLkmym2Ur1w1X1aDvmy8ADwO1JtgBXtsfS1HDXNEmSBs6ZuSRJA2eYS5I0cIa5JEkDZ5hLkjRwhrkkSQNnmEuSNHCGuSRJA/c/wWcf7SLGsRkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x1872 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot bar graphs that show mean and standard deviation of the performance metrics of SVM models with different kernels \n",
    "x_labels = ['Linear kernel',\n",
    "            'Polynomial (degree 2) kernel',\n",
    "            'Polynomial (degree 3) kernel',\n",
    "            'Radial basis function kernel',\n",
    "            'Sigmoid kernel',\n",
    "            'Dummy classifier']\n",
    "n_bars = len(mean_scores_table.iloc[0,:-1])\n",
    "xval = np.arange(n_bars)\n",
    "ax = plt.figure(figsize = (6,26))\n",
    "for k in range(len(mean_scores_table)):\n",
    "   ax = plt.subplot(5,1,k+1)\n",
    "   for j in xval:\n",
    "      plt.barh([j], mean_scores_table.iloc[k,j], xerr=std_scores_table.iloc[k,j], alpha=0.6, align='center')\n",
    "   plt.title('%s for SVM models with different kernels'%mean_scores_table.index[k])\n",
    "   plt.xlabel('%s'%mean_scores_table.index[k])\n",
    "   ax.set_yticks(xval)\n",
    "   ax.invert_yaxis()\n",
    "   ax.set_yticklabels(x_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM model with radial basis function (RBF) kernel yielded highest AUC score, accuracy, precision, recall and F1 score. Linear kernal and the third degree polynomial kernel model were next best models. The Linear kernel model was the second highest in terms of AUC score, accuracy, recall and F1 score, while the third degree polynomial kernel showed second highest precision. The sigmoid kernel model was better than the  second degree polynomial kernel model in terms of AUC score, accuracy, precision, recall and F1 score amongst the SVM models. \n",
    "\n",
    "The dummy classifier model that makes stratified random class predictions showed poorest performance in all the perfomance metrics (AUC, accuracy, precision, recall and F1 score).\n",
    "\n",
    "I will search for the best hyperparameters for the RBF kernel, linear kernel and third degree polynomial kernel models, since these three kernels showed the highest performance in terms of AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform randomized search on SVM model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed randomized search on combinations of the following hyperparameters for the 5-fold cross-validated SVM model.\n",
    "- kernel: 'rbf', 'poly' (with 'degree' set to 3), 'linear'\n",
    "- C: four options, 0.1, 1,10 or 100 \n",
    "- gamma (only for 'rbf' kernel): three options, 0.01, 0.02 or 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters found:\n",
      "\n",
      "{'kernel': 'rbf', 'gamma': 0.02, 'C': 100}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.731 (+/-0.061) for {'kernel': 'linear', 'C': 0.1}\n",
      "0.609 (+/-0.053) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 1}\n",
      "0.653 (+/-0.042) for {'kernel': 'poly', 'gamma': 0.02, 'degree': 3, 'C': 10}\n",
      "0.694 (+/-0.045) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 10}\n",
      "0.509 (+/-0.035) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 0.1}\n",
      "0.741 (+/-0.054) for {'kernel': 'rbf', 'gamma': 0.01, 'C': 1}\n",
      "0.715 (+/-0.047) for {'kernel': 'poly', 'gamma': 0.02, 'degree': 3, 'C': 100}\n",
      "0.784 (+/-0.056) for {'kernel': 'rbf', 'gamma': 0.02, 'C': 100}\n",
      "0.659 (+/-0.040) for {'kernel': 'poly', 'gamma': 0.01, 'degree': 3, 'C': 100}\n",
      "0.745 (+/-0.064) for {'kernel': 'rbf', 'gamma': 0.02, 'C': 1}\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bona/Applications/miniconda2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/bona/Applications/miniconda2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/bona/Applications/miniconda2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/bona/Applications/miniconda2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "\n",
      "{'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 1}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.745 (+/-0.056) for {'kernel': 'linear', 'C': 0.1}\n",
      "0.834 (+/-0.133) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 1}\n",
      "0.824 (+/-0.041) for {'kernel': 'poly', 'gamma': 0.02, 'degree': 3, 'C': 10}\n",
      "0.801 (+/-0.049) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 10}\n",
      "0.147 (+/-0.587) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 0.1}\n",
      "0.747 (+/-0.057) for {'kernel': 'rbf', 'gamma': 0.01, 'C': 1}\n",
      "0.779 (+/-0.073) for {'kernel': 'poly', 'gamma': 0.02, 'degree': 3, 'C': 100}\n",
      "0.758 (+/-0.057) for {'kernel': 'rbf', 'gamma': 0.02, 'C': 100}\n",
      "0.814 (+/-0.060) for {'kernel': 'poly', 'gamma': 0.01, 'degree': 3, 'C': 100}\n",
      "0.741 (+/-0.057) for {'kernel': 'rbf', 'gamma': 0.02, 'C': 1}\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters found:\n",
      "\n",
      "{'kernel': 'rbf', 'gamma': 0.02, 'C': 100}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.702 (+/-0.086) for {'kernel': 'linear', 'C': 0.1}\n",
      "0.277 (+/-0.141) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 1}\n",
      "0.388 (+/-0.097) for {'kernel': 'poly', 'gamma': 0.02, 'degree': 3, 'C': 10}\n",
      "0.515 (+/-0.097) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 10}\n",
      "0.028 (+/-0.110) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 0.1}\n",
      "0.730 (+/-0.072) for {'kernel': 'rbf', 'gamma': 0.01, 'C': 1}\n",
      "0.603 (+/-0.093) for {'kernel': 'poly', 'gamma': 0.02, 'degree': 3, 'C': 100}\n",
      "0.835 (+/-0.078) for {'kernel': 'rbf', 'gamma': 0.02, 'C': 100}\n",
      "0.412 (+/-0.094) for {'kernel': 'poly', 'gamma': 0.01, 'degree': 3, 'C': 100}\n",
      "0.753 (+/-0.099) for {'kernel': 'rbf', 'gamma': 0.02, 'C': 1}\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters found:\n",
      "\n",
      "{'kernel': 'rbf', 'gamma': 0.02, 'C': 100}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.723 (+/-0.069) for {'kernel': 'linear', 'C': 0.1}\n",
      "0.410 (+/-0.154) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 1}\n",
      "0.525 (+/-0.093) for {'kernel': 'poly', 'gamma': 0.02, 'degree': 3, 'C': 10}\n",
      "0.626 (+/-0.078) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 10}\n",
      "0.046 (+/-0.185) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 0.1}\n",
      "0.738 (+/-0.056) for {'kernel': 'rbf', 'gamma': 0.01, 'C': 1}\n",
      "0.678 (+/-0.064) for {'kernel': 'poly', 'gamma': 0.02, 'degree': 3, 'C': 100}\n",
      "0.794 (+/-0.054) for {'kernel': 'rbf', 'gamma': 0.02, 'C': 100}\n",
      "0.546 (+/-0.082) for {'kernel': 'poly', 'gamma': 0.01, 'degree': 3, 'C': 100}\n",
      "0.746 (+/-0.072) for {'kernel': 'rbf', 'gamma': 0.02, 'C': 1}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters found:\n",
      "\n",
      "{'kernel': 'rbf', 'gamma': 0.02, 'C': 100}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.834 (+/-0.055) for {'kernel': 'linear', 'C': 0.1}\n",
      "0.818 (+/-0.046) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 1}\n",
      "0.828 (+/-0.041) for {'kernel': 'poly', 'gamma': 0.02, 'degree': 3, 'C': 10}\n",
      "0.829 (+/-0.042) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 10}\n",
      "0.814 (+/-0.052) for {'kernel': 'poly', 'gamma': 0.03, 'degree': 3, 'C': 0.1}\n",
      "0.841 (+/-0.052) for {'kernel': 'rbf', 'gamma': 0.01, 'C': 1}\n",
      "0.825 (+/-0.053) for {'kernel': 'poly', 'gamma': 0.02, 'degree': 3, 'C': 100}\n",
      "0.851 (+/-0.044) for {'kernel': 'rbf', 'gamma': 0.02, 'C': 100}\n",
      "0.828 (+/-0.043) for {'kernel': 'poly', 'gamma': 0.01, 'degree': 3, 'C': 100}\n",
      "0.849 (+/-0.054) for {'kernel': 'rbf', 'gamma': 0.02, 'C': 1}\n",
      "\n",
      "Time taken in seconds: 4.98\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search on SVM model hyperparmeters\n",
    "# Code is adapted based on https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
    "\n",
    "# Start timer\n",
    "tic = time()\n",
    "\n",
    "# Define the search values\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.01, 0.02, 0.03],\n",
    "                     'C': [0.1, 1, 10, 100]},\n",
    "                    {'kernel': ['poly'], 'degree': [3],\n",
    "                      'gamma': [0.01, 0.02, 0.03],\n",
    "                     'C': [0.1, 1, 10, 100]},\n",
    "                    {'kernel': ['linear'], \n",
    "                     'C': [0.1, 1, 10, 100]}]\n",
    "\n",
    "# Print the accuracy, precision, recall, F1 score and AUC score for each set of parameters\n",
    "for score in ['accuracy','precision','recall','f1','roc_auc']:\n",
    " print(\"# Tuning hyper-parameters for %s\" %score)\n",
    " print()\n",
    " classifier = RandomizedSearchCV(SVC(), tuned_parameters, scoring=score, cv=5, random_state =1)\n",
    " classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    " print(\"Best parameters found:\")\n",
    " print()\n",
    " print(classifier.best_params_)\n",
    " print()\n",
    " print(\"Randomized search scores on training set:\")\n",
    " print()\n",
    " means = classifier.cv_results_['mean_test_score']\n",
    " stds = classifier.cv_results_['std_test_score']\n",
    " for mean, std, params in zip(means, stds, classifier.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    \n",
    " print()\n",
    "\n",
    "# Print time required in seconds for the search\n",
    "toc = time()\n",
    "print('Time taken in seconds: %.2f'%(toc-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different optimal hyperparameters were given by the different performance metrics.\n",
    "\n",
    "Highest AUC score and accuracy was obtained for radial basis function (RBF) kernel, gamma=0.02 and C=100. We will use these hyperparameters to construct the best SVM model.\n",
    "\n",
    "Highest precision was obtained for third degree polynomial kernel, gamma=0.03 and C=1.\n",
    "\n",
    "Highest recall was obtained for RBF kernel, gamma=0.02 and C=100.\n",
    "\n",
    "Highest F1 score was obtained for RBF kernel, gamma=0.02 and C=100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best SVM model\n",
    "\n",
    "Train best SVM model using radial basis function (RBF) kernel, gamma=0.02 and C=100 based on Randomized Search results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, gamma=0.02, probability=True, random_state=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create best SVM model and fit the model to training data\n",
    "best_svm = SVC(kernel='rbf', C= 100, gamma= 0.02, probability= True, random_state=1)\n",
    "best_svm.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([195, 203], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of support vectors for each class\n",
    "best_svm.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save the best SVM model to file\n",
    "pickle.dump(best_svm, open('best_svm.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Multilayer Perceptron (MLP) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run codes on 'CPU'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare between wide, deep and intermediate network architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performances of 5-fold cross-validated wide, deep and intermediate network architectures were compared in terms of accuracy, precision, recall, F1 score and AUC score.\n",
    "\n",
    "Wide neural network had only one hidden layer containing 9 neurons.\n",
    "\n",
    "Deep neural network had four hidden layers each containing 4 neurons.\n",
    "\n",
    "Intermediate neural network had three hidden layers each containing 6 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in this section is adapted based on https://towardsdatascience.com/\n",
    "#    machine-learning-classifiers-comparison-with-python-33149aecdbca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a wide neural network that has only one hidden layer\n",
    "\n",
    "# Set number of neurons in hidden layer equal to 9\n",
    "hidden_size = 9\n",
    "\n",
    "class WideNetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dim=hidden_size,\n",
    "            dropout=0.2):  # Apply mild dropout for regularization\n",
    "        super(WideNetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout) #  Number of input neurons equals the number of features in dataset\n",
    "        self.hidden = nn.Linear(X.shape[1], hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, 2)  # Number of output neurons is two, because there are two target classes\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a deep neural network that has four hidden layers\n",
    "\n",
    "# Set number of neurons in each hidden layer equal to 4\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "hidden_size3 = 4 \n",
    "hidden_size4 = 4 \n",
    "\n",
    "class DeepNetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dim1=hidden_size1,\n",
    "            hidden_dim2=hidden_size2,\n",
    "            hidden_dim3=hidden_size3,\n",
    "            hidden_dim4=hidden_size4,\n",
    "            dropout=0.2): # Apply mild dropout for regularization\n",
    "        super(DeepNetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden1 = nn.Linear(X.shape[1], hidden_dim1) # Number of input neurons equals the number of features in dataset\n",
    "        self.hidden2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.hidden3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
    "        self.hidden4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
    "        self.output = nn.Linear(hidden_dim4, 2) # Number of output neurons is two, because there are two target classes\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.hidden1(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.relu(self.hidden2(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.relu(self.hidden3(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.relu(self.hidden4(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an intermediate network that has two hidden layers\n",
    "\n",
    "# Set the number of neurons in each hidden layer equal to 6\n",
    "hidden_size1 = 6\n",
    "hidden_size2 = 6\n",
    "\n",
    "class IntermediateNetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dim1=hidden_size1,\n",
    "            hidden_dim2=hidden_size2, \n",
    "            dropout=0.2 # Apply mild dropout for regularization\n",
    "    ):\n",
    "        super(IntermediateNetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden1 = nn.Linear(X.shape[1], hidden_dim1) # Number of input neurons equals the number of features in dataset\n",
    "        self.hidden2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.output = nn.Linear(hidden_dim2, 2) # Number of output neurons is two, because there are two target classes\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.hidden1(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.relu(self.hidden2(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters for each neural network\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "wideNet = NeuralNetClassifier(module=WideNetModule, \n",
    "                                    lr = 0.1, # Learning rate set to 0.1\n",
    "                                    max_epochs=100, # Maximum epochs set to 100\n",
    "                                    callbacks=[EarlyStopping()], # Apply early stopping to avoid overfitting\n",
    "                                    device=device, # Set device to 'cpu'\n",
    "                                    iterator_train__shuffle=True, # Shuffle training data on each epoch\n",
    "                                    optimizer = torch.optim.SGD, # Use stochastic gradient descent algorithm\n",
    "                                    batch_size = 32) # Batch size set to 32\n",
    "                                \n",
    "deepNet = NeuralNetClassifier(module=DeepNetModule,\n",
    "                                    lr = 0.1, # Learning rate set to 0.1\n",
    "                                    max_epochs=100, # Maximum epochs set to 100\n",
    "                                    callbacks=[EarlyStopping()], # Apply early stopping to avoid overfitting\n",
    "                                    device=device, # Set device to 'cpu'\n",
    "                                    iterator_train__shuffle=True, # Shuffle training data on each epoch\n",
    "                                    optimizer = torch.optim.SGD, # Use stochastic gradient descent algorithm\n",
    "                                    batch_size = 32) # Batch size set to 32\n",
    "                                   \n",
    "intermediateNet = NeuralNetClassifier(module=IntermediateNetModule,\n",
    "                                    lr = 0.1, # Learning rate set to 0.1\n",
    "                                    max_epochs=100, # Maximum epochs set to 100\n",
    "                                    callbacks=[EarlyStopping()], # Apply early stopping to avoid overfitting\n",
    "                                    device=device, # Set device to 'cpu'\n",
    "                                    iterator_train__shuffle=True, # Shuffle training data on each epoch\n",
    "                                    optimizer = torch.optim.SGD, # Use stochastic gradient descent algorithm\n",
    "                                    batch_size = 32) # Batch size set to 32\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7001\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6721\u001b[0m  0.0229\n",
      "      2        \u001b[36m0.6576\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6269\u001b[0m  0.0202\n",
      "      3        \u001b[36m0.6248\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5875\u001b[0m  0.0177\n",
      "      4        \u001b[36m0.5915\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5469\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.5704\u001b[0m       0.7422        \u001b[35m0.5190\u001b[0m  0.0306\n",
      "      6        \u001b[36m0.5594\u001b[0m       0.7500        \u001b[35m0.4979\u001b[0m  0.0378\n",
      "      7        \u001b[36m0.5339\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4794\u001b[0m  0.0299\n",
      "      8        0.5377       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4655\u001b[0m  0.0269\n",
      "      9        0.5410       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4555\u001b[0m  0.0418\n",
      "     10        \u001b[36m0.5171\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4466\u001b[0m  0.0254\n",
      "     11        0.5334       0.7891        \u001b[35m0.4452\u001b[0m  0.0320\n",
      "     12        \u001b[36m0.5110\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4369\u001b[0m  0.0395\n",
      "     13        0.5314       0.8047        \u001b[35m0.4342\u001b[0m  0.0349\n",
      "     14        0.5156       \u001b[32m0.8281\u001b[0m        \u001b[35m0.4292\u001b[0m  0.0422\n",
      "     15        0.5189       0.8281        \u001b[35m0.4254\u001b[0m  0.0270\n",
      "     16        0.5224       0.8203        \u001b[35m0.4232\u001b[0m  0.0354\n",
      "     17        0.5267       0.8281        \u001b[35m0.4224\u001b[0m  0.0715\n",
      "     18        0.5193       0.8281        \u001b[35m0.4187\u001b[0m  0.0681\n",
      "     19        0.5202       0.8281        \u001b[35m0.4180\u001b[0m  0.0961\n",
      "     20        \u001b[36m0.5033\u001b[0m       0.8281        \u001b[35m0.4134\u001b[0m  0.0284\n",
      "     21        0.5169       0.8203        \u001b[35m0.4118\u001b[0m  0.0365\n",
      "     22        0.5085       0.8203        \u001b[35m0.4087\u001b[0m  0.0327\n",
      "     23        \u001b[36m0.5021\u001b[0m       0.8203        \u001b[35m0.4075\u001b[0m  0.0350\n",
      "     24        0.5051       0.8281        \u001b[35m0.4066\u001b[0m  0.0301\n",
      "     25        \u001b[36m0.4896\u001b[0m       0.8203        \u001b[35m0.4064\u001b[0m  0.0493\n",
      "     26        0.4980       0.8281        \u001b[35m0.4049\u001b[0m  0.0368\n",
      "     27        \u001b[36m0.4785\u001b[0m       \u001b[32m0.8359\u001b[0m        \u001b[35m0.4022\u001b[0m  0.0506\n",
      "     28        0.4991       0.8359        \u001b[35m0.4021\u001b[0m  0.0292\n",
      "     29        0.4939       0.8359        0.4034  0.0423\n",
      "     30        0.4918       0.8359        0.4034  0.0283\n",
      "     31        0.5012       0.8359        0.4061  0.0289\n",
      "     32        0.4969       0.8359        0.4050  0.0270\n",
      "     33        0.4887       0.8359        \u001b[35m0.4018\u001b[0m  0.0246\n",
      "     34        0.4878       0.8359        \u001b[35m0.4009\u001b[0m  0.0448\n",
      "     35        0.4966       0.8359        \u001b[35m0.3990\u001b[0m  0.0684\n",
      "     36        0.4854       0.8281        0.3997  0.0375\n",
      "     37        \u001b[36m0.4775\u001b[0m       0.8359        \u001b[35m0.3988\u001b[0m  0.0418\n",
      "     38        0.4932       0.8281        \u001b[35m0.3982\u001b[0m  0.0767\n",
      "     39        0.4902       0.8359        0.3991  0.0496\n",
      "     40        \u001b[36m0.4748\u001b[0m       0.8281        \u001b[35m0.3959\u001b[0m  0.0316\n",
      "     41        0.4938       0.8359        0.4006  0.0276\n",
      "     42        0.4826       0.8281        0.4001  0.0219\n",
      "     43        0.4856       0.8359        0.3989  0.0561\n",
      "     44        0.4770       0.8359        0.4009  0.0672\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6569\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6144\u001b[0m  0.0349\n",
      "      2        \u001b[36m0.5966\u001b[0m       0.6875        \u001b[35m0.5839\u001b[0m  0.1221\n",
      "      3        \u001b[36m0.5723\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5695\u001b[0m  0.0532\n",
      "      4        \u001b[36m0.5558\u001b[0m       0.6953        \u001b[35m0.5602\u001b[0m  0.0445\n",
      "      5        \u001b[36m0.5401\u001b[0m       0.6875        \u001b[35m0.5539\u001b[0m  0.0487\n",
      "      6        \u001b[36m0.5347\u001b[0m       0.6797        \u001b[35m0.5495\u001b[0m  0.0330\n",
      "      7        \u001b[36m0.5270\u001b[0m       0.6875        \u001b[35m0.5464\u001b[0m  0.0399\n",
      "      8        \u001b[36m0.5136\u001b[0m       0.6797        0.5466  0.0261\n",
      "      9        \u001b[36m0.5052\u001b[0m       0.6875        \u001b[35m0.5456\u001b[0m  0.0269\n",
      "     10        0.5136       0.6875        \u001b[35m0.5420\u001b[0m  0.0306\n",
      "     11        0.5128       0.6797        \u001b[35m0.5405\u001b[0m  0.0382\n",
      "     12        0.5155       0.6797        \u001b[35m0.5360\u001b[0m  0.0337\n",
      "     13        0.5106       0.6797        0.5363  0.0346\n",
      "     14        0.5079       0.6875        \u001b[35m0.5356\u001b[0m  0.0569\n",
      "     15        0.5077       0.6875        \u001b[35m0.5349\u001b[0m  0.0719\n",
      "     16        \u001b[36m0.5024\u001b[0m       0.6953        \u001b[35m0.5324\u001b[0m  0.0711\n",
      "     17        \u001b[36m0.4932\u001b[0m       0.6953        \u001b[35m0.5311\u001b[0m  0.0457\n",
      "     18        0.4987       0.6953        \u001b[35m0.5307\u001b[0m  0.0288\n",
      "     19        0.5051       0.6953        \u001b[35m0.5297\u001b[0m  0.0253\n",
      "     20        0.5076       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5278\u001b[0m  0.0334\n",
      "     21        \u001b[36m0.4903\u001b[0m       0.7109        \u001b[35m0.5273\u001b[0m  0.0305\n",
      "     22        0.4907       0.7109        0.5282  0.0296\n",
      "     23        0.4938       0.7109        0.5292  0.0466\n",
      "     24        0.5007       0.7109        0.5294  0.0307\n",
      "     25        0.4930       0.7031        0.5290  0.0265\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6532\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6218\u001b[0m  0.0434\n",
      "      2        \u001b[36m0.6022\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5792\u001b[0m  0.0599\n",
      "      3        \u001b[36m0.5588\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5532\u001b[0m  0.0718\n",
      "      4        \u001b[36m0.5537\u001b[0m       0.6797        \u001b[35m0.5417\u001b[0m  0.0509\n",
      "      5        \u001b[36m0.5442\u001b[0m       0.6797        \u001b[35m0.5365\u001b[0m  0.0361\n",
      "      6        \u001b[36m0.5219\u001b[0m       0.6797        \u001b[35m0.5333\u001b[0m  0.0417\n",
      "      7        \u001b[36m0.5199\u001b[0m       0.6875        \u001b[35m0.5315\u001b[0m  0.0279\n",
      "      8        0.5220       0.6875        0.5321  0.0317\n",
      "      9        0.5245       0.6953        0.5325  0.0319\n",
      "     10        \u001b[36m0.5188\u001b[0m       0.7031        0.5323  0.0347\n",
      "     11        \u001b[36m0.4947\u001b[0m       0.6953        0.5341  0.0320\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6704\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6418\u001b[0m  0.0189\n",
      "      2        \u001b[36m0.6304\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6122\u001b[0m  0.0187\n",
      "      3        \u001b[36m0.6024\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5876\u001b[0m  0.0236\n",
      "      4        \u001b[36m0.5816\u001b[0m       0.7422        \u001b[35m0.5709\u001b[0m  0.0376\n",
      "      5        \u001b[36m0.5465\u001b[0m       0.7344        \u001b[35m0.5586\u001b[0m  0.0549\n",
      "      6        \u001b[36m0.5375\u001b[0m       0.7188        \u001b[35m0.5538\u001b[0m  0.0409\n",
      "      7        \u001b[36m0.5253\u001b[0m       0.7188        \u001b[35m0.5520\u001b[0m  0.0404\n",
      "      8        \u001b[36m0.5161\u001b[0m       0.7109        \u001b[35m0.5495\u001b[0m  0.0319\n",
      "      9        0.5257       0.7109        \u001b[35m0.5490\u001b[0m  0.0334\n",
      "     10        0.5180       0.7109        \u001b[35m0.5482\u001b[0m  0.0258\n",
      "     11        \u001b[36m0.5019\u001b[0m       0.7109        \u001b[35m0.5472\u001b[0m  0.0330\n",
      "     12        0.5125       0.7109        \u001b[35m0.5454\u001b[0m  0.0307\n",
      "     13        \u001b[36m0.4961\u001b[0m       0.6953        \u001b[35m0.5452\u001b[0m  0.0307\n",
      "     14        0.5089       0.7109        0.5457  0.0335\n",
      "     15        0.5026       0.6953        \u001b[35m0.5440\u001b[0m  0.0365\n",
      "     16        0.5070       0.6797        \u001b[35m0.5438\u001b[0m  0.0335\n",
      "     17        0.5101       0.6875        \u001b[35m0.5426\u001b[0m  0.0364\n",
      "     18        0.4968       0.6875        \u001b[35m0.5424\u001b[0m  0.0417\n",
      "     19        0.5056       0.6797        \u001b[35m0.5414\u001b[0m  0.0321\n",
      "     20        \u001b[36m0.4895\u001b[0m       0.6875        \u001b[35m0.5414\u001b[0m  0.0516\n",
      "     21        \u001b[36m0.4813\u001b[0m       0.6875        \u001b[35m0.5413\u001b[0m  0.0295\n",
      "     22        0.4930       0.6875        \u001b[35m0.5395\u001b[0m  0.0436\n",
      "     23        0.4959       0.6797        \u001b[35m0.5391\u001b[0m  0.0341\n",
      "     24        0.4941       0.6875        \u001b[35m0.5390\u001b[0m  0.0259\n",
      "     25        0.5008       0.6875        \u001b[35m0.5377\u001b[0m  0.0462\n",
      "     26        0.5018       0.6875        0.5394  0.0314\n",
      "     27        0.5005       0.6875        0.5387  0.0306\n",
      "     28        0.4984       0.6797        \u001b[35m0.5363\u001b[0m  0.0278\n",
      "     29        0.4815       0.6875        0.5364  0.0261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     30        0.4999       0.6797        \u001b[35m0.5346\u001b[0m  0.0265\n",
      "     31        0.4998       0.6875        0.5357  0.0302\n",
      "     32        0.4972       0.6797        0.5366  0.0259\n",
      "     33        0.4837       0.6797        0.5369  0.0297\n",
      "     34        0.4992       0.6875        0.5357  0.0327\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6500\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6069\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.5797\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5674\u001b[0m  0.0180\n",
      "      3        \u001b[36m0.5375\u001b[0m       0.6875        \u001b[35m0.5440\u001b[0m  0.0228\n",
      "      4        \u001b[36m0.5230\u001b[0m       0.6953        \u001b[35m0.5318\u001b[0m  0.0302\n",
      "      5        \u001b[36m0.5027\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5266\u001b[0m  0.0310\n",
      "      6        \u001b[36m0.4846\u001b[0m       0.7109        \u001b[35m0.5258\u001b[0m  0.0307\n",
      "      7        \u001b[36m0.4658\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5255\u001b[0m  0.0202\n",
      "      8        0.4716       0.7109        0.5291  0.0182\n",
      "      9        0.4733       0.7031        0.5305  0.0201\n",
      "     10        \u001b[36m0.4625\u001b[0m       0.7188        0.5305  0.0177\n",
      "     11        0.4649       0.7109        0.5329  0.0188\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6940\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6933\u001b[0m  0.0258\n",
      "      2        0.6941       0.5000        \u001b[35m0.6932\u001b[0m  0.0263\n",
      "      3        \u001b[36m0.6938\u001b[0m       0.5000        \u001b[35m0.6932\u001b[0m  0.0253\n",
      "      4        0.6939       0.5000        0.6932  0.0307\n",
      "      5        0.6939       0.5000        \u001b[35m0.6931\u001b[0m  0.0396\n",
      "      6        0.6940       0.5000        0.6932  0.0493\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6943\u001b[0m       \u001b[32m0.4844\u001b[0m        \u001b[35m0.6934\u001b[0m  0.0249\n",
      "      2        \u001b[36m0.6939\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6934\u001b[0m  0.0325\n",
      "      3        \u001b[36m0.6939\u001b[0m       0.4766        \u001b[35m0.6933\u001b[0m  0.0418\n",
      "      4        0.6942       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6933\u001b[0m  0.0471\n",
      "      5        \u001b[36m0.6937\u001b[0m       0.5000        \u001b[35m0.6933\u001b[0m  0.0288\n",
      "      6        0.6945       0.5000        0.6933  0.0294\n",
      "      7        0.6939       0.4922        \u001b[35m0.6932\u001b[0m  0.0390\n",
      "      8        0.6940       0.4844        0.6933  0.0319\n",
      "      9        0.6942       0.4922        0.6932  0.0322\n",
      "     10        0.6945       0.4844        0.6932  0.0321\n",
      "     11        0.6942       0.5000        0.6932  0.0346\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6950\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6932\u001b[0m  0.0782\n",
      "      2        \u001b[36m0.6944\u001b[0m       0.5000        \u001b[35m0.6926\u001b[0m  0.0669\n",
      "      3        0.6950       0.5000        \u001b[35m0.6920\u001b[0m  0.0527\n",
      "      4        \u001b[36m0.6919\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6918\u001b[0m  0.0419\n",
      "      5        0.6946       0.5078        \u001b[35m0.6917\u001b[0m  0.0872\n",
      "      6        0.6942       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6916\u001b[0m  0.0680\n",
      "      7        \u001b[36m0.6911\u001b[0m       0.5234        \u001b[35m0.6914\u001b[0m  0.0518\n",
      "      8        0.6928       0.5312        \u001b[35m0.6913\u001b[0m  0.0396\n",
      "      9        0.6949       0.5391        \u001b[35m0.6912\u001b[0m  0.0424\n",
      "     10        0.6919       0.5312        \u001b[35m0.6910\u001b[0m  0.0505\n",
      "     11        0.6928       0.5156        0.6910  0.0739\n",
      "     12        0.6936       0.5625        \u001b[35m0.6906\u001b[0m  0.0701\n",
      "     13        0.6933       0.5625        \u001b[35m0.6904\u001b[0m  0.0392\n",
      "     14        0.6919       0.5625        \u001b[35m0.6903\u001b[0m  0.0451\n",
      "     15        0.6932       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6902\u001b[0m  0.0824\n",
      "     16        0.6946       0.5703        \u001b[35m0.6899\u001b[0m  0.0947\n",
      "     17        \u001b[36m0.6904\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6893\u001b[0m  0.0693\n",
      "     18        0.6924       0.5234        \u001b[35m0.6892\u001b[0m  0.0912\n",
      "     19        \u001b[36m0.6879\u001b[0m       0.5938        \u001b[35m0.6883\u001b[0m  0.0638\n",
      "     20        \u001b[36m0.6873\u001b[0m       0.6016        \u001b[35m0.6875\u001b[0m  0.0556\n",
      "     21        0.6889       0.6172        \u001b[35m0.6867\u001b[0m  0.0502\n",
      "     22        0.6901       0.6094        \u001b[35m0.6858\u001b[0m  0.0325\n",
      "     23        0.6894       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6855\u001b[0m  0.0347\n",
      "     24        0.6896       0.6328        \u001b[35m0.6848\u001b[0m  0.0333\n",
      "     25        0.6891       0.6250        \u001b[35m0.6835\u001b[0m  0.0296\n",
      "     26        0.6886       0.6094        \u001b[35m0.6825\u001b[0m  0.0337\n",
      "     27        \u001b[36m0.6858\u001b[0m       0.6172        \u001b[35m0.6810\u001b[0m  0.0372\n",
      "     28        0.6908       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6804\u001b[0m  0.0330\n",
      "     29        0.6859       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6797\u001b[0m  0.0329\n",
      "     30        \u001b[36m0.6849\u001b[0m       0.6562        \u001b[35m0.6781\u001b[0m  0.0345\n",
      "     31        0.6851       0.6484        \u001b[35m0.6763\u001b[0m  0.0326\n",
      "     32        0.6901       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6759\u001b[0m  0.0288\n",
      "     33        \u001b[36m0.6832\u001b[0m       0.6562        \u001b[35m0.6744\u001b[0m  0.0352\n",
      "     34        \u001b[36m0.6822\u001b[0m       0.6719        \u001b[35m0.6707\u001b[0m  0.0353\n",
      "     35        \u001b[36m0.6804\u001b[0m       0.6719        \u001b[35m0.6679\u001b[0m  0.0419\n",
      "     36        \u001b[36m0.6697\u001b[0m       0.6719        \u001b[35m0.6641\u001b[0m  0.0992\n",
      "     37        0.6754       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6597\u001b[0m  0.1170\n",
      "     38        \u001b[36m0.6672\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6546\u001b[0m  0.0577\n",
      "     39        \u001b[36m0.6621\u001b[0m       0.6875        \u001b[35m0.6497\u001b[0m  0.0277\n",
      "     40        \u001b[36m0.6567\u001b[0m       0.6797        \u001b[35m0.6474\u001b[0m  0.0346\n",
      "     41        0.6580       0.7031        \u001b[35m0.6364\u001b[0m  0.0340\n",
      "     42        0.6618       0.6797        \u001b[35m0.6335\u001b[0m  0.1091\n",
      "     43        0.6639       0.6953        \u001b[35m0.6311\u001b[0m  0.0861\n",
      "     44        0.6721       0.6953        \u001b[35m0.6274\u001b[0m  0.0483\n",
      "     45        \u001b[36m0.6452\u001b[0m       0.6875        \u001b[35m0.6226\u001b[0m  0.0373\n",
      "     46        0.6592       0.6797        0.6234  0.0513\n",
      "     47        \u001b[36m0.6437\u001b[0m       0.6875        \u001b[35m0.6209\u001b[0m  0.0525\n",
      "     48        0.6555       0.6875        \u001b[35m0.6197\u001b[0m  0.0975\n",
      "     49        \u001b[36m0.6352\u001b[0m       0.6875        \u001b[35m0.6180\u001b[0m  0.1090\n",
      "     50        \u001b[36m0.6310\u001b[0m       0.6875        \u001b[35m0.6167\u001b[0m  0.0606\n",
      "     51        \u001b[36m0.6242\u001b[0m       0.6875        \u001b[35m0.6153\u001b[0m  0.0827\n",
      "     52        0.6417       0.6641        \u001b[35m0.6115\u001b[0m  0.0460\n",
      "     53        0.6499       0.6719        0.6145  0.0423\n",
      "     54        0.6449       0.6875        0.6193  0.0370\n",
      "     55        0.6621       0.6719        0.6189  0.0446\n",
      "     56        0.6318       0.6719        0.6139  0.0298\n",
      "     57        0.6287       0.6797        \u001b[35m0.6095\u001b[0m  0.0360\n",
      "     58        0.6413       0.6797        \u001b[35m0.6091\u001b[0m  0.0312\n",
      "     59        0.6303       0.6797        0.6101  0.0353\n",
      "     60        \u001b[36m0.6239\u001b[0m       0.6797        \u001b[35m0.6049\u001b[0m  0.0302\n",
      "     61        0.6392       0.6719        0.6080  0.0379\n",
      "     62        0.6402       0.6953        0.6141  0.0360\n",
      "     63        \u001b[36m0.6015\u001b[0m       0.7031        0.6067  0.0320\n",
      "     64        0.6183       0.6953        0.6100  0.0286\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6992\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6900\u001b[0m  0.0313\n",
      "      2        \u001b[36m0.6927\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6888\u001b[0m  0.0269\n",
      "      3        \u001b[36m0.6898\u001b[0m       0.6250        \u001b[35m0.6882\u001b[0m  0.0281\n",
      "      4        \u001b[36m0.6895\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6866\u001b[0m  0.0356\n",
      "      5        \u001b[36m0.6868\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6844\u001b[0m  0.0736\n",
      "      6        0.6879       0.5625        \u001b[35m0.6840\u001b[0m  0.1040\n",
      "      7        0.6889       0.6953        \u001b[35m0.6811\u001b[0m  0.0611\n",
      "      8        \u001b[36m0.6819\u001b[0m       0.5000        \u001b[35m0.6785\u001b[0m  0.0425\n",
      "      9        \u001b[36m0.6792\u001b[0m       0.6875        \u001b[35m0.6729\u001b[0m  0.0597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        \u001b[36m0.6787\u001b[0m       0.6562        \u001b[35m0.6686\u001b[0m  0.0307\n",
      "     11        \u001b[36m0.6676\u001b[0m       0.6797        \u001b[35m0.6609\u001b[0m  0.0318\n",
      "     12        0.6724       0.6094        0.6622  0.0341\n",
      "     13        0.6717       0.6953        \u001b[35m0.6534\u001b[0m  0.0810\n",
      "     14        0.6785       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6516\u001b[0m  0.0448\n",
      "     15        \u001b[36m0.6599\u001b[0m       0.6797        \u001b[35m0.6480\u001b[0m  0.0781\n",
      "     16        0.6616       0.6719        \u001b[35m0.6445\u001b[0m  0.0324\n",
      "     17        \u001b[36m0.6520\u001b[0m       0.6797        \u001b[35m0.6384\u001b[0m  0.0299\n",
      "     18        0.6604       0.6641        0.6391  0.0295\n",
      "     19        0.6556       0.6250        0.6411  0.0423\n",
      "     20        0.6551       0.6797        \u001b[35m0.6346\u001b[0m  0.0345\n",
      "     21        \u001b[36m0.6370\u001b[0m       0.6719        \u001b[35m0.6289\u001b[0m  0.0341\n",
      "     22        \u001b[36m0.6332\u001b[0m       0.6719        \u001b[35m0.6212\u001b[0m  0.0364\n",
      "     23        0.6554       0.6641        0.6248  0.0317\n",
      "     24        0.6581       0.6719        \u001b[35m0.6201\u001b[0m  0.0298\n",
      "     25        \u001b[36m0.6193\u001b[0m       0.6719        \u001b[35m0.6104\u001b[0m  0.0320\n",
      "     26        \u001b[36m0.6153\u001b[0m       0.6719        \u001b[35m0.6054\u001b[0m  0.0325\n",
      "     27        0.6200       0.6719        0.6077  0.0400\n",
      "     28        0.6260       0.6641        \u001b[35m0.6049\u001b[0m  0.0334\n",
      "     29        0.6160       0.6641        \u001b[35m0.6015\u001b[0m  0.0347\n",
      "     30        0.6395       0.6797        \u001b[35m0.6011\u001b[0m  0.0308\n",
      "     31        0.6356       0.6797        0.6024  0.0303\n",
      "     32        0.6256       0.6797        \u001b[35m0.6002\u001b[0m  0.0333\n",
      "     33        0.6305       0.6797        0.6042  0.0509\n",
      "     34        0.6214       0.6719        0.6013  0.0268\n",
      "     35        \u001b[36m0.6128\u001b[0m       0.6797        \u001b[35m0.5979\u001b[0m  0.0264\n",
      "     36        0.6280       0.6719        0.6003  0.0276\n",
      "     37        \u001b[36m0.5908\u001b[0m       0.6797        \u001b[35m0.5941\u001b[0m  0.0277\n",
      "     38        0.5983       0.6797        \u001b[35m0.5932\u001b[0m  0.0278\n",
      "     39        \u001b[36m0.5693\u001b[0m       0.6719        0.5946  0.0299\n",
      "     40        0.6071       0.6797        0.5942  0.0311\n",
      "     41        0.6132       0.6719        0.5960  0.0294\n",
      "     42        0.6116       0.6875        \u001b[35m0.5924\u001b[0m  0.1023\n",
      "     43        0.6108       0.6797        0.5957  0.0279\n",
      "     44        0.6027       0.6797        0.5928  0.0394\n",
      "     45        0.5838       0.6875        0.5925  0.0392\n",
      "     46        0.6134       0.6797        0.5976  0.0447\n",
      "     47        0.5801       0.6875        \u001b[35m0.5919\u001b[0m  0.0471\n",
      "     48        0.5814       0.6953        \u001b[35m0.5887\u001b[0m  0.0337\n",
      "     49        0.6043       0.6953        0.5894  0.0373\n",
      "     50        0.5740       0.6797        \u001b[35m0.5877\u001b[0m  0.0335\n",
      "     51        \u001b[36m0.5651\u001b[0m       0.6797        0.5895  0.0336\n",
      "     52        0.6110       0.6953        0.5886  0.0385\n",
      "     53        0.5736       0.6719        \u001b[35m0.5874\u001b[0m  0.0650\n",
      "     54        0.6030       0.6797        0.5900  0.0475\n",
      "     55        0.5931       0.6719        \u001b[35m0.5854\u001b[0m  0.0535\n",
      "     56        0.5884       0.6875        0.5924  0.0348\n",
      "     57        0.5755       0.6719        0.5867  0.0343\n",
      "     58        0.5970       0.6719        0.5883  0.0326\n",
      "     59        0.5943       0.6719        0.5859  0.0501\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7662\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7122\u001b[0m  0.0243\n",
      "      2        \u001b[36m0.7038\u001b[0m       0.5000        \u001b[35m0.6956\u001b[0m  0.0341\n",
      "      3        \u001b[36m0.6939\u001b[0m       0.5000        \u001b[35m0.6930\u001b[0m  0.0370\n",
      "      4        0.6950       0.5000        \u001b[35m0.6929\u001b[0m  0.0326\n",
      "      5        \u001b[36m0.6934\u001b[0m       0.5000        \u001b[35m0.6928\u001b[0m  0.0470\n",
      "      6        \u001b[36m0.6929\u001b[0m       0.5000        \u001b[35m0.6927\u001b[0m  0.0576\n",
      "      7        0.6942       0.5000        \u001b[35m0.6927\u001b[0m  0.0395\n",
      "      8        0.6932       0.5000        0.6927  0.0569\n",
      "      9        0.6943       0.5000        \u001b[35m0.6927\u001b[0m  0.0482\n",
      "     10        0.6938       0.5000        \u001b[35m0.6926\u001b[0m  0.0425\n",
      "     11        0.6953       0.5000        \u001b[35m0.6925\u001b[0m  0.0478\n",
      "     12        0.6955       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6924\u001b[0m  0.0514\n",
      "     13        \u001b[36m0.6925\u001b[0m       0.5000        \u001b[35m0.6924\u001b[0m  0.0476\n",
      "     14        0.6933       0.5000        \u001b[35m0.6923\u001b[0m  0.0357\n",
      "     15        0.6932       0.5000        \u001b[35m0.6922\u001b[0m  0.0347\n",
      "     16        0.6931       0.5000        \u001b[35m0.6921\u001b[0m  0.0384\n",
      "     17        \u001b[36m0.6924\u001b[0m       0.5000        \u001b[35m0.6919\u001b[0m  0.0421\n",
      "     18        \u001b[36m0.6907\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6918\u001b[0m  0.0371\n",
      "     19        0.6946       0.5000        \u001b[35m0.6917\u001b[0m  0.0312\n",
      "     20        0.6918       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6914\u001b[0m  0.0372\n",
      "     21        0.6912       0.5000        \u001b[35m0.6912\u001b[0m  0.0375\n",
      "     22        0.6911       0.5000        \u001b[35m0.6909\u001b[0m  0.0510\n",
      "     23        0.6909       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6906\u001b[0m  0.0482\n",
      "     24        0.6940       0.5391        \u001b[35m0.6903\u001b[0m  0.0494\n",
      "     25        0.6920       0.5547        \u001b[35m0.6898\u001b[0m  0.0507\n",
      "     26        \u001b[36m0.6901\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6892\u001b[0m  0.0508\n",
      "     27        0.6909       0.7422        \u001b[35m0.6885\u001b[0m  0.0551\n",
      "     28        \u001b[36m0.6884\u001b[0m       0.5000        \u001b[35m0.6877\u001b[0m  0.0433\n",
      "     29        0.6907       0.5000        \u001b[35m0.6869\u001b[0m  0.0371\n",
      "     30        \u001b[36m0.6873\u001b[0m       0.5000        \u001b[35m0.6856\u001b[0m  0.0326\n",
      "     31        0.6896       0.7578        \u001b[35m0.6839\u001b[0m  0.0344\n",
      "     32        0.6877       0.7422        \u001b[35m0.6822\u001b[0m  0.0389\n",
      "     33        \u001b[36m0.6842\u001b[0m       0.7188        \u001b[35m0.6803\u001b[0m  0.0353\n",
      "     34        0.6866       0.7500        \u001b[35m0.6784\u001b[0m  0.0297\n",
      "     35        \u001b[36m0.6840\u001b[0m       0.7422        \u001b[35m0.6761\u001b[0m  0.0426\n",
      "     36        \u001b[36m0.6823\u001b[0m       0.7500        \u001b[35m0.6732\u001b[0m  0.0362\n",
      "     37        \u001b[36m0.6782\u001b[0m       0.7266        \u001b[35m0.6703\u001b[0m  0.0378\n",
      "     38        \u001b[36m0.6771\u001b[0m       0.7344        \u001b[35m0.6663\u001b[0m  0.0283\n",
      "     39        \u001b[36m0.6688\u001b[0m       0.6953        \u001b[35m0.6616\u001b[0m  0.0384\n",
      "     40        \u001b[36m0.6575\u001b[0m       0.7109        \u001b[35m0.6502\u001b[0m  0.0302\n",
      "     41        \u001b[36m0.6529\u001b[0m       0.7188        \u001b[35m0.6374\u001b[0m  0.0353\n",
      "     42        \u001b[36m0.6506\u001b[0m       0.7422        \u001b[35m0.6254\u001b[0m  0.0330\n",
      "     43        0.6556       0.7344        \u001b[35m0.6160\u001b[0m  0.0353\n",
      "     44        \u001b[36m0.6387\u001b[0m       0.7266        \u001b[35m0.6070\u001b[0m  0.0329\n",
      "     45        \u001b[36m0.6187\u001b[0m       0.7266        \u001b[35m0.5938\u001b[0m  0.0304\n",
      "     46        \u001b[36m0.6071\u001b[0m       0.7344        \u001b[35m0.5767\u001b[0m  0.0366\n",
      "     47        0.6209       0.7500        \u001b[35m0.5711\u001b[0m  0.0308\n",
      "     48        0.6203       0.7422        \u001b[35m0.5665\u001b[0m  0.0486\n",
      "     49        0.6133       0.7500        0.5672  0.0362\n",
      "     50        0.6140       0.7344        \u001b[35m0.5602\u001b[0m  0.0363\n",
      "     51        0.6154       0.7344        \u001b[35m0.5573\u001b[0m  0.0401\n",
      "     52        0.6079       0.7500        \u001b[35m0.5572\u001b[0m  0.0326\n",
      "     53        \u001b[36m0.6006\u001b[0m       0.7500        \u001b[35m0.5540\u001b[0m  0.0384\n",
      "     54        0.6268       0.7500        \u001b[35m0.5538\u001b[0m  0.0422\n",
      "     55        0.6028       0.7422        \u001b[35m0.5502\u001b[0m  0.0314\n",
      "     56        0.6065       0.7266        0.5506  0.0388\n",
      "     57        \u001b[36m0.5857\u001b[0m       0.7188        \u001b[35m0.5468\u001b[0m  0.0278\n",
      "     58        0.6039       0.7344        \u001b[35m0.5465\u001b[0m  0.0351\n",
      "     59        0.6254       0.7500        0.5526  0.0312\n",
      "     60        0.5930       0.7422        0.5480  0.0518\n",
      "     61        \u001b[36m0.5633\u001b[0m       0.7266        \u001b[35m0.5432\u001b[0m  0.0540\n",
      "     62        0.6066       0.7422        0.5468  0.0338\n",
      "     63        0.5882       0.7266        0.5487  0.0365\n",
      "     64        0.6317       0.7422        0.5465  0.0580\n",
      "     65        0.5763       0.7500        \u001b[35m0.5406\u001b[0m  0.0487\n",
      "     66        0.5892       0.7578        \u001b[35m0.5353\u001b[0m  0.0437\n",
      "     67        0.6102       0.7344        0.5404  0.0418\n",
      "     68        0.5993       0.7578        0.5399  0.0457\n",
      "     69        0.5849       0.7578        \u001b[35m0.5323\u001b[0m  0.0438\n",
      "     70        0.5987       0.7500        0.5372  0.0374\n",
      "     71        0.5958       0.7578        0.5389  0.0410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     72        0.5823       0.7422        0.5358  0.0273\n",
      "     73        0.5929       0.7578        0.5332  0.0326\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7078\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6973\u001b[0m  0.0229\n",
      "      2        \u001b[36m0.6994\u001b[0m       0.4844        \u001b[35m0.6923\u001b[0m  0.0273\n",
      "      3        \u001b[36m0.6934\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6903\u001b[0m  0.0306\n",
      "      4        \u001b[36m0.6915\u001b[0m       0.5859        \u001b[35m0.6874\u001b[0m  0.0291\n",
      "      5        \u001b[36m0.6897\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6836\u001b[0m  0.0280\n",
      "      6        \u001b[36m0.6842\u001b[0m       0.6719        \u001b[35m0.6772\u001b[0m  0.0268\n",
      "      7        \u001b[36m0.6786\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6670\u001b[0m  0.0294\n",
      "      8        \u001b[36m0.6698\u001b[0m       0.6953        \u001b[35m0.6530\u001b[0m  0.0266\n",
      "      9        \u001b[36m0.6478\u001b[0m       0.6875        \u001b[35m0.6273\u001b[0m  0.0356\n",
      "     10        \u001b[36m0.6342\u001b[0m       0.7031        \u001b[35m0.5949\u001b[0m  0.0325\n",
      "     11        \u001b[36m0.6149\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5572\u001b[0m  0.0242\n",
      "     12        \u001b[36m0.5911\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5255\u001b[0m  0.0292\n",
      "     13        \u001b[36m0.5901\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5029\u001b[0m  0.0300\n",
      "     14        \u001b[36m0.5881\u001b[0m       0.7422        \u001b[35m0.4908\u001b[0m  0.0301\n",
      "     15        \u001b[36m0.5713\u001b[0m       0.7344        \u001b[35m0.4811\u001b[0m  0.0303\n",
      "     16        0.5758       \u001b[32m0.7578\u001b[0m        \u001b[35m0.4736\u001b[0m  0.0277\n",
      "     17        \u001b[36m0.5502\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4637\u001b[0m  0.0317\n",
      "     18        0.5522       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4547\u001b[0m  0.0302\n",
      "     19        \u001b[36m0.5496\u001b[0m       0.8125        \u001b[35m0.4449\u001b[0m  0.0302\n",
      "     20        \u001b[36m0.5496\u001b[0m       0.7969        0.4452  0.0311\n",
      "     21        \u001b[36m0.5420\u001b[0m       0.8125        \u001b[35m0.4390\u001b[0m  0.0296\n",
      "     22        \u001b[36m0.5352\u001b[0m       0.8125        \u001b[35m0.4297\u001b[0m  0.0310\n",
      "     23        0.5381       0.8125        \u001b[35m0.4293\u001b[0m  0.0430\n",
      "     24        0.5594       \u001b[32m0.8203\u001b[0m        0.4347  0.0249\n",
      "     25        0.5429       0.8203        0.4316  0.0485\n",
      "     26        \u001b[36m0.5123\u001b[0m       0.8125        0.4298  0.0333\n",
      "     27        0.5351       0.8203        \u001b[35m0.4288\u001b[0m  0.0311\n",
      "     28        0.5389       0.8203        \u001b[35m0.4276\u001b[0m  0.0320\n",
      "     29        0.5211       0.8203        \u001b[35m0.4233\u001b[0m  0.0276\n",
      "     30        0.5266       0.8125        0.4245  0.0478\n",
      "     31        0.5460       \u001b[32m0.8281\u001b[0m        0.4271  0.0508\n",
      "     32        0.5203       0.8203        \u001b[35m0.4202\u001b[0m  0.0303\n",
      "     33        0.5397       0.8047        0.4259  0.0384\n",
      "     34        0.5428       0.8047        0.4302  0.0256\n",
      "     35        0.5281       0.8047        0.4229  0.0293\n",
      "     36        0.5199       0.8281        \u001b[35m0.4138\u001b[0m  0.0300\n",
      "     37        0.5232       0.8125        0.4166  0.0288\n",
      "     38        0.5184       0.8203        0.4138  0.0334\n",
      "     39        0.5320       0.8047        0.4181  0.0280\n",
      "     40        \u001b[36m0.5095\u001b[0m       0.8203        \u001b[35m0.4136\u001b[0m  0.0280\n",
      "     41        0.5368       0.8125        0.4194  0.0286\n",
      "     42        \u001b[36m0.5065\u001b[0m       0.8047        0.4160  0.0302\n",
      "     43        0.5196       0.8125        \u001b[35m0.4128\u001b[0m  0.0243\n",
      "     44        0.5144       0.8047        0.4131  0.0432\n",
      "     45        0.5202       0.8047        0.4173  0.0419\n",
      "     46        0.5073       0.7969        0.4141  0.0223\n",
      "     47        0.5173       0.8047        \u001b[35m0.4119\u001b[0m  0.0415\n",
      "     48        0.5160       0.8125        \u001b[35m0.4086\u001b[0m  0.0479\n",
      "     49        0.5068       0.8203        \u001b[35m0.4031\u001b[0m  0.0319\n",
      "     50        \u001b[36m0.5026\u001b[0m       0.8203        \u001b[35m0.4021\u001b[0m  0.0393\n",
      "     51        \u001b[36m0.4945\u001b[0m       0.8125        \u001b[35m0.4021\u001b[0m  0.0233\n",
      "     52        0.5070       0.8125        0.4053  0.0361\n",
      "     53        0.5117       0.8203        0.4023  0.0264\n",
      "     54        0.5109       0.8281        \u001b[35m0.4013\u001b[0m  0.0265\n",
      "     55        0.5196       0.8281        0.4090  0.0246\n",
      "     56        0.5120       0.8125        0.4124  0.0318\n",
      "     57        0.5174       0.8281        0.4083  0.0350\n",
      "     58        0.5068       0.8281        0.4058  0.0492\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6991\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6884\u001b[0m  0.0330\n",
      "      2        \u001b[36m0.6840\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6796\u001b[0m  0.0360\n",
      "      3        \u001b[36m0.6709\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6671\u001b[0m  0.0390\n",
      "      4        \u001b[36m0.6586\u001b[0m       0.7188        \u001b[35m0.6480\u001b[0m  0.0274\n",
      "      5        \u001b[36m0.6319\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6205\u001b[0m  0.0210\n",
      "      6        \u001b[36m0.6163\u001b[0m       0.7266        \u001b[35m0.5949\u001b[0m  0.0443\n",
      "      7        \u001b[36m0.6001\u001b[0m       0.7266        \u001b[35m0.5742\u001b[0m  0.0355\n",
      "      8        \u001b[36m0.5884\u001b[0m       0.7266        \u001b[35m0.5588\u001b[0m  0.0361\n",
      "      9        \u001b[36m0.5785\u001b[0m       0.7266        \u001b[35m0.5452\u001b[0m  0.0357\n",
      "     10        \u001b[36m0.5610\u001b[0m       0.7266        \u001b[35m0.5354\u001b[0m  0.0319\n",
      "     11        \u001b[36m0.5555\u001b[0m       0.7266        \u001b[35m0.5288\u001b[0m  0.0305\n",
      "     12        0.5556       0.7188        \u001b[35m0.5244\u001b[0m  0.0321\n",
      "     13        \u001b[36m0.5503\u001b[0m       0.7266        \u001b[35m0.5223\u001b[0m  0.0327\n",
      "     14        0.5513       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5206\u001b[0m  0.0370\n",
      "     15        \u001b[36m0.5445\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5176\u001b[0m  0.0371\n",
      "     16        \u001b[36m0.5338\u001b[0m       0.7500        \u001b[35m0.5155\u001b[0m  0.0260\n",
      "     17        0.5399       0.7500        \u001b[35m0.5150\u001b[0m  0.0312\n",
      "     18        \u001b[36m0.5266\u001b[0m       0.7422        0.5152  0.0303\n",
      "     19        \u001b[36m0.5259\u001b[0m       0.7266        \u001b[35m0.5147\u001b[0m  0.0350\n",
      "     20        0.5385       0.7344        \u001b[35m0.5143\u001b[0m  0.0354\n",
      "     21        \u001b[36m0.5183\u001b[0m       0.7344        \u001b[35m0.5116\u001b[0m  0.0388\n",
      "     22        0.5352       0.7422        \u001b[35m0.5087\u001b[0m  0.0307\n",
      "     23        0.5186       0.7422        \u001b[35m0.5070\u001b[0m  0.0300\n",
      "     24        0.5289       0.7500        0.5081  0.0310\n",
      "     25        0.5340       0.7422        0.5088  0.0283\n",
      "     26        \u001b[36m0.5162\u001b[0m       0.7422        0.5086  0.0262\n",
      "     27        \u001b[36m0.5110\u001b[0m       0.7500        0.5091  0.0311\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6839\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6643\u001b[0m  0.0266\n",
      "      2        \u001b[36m0.6623\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6412\u001b[0m  0.0453\n",
      "      3        \u001b[36m0.6561\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6233\u001b[0m  0.0294\n",
      "      4        \u001b[36m0.6348\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6031\u001b[0m  0.0281\n",
      "      5        \u001b[36m0.6139\u001b[0m       0.7031        \u001b[35m0.5842\u001b[0m  0.0294\n",
      "      6        \u001b[36m0.5852\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5685\u001b[0m  0.0492\n",
      "      7        \u001b[36m0.5809\u001b[0m       0.7031        \u001b[35m0.5577\u001b[0m  0.0417\n",
      "      8        \u001b[36m0.5581\u001b[0m       0.7031        \u001b[35m0.5508\u001b[0m  0.0347\n",
      "      9        0.5683       0.7109        \u001b[35m0.5438\u001b[0m  0.0306\n",
      "     10        0.5638       0.7109        \u001b[35m0.5407\u001b[0m  0.0317\n",
      "     11        \u001b[36m0.5486\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5373\u001b[0m  0.0276\n",
      "     12        0.5607       0.7266        \u001b[35m0.5367\u001b[0m  0.0301\n",
      "     13        \u001b[36m0.5223\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5331\u001b[0m  0.0313\n",
      "     14        0.5378       0.7344        \u001b[35m0.5307\u001b[0m  0.0338\n",
      "     15        0.5273       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5274\u001b[0m  0.0297\n",
      "     16        0.5278       0.7266        \u001b[35m0.5252\u001b[0m  0.0251\n",
      "     17        0.5427       0.7188        0.5287  0.0361\n",
      "     18        0.5284       0.7344        0.5308  0.0325\n",
      "     19        0.5269       0.7266        0.5333  0.0275\n",
      "     20        \u001b[36m0.5080\u001b[0m       0.7344        0.5349  0.0222\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6987\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6922\u001b[0m  0.0213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.6914\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6875\u001b[0m  0.0367\n",
      "      3        \u001b[36m0.6849\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6817\u001b[0m  0.0394\n",
      "      4        \u001b[36m0.6811\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6738\u001b[0m  0.0304\n",
      "      5        \u001b[36m0.6671\u001b[0m       0.7188        \u001b[35m0.6607\u001b[0m  0.0282\n",
      "      6        \u001b[36m0.6524\u001b[0m       0.7188        \u001b[35m0.6405\u001b[0m  0.0297\n",
      "      7        \u001b[36m0.6415\u001b[0m       0.7109        \u001b[35m0.6197\u001b[0m  0.0267\n",
      "      8        \u001b[36m0.6075\u001b[0m       0.7188        \u001b[35m0.5945\u001b[0m  0.0352\n",
      "      9        \u001b[36m0.5844\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5694\u001b[0m  0.0343\n",
      "     10        \u001b[36m0.5736\u001b[0m       0.7266        \u001b[35m0.5573\u001b[0m  0.0432\n",
      "     11        \u001b[36m0.5689\u001b[0m       0.7344        \u001b[35m0.5520\u001b[0m  0.0296\n",
      "     12        0.5722       0.7188        \u001b[35m0.5494\u001b[0m  0.0391\n",
      "     13        \u001b[36m0.5372\u001b[0m       0.7188        \u001b[35m0.5415\u001b[0m  0.0350\n",
      "     14        0.5465       0.7266        \u001b[35m0.5403\u001b[0m  0.0319\n",
      "     15        0.5429       0.7266        0.5405  0.0349\n",
      "     16        \u001b[36m0.5285\u001b[0m       0.7266        \u001b[35m0.5385\u001b[0m  0.0367\n",
      "     17        \u001b[36m0.5142\u001b[0m       0.7188        \u001b[35m0.5380\u001b[0m  0.0317\n",
      "     18        0.5174       0.7109        0.5427  0.0353\n",
      "     19        0.5317       0.7188        0.5416  0.0374\n",
      "     20        0.5200       0.7109        0.5448  0.0317\n",
      "     21        0.5265       0.7109        0.5437  0.0346\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6926\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6924\u001b[0m  0.0293\n",
      "      2        \u001b[36m0.6895\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6893\u001b[0m  0.0254\n",
      "      3        \u001b[36m0.6866\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6851\u001b[0m  0.0244\n",
      "      4        \u001b[36m0.6792\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6769\u001b[0m  0.0248\n",
      "      5        \u001b[36m0.6697\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6585\u001b[0m  0.0245\n",
      "      6        \u001b[36m0.6477\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6336\u001b[0m  0.0262\n",
      "      7        \u001b[36m0.6245\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6127\u001b[0m  0.0256\n",
      "      8        0.6317       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5998\u001b[0m  0.0280\n",
      "      9        \u001b[36m0.5961\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5884\u001b[0m  0.0247\n",
      "     10        \u001b[36m0.5909\u001b[0m       0.7109        \u001b[35m0.5853\u001b[0m  0.0258\n",
      "     11        \u001b[36m0.5743\u001b[0m       0.7266        \u001b[35m0.5802\u001b[0m  0.0401\n",
      "     12        0.5856       0.7188        \u001b[35m0.5784\u001b[0m  0.0253\n",
      "     13        0.5886       0.7188        \u001b[35m0.5776\u001b[0m  0.0247\n",
      "     14        \u001b[36m0.5732\u001b[0m       0.7109        \u001b[35m0.5761\u001b[0m  0.0260\n",
      "     15        \u001b[36m0.5608\u001b[0m       0.7109        \u001b[35m0.5753\u001b[0m  0.0296\n",
      "     16        \u001b[36m0.5559\u001b[0m       0.7031        0.5757  0.0296\n",
      "     17        \u001b[36m0.5420\u001b[0m       0.7109        \u001b[35m0.5739\u001b[0m  0.0321\n",
      "     18        0.5812       0.7109        0.5746  0.0620\n",
      "     19        0.5706       0.7031        \u001b[35m0.5730\u001b[0m  0.0339\n",
      "     20        0.5541       0.6953        0.5732  0.0266\n",
      "     21        0.5490       0.6953        \u001b[35m0.5682\u001b[0m  0.0391\n",
      "     22        0.5619       0.6953        \u001b[35m0.5649\u001b[0m  0.0370\n",
      "     23        \u001b[36m0.5420\u001b[0m       0.6875        0.5674  0.0295\n",
      "     24        \u001b[36m0.5143\u001b[0m       0.6875        0.5674  0.0308\n",
      "     25        0.5713       0.6797        0.5660  0.0361\n",
      "     26        0.5600       0.6875        \u001b[35m0.5630\u001b[0m  0.0482\n",
      "     27        0.5360       0.6875        \u001b[35m0.5577\u001b[0m  0.0341\n",
      "     28        0.5223       0.6953        \u001b[35m0.5566\u001b[0m  0.0337\n",
      "     29        0.5346       0.7031        \u001b[35m0.5560\u001b[0m  0.0496\n",
      "     30        0.5309       0.7031        \u001b[35m0.5498\u001b[0m  0.0349\n",
      "     31        0.5342       0.7109        \u001b[35m0.5458\u001b[0m  0.0355\n",
      "     32        \u001b[36m0.5060\u001b[0m       0.7188        \u001b[35m0.5435\u001b[0m  0.0471\n",
      "     33        0.5263       0.7031        0.5454  0.0370\n",
      "     34        0.5202       0.7031        \u001b[35m0.5431\u001b[0m  0.0359\n",
      "     35        \u001b[36m0.4811\u001b[0m       0.7031        0.5469  0.0331\n",
      "     36        0.5356       0.6953        0.5442  0.0332\n",
      "     37        0.4859       0.7109        \u001b[35m0.5430\u001b[0m  0.0454\n",
      "     38        0.5182       0.7031        \u001b[35m0.5398\u001b[0m  0.0333\n",
      "     39        0.5254       0.7031        \u001b[35m0.5359\u001b[0m  0.0351\n",
      "     40        0.4897       0.6953        0.5391  0.0368\n",
      "     41        0.5165       0.7031        0.5388  0.0284\n",
      "     42        0.4941       0.7344        0.5385  0.0413\n",
      "     43        0.4984       0.7109        \u001b[35m0.5345\u001b[0m  0.0342\n",
      "     44        0.4861       0.7109        0.5365  0.0330\n",
      "     45        0.4885       0.7031        0.5359  0.0354\n",
      "     46        0.5097       0.7109        \u001b[35m0.5334\u001b[0m  0.0339\n",
      "     47        0.4824       0.7344        0.5377  0.0341\n",
      "     48        \u001b[36m0.4678\u001b[0m       0.7188        0.5339  0.0326\n",
      "     49        0.5087       0.7109        \u001b[35m0.5324\u001b[0m  0.0238\n",
      "     50        0.4888       0.7188        \u001b[35m0.5252\u001b[0m  0.0326\n",
      "     51        0.5130       0.7266        0.5306  0.0316\n",
      "     52        0.4893       0.7031        0.5320  0.0257\n",
      "     53        0.4926       0.7031        0.5313  0.0280\n",
      "     54        0.4898       0.7109        0.5307  0.0351\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "           Wide neural network  Deep neural network  \\\n",
      "Accuracy              0.756250             0.651250   \n",
      "Precision             0.749631             0.556240   \n",
      "Recall                0.770000             0.655000   \n",
      "F1 Score              0.759251             0.584890   \n",
      "AUC                   0.841719             0.688109   \n",
      "\n",
      "           Intermediate neural network  Dummy classifier  \\\n",
      "Accuracy                      0.755000          0.455000   \n",
      "Precision                     0.735834          0.453846   \n",
      "Recall                        0.795000          0.442500   \n",
      "F1 Score                      0.764125          0.448101   \n",
      "AUC                           0.835797          0.455000   \n",
      "\n",
      "                            Best Score  \n",
      "Accuracy           Wide neural network  \n",
      "Precision          Wide neural network  \n",
      "Recall     Intermediate neural network  \n",
      "F1 Score   Intermediate neural network  \n",
      "AUC                Wide neural network  \n",
      "           Wide neural network  Deep neural network  \\\n",
      "Accuracy              0.036012             0.126947   \n",
      "Precision             0.034181             0.298012   \n",
      "Recall                0.047170             0.349160   \n",
      "F1 Score              0.036769             0.295545   \n",
      "AUC                   0.036300             0.138627   \n",
      "\n",
      "           Intermediate neural network  Dummy classifier  \\\n",
      "Accuracy                      0.019922          0.010000   \n",
      "Precision                     0.012983          0.010256   \n",
      "Recall                        0.034095          0.010000   \n",
      "F1 Score                      0.022305          0.010127   \n",
      "AUC                           0.028925          0.010000   \n",
      "\n",
      "          Minimum standard deviation  \n",
      "Accuracy            Dummy classifier  \n",
      "Precision           Dummy classifier  \n",
      "Recall              Dummy classifier  \n",
      "F1 Score            Dummy classifier  \n",
      "AUC                 Dummy classifier  \n"
     ]
    }
   ],
   "source": [
    "# Create a function that performs cross-validation and evaluates each MLP model and dummy classifier\n",
    "\n",
    "def models_evaluation(X_train, y_train):\n",
    "    # Perform cross-validation on each classifier\n",
    "    cv_wideNet = cross_validate(wideNet, X_train, y_train, cv=5, scoring=scoring)\n",
    "    cv_deepNet = cross_validate(deepNet, X_train, y_train, cv=5, scoring=scoring)\n",
    "    cv_intermediateNet = cross_validate(intermediateNet, X_train, y_train, cv=5, scoring=scoring)\n",
    "    cv_dummy_model = cross_validate(dummy_model, X_train, y_train, cv=5, scoring=scoring)\n",
    "    \n",
    "    # Create 'mean_scores_table' DataFrame with mean performance metric scores for each classifier\n",
    "    mean_scores_table = pd.DataFrame({'Wide neural network':[cv_wideNet['test_accuracy'].mean(),\n",
    "                                                         cv_wideNet['test_precision'].mean(),\n",
    "                                                         cv_wideNet['test_recall'].mean(),\n",
    "                                                         cv_wideNet['test_f1_score'].mean(),\n",
    "                                                         cv_wideNet['test_AUC'].mean()],\n",
    "                                       'Deep neural network':[cv_deepNet['test_accuracy'].mean(),\n",
    "                                                            cv_deepNet['test_precision'].mean(),\n",
    "                                                            cv_deepNet['test_recall'].mean(),\n",
    "                                                            cv_deepNet['test_f1_score'].mean(),\n",
    "                                                            cv_deepNet['test_AUC'].mean()],\n",
    "                                      'Intermediate neural network':[cv_intermediateNet['test_accuracy'].mean(),\n",
    "                                                            cv_intermediateNet['test_precision'].mean(),\n",
    "                                                            cv_intermediateNet['test_recall'].mean(),\n",
    "                                                            cv_intermediateNet['test_f1_score'].mean(),\n",
    "                                                            cv_intermediateNet['test_AUC'].mean()],\n",
    "                                     'Dummy classifier':[cv_dummy_model['test_accuracy'].mean(),\n",
    "                                                         cv_dummy_model['test_precision'].mean(),\n",
    "                                                         cv_dummy_model['test_recall'].mean(),\n",
    "                                                         cv_dummy_model['test_f1_score'].mean(),\n",
    "                                                        cv_dummy_model['test_AUC'].mean()]},\n",
    "                                      index=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'])\n",
    "    \n",
    "    # Add 'Best Score' column to 'mean_scores_table'\n",
    "    mean_scores_table['Best Score'] = mean_scores_table.idxmax(axis=1)  \n",
    "\n",
    "    # Create 'std_scores_table' DataFrame with standard deviation of performance metric scores for each classifier\n",
    "    std_scores_table = pd.DataFrame({'Wide neural network':[cv_wideNet['test_accuracy'].std(),\n",
    "                                                         cv_wideNet['test_precision'].std(),\n",
    "                                                         cv_wideNet['test_recall'].std(),\n",
    "                                                         cv_wideNet['test_f1_score'].std(),\n",
    "                                                         cv_wideNet['test_AUC'].std()],\n",
    "                                     'Deep neural network':[cv_deepNet['test_accuracy'].std(),\n",
    "                                                            cv_deepNet['test_precision'].std(),\n",
    "                                                            cv_deepNet['test_recall'].std(),\n",
    "                                                            cv_deepNet['test_f1_score'].std(),\n",
    "                                                            cv_deepNet['test_AUC'].std()],\n",
    "                                     'Intermediate neural network':[cv_intermediateNet['test_accuracy'].std(),\n",
    "                                                            cv_intermediateNet['test_precision'].std(),\n",
    "                                                            cv_intermediateNet['test_recall'].std(),\n",
    "                                                            cv_intermediateNet['test_f1_score'].std(),\n",
    "                                                            cv_intermediateNet['test_AUC'].std()],\n",
    "                                     'Dummy classifier':[cv_dummy_model['test_accuracy'].std(),\n",
    "                                                         cv_dummy_model['test_precision'].std(),\n",
    "                                                         cv_dummy_model['test_recall'].std(),\n",
    "                                                         cv_dummy_model['test_f1_score'].std(),\n",
    "                                                        cv_dummy_model['test_AUC'].std()]},\n",
    "                                     index=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'])\n",
    "   \n",
    "    # Add 'Minimum standard deviation' column to 'std_scores_table'\n",
    "    std_scores_table['Minimum standard deviation'] = std_scores_table.idxmin(axis=1)  \n",
    "\n",
    "    # Return DataFrames with mean and standard deviation performance metrics scores for each classifier\n",
    "    return mean_scores_table, std_scores_table\n",
    "    \n",
    "                                       \n",
    "# Evaluate 5-fold cross-validated MLP models with different architectures and dummy classifier\n",
    "mean_scores_table, std_scores_table = models_evaluation(X_train_smote, y_train_smote)\n",
    "\n",
    "# Display the mean cross-validation scores \n",
    "print(mean_scores_table)\n",
    "\n",
    "# Display the standard deviations of the cross-validation scores\n",
    "print(std_scores_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAXCCAYAAAAPZgRQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAADFUElEQVR4nOzdd5xcZd3+8c9FEkhIMIABTEKJ9E6ABAjNgIiKIFUBUapiVx6kWCGgCDYsICLyQARBUNoPUAQeJSSEUBIIVVHEQCjSCUno4fv7476XnAwzu7Nhd2fv5Hq/XvvamVPu8z1nZuea+z5nZxQRmJmZWbmWaHUBZmZm9s44zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3azFJn5f0pKQ5kt7d6np6E0kTJH26yWVD0prdVMc3JZ3dzvyDJd30DtofL+l7+fZ2kh6ozFtH0p2SZkv6iqQBkq6SNEvSHxd2myWQNEPSTg3mLXCcFncOc+vV8ov585KWanUt3UFSP+BUYOeIGBQRz3ZBmzMkvSZpSM306TnwRuT7bwVInTZC0tz8BuMxSadK6vNOaytVRHw/Ij4NIGlEPj59u2lbkyJincqkY4AJEbFMRPwC2AdYCXh3RHysO2poRNJYSY/25DYbqT1O7QV/Z/SmfewMh7n1Wjl0tgMC+GgPb7tbXqjrWAnoD9zX2RWVNPob/g+wf2XZjYABndzEJhExCHg/8AngM52t0brEaiz4/FgN+GdEvNHZhnrwed2U3lZPV2jVPjnMrTc7ELgFGA8cVJ0haRVJl0l6WtKzkk6vzPuMpL/nYcn7JW2Wpy8wDFsztDlW0qOSjpX0X+BcSctJujpv4/l8e+XK+stLOlfS43n+FXn6vZJ2qyzXT9IzkkbW7MPaQNsw4QuS/panby3p9jyMerukrSvrTJB0kqTJwEvA6g2O3fn5+LU5CDiv4ZFuR0T8A5gEbFhvfj6uX5D0r3zMvytpDUlTJL0o6Q+Slqws/xlJD0p6TtKVkoZV5n1A0j/yvp8OqGZbh+bH9nlJ10parUFNu+THfnYeWTiqwXIPS9o83/5k3pf18/1PVx7TcZJ+l1ebmH+/kEcuxlTa+3Gu7T+SPtzomEraVNIdub6LSW/o2ua91TPMz4kdgNPztn4PHAfsm+8f1tFxyfv0RUn/Av6Vp+2qNFLzgqSbJW1cWX6GpKMk3Z0fh4sl9Zc0ELgGGJa3Paf62FXW/4jSaYEXJc2UNK4yr21U4zBJjwBtz/m6f7PZyNpa6hyn84FVgatyXcfk6Vvl/XtB0l2SxlZqedvfb6N9VM0olmp67/mYHSvpbmCupL4dbPtgSQ/l/f2PpAMaPVeaFhH+8U+v/AEeBL4AbA68DqyUp/cB7gJ+CgwkvRBum+d9DHgMGE0KgjWB1fK8ANastD8e+F6+PRZ4A/gBsBSpF/tuYG9gaWAZ4I/AFZX1/wRcDCwH9APel6cfA1xcWW534J4G+zgi19U3318eeB74FNCX1Lt+njSkCjABeATYIM/vV6fNGcBOpDcK6+XjNZPUowtgRO3+12njrWMFrA/8FzisnWWvBN6V63oV+CvpjcZg4H7goLzsjsAzwGb5OJ8GTMzzhgAvkoaR+wH/kx+TT+f5e+TnxHp5378N3Nyg5ieA7fLt5YDNGtR+HvC1fPss4N/A5yvz/iffHgf8rt5jlqcdTHqOfiYf788DjwOqs80lgYfz/vXL+/s6Cz4XH60sP6HtGNTW0onjcj3puTUgH/ungC1zrQeRnjNLVZ4/twHD8jp/Bz5Xr7YGx3QssBGps7gx8CSwR82xO4/0tzuA9v9mm64lL7tT5f5w4Flgl1zLB/L9FTr4+33bPlLzt9Jg29OBVfI+Ndx23u8XgXXyukOBDd7x6+U7bcA//umOH2Bb0gvckHz/H8x/YR0DPE3lxbSy3rXAVxu02VGYvwb0b6emkcDz+fZQ4E1guTrLDQNmA+/K9y8BjmnQZtuLW1uYfwq4rWaZKcDB+fYE4MQOjt0MUph/GzgZ+BDpxbwvnQvzF0lvJP4NfA9Yop1lt6ncnwYcW7n/E+Bn+fb/Aj+szBuUH+cR5JGYyjwBjzI/zK+h8oYiv0i+RJ03a6Q3PJ9tewzaOVaHAVfm238HPg1clO8/TH4TQHNh/mDl/tJ5mffU2eb21AQ9cDMLH+bNHJcdK/N/BXy3pqYHmB9mM4BPVub9EDizXm1N/i3/DPhpzbFbvcm/2aZr4e1hfixwfk1715LevLT39/u2faS5MD+0yW0PBF4gdRQGdOZYtvfjYXbrrQ4CrouIZ/L9C5k/1L4K8HDUP2e4Cil8FsbTEfFK2x1JS0v6dR6KfZE0vLqs0oVgqwDPRcTztY1ExOPAZGBvScsCHwYuaLKGYaQQqXqY9E6/zcwm2zqfdK77YBZuiH2ziFguItaIiG9HxJvtLPtk5fbLde4PyrcX2L+ImEPqsQzP82ZW5gUL7utqwM/zsOULwHOkwK8emzZ7k3pFD0u6sToUXuNGYDtJ7yH1Ui8GtlG6XmMwqbfVrP9Wan8p3xxUZ7lhwGN5/9rUPuad0cxxqT2OX2tbPq+zSq6rzX8rt1+i/n7UJWlLSTconZ6aBXyONOpSVa2no7/Zha1lNeBjNfu5LSnIG/79vgO1x7jutiNiLrAv6bg8IelPktZ9pxtf5C4+sPJJGgB8HOijdP4a0pDsspI2If3RrCqpb51Anwms0aDpl0g9pjbvIfX82sSCi/M1YB1gy4j4r9I57ztJL5QzgeUlLRsRL9TZ1m9Jvby+wJSIeKzR/tZ4nPRCULUq8Jd26qwrIh6W9B9SqB3W5Pa72wL7l89Rvps0zPoE6UW2bZ6q90nH/KSI6PCNUUTcDuyu9N8CXwL+UNNW23IPSnoJ+AppuH92fs4dDtzU4A1MU8e/HU8AwyWpEuirsvBvQps5LtWa25Y/aSG21cy+XwicDnw4Il6R9DPeHua19TT6m30ntc0k9Y7fduGmpKE0/vutt49zeftrR3vbb7htgIi4Frg2v9Z9D/gN6WLfheaeufVGewDzSOdqR+af9UgXYR1IOof2BHCKpIH54pxt8rpnA0dJ2lzJmpp/MdB04BOS+kj6EPC+DupYhtSrfEHS8sDxbTMi4gnS8OYZShfK9ZO0fWXdK0jnJr9K53rFfwbWlvSJfBHNvvk4XN2JNqoOIw2xzm0wv08+fm0/SzZYrqtcCBwiaaTSvxt+H7g1ImaQzmFuIGkvpSuCv8KCL5pnAt+QtAGApMGS3vavWZKWlHSApMER8TrpdMG8dmq6kRT4N+b7E2ru13qaNETb6OLDjkwhXQvwlfwY7wVssZBtQZPHpeI3wOdyD1r5b+gjkpZpYltPAu+WNLidZZYh9XpfkbQFaXSoPe39zXbGkyz4mPwO2E3SB/PffH+lC9dW7uDvt94+Tgd2Ubpo7j3AER3U0nDbklaS9NH8RvZVYA7tPz+b4jC33ugg4NyIeCQi/tv2Q3q3fwCpZ7wb6UKZR0i9630BIuKPwEmk0JhNCtXlc7tfzeu9kNu5ooM6fka6mOUZ0lX1f6mZ/ynS+d5/kC4oOqJtRkS8DFwKvBe4rNkdj/R/5ruSRgWeJV1Mt2vldEOnRMS/I2JqO4t8nfSGpe3nbwuznU7U81fgO6Rj8wSpR7ZfnvcM6WKoU0j7vhbpdEXbupeTLlC8KJ/2uJd0CqOeTwEz8nKfAz7ZTlk3kgJoYoP7tfvwEuk5NjkPoW7V/l6/bf3XgL1Ipz+eJz13m36O1GmvM8eF/Hz4DOnv6XnSxXMHN7mtfwC/Bx7K+/62q9lJF62eKGk26cr7P3TQZnt/s51xMvDtXNdRETGTdPHpN0lvwGYCRzM/9+r+/TbYx/NJF93OAK4jnY5pb5/a2/YSpL/vx0mnRN5HOmbviBY8bWNmXUXSccDaEdFekJiZvWM+Z27WDfKw/GGkd/9mZt3Kw+xmXUzSZ0jDatdERN2hWjOzruRhdjMzs8K5Z25mZlY4nzO3HjdkyJAYMWJEq8swMyvKtGnTnomIFerNc5hbjxsxYgRTp7b331JmZlZLUsNPCvQwu5mZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhfPHuVqPe+yFl/nGZfe0ugwzs4Vy8l4btbqEt3HP3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwKV3SYS/qppCMq96+VdHbl/k8kHSnpo5K+3qCNOT1Q6jsiaYKkUV3QzkhJu3RFTTXtjpV0dVe3a2ZmzSk6zIGbga0BJC0BDAE2qMzfGpgcEVdGxCktqK8pSnrisRgJdGmYS+rble2ZmVnnlf5CPBn4ab69AXAvMFTScsBLwHrAnZIOBkZFxJckvRe4kLTvf6k2Julo4OPAUsDlEXF87QZzT/7nwK7Ay8DuEfGkpBWAM4FV86JHRMRkSeOAORHx47z+vXldgGuAG4AxwB559GA0MAC4pN72a2qZAfwW2A3oB3wsIv4haSBwGrBR3s9xeVsnAgMkbQucDHwb2A6YBTwD/E9EnCfp/NzuTcCvgFHAG8CREXFDPp4fAfoDA3O7bTWNBs4C9o6Ih9qr38ysVS447tCFXnfKLwYu1HoTJkxY6G12pOieeUQ8DrwhaVVSL3wKcCspHEcBd0fEazWr/Rz4VUSMBv7bNlHSzsBawBakHuzmkravs9mBwC0RsQkwEfhMpd2f5nb3Bs6us26tdYDzImLTiHgY+FZEjAI2Bt4naeMm2ngmIjYjhe5Redq3gL/lWnYAfkQK++OAiyNiZERcTHoztA3pjdBDpGAH2Aq4BfgiQERsBOwP/FZS/7zMGOCgiNixrRBJW5Pe0OxeG+SSDpc0VdLUl2Y938RumZlZs0rvmUMKpK3zz6nA8Hx7FmkYvtY2pLAFOB/4Qb69c/65M98fRAr3iTXrvwa0nR+eBnwg394JWF9S23LvkrRMB7U/HBG3VO5/XNLhpMdlKLA+cHcHbVxWqWWvyr58VFJbuPdn/ohB1SRge+Bh0puBwyUNB56LiDm5B38aQO7xPwysnde9PiKeq7S1HqlHvnN+k7WAiDgrz2fomhtEB/tkZtatDjjxnIVe9+S9NurCSrrGohDmbefNNyINs88Evga8CDR6tOqFiYCTI+LXHWzv9YhoW38e84/hEsCYiHh5gUalN1hwBKR/5fbcynLvJfWsR0fE85LG1yzbyKt1ahFpmPuBmlq2rFl3Iqn3vSqpN78nsA8p5NvaaWRuzf0ncr2bAm8LczMz6z5FD7Nnk0nnoJ+LiHm5t7gsaRh4SoPl98u3D6hMvxY4VNIgAEnDJa3YiTquA77UdkfSyHxzBrBZnrYZ8N4G67+LFJCzJK0EfLgT2651LfBl5WECSZvm6bOBt0YLImIm6aLBtfKw+E2kNxRtYT6RfIwkrU0K/QXeIFS8QDqP/n1JY99B7WZm1kmLQpjfQwqkW2qmzYqIZ+os/1Xgi5JuBwa3TYyI60gXxk2RdA9wCZXga8JXgFGS7pZ0P/C5PP1SYHlJ04HPA/+st3JE3EUa4r+PNKIwuRPbrvVd0jnyu/MFd9/N028gnQqYLmnfPO3WSk2TSKcpbsr3zwD65ONxMXBwRLSNBNTbhydJF+P9ss4ogJmZdRPNHzE26xlD19wgDv7hRa0uw8xsobTqnLmkafki6bdZFHrmZmZmizWHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZla4vq0uwBY/w5cdwMl7bdTqMszMFhnumZuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeH82ezW82bNhKu+2uoqzKw32e3nra6gaO6Zm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhig1zSfMkTZd0n6S7JB0pqdj9aUTSOElHdUE7y0r6QlfUVKftOd3RrpmZNafk8Hs5IkZGxAbAB4BdgONbXNNCkdSnBzazLNClYa6k5OeQmdkioW+rC+gKEfGUpMOB2yWNI71JOQUYCywF/DIifg0g6Wjg43n65RFxvKQRwF+AW4FNgX8CB0bES9XtSJqQl9mBFI6HRcSkHMZv256kscBREbFrXv90YGpEjJc0AzgH2Bk4XdIywOHAksCDwKdqt19Ty3jgRWAU8B7gmIi4pNE+5vrWkDQduB4YCPwlIq6UdDnwfEQcKukw4L0R8W1JRwKH5k2eHRE/y8fqGuAGYAywR6WmIcBVwPci4k+NajezrjH2m5e2uoSu85O7Wl1Bl5kwYUKPb3OR6VVFxEOk/VkROAyYFRGjgdHAZyS9V9LOwFrAFsBIYHNJ2+cm1gHOioiNSSHZqBfbNyK2AI5g/khA3e01UfYrEbFtRFwEXBYRoyNiE+Dvuc2ODAW2BXYlhTXt7OPXgX/n0YyjgYnAdrmd4cD6+fa2wCRJmwOHAFsCW+V92jQvsw5wXkRsGhEP5+2uBPwJOK5ekEs6XNJUSVOfnvVyE7tmZmbNWiR65hXKv3cGNpa0T74/mBRwO+efO/P0QXn6I8DMiJicp/8O+Arw4zrbuCz/ngaM6GB7r3VQ78WV2xtK+h6pxz8IuLaDdQGuiIg3gftzmLbV0mgfqyYBR0haH7gfWE7SUFJv+yukHvnlETEXQNJlpPC/Eng4Im6ptNUP+CvwxYi4sV6hEXEWcBbAqLVWiib2zcw6MOH7e7e6hK6z289bXUHRFpkwl7Q6MA94ihTqX46Ia2uW+SBwctuQe2X6CKA2YBoFzqv59zzmH79G29uWBUc/+te0NbdyezywR0TcJelg0pB9R16t3Fbld6N9fEtEPCZpOeBDpF768qSh+TkRMVuSaGxuzf03SG9uPgjUDXMzM+s+i8Qwu6QVgDOB0yMiSL3az0vql+evLWlgnn6opEF5+nBJK+ZmVpU0Jt/eH7ipEyU02t7DwPqSlpI0GHh/O20sAzyR2zigE9uuV0u9fZydt1E1hXS6YCKpp35U/k2etoekpfO+7FmZVytIPfl1JX39HdRuZmYLoeSe+YB8MVc/Us/wfODUPO9s0hD4HbmH+TSp13udpPWAKbnjOQf4JKmX/XfgIEm/Bv4F/KoTtTTa3kxJfwDuzm3e2bgJvkO6uO5h4B7eHrxNabSPEfFvSZMl3Qtck8+bTwJ2jogHJT1M6p1Pyu3ckS+yu61tHyPiztoefmW78yTtB1wl6cWIOGNh6jczs85T6sgu3nJAXR0RG7a6lsXBqLVWiqmn7tfqMsysN/E58w5JmhYRo+rNWySG2c3MzBZnJQ+zd5mImAG4V25mZkVyz9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5+8zt543eBXY7eetrsLMbJHhnrmZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOn81uPe7xuY9zwpQTWl2GmVmnHT/m+FaXUJd75mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWuA7DXNKcJpY5QtLSXVPSwpE0TtJR+faJknbqYPmDJQ3rmeoWXq7z9C5q65td0U6ddmdIGtIdbZuZWce6qmd+BNCpMJfUp4u2/TYRcVxE/F8Hix0M9Iowl9S3hzbV5WHenY+jmZk1p+kQkTQWGAc8A2wITAM+CXyZFIo3SHomInaQtDNwArAU8G/gkIiYI2kGcA6wM3C6pFOAC4EdgH7A4cDJwJrAjyLizLzto4GP5/Yuj4jj8/RvAQcCM4Gnc01IGg9cHRGXSDoO2A0YANwMfBbYGxgFXCDpZWAMsD5wKjAo7+PBEfFEzTEYD7yY130PcExEXNKoRkkjch0b5mWOAgZFxDhJE3I92wBXSvon8G1gSeBZ4ICIeLKdx2McsCqwev79s4j4RZ73SeArua1bgS8AJwEDJE0H7gPuAl6JiF9I+imwSUTsKOn9+fH6pKT9SW8ABPwpIo7N7c/Jx+qDwNcqNQ0ALgcujYjfNKrdzKy3OveL57Y7/4Z33dDu/AkTJnRhNc3rbM98U1IvfH1SiGyTA+RxYIcc5ENIobRTRGwGTAWOrLTxSkRsGxEX5fszI2IMMAkYD+wDbAWcCJDfGKwFbAGMBDaXtL2kzYH9ck17AaMb1Hx6RIzOgToA2DUH8FRSYI4E3gBOA/aJiM1JbzhOatDeUGBbYFfglPZqbHwY37JsRLwvIn4C3ARsFRGbAhcBxzSx/rqkQN0COF5SP0nrAfuSHpuRwLy8n18HXo6IkRFxADAR2C63MwoYJKlf3rdJ+RTED4Ad8z6NlrRHXn4gcG9EbBkRN+Vpg4CrgAvrBbmkwyVNlTT1pedfamLXzMysWZ0d3r0tIh4FyD28EaQQqtqKFPaTJUHqHU6pzL+4Zvkr8+97SL3W2cBsSa9IWpbUi98ZuDMvN4gUnMuQesAv5XqupL4dJB1DOg2wPKlXelXNMuuQRhuuzzX3AZ6gvisi4k3gfkkr5WmNanykQRttqsdiZeBiSUNJx+w/HawLqbf8KvCqpKeAlYD3A5sDt+d9GQA8VWfdaaQ3HcsArwJ3kEJ9O1KvfjQwISKeBpB0AbA9cAXpDcKlNe39P+CHEXFBvUIj4izgLIBh6w2LJvbNzKzHHfLLQ9qdf/yY43uoks7pbJi/Wrk9r8H6Aq6PiP0btDG3QZtv1rT/Zm5fwMkR8esFNiIdAbQbCpL6A2cAoyJiZh6a7t+g5vvyCEFHqjWq8rtejSuz4OhH7barx+I04NSIuLJySqMztbQ9HgJ+GxHfaG/FiHg9n/Y4hDTcfzfpdMcawN+BtdtZ/ZWImFczbTLwYUkXRoTD2sysB3XVBXCzST1lgFuAbSStCSBpaUntBUNHrgUOlTQotzdc0oqkYeI9JQ3Ivcvd6qzbFp7P5PX3aVDzA8AKksbkbfSTtEEX1PgksKKkd0taijQ038hg4LF8+6BObLvWX4F98vaRtLyk1fK81/NQepuJwFH59yTgc8D0HMa3Au+TNCRf5LY/cGM72z2OdK7/jHdQu5mZLYSuCvOzgGsk3ZCHZQ8Gfi/pblK4r7uwDUfEdaSL5KZIuge4BFgmIu4gDVNPJw35Tqqz7gvAb0hD+FcAt1dmjwfOzKcL+pCC/geS7sptbt0FNb5OOvd/K3A18I92mhkH/FHSJNIFeAslIu4nXbNwXT7+15PO80N6nO7OQ+aQjtlQYEq+2O6VPI188d83gBtIF8vdERH/r4PNHwH0l/TDha3fzMw6Tx4RtZ42bL1h8dlzPtvqMszMOq2V58wlTYuIUfXm+RPgzMzMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMytc31YXYIufYQOHcfyY41tdhpnZIsM9czMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCuePc7Ue9/rjj/PEcf44V1v0DD3xhFaXYIsp98zNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHCLfZhLmidpuqT7JN0l6UhJRRwXSSMk3duF7Z0oaad8e7t8TKZLGi7pkq7ajpmZda2+rS6gF3g5IkYCSFoRuBAYDBzfyqJaISKOq9w9APhxRJyb7+/TbDuS+kTEvC4tzszMGiqiB9pTIuIp4HDgS0oOlnR623xJV0sam2/PkfQDSdMk/Z+kLSRNkPSQpI/mZQ6WdIWkqyT9R9KXcs//Tkm3SFpe0hqS7qhsYy1J02prk7Rm3s5dku6QtEbN/BGSJuV5d0jaOk8fKmli7mHfm3vcfSSNz/fvkfQ/ednxkvaR9Gng48Bxki6ojgDkdX8k6XZJd0v6bJ4+VtINki4E7unCh8XMzDrgnnmNiHgoD7Ov2MGiA4EJEXGspMuB7wEfANYHfgtcmZfbENgU6A88CBwbEZtK+ilwYET8TNIsSSMjYjpwCDC+zvYuAE6JiMsl9Se9EavW+BTwgYh4RdJawO+BUcAngGsj4iRJfYClgZHA8IjYEEDSsjXH4GxJ2wJXR8QlkkZUZh8GzIqI0ZKWAiZLui7P2wLYMCL+08GxM1sk7H3ebxe4v+TEGxe4P2HChB6sxhZnDvP61MQyrwF/ybfvAV6NiNcl3QOMqCx3Q0TMBmZLmgVcVVln43z7bOAQSUcC+5JCcX4x0jKk8L0cICJeydOri/UDTpc0EpgHrJ2n3w6cI6kfcEVETJf0ELC6pNOAPwHX0bydgY0ltQ27DwbWysfjtkZBLulw0qgHwwcP7sTmzMysIw7zGpJWJ4XhU8AbLHgqon/l9usREfn2m8CrABHxpqTqcX21cvvNyv03mX/8LyWdo/8bMC0inq0tq4nS/wd4Etgk1/xKrmeipO2BjwDnS/pRRJwnaRPgg8AXSUPqhzaxjbZavhwR1y4wMZ1+mNtopYg4CzgLYJNhw6LRcmYlufTAgxa4P/TEE1pUiS3ufM68QtIKwJnA6TmoZwAjJS0haRVqesxdJfe0rwV+BZxbZ/6LwKOS9sh1LiVp6ZrFBgNPRMSbwKeAPnnZ1YCnIuI3wP8Cm0kaAiwREZcC3wE260S51wKfzz19JK0taWAn1jczsy7mnjkMkDSdNEz9BnA+cGqeNxn4D2lI/F7gjnoNdJELgL1oPOT9KeDXkk4EXgc+RurdtzkDuFTSx4AbmN9LHgscLel1YA5wIDAcOLfyL3jf6ESdZ5NOI9yhNM7/NLBHJ9Y3M7MupvkjxdZKko4CBkfEd1pdS3fbZNiw+MunP9PqMsy6nIfZrTtJmhYRo+rNc8+8F8hXw68B7NjqWszMrDwO814gIvZsdQ1mZlYuXwBnZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFa5vqwuwxU+/YcMYeuIJrS7DzGyR4Z65mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFU0S0ugZbzEiaDTzQ6jraMQR4ptVFdKC31+j63pneXh/0/hoXxfpWi4gV6s3wZ7NbKzwQEaNaXUQjkqb25vqg99fo+t6Z3l4f9P4aF7f6PMxuZmZWOIe5mZlZ4Rzm1gpntbqADvT2+qD31+j63pneXh/0/hoXq/p8AZyZmVnh3DM3MzMrnMPczMyscA5z6zaSPiTpAUkPSvp6nfmS9Is8/25Jm/Wy+taVNEXSq5KO6snamqzvgHzc7pZ0s6RNemGNu+f6pkuaKmnb3lRfZbnRkuZJ2qc31SdprKRZ+fhNl3Rcb6qvUuN0SfdJurEn62umRklHV47fvflxXr4X1TdY0lWS7srH8JCF2lBE+Mc/Xf4D9AH+DawOLAncBaxfs8wuwDWAgK2AW3tZfSsCo4GTgKN64fHbGlgu3/5wTx6/TtQ4iPnX5mwM/KM31VdZ7m/An4F9elN9wFjg6p58XDtZ37LA/cCq+f6Kva3GmuV3A/7Wm+oDvgn8IN9eAXgOWLKz23LP3LrLFsCDEfFQRLwGXATsXrPM7sB5kdwCLCtpaG+pLyKeiojbgdd7qKbO1ndzRDyf794CrNwLa5wT+VUKGAj05BW3zTwHAb4MXAo81YO1QfP1tUoz9X0CuCwiHoH0N9MLa6zaH/h9j1SWNFNfAMtIEunN73PAG53dkMPcustwYGbl/qN5WmeX6S6t3HYzOlvfYaRRjp7UVI2S9pT0D+BPwKE9VBs0UZ+k4cCewJk9WFebZh/jMXkI9hpJG/RMaUBz9a0NLCdpgqRpkg7sseqSpv9OJC0NfIj0xq2nNFPf6cB6wOPAPcBXI+LNzm7IH+dq3UV1ptX2yppZpru0ctvNaLo+STuQwrxHz0fTZI0RcTlwuaTtge8CO3V3YVkz9f0MODYi5qWOUY9qpr47SJ/HPUfSLsAVwFrdXVjWTH19gc2B9wMDgCmSbomIf3Z3cVln/o53AyZHxHPdWE+tZur7IDAd2BFYA7he0qSIeLEzG3LP3LrLo8Aqlfsrk955dnaZ7tLKbTejqfokbQycDeweEc/2UG1tOnUMI2IisIakId1dWNZMfaOAiyTNAPYBzpC0R49U10R9EfFiRMzJt/8M9Otlx+9R4C8RMTcingEmAj15IWZnnoP70bND7NBcfYeQTlVERDwI/AdYt9Nb6qkLAfyzeP2Q3rE/BLyX+Rd+bFCzzEdY8AK423pTfZVlx9HzF8A1c/xWBR4Etu7Fj/GazL8AbjPgsbb7vaG+muXH07MXwDVz/N5TOX5bAI/0puNHGh7+a152aeBeYMPedAzzcoNJ56IH9lRtnTiGvwLG5dsr5b+RIZ3dlofZrVtExBuSvgRcS7qi85yIuE/S5/L8M0lXD+9CCqSXSO9Qe019kt4DTAXeBbwp6QjSlaidGv7qrvqA44B3k3qTAG9ED35LVJM17g0cKOl14GVg38ivWr2kvpZpsr59gM9LeoN0/PbrTccvIv4u6S/A3cCbwNkRcW9P1NdsjXnRPYHrImJuT9XWifq+C4yXdA+pY3NspFGOTvHHuZqZmRXO58zNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwN7Ni5Y+KDUmd/5ANs0WIw9zMSrY/cBPp0726haQ+3dW2WVdxmJtZkSQNArYhfS79fnlaH0k/lnRP/h71L+fpo/N3vt8l6TZJy0g6WNLplfauljQ2354j6URJt5K+6OQ4Sbfn78M+K3/DFZLWlPR/ud07JK0h6XxJu1favUDSR3vquNjiyWFuZqXag/S54P8EnpO0GXA46aMzN42IjYELJC0JXEz6NqpNSF/08nIHbQ8E7o2ILSPiJuD0iBgdERuSvlBk17zcBcAvc7tbA0+QPiv/EABJg/P0P3fVTpvV4zA3s1LtT/p+aPLv/UlBfWZEvAEQ6Ruy1gGeiPTd9ET68pKOvi96Hgt+VeYOkm7NH7m5I7CBpGWA4ZG+FY6IeCUiXoqIG4E1Ja2Ya7q0ie2ZvSP+bHYzK46kd5NCdUNJQfrc6wCmUf+rdut9bvUbLNih6V+5/UpEzMvb6g+cAYyKiJmSxuVl2/vO1POBA0jD/z35He62mHLP3MxKtA9wXkSsFhEjImIV0ldH3gF8TlJfAEnLA/8Ahkkanactk+fPAEZKWkLSKqRvJaunLeSfyefp94HUwwcebfvKVElLSVo6LzseOCIvd1+X7bVZAw5zMyvR/sDlNdMuBYaRvib0bkl3AZ+IiNeAfYHT8rTrSQE9mfQG4B7gx6Q3Am8TES8Av8nLXQHcXpn9KeArku4GbiZ9ZSkR8STwd+Dcd7ifZk3xt6aZmXWx3EO/B9gsIma1uh5b9LlnbmbWhSTtRBraP81Bbj3FPXMzM7PCuWduZmZWOIe5LdYkHSDpuiaWO1PSd7ph+5J0rqTnJd3W1e2XLn/u+ppNLDdW0qPdWMc1kg5qZ/54Sd97B+3PyMPzSPqmpLMr8/aUNDN/Kt2mktaRdKek2ZK+srDb7O0kjciPf91/oa49Tos7h7n1WvkF7uX8IvZkDr1BXbmNiLggInZuYrnPRcR3u3Lb2bbAB4CVI6LRv0Y1rfICeEfN9CGSXpM0ozLtrQCpWXaspDfzcZ8t6QFJh7zT2koWER+OiN8C5I+Bvakbt/X9iPh0ZdKPgS9FxKCIuBM4BpgQEctExC+6q456JI2T9Lue3GYj1ePUUfB3Rm/ax85wmFtvt1tEDAI2A0YD365doCv+gFtoNWBGRMzt7Iod7PdASRtW7n+C9G9YzXo8H/d3AccCv5G0fmdrtC6xGnBfO/eb1tv+VnpbPV2hVfvkMLciRMRjwDXAhvDW8OsXJf0L+Feetquk6ZJeUPpSjY3b1pe0iqTLJD0t6VnlL9io9rLykPdPJT0laZbSF3W0bW+BYVRJn5H0oKTnJF0paVhlXkj6nKR/5eHzX0p626eFSTqM9DneY3Iv+IQm215gvxs4H6gOCx8InNfc0Z4vkiuA54G3hXnb8LakY/Jxe0LSHpJ2kfTPvA/frCy/lKSfSXo8//xM0lKV+UfnNh6XdGjNtpZS+hKVR/JIzZmSBtSrW9Kxkh6rjCy8v84y783PlSXy/bMlPVWZ/ztJR+TbEyR9WtJ6wJnMf8xeqDS5nKQ/5W3eKmmNRsdV0qckPZyfi9+qmTcub3spSXNIn253l6R/S/obsANwet7+2u0dl8rjc6yk/wLnKn1Iztdze89K+oPSh+tUe7gH5faeaatP0oeAbwL75m3f1WDf2tqeLel+SXtW5h0saXL+O3sOGCdpgKSf5OMxS9JNNY/rAbW1VI9Tvjsx/34h1zYmL3OopL8r/R1eK2m1yvobSLo+P0efVBq2r7uPqhnFqm67cswOk/QI8Lf2tq2k7uvMOxIR/vFPr/whfULXTvn2KqTeyHfz/SB9+MfypC++2Ax4CtiS9OJ3UF5/qXz/LuCnpC/Q6A9sm9s5GLgp3/4g6eNAlyV9VOd6wNA8bzzwvXx7R+CZvM2lgNOAiZW6A7g6t7Mq8DTwoQb7+Nb2O9H2W/tdp70ReZkRwMy87+sBD5A+t3xGveNb08ZY4NF8ewlgT+B1YJ0Gy74BHAf0Az6T9/dCYBlgA+AVYPW8/InALcCKwAqkD1ppe0w/BDxJesM2MLcRwJp5/s+AK/O+LwNcBZxcp+Z18r4PqxyTNRoc/0eAzfPtB4CHgPUq8zbNtycAn673mFWeH8+RPkWuL+kLWC5qsM31gTnA9vkxPjUfw7bn+jjgdzWP+ZqV+2/V0uRxeQP4Qd7WANIn090CrJyn/Rr4fc3z5zd52U2AVyvHZIHaGuzfx0gf3rME6cN65jL/7+jgXM+X83EaAPwy79Nw0vN161xX07VUlu1bqWMP4EHS878vaVTv5jxvGdKX4nyN9HqwDLBlo32k5m+lwbbPIz1vB3Sw7YavM+/o9bKnXpj945/O/uQ/oDnAC8DDpM/HHpDnBbBjZdlfkUOhMu0B4H3AGFLA9K2zjYOZH+Y7Av8EtgKWqFluPPPD/H+BH1bmDSKF3YhKbdtW5v8B+HqDfXxr+51oe8d6beX5b72oAf+XXzhOAb5F58L8zXzcnwOmA/s12N5Y0jeQ9cn3l8nb37KyzDRgj3z738AulXkfbKsJOAc4pTJv7dzWmvlFby6VUM6P638qdbSF+ZqkN3Y7Af06eI6dDxxJ+uS2B4AfAp8jffPaC23PA5oL87Mr93cB/tFgm8dRCXpSALzGQoR5k8flNaB/Zf7fgfdX7g8lPcf6Vp4/K1fm39b2+NfW1uTf8XRg98qxe6Qyb4n8/Nmknedyh7VQP8yvAQ6r2dZLpNMU+wN3Nqj3bftIc2G+epPbbvg6805+FrnzFbbI2SMi/q/BvJmV26sBByl/f3W2JKmHMA94ODr45qqI+JvS8PsvgVUlXQ4cFekzuKuGUfnoz4iYI+lZUs9iRp7838ryL5FCuRnNtD2zznr1nEd68dya1Atcq8n1IJ0zX7nJZZ+N/KUkzP9q0Scr819m/v4PI70xa/NwntY2b1rNvDYrAEsD0zT/jIVIPbkFRMSDeXh8HOnbza4FjoyIx+vUfiPwUeBR0lDtBNJHtL4CTIqIN+us00izj/kwKo9hRMzNj/HCaOa4PB0Rr1TurwZcLqm6b/OAlSr3F/b5i6QDSW+QRuRJg4AhlUWqz98hpJ7xv9tpcmFrWQ34uaSfVMsj/S2t0sE2F0bt61HdbXfidaZTfM7cShaV2zOBkyJi2crP0hHx+zxvVTVxYUpE/CIiNicND68NHF1nscdJf6wASBoIvBt47B3sS2fajtqVGrgU+AjwUEQ83NHCPWSB/SOdhmgL2SdIL7LVeW2eIb0p2KDy+A6OdJHe20TEhRGxbd5WkIaZ67kR2I7Ug70RuAnYhjSic2ODdZo9/o0ssJ9KH/367oVsq5njUlvvTODDNX8r/SNdl9KRdvc9nxf+DfAl4N0RsSxwLwt+w1y1jWdIb5waXl/QpHp1zQQ+W7OfAyLi5jyv0TbrtTWX9KapzXs6WK+9bTf7OtMpDnNbVPyG9G1ZW+YLTAZK+ojSd07fRnoBPSVP7y9pm9oGJI3O6/cj/fG+Quqx1LoQOETSSKWLt74P3BoRM7pgP7qs7UhXyO8IfLqdxfrl49H2092jdb8Hvi1pBUlDSEPObRcx/QE4WNL6OeCOb1sp95B/A/xU6XvCkTRc0gdrN6D0f9g75uP3Cins6j2ORMS/8vxPkq5NeJE0qrA3jcP8SWBlSUt2ct/bXALsKmnb3MaJLORrcWeOS8WZwEmVC7JWkLR7k5t8EhihfNFgHQNJofZ0bvsQ8kWr7dR/DnCqpGGS+kgao8pFkU16mnRqaPXKtDOBb0jaINcyWNLH8ryrgfdIOkLpAsJlJG3Zzj5OB/aT1E/SKPI357Wj4bY78TrTKQ5zWyRExFTSxVenk668fpA0xEweAt6NdC71EdKQ6r51mnkX6YXxedIQ77Ok//Gt3dZfge+Qer5PkN7h79dF+9GlbUfE1Ihobzjxz6Qwa/sZt7DbatL3gKnA3aQvIrkjTyMiriFdzPU30uP3t5p1j83Tb5H0IumagHXqbGMp0nUCz5CGaFckXaHcyI2kUwWPVO4LuLPB8n8jXYz5X0nPtNNuXZG+EvWLpDduT5Ceb+/kA2+aPS5tfk66YO46SbNJF8Nt2c7yVX/Mv59VzWcZAETE/cBPgCmkUNyI9O107TmK9Fy4nXSNxg/oZDZFxEvAScBkpf9Q2CoiLs9tXZSPy73Ah/Pys0mf77Ab6TnyL9J/CTTax++Q/hafB04gPXbt1dNw2zT5OtNZ/mx2MzOzwrlnbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOHxpjPW7IkCExYsSIVpdhZlaUadOmPRMRK9Sb5zC3HjdixAimTp3a6jLMzIoiqeGHP3mY3czMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscP4EOOtxj73wMt+47J5Wl2Fmi6CT99qo1SW0hHvmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZla4osNc0k8lHVG5f62ksyv3fyLpSEkflfT1Bm3M6YFS3xFJEySN6oJ2RkrapStqqml3rKSru7pdMzNrTtFhDtwMbA0gaQlgCLBBZf7WwOSIuDIiTmlBfU1R0hOPxUigS8NcUt+ubM/MzDqv9BfiycBP8+0NgHuBoZKWA14C1gPulHQwMCoiviTpvcCFpH3/S7UxSUcDHweWAi6PiONrN5h78j8HdgVeBnaPiCclrQCcCayaFz0iIiZLGgfMiYgf5/XvzesCXAPcAIwB9sijB6OBAcAl9bZfU8sM4LfAbkA/4GMR8Q9JA4HTgI3yfo7L2zoRGCBpW+Bk4NvAdsAs4BngfyLiPEnn53ZvAn4FjALeAI6MiBvy8fwI0B8YmNttq2k0cBawd0Q81F79ZmbtueC4Qzu9zpRfDOz0OhMmTOj0Or1N0T3ziHgceEPSqqRe+BTgVlI4jgLujojXalb7OfCriBgN/LdtoqSdgbWALUg92M0lbV9nswOBWyJiE2Ai8JlKuz/N7e4NnF1n3VrrAOdFxKYR8TDwrYgYBWwMvE/Sxk208UxEbEYK3aPytG8Bf8u17AD8iBT2xwEXR8TIiLiY9GZoG9IboYdIwQ6wFXAL8EWAiNgI2B/4raT+eZkxwEERsWNbIZK2Jr2h2b02yCUdLmmqpKkvzXq+id0yM7Nmld4zhxRIW+efU4Hh+fYs0jB8rW1IYQtwPvCDfHvn/HNnvj+IFO4Ta9Z/DWg7PzwN+EC+vROwvqS25d4laZkOan84Im6p3P+4pMNJj8tQYH3g7g7auKxSy16VffmopLZw78/8EYOqScD2wMOkNwOHSxoOPBcRc3IP/jSA3ON/GFg7r3t9RDxXaWs9Uo985/wmawERcVaez9A1N4gO9snMjANOPKfT65y810bdUEnvtyiEedt5841Iw+wzga8BLwKNngn1wkTAyRHx6w6293pEtK0/j/nHcAlgTES8vECj0hssOALSv3J7bmW595J61qMj4nlJ42uWbeTVOrWINMz9QE0tW9asO5HU+16V1JvfE9iHFPJt7TQyt+b+E7neTYG3hbmZmXWfoofZs8mkc9DPRcS83FtcljQMPKXB8vvl2wdUpl8LHCppEICk4ZJW7EQd1wFfarsjaWS+OQPYLE/bDHhvg/XfRQrIWZJWAj7ciW3Xuhb4svIwgaRN8/TZwFujBRExk3TR4Fp5WPwm0huKtjCfSD5GktYmhf4CbxAqXiCdR/++pLHvoHYzM+ukRSHM7yEF0i0102ZFxDN1lv8q8EVJtwOD2yZGxHWkC+OmSLoHuIRK8DXhK8AoSXdLuh/4XJ5+KbC8pOnA54F/1ls5Iu4iDfHfRxpRmNyJbdf6Lukc+d35grvv5uk3kE4FTJe0b552a6WmSaTTFDfl+2cAffLxuBg4OCLaRgLq7cOTpIvxfllnFMDMzLqJ5o8Ym/WMoWtuEAf/8KJWl2Fmi6BF+Zy5pGn5Ium3WRR65mZmZos1h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4fq2ugBb/AxfdgAn77VRq8swM1tkuGduZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnh/HGu1vNmzYSrvtrqKszKtNvPW12B9ULumZuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4YoNc0nzJE2XdJ+kuyQdKanY/WlE0jhJR3VBO8tK+kJX1FSn7Tnd0a6ZmTWn5PB7OSJGRsQGwAeAXYDjW1zTQpHUpwc2syzQpWGupOTnkJnZImGReCGOiKeAw4Ev5YDpI+lHkm6XdLekz7YtK+noyvQT8rQRkv4h6bd5+iWSlq7djqQJkn4g6TZJ/5S0XZ5ed3uSxkq6urL+6ZIOzrdnSDpO0k3AxyR9Jq9/l6RL622/ppbxkn4h6WZJD0nap719BE4B1sijGT+SdIakj+blL5d0Tr59mKTv5dtHSro3/xxROVZ/l3QGcAewSmW7QyRNkfSRph44MzPrEn1bXUBXiYiHci9xRWB3YFZEjJa0FDBZ0nXAWvlnC0DAlZK2Bx4B1gEOi4jJOdi+APy4zqb6RsQWktpGAnYCDmuwvY68EhHbAkh6d0T8Jt/+Xm7ztA7WHwpsC6wLXAlcImnnBvv4dWDDiBiZt7EfsF1eb3hui9zeRZI2Bw4Btszt3CrpRuD5fKwOiYgv5LaQtFJu69sRcX0T+24tNPabl7a6BFtYP7mr1RXYQpowYUK3tb1I9MwrlH/vDBwoaTpwK/BuUsDtnH/uJPUq183TAWZGxOR8+3ekUKvnsvx7GjCig+115OLK7Q0lTZJ0D3AAsEET618REW9GxP3ASpVaGu1j1SRgO0nrA/cDT0oaCowBbibt/+URMTci5pD2e7u87sMRcUulrX7AX4FjGgW5pMMlTZU09elZLzexa2Zm1qxFpmcuaXVgHvAUKdS/HBHX1izzQeDkiPh1zfQRQNQ0WXu/zav59zzmH79G29uWBd8w9a9pa27l9nhgj4i4Kw/Fj22w/Xq1tNXQ9rvRPr4lIh6TtBzwIWAisDzwcWBORMyWJBqbW3P/DdKbmw8CN9ZbISLOAs4CGLXWSo2OrfWQCd/fu9Ul2MLa7eetrsB6oUWiZy5pBeBM4PSICOBa4POS+uX5a0samKcfKmlQnj5c0oq5mVUljcm39wdu6kQJjbb3MLC+pKUkDQbe304bywBP5DYO6MS269VSbx9n521UTQGOIIX5JOCo/Js8bQ9JS+d92bMyr1YAhwLrSvr6O6jdzMwWQsk98wF5WLsfqWd4PnBqnnc2aQj8jtzDfJrU671O0nrAlNzxnAN8ktTL/jtwkKRfA/8CftWJWhptb6akPwB35zbvbKeN75CG6B8G7uHtwduURvsYEf+WNFnSvcA1EXE0KZx3jogHJT1M6p1Pyu3cIWk8cFvbPkbEnbU9/Mp25+Xz8FdJejEizliY+s3MrPOUOrKLtxxQV0fEhq2uZXEwaq2VYuqp+7W6DLMyeZh9sSVpWkSMqjdvkRhmNzMzW5yVPMzeZSJiBuBeuZmZFck9czMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwfVtdgC2GBq8Cu/281VWYmS0y3DM3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PC+bPZrcc9PvdxTphyQqvLMLPCHT/m+FaX0Gu4Z25mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmheswzCXNaWKZIyQt3TUlLRxJ4yQdlW+fKGmnDpY/WNKwnqlu4eU6T++itr7ZFe3UaXeGpCHd0baZmXWsq3rmRwCdCnNJfbpo228TEcdFxP91sNjBQK8Ic0l9e2hTXR7m3fk4mplZc5oOEUljgXHAM8CGwDTgk8CXSaF4g6RnImIHSTsDJwBLAf8GDomIOZJmAOcAOwOnSzoFuBDYAegHHA6cDKwJ/CgizszbPhr4eG7v8og4Pk//FnAgMBN4OteEpPHA1RFxiaTjgN2AAcDNwGeBvYFRwAWSXgbGAOsDpwKD8j4eHBFP1ByD8cCLed33AMdExCWNapQ0ItexYV7mKGBQRIyTNCHXsw1wpaR/At8GlgSeBQ6IiCfbeTzGAasCq+ffP4uIX+R5nwS+ktu6FfgCcBIwQNJ04D7gLuCViPiFpJ8Cm0TEjpLenx+vT0ran/QGQMCfIuLY3P6cfKw+CHytUtMA4HLg0oj4TaPazcw669wvnvu2aTe864a3TZswYUIPVNP7dLZnvimpF74+KUS2yQHyOLBDDvIhpFDaKSI2A6YCR1baeCUito2Ii/L9mRExBpgEjAf2AbYCTgTIbwzWArYARgKbS9pe0ubAfrmmvYDRDWo+PSJG50AdAOyaA3gqKTBHAm8ApwH7RMTmpDccJzVobyiwLbArcEp7NTY+jG9ZNiLeFxE/AW4CtoqITYGLgGOaWH9dUqBuARwvqZ+k9YB9SY/NSGBe3s+vAy9HxMiIOACYCGyX2xkFDJLUL+/bpHwK4gfAjnmfRkvaIy8/ELg3IraMiJvytEHAVcCF9YJc0uGSpkqa+tLzLzWxa2Zm1qzODu/eFhGPAuQe3ghSCFVtRQr7yZIg9Q6nVOZfXLP8lfn3PaRe62xgtqRXJC1L6sXvDNyZlxtECs5lSD3gl3I9V1LfDpKOIZ0GWJ7UK72qZpl1SKMN1+ea+wBPUN8VEfEmcL+klfK0RjU+0qCNNtVjsTJwsaShpGP2nw7WhdRbfhV4VdJTwErA+4HNgdvzvgwAnqqz7jTSm45lgFeBO0ihvh2pVz8amBARTwNIugDYHriC9Abh0pr2/h/ww4i4oF6hEXEWcBbAsPWGRRP7Zmb2lkN+ecjbph0/5vgWVNI7dTbMX63cntdgfQHXR8T+DdqY26DNN2vafzO3L+DkiPj1AhuRjgDaDQVJ/YEzgFERMTMPTfdvUPN9eYSgI9UaVfldr8aVWXD0o3bb1WNxGnBqRFxZOaXRmVraHg8Bv42Ib7S3YkS8nk97HEIa7r+bdLpjDeDvwNrtrP5KRMyrmTYZ+LCkCyPCYW1m1oO66gK42aSeMsAtwDaS1gSQtLSk9oKhI9cCh0oalNsbLmlF0jDxnpIG5N7lbnXWbQvPZ/L6+zSo+QFgBUlj8jb6SdqgC2p8ElhR0rslLUUamm9kMPBYvn1QJ7Zd66/APnn7SFpe0mp53ut5KL3NROCo/HsS8Dlgeg7jW4H3SRqSL3LbH7ixne0eRzrXf8Y7qN3MzBZCV4X5WcA1km7Iw7IHA7+XdDcp3Ndd2IYj4jrSRXJTJN0DXAIsExF3kIapp5OGfCfVWfcF4DekIfwrgNsrs8cDZ+bTBX1IQf8DSXflNrfughpfJ537vxW4GvhHO82MA/4oaRLpAryFEhH3k65ZuC4f/+tJ5/khPU535yFzSMdsKDAlX2z3Sp5GvvjvG8ANpIvl7oiI/9fB5o8A+kv64cLWb2ZmnSePiFpPG7besPjsOZ9tdRlmVrjF7Zy5pGkRMarePH8CnJmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnh+ra6AFv8DBs4jOPHHN/qMszMFhnumZuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeH82ezW415//HGeOM6fzW6929ATT2h1CWZNc8/czMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzAq32Ie5pHmSpku6T9Jdko6UVMRxkTRC0r1d2N6JknbKt7fLx2S6pOGSLumq7ZiZWdfq2+oCeoGXI2IkgKQVgQuBwcDxrSyqFSLiuMrdA4AfR8S5+f4+zbYjqU9EzOvS4szMrCGHeUVEPCXpcOB2SeOAg4BREfElAElXkwJugqQ5wC+BnYDngW8CPwRWBY6IiCslHQzsAfQBNgR+AiwJfAp4FdgFWA74Y0RslrexFnBRRGxerU3SmsCZwArAPOBj+Xfb/BHA+cDAPOlLEXGzpKHAxcC7SI/354Gbgf8FRgEBnBMRP5U0HrgaWBb4OPDB3FP/FnB1RGwoqQ9wCjAWWAr4ZUT8WtJY0hugJ4CRwPqdOPRmLbf3eb9d4P6SE2986/aECRN6uBqzznGY14iIh/Iw+4odLDoQmBARx0q6HPge8AFSiP0WuDIvtyGwKdAfeBA4NiI2lfRT4MCI+JmkWZJGRsR04BBgfJ3tXQCcEhGXS+pPOkVSrfEp4AMR8Up+Q/B7Ulh/Arg2Ik7KQbw0KWyHR8SGAJKWrTkGZ0valhTgl+Q3Cm0OA2ZFxGhJSwGTJV2X520BbBgR/6ktPr9JOhxg+ODBDQ6pmZktDId5fWpimdeAv+Tb9wCvRsTrku4BRlSWuyEiZgOzJc0Crqqss3G+fTZwiKQjgX1JoTi/GGkZUvheDhARr+Tp1cX6AadLGknqsa+dp98OnCOpH3BFREyX9BCwuqTTgD8B19G8nYGNJbUNuw8G1srH47Z6QZ5rPgs4C2CTYcOiE9sz6xGXHnjQAveHnnhCiyox67wiLvTqSZJWJ4XhU8AbLHiM+lduvx4RbaH0JmnYnIh4kwXfJL1auf1m5X51uUuBDwO7AtMi4tnaspoo/X+AJ4FNSD3yJXM9E4HtgceA8yUdGBHP5+UmAF8kvZloloAvR8TI/PPeiGh7MzC3E+2YmVkXcZhXSFqBdF769BzUM4CRkpaQtAo1Peauknva1wK/As6tM/9F4FFJe+Q6l5K0dM1ig4En8puJT5HO0yNpNeCpiPgN6Tz5ZpKGAEtExKXAd4DNOlHutcDnc08fSWtLGtjBOmZm1o08zA4DJE0nDVO/QbqI7NQ8bzLwH9KQ+L3AHd1YxwXAXjQe8v4U8GtJJwKvky6Ae7My/wzgUkkfA25gfi95LHC0pNeBOcCBwHDg3Mq/4H2jE3WeTTqNcIfSOP/TpIv8zMysRTR/pNhaSdJRwOCI+E6ra+lumwwbFn/59GdaXYZZu3zO3HobSdMiYlS9ee6Z9wL5avg1gB1bXYuZmZXHYd4LRMSera7BzMzK5QvgzMzMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHD+PnPrcf2GDWPoiSe0ugwzs0WGe+ZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4RUSra7DFjKTZwAOtrqOOIcAzrS6ihmtqXm+syzU1pzfWBL2vrtUiYoV6M/xFK9YKD0TEqFYXUUvS1N5Wl2tqXm+syzU1pzfWBL23rno8zG5mZlY4h7mZmVnhHObWCme1uoAGemNdrql5vbEu19Sc3lgT9N663sYXwJmZmRXOPXMzM7PCOcyt20j6kKQHJD0o6et15kvSL/L8uyVt1gtqWlfSFEmvSjqqu+tpsqYD8vG5W9LNkjbpJXXtnmuaLmmqpG1bXVNludGS5knap9U1SRoraVY+TtMlHdfdNTVTV6W26ZLuk3Rjq2uSdHTlON2bH8PlW1zTYElXSborH6dDurOehRYR/vFPl/8AfYB/A6sDSwJ3AevXLLMLcA0gYCvg1l5Q04rAaOAk4Khecpy2BpbLtz/c3cepE3UNYv6puo2Bf7S6pspyfwP+DOzT6pqAscDV3f2YLURdywL3A6vm+yu2uqaa5XcD/tbqmoBvAj/It1cAngOW7MnHs5kf98ytu2wBPBgRD0XEa8BFwO41y+wOnBfJLcCykoa2sqaIeCoibgde78Y6OlvTzRHxfL57C7ByL6lrTuRXOGAg0N0X4DTznAL4MnAp8FQ319OZmnpaM3V9ArgsIh6B9NzvBTVV7Q/8vhfUFMAykkR6A/sc8EY319VpDnPrLsOBmZX7j+ZpnV2mp2vqaZ2t6TDSaEZ3a6ouSXtK+gfwJ+DQVtckaTiwJ3BmN9fSdE3ZmDxMe42kDXpJXWsDy0maIGmapAN7QU0ASFoa+BDpTVmrazodWA94HLgH+GpEvNnNdXWaPwHOuovqTKvtuTWzTFfq6e01o+maJO1ACvNuPzdNk3VFxOXA5ZK2B74L7NTimn4GHBsR81JHqts1U9MdpI/hnCNpF+AKYK1eUFdfYHPg/cAAYIqkWyLiny2sqc1uwOSIeK6bamnTTE0fBKYDOwJrANdLmhQRL3ZzbZ3inrl1l0eBVSr3Vya9s+3sMj1dU09rqiZJGwNnA7tHxLO9pa42ETERWEPSkBbXNAq4SNIMYB/gDEl7tLKmiHgxIubk238G+nXzcWqqrrzMXyJibkQ8A0wEuvPiys48p/aj+4fYobmaDiGdjoiIeBD4D7BuD9TWOa0+ae+fRfOH9K7/IeC9zL+wZIOaZT7CghfA3dbqmirLjqNnLoBr5jitCjwIbN3LHr81mX8B3GbAY233W/345eXH0/0XwDVznN5TOU5bAI9053HqRF3rAX/Nyy4N3Ats2OrHDxhMOi89sDuPUSeO06+Acfn2Svl5PqS7a+vsj4fZrVtExBuSvgRcS7pi9JyIuE/S5/L8M0lXG+9CCqqXSO+AW1qTpPcAU4F3AW9KOoJ0dWu3DKk1eZyOA95N6mUCvBHd/OUPTda1N3CgpNeBl4F9I7/itbCmHtVkTfsAn5f0Buk47dedx6nZuiLi75L+AtwNvAmcHRH3trKmvOiewHURMbe7aulkTd8Fxku6h9TxODbSSEav4k+AMzMzK5zPmZuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZkXK36jV9u1af8wfAfpO2zxRUsNPsZP0uR742FOzTvO/pplZkSTNiYhB+fYFwLSIOLUyv09EzGtZgWY9yD1zM1sUTALWzN/PfYOkC4F7JPWR9CNJt+fvXv9s2wqSjpF0T/4ClFPytPFt34Eu6RRJ9+f1fpynjVP+nntJIyXdkudfLmm5PH2CpB9Iuk3SPyVt19MHwxY//gQ4MyuapL6k73n/S560BeljSf8j6XBgVkSMlrQUMFnSdaTP1t4D2DIiXpK0fE2by5M+iWzdiAhJy9bZ9HnAlyPiRkknAscDR+R5fSNii/zFKsfTvV9AY+aeuZkVa4Ck6aSP330E+N88/baI+E++vTPpI2enA7eSPhZ3LVK4nhsRLwHE27+d60XgFeBsSXuRPm74LZIGA8tGxI150m+B7SuLXJZ/TwNGLPwumjXHPXMzK9XLETGyOiF/dn31M71F6j1fW7Pch2jn62/zZ3ZvQfp60P2AL5G+ArNZr+bf8/DrrPUA98zNbFF2LelLTvoBSFpb0kDgOuDQtivg6wyzDwIGR/rK0iOAkdX5ETELeL5yPvxTwI2YtYjfMZrZouxs0jD3HUrd9qeBPSLiL5JGAlMlvUb6Br9vVtZbBvh/kvqTevf/U6ftg4Az8xuCh+jmb/0za4//Nc3MzKxwHmY3MzMrnMPczMyscA5zMzOzwjnMzTopf8LXp/PtgyXd1M6ye0qaKWmOpE17rsreL3/a2veaXHZGe5+Z/g7rOCB/kEyj+WMlPfoO2h8n6Xf59qr5udAn319J0kRJsyX9RMm5kp6XdNvCbrME1b+jOvMWOE7WMYe5FS2/yL+c//D/mwNiUKvrqvgx8KWIGBQRd77TxvILYEjapGb6FXn62Hz/rQCp00b1mD2Zw6M3HbMeFREXRMTObffzcVyzm7b1SH4utH1m/OHAM8C7IuJrwLbAB4CVI2KL7qihEUkj8r63/L+cao9Te8HfGb1pH7uaw9wWBbvlL9wYCWwKfKO15SxgNeC+hVmxnV7JP4EDK8u9G9iK9G9XzWo7ZpsBo4FvL0yN9o6tBtwf8/+taDVgRkTMbWedunpbQPW2erpCHjnplbnZK4syWxgR8V/Sh4SMbJsmaStJN0t6QekLNcZW5i2fe6WP52HNK/L05SRdLenpPP1qSSt3phZJS0maA/QB7pL07zx9vdzLeEHSfZI+WllnvKRfSfqzpLnADg2avwDYtxL2+wOXA691pkaAiHgMuAbYsMF+zJB0tNKXicyV9L95aPiaPDT8f8pfMJKX/2jerxfyfq5XmbeppDvyehcD/Wu2tavSV5q+kB+zjRvUtIWkqZJezCMLpzZY7kZJe+fb2+Ye2S75/k5KH/G6wKkSSRPz6nflkYt9K+19TdJTkp6Q1PB/yiW9N297tqTrgSGVeW/1DCWNJ/2v+jF5W58l/V/8mHz/hI6OS358jpV0NzA3t9vec36CpO9Kmpzru05SW31t+/5C3v6YBsd+Sm77CUmnS1qyMj8kfVHSv4B/5Wm75/pflPRvpU/fa7NavVpqjtNJwHbA6bmu0/My60q6XtJzkh6Q9PFKHQOUTls8LGmWpJskDai3j6oZxVJN7z0fs5MkTSZ9rO/qHWx7F6Uv6Jkt6THlL+bpdhHhH/8U+wPMAHbKt1cG7gF+nu8PB54FdiG9cf1Avr9Cnv8n4GJgOaAf8L48/d3A3sDSpA8P+SNwRWWbE4BP59sHAze1U18Aa+bb/YAHSR9OsiTp40FnA+vk+eOBWcA2ud7+ddqbAHya9AlmH87TbgPGAI8CY/O0ccDvmjhmq5BGDr7bzrK3ACvl4/kUcAdpBGQp4G/A8XnZtUkfpfqBvK/H5P1dMv88TPrwlX7APsDrwPfyupvltrckvQE6KG97qTo1TwE+lW8PArZqUPuJwGn59jeBfwM/qMxre54s8BhWH7N8fyzwRl6nH+n59BKwXIPtTgFOzcdn+/wY/y7PG5Hb71t5zL9XWbe2lmaOy/T8OA6g4+f8hHwc1s7LTwBOqVdbg33bnDQK1Dcv/3fgiJpjdz2wfG5/C9Jz+gO5nuGkL6/pVC1U/uby/YHATNIH9fTNx+kZYIM8/5d5neH5uG2dH4+37SM1fysNtv0IsEHe1uAOtv0EsF2+vRywWU+8FrpnbouCKyTNJv2BPUX6liqATwJ/jog/R8SbEXE96Us5dpE0lPRNW5+LiOcj4vXIX5oREc9GxKUR8VJEzAZOAt7XBXVuRQqfUyLitYj4G3A1qWfd5v9FxORc7yvttHUe6QtE1iF94ceUTtZyhaQXgJtIH0P6/XaWPS0inozUi58E3BoRd0bEq6QRgbYL+/YF/hQR10fE66TrBQaQXki3IgXhz/KxvgS4vbKNzwC/johbI2JeRPyW9PnmW9Wp53XS150OiYg5EXFLg7pvZP7jtj1wcuX+++jcx6++DpyYa/8zMAdYp3YhSauSTlt8JyJejYiJwFWd2E6tZo7LLyJiZkS8TDvP+cry50bEP/Pyf6Dmo2rbExHTIuKWiHgjImYAv+btfxsnR8Rzuf3DgHPyc+LNiHgsIv7RBbXsSjodcW6u5Q7gUmAfpWHwQ4Gv5u3Ni4ib8/N1YY2PiPsi4g3gQ422nZd9HVhf0rvya8sd72C7TXOY26Jgj4hYhtSDWpf5w5qrAR/LQ4Iv5PDaFhhK6sk8FxHP1zYmaWlJv85DdC+ShuaW1Tu/snYYMDMi3qxMe5jUe2gzs8m2LiP17L8MnL8QtewREctGxGoR8YX8YtrIk5XbL9e533bx3DDS/gCQ93Mmaf+GAY9F7q5kD1durwZ8reaxWiWvV+swUm/uH0rfU75rg7qnAGtLWokUEucBq+Sh3C2YP+TajGfzC3mbl5i/31XDgOdjwXPeD9dZrlnNHJeZNcs3es63+W/ldqP9qEvps+2vVrrY9EXSm8AhNYtV61mF1PtuZGFrWQ3YsmY/DwDek+vp38F2O6v2GDfaNqRRvV2Ah5VOt7ztdEV3WOQuULDFV6TvlR5P6hHuQfoDPD8iPlO7bO6ZLy9p2Yh4oWb210i9ri0j4r9Kn+F9J+kzut+Jx0lhskQl0FclXdD21m4001Ck7+C+Bvg8sMY7rKurPA5s1HZHkkgv5o+R9mu4JFUCfVXmv+DOBE6KiJM62khE/AvYP/fA9gIukfTumgBtO0bTgK8C90bEa5JuBo4E/h0Rz7yTnW3gCWA5SQMr9axKk49rHc0cl2rbDZ/zTWimxl+R/hb2j4jZko5gfo+0UT1d8fysrW0mcGNEfKB2wfy8eCVv964O2oF0amjpyv331Fmmdp/qbhsgIm4Hdlf6cp8vkUYcVqm3bFdyz9wWNT8DPpAD+HfAbpI+KKmPpP5K/zO8ckQ8Qbrw6wylC976SWr7PuplSD3OF5S+Tev4OttZGLeSXjiOydsbC+wGXLSQ7X2TdJ5/RoP5S+R9bvtZaiG306w/AB+R9P78QvY10pDwzaRe8hvAV/JFTXuResdtfgN8TtKWSgZK+oikZWo3IumTklbIb4heyJPn1S6X3Uh6QW0bUp9Qc7+eJ4HVO97dt4uIh0nD2idIWlLStqTHeGE1fVyyhs/5Jrb1NPAm7e/7MqTvep8jaV3Sm8n2/C9wSH5OLCFpeF6vs2ofk6tJoy6fyn9L/SSNlrRefl6cA5wqaVg+DmPy87/ePk4Htlf63/bBdPzfMA23nR/zAyQNzqeaXqTxc7NLOcxtkRIRT5OGU78TETOB3Umh9zTpHfXRzH/ef4p0fusfpHPtR+TpPyOd632GdPHXX7qotteAj5LO1T8DnAEcWHMOsTPtPR4RDT+whnQu/uXKT1cOO9ar5wHSOdvTSPu3G+lf4F7L+74X6QKv50nn1y+rrDuVdH749Dz/wbxsPR8C7lP6b4GfA/u1c33BjaQAmtjgfj3jgN/mIdSPt7NcI58gXbD2HOmN4HkL0QbQ6eNCE8/59rb1Eun6kMl53+tdr3AUaf9mk95oXNxBm7eRLhT7KelCuBtJw9Sd9XPS+fDnJf0iX8uyM+m75h8nDdf/gHSRW1ud95Cuy3guz1ui3j7m6wouBu4GppHCur196mjbnwJm5NMQnyP9TXQ7f2uamZlZ4dwzNzMzK5zD3MzMrHAOczMzs8I5zM3MzArn/zO3HjdkyJAYMWJEq8swMyvKtGnTnomIFerNc5hbjxsxYgRTp05tdRlmZkWR1PDTBD3MbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOH8CnPW4x154mW9cdk+ryzCzLnLyXhu1uoTFnnvmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZla4osNc0k8lHVG5f62ksyv3fyLpSEkflfT1Bm3M6YFS3xFJEySN6oJ2RkrapStqqml3rKSru7pdMzNrTtFhDtwMbA0gaQlgCLBBZf7WwOSIuDIiTmlBfU1R0hOPxUigS8NcUt+ubM/MzDqv9DCfTA5zUojfC8yWtJykpYD1gDslHSzpdABJ75U0RdLtkr5bbUzS0Xn63ZJOqLdBSXMknSTpLkm3SFopT19B0qV5/dslbZOnj5N0VGX9eyWNyD9/l3QGcAewiqRfSZoq6b5G26+pZYakEyTdIekeSevm6QMlnZPruFPS7pKWBE4E9pU0XdK+eZ1l85uJZyUdmNc/X9JOkvpLOjcvd6ekHfL8gyX9UdJVwHU1NY3Oy67eUf1mZtY1iu5VRcTjkt6QtCop1KcAw4ExwCzg7oh4TVJ1tZ8Dv4qI8yR9sW2ipJ2BtYAtAAFXSto+IibWbHYgcEtEfEvSD4HPAN/L7f40Im7K9VxLejPRnnWAQyLiC7mGb0XEc5L6AH+VtHFE3N1BG89ExGaSvgAcBXwa+Bbwt4g4VNKywG3A/wHHAaMi4kt5ezsA2wAPAw8B2wHnAVsBnwe+CBARG+U3CtdJWjtvdwywca53bG5va+A0YPeIeKSDus2sF7nguEMXet0pvxi40OtOmDBhode1+UrvmcP83nlbmE+p3L+5zvLbAL/Pt8+vTN85/9xJ6imvSwr3Wq8BbeeHpwEj8u2dgNMlTQeuBN4laZkOan84Im6p3P+4pDtyDRsA63ewPsBldWrZGfh6rmUC0B9Ytc66k4Dt88+vgI0kDQeei4g5wLbkYxQR/yCFfluYXx8Rz1XaWg84C9itXpBLOjyPOkx9adbzTeyWmZk1q+ieedZ23nwj0jD7TOBrwIvAOQ3WiTrTBJwcEb/uYHuvR0Tb+vOYfwyXAMZExMsLNCq9wYJvmvpXbs+tLPdeUs96dEQ8L2l8zbKNvFqnFgF7R8QDNbVsWbPuRFLve1VSb35PYB9SyLe108jcmvtP5Ho3BR6vXTgiziKFPUPX3KDe8TezFjrgxEYvlx07ea+NurASWxiLSs98V1Jvcl7uLS5LGgae0mD5/fLtAyrTrwUOlTQIQNJwSSt2oo7rgC+13ZE0Mt+cAWyWp20GvLfB+u8iBeSsfB7+w53Ydq1rgS8rn1+QtGmePht4a7QgImaSLhpcKyIeAm4ivaFoC/OJ5GOUh9dXBRZ4g1DxAvAR4Pttw+5mZtYzFoUwv4cUSLfUTJsVEc/UWf6rwBcl3Q4MbpsYEdcBFwJTJN0DXEIl+JrwFWBUvnjufuBzefqlwPJ5yPvzwD/rrRwRd5GG1+8jjShM7sS2a30X6AfcLenefB/gBmD9tgvg8rRbKzVNIl1zcFO+fwbQJx+Pi4GDI6JtJKDePjwJ7Ab8ss4ogJmZdRPNHzE26xlD19wgDv7hRa0uw8y6iIfZe4akaRFR9zNHFoWeuZmZ2WLNYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWuL6tLsAWP8OXHcDJe23U6jLMzBYZ7pmbmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnh/Nns1vNmzYSrvtrqKszKtNvPW12B9ULumZuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4YoNc0nzJE2XdJ+kuyQdKanY/WlE0jhJR3VBO8tK+kJX1FSn7Tnd0a6ZmTWn5PB7OSJGRsQGwAeAXYDjW1zTQpHUpwc2syzQpWGupOTnkJnZIqFvqwvoChHxlKTDgdsljSO9STkFGAssBfwyIn4NIOlo4ON5+uURcbykEcBfgFuBTYF/AgdGxEvV7UiakJfZgRSOh0XEpBzGb9uepLHAURGxa17/dGBqRIyXNAM4B9gZOF3SMsDhwJLAg8CnardfU8t44EVgFPAe4JiIuKTRPub61pA0HbgeGAj8JSKulHQ58HxEHCrpMOC9EfFtSUcCh+ZNnh0RP8vH6hrgBmAMsEelpiHAVcD3IuJPjWq31hv7zUtbXYItrJ/c1eoKbCFNmDCh29peZHpVEfEQaX9WBA4DZkXEaGA08BlJ75W0M7AWsAUwEthc0va5iXWAsyJiY1JINurF9o2ILYAjmD8SUHd7TZT9SkRsGxEXAZdFxOiI2AT4e26zI0OBbYFdSWFNO/v4deDfeTTjaGAisF1uZziwfr69LTBJ0ubAIcCWwFZ5nzbNy6wDnBcRm0bEw3m7KwF/Ao6rF+SSDpc0VdLUp2e93MSumZlZsxaJnnmF8u+dgY0l7ZPvDyYF3M755848fVCe/ggwMyIm5+m/A74C/LjONi7Lv6cBIzrY3msd1Htx5faGkr5H6vEPAq7tYF2AKyLiTeD+HKZttTTax6pJwBGS1gfuB5aTNJTU2/4KqUd+eUTMBZB0GSn8rwQejohbKm31A/4KfDEibqxXaEScBZwFMGqtlaKJfbNuNOH7e7e6BFtYu/281RVYL7TIhLmk1YF5wFOkUP9yRFxbs8wHgZPbhtwr00cAtQHTKHBezb/nMf/4Ndretiw4+tG/pq25ldvjgT0i4i5JB5OG7DvyauW2Kr8b7eNbIuIxScsBHyL10pcnDc3PiYjZkkRjc2vuv0F6c/NBoG6Ym5lZ91kkhtklrQCcCZweEUHq1X5eUr88f21JA/P0QyUNytOHS1oxN7OqpDH59v7ATZ0oodH2HgbWl7SUpMHA+9tpYxngidzGAZ3Ydr1a6u3j7LyNqimk0wUTST31o/Jv8rQ9JC2d92XPyrxaQerJryvp6++gdjMzWwgl98wH5Iu5+pF6hucDp+Z5Z5OGwO/IPcynSb3e6yStB0zJHc85wCdJvey/AwdJ+jXwL+BXnail0fZmSvoDcHdu887GTfAd0sV1DwP38PbgbUqjfYyIf0uaLOle4Jp83nwSsHNEPCjpYVLvfFJu5458kd1tbfsYEXfW9vAr250naT/gKkkvRsQZC1O/mZl1nlJHdvGWA+rqiNiw1bUsDkattVJMPXW/VpdhViafM19sSZoWEaPqzVskhtnNzMwWZyUPs3eZiJgBuFduZmZFcs/czMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCufvM7eeN3gV2O3nra7CzGyR4Z65mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzp/Nbj3u8bmPc8KUE1pdhpn1kOPHHN/qEhZ57pmbmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeE6DHNJc5pY5ghJS3dNSQtH0jhJR+XbJ0raqYPlD5Y0rGeqW3i5ztO7qK1vdkU7ddqdIWlId7RtZmYd66qe+RFAp8JcUp8u2vbbRMRxEfF/HSx2MNArwlxS3x7aVJeHeXc+jmZm1pymQ0TSWGAc8AywITAN+CTwZVIo3iDpmYjYQdLOwAnAUsC/gUMiYo6kGcA5wM7A6ZJOAS4EdgD6AYcDJwNrAj+KiDPzto8GPp7buzwijs/TvwUcCMwEns41IWk8cHVEXCLpOGA3YABwM/BZYG9gFHCBpJeBMcD6wKnAoLyPB0fEEzXHYDzwYl73PcAxEXFJoxoljch1bJiXOQoYFBHjJE3I9WwDXCnpn8C3gSWBZ4EDIuLJdh6PccCqwOr5988i4hd53ieBr+S2bgW+AJwEDJA0HbgPuAt4JSJ+IemnwCYRsaOk9+fH65OS9ie9ARDwp4g4Nrc/Jx+rDwJfq9Q0ALgcuDQiftOodjMr37lfPLfpZW941w1NLTdhwoSFrMY62zPflNQLX58UItvkAHkc2CEH+RBSKO0UEZsBU4EjK228EhHbRsRF+f7MiBgDTALGA/sAWwEnAuQ3BmsBWwAjgc0lbS9pc2C/XNNewOgGNZ8eEaNzoA4Ads0BPJUUmCOBN4DTgH0iYnPSG46TGrQ3FNgW2BU4pb0aGx/GtywbEe+LiJ8ANwFbRcSmwEXAMU2svy4pULcAjpfUT9J6wL6kx2YkMC/v59eBlyNiZEQcAEwEtsvtjAIGSeqX921SPgXxA2DHvE+jJe2Rlx8I3BsRW0bETXnaIOAq4MJ6QS7pcElTJU196fmXmtg1MzNrVmeHd2+LiEcBcg9vBCmEqrYihf1kSZB6h1Mq8y+uWf7K/PseUq91NjBb0iuSliX14ncG7szLDSIF5zKkHvBLuZ4rqW8HSceQTgMsT+qVXlWzzDqk0Ybrc819gCeo74qIeBO4X9JKeVqjGh9p0Eab6rFYGbhY0lDSMftPB+tC6i2/Crwq6SlgJeD9wObA7XlfBgBP1Vl3GulNxzLAq8AdpFDfjtSrHw1MiIinASRdAGwPXEF6g3BpTXv/D/hhRFxQr9CIOAs4C2DYesOiiX0zs17skF8e0vSyx485vhsrMeh8mL9auT2vwfoCro+I/Ru0MbdBm2/WtP9mbl/AyRHx6wU2Ih0BtBsKkvoDZwCjImJmHpru36Dm+/IIQUeqNaryu16NK7Pg6EfttqvH4jTg1Ii4snJKozO1tD0eAn4bEd9ob8WIeD2f9jiENNx/N+l0xxrA34G121n9lYiYVzNtMvBhSRdGhMPazKwHddUFcLNJPWWAW4BtJK0JIGlpSe0FQ0euBQ6VNCi3N1zSiqRh4j0lDci9y93qrNsWns/k9fdpUPMDwAqSxuRt9JO0QRfU+CSwoqR3S1qKNDTfyGDgsXz7oE5su9ZfgX3y9pG0vKTV8rzX81B6m4nAUfn3JOBzwPQcxrcC75M0JF/ktj9wYzvbPY50rv+Md1C7mZkthK4K87OAayTdkIdlDwZ+L+luUrivu7ANR8R1pIvkpki6B7gEWCYi7iANU08nDflOqrPuC8BvSEP4VwC3V2aPB87Mpwv6kIL+B5Luym1u3QU1vk46938rcDXwj3aaGQf8UdIk0gV4CyUi7idds3BdPv7Xk87zQ3qc7s5D5pCO2VBgSr7Y7pU8jXzx3zeAG0gXy90REf+vg80fAfSX9MOFrd/MzDpPHhG1njZsvWHx2XM+2+oyzKyH+Jx515A0LSJG1ZvnT4AzMzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHB9W12ALX6GDRzG8WOOb3UZZmaLDPfMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnD/O1Xrc648/zhPH+eNcrXlDTzyh1SWY9WrumZuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4Rb7MJc0T9J0SfdJukvSkZKKOC6SRki6twvbO1HSTvn2dvmYTJc0XNIlXbUdMzPrWn1bXUAv8HJEjASQtCJwITAYOL6VRbVCRBxXuXsA8OOIODff36fZdiT1iYh5XVqcmZk1VEQPtKdExFPA4cCXlBws6fS2+ZKuljQ2354j6QeSpkn6P0lbSJog6SFJH83LHCzpCklXSfqPpC/lnv+dkm6RtLykNSTdUdnGWpKm1dYmac28nbsk3SFpjZr5IyRNyvPukLR1nj5U0sTcw74397j7SBqf798j6X/ysuMl7SPp08DHgeMkXVAdAcjr/kjS7ZLulvTZPH2spBskXQjc04UPi5mZdcA98xoR8VAeZl+xg0UHAhMi4lhJlwPfAz4ArA/8FrgyL7chsCnQH3gQODYiNpX0U+DAiPiZpFmSRkbEdOAQYHyd7V0AnBIRl0vqT3ojVq3xKeADEfGKpLWA3wOjgE8A10bESZL6AEsDI4HhEbEhgKRla47B2ZK2Ba6OiEskjajMPgyYFRGjJS0FTJZ0XZ63BbBhRPyng2Nn1qG9z/vtW7eXnHjjW7cnTJjQgmrMejeHeX1qYpnXgL/k2/cAr0bE65LuAUZUlrshImYDsyXNAq6qrLNxvn02cIikI4F9SaE4vxhpGVL4Xg4QEa/k6dXF+gGnSxoJzAPWztNvB86R1A+4IiKmS3oIWF3SacCfgOto3s7AxpLaht0HA2vl43FboyCXdDhp1IPhgwd3YnNmZtYRh3kNSauTwvAp4A0WPBXRv3L79YiIfPtN4FWAiHhTUvW4vlq5/Wbl/pvMP/6Xks7R/w2YFhHP1pbVROn/AzwJbJJrfiXXM1HS9sBHgPMl/SgizpO0CfBB4IukIfVDm9hGWy1fjohrF5iYTj/MbbRSRJwFnAWwybBh0Wg5szaXHnjQW7eHnnhCCysx6/18zrxC0grAmcDpOahnACMlLSFpFWp6zF0l97SvBX4FnFtn/ovAo5L2yHUuJWnpmsUGA09ExJvAp4A+ednVgKci4jfA/wKbSRoCLBERlwLfATbrRLnXAp/PPX0krS1pYCfWNzOzLuaeOQyQNJ00TP0GcD5wap43GfgPaUj8XuCOeg10kQuAvWg85P0p4NeSTgReBz5G6t23OQO4VNLHgBuY30seCxwt6XVgDnAgMBw4t/IveN/oRJ1nk04j3KE0zv80sEcn1jczsy6m+SPF1kqSjgIGR8R3Wl1Ld9tk2LD4y6c/0+oyrCAeZjcDSdMiYlS9ee6Z9wL5avg1gB1bXYuZmZXHYd4LRMSera7BzMzK5QvgzMzMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8L1bXUBtvjpN2wYQ088odVlmJktMtwzNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscIqIVtdgixlJs4EHWl1HCw0Bnml1ES2yOO87LN77vzjvO3TN/q8WESvUm+HPZrdWeCAiRrW6iFaRNHVx3f/Fed9h8d7/xXnfofv338PsZmZmhXOYm5mZFc5hbq1wVqsLaLHFef8X532HxXv/F+d9h27ef18AZ2ZmVjj3zM3MzArnMDczMyucw9y6jaQPSXpA0oOSvl5nviT9Is+/W9JmraizOzSx7wfkfb5b0s2SNmlFnd2lo/2vLDda0jxJ+/Rkfd2pmX2XNFbSdEn3Sbqxp2vsTk089wdLukrSXXn/D2lFnd1B0jmSnpJ0b4P53feaFxH+8U+X/wB9gH8DqwNLAncB69csswtwDSBgK+DWVtfdg/u+NbBcvv3hRWXfm93/ynJ/A/4M7NPqunvwsV8WuB9YNd9fsdV19/D+fxP4Qb69AvAcsGSra++i/d8e2Ay4t8H8bnvNc8/cussWwIMR8VBEvAZcBOxes8zuwHmR3AIsK2loTxfaDTrc94i4OSKez3dvAVbu4Rq7UzOPPcCXgUuBp3qyuG7WzL5/ArgsIh4BiIjFbf8DWEaSgEGkMH+jZ8vsHhExkbQ/jXTba57D3LrLcGBm5f6jeVpnlylRZ/frMNK79UVFh/svaTiwJ3BmD9bVE5p57NcGlpM0QdI0SQf2WHXdr5n9Px1YD3gcuAf4akS82TPltVy3veb541ytu6jOtNr/g2xmmRI1vV+SdiCF+bbdWlHPamb/fwYcGxHzUgdtkdHMvvcFNgfeDwwApki6JSL+2d3F9YBm9v+DwHRgR2AN4HpJkyLixW6urTfottc8h7l1l0eBVSr3Vya9E+/sMiVqar8kbQycDXw4Ip7todp6QjP7Pwq4KAf5EGAXSW9ExBU9UmH3afZ5/0xEzAXmSpoIbAIsCmHezP4fApwS6STyg5L+A6wL3NYzJbZUt73meZjdusvtwFqS3itpSWA/4MqaZa4EDsxXeG4FzIqIJ3q60G7Q4b5LWhW4DPjUItIjq+pw/yPivRExIiJGAJcAX/j/7d15nF7j/f/x11sSEkJCgyYpYl9LEEtsjdK0lJZWtaolaHWh6qtauhG60P7aalWVVEn5Klpb0W8tbYUgipCIpVp7LLWLJJZKfH5/XNdwcrvvmXtiZu5ck/fz8ZjH3Pc55z7nc657Zt7nus6Z+/SCIIfmfu7/BGwvqa+kpYGtgHt7uM7u0sz+P0oalUDSysC6wIM9WmXrdNvfPPfMrVtExDxJhwJXka5wPTMi7pb0xTz/NNJVzLsC9wMvk47Yi9fkvh8DvAs4NfdO50UvuaNUk/vfKzWz7xFxr6QrgTuBN4AzIqLuvzKVpsn3/nvAREkzSMPOR0VEr7g1qqTzgDHAEEmPAccC/aD7/+b541zNzMwK52F2MzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM2sV8p3Y5sm6a58l67BXbz+hyUNyY/ndOW6zTrLYW5mvdUrETEyIjYi3fzikFYXZNZdHOZmtjiYQr6hhaQ1JV2Zb3IyWdJ6efrKki7J99meLmmbPP3SvOzdkg5u4T6YNeRPgDOzXk1SH9LHh/42T5oAfDEi/i1pK+BU0k0/Tgaui4g982sG5uUPjIjnJQ0AbpV0US/7LH3rBRzmZtZbDZA0DRgBTCXdnWsgsA3wx8rd2pbK398P7AcQEfOBWXn6YZL2zI9XAdYGHOa2SHGYm1lv9UpEjJQ0CLiCdM58IvBiRIxsZgWSxgA7A6Mj4mVJk4D+3VGs2Tvhc+Zm1qtFxCzgMOBI4BXgIUmfAMh3r9okL/o34Et5eh9JywGDgBdykK8HbN3jO2DWBIe5mfV6EXEHMJ10S859gYMkTQfuBj6aF/sqsGO+m9dUYEPgSqCvpDtJd/u6uadrN2uG75pmZmZWOPfMzczMCucwNzMzK5zD3KyFJH1f0rOS/tPqWhY1+eNSd25iuRGSQlK3/HeOpNMkfbed+eMl/e87WP8kSZ/Lj/eVdHVl3raS/i1pjqQ98gfbXC9ptqSfLuw2S5Df07UazFugncxhbou4/Af9lfzHrO1rWJ43QdJ9kt6QNK6D9bxH0kU5OGdJmtHRa7qbpFWArwEbRMS7u2idIemparBJ6ivpaUlRmfZmgNS8vi0Y29r6YUlHd0VtpYqIL0bE9yD9q5qkx7pxW+dGxNjKpOOBUyJiYERcChwMPAssFxFf66466pE0TtINPbnNRmrbqb3g74xFaR87y2FuJdg9/zFr+3oiT58OfBm4vYl1nAPMBFYD3kX6cJCnurLIhegZrgY8FxFPd/G2XgR2qTzfFXihk5sYHBEDgX2AYyR9qJOvt66xGumK++rze2IhrlzurpGLhbWo1dMVWrlPDnMrVkT8KiL+BrzaxOJbABMjYm5EzIuIOyLiL20zJW0n6SZJL0qa2dZrlzRI0tmSnpH0iKTvSFoizxsn6UZJJ0l6HhgvaSlJP5H0aO4hn5Y/BnQBefj4GmBY7gFPzNM/ovQZ4C/m3vP6ldc8LOmo/G9Sc9v5w3EO+ZPMsv2As5too7eJiCmkMNmozj609eIPyG32gqQvStpC0p15H06pLL9Ebr9H8kjB2Uof6NI2/7N53nOSvl2zrSUkHS3pgTz/D5JWqFdzfl8ezEPRD0nat84y/fOIT9tdz74jaZ7S/5a3nf74eX48MT9fBvgLb71nb44SAUvm/Zmd379RjdpU0gck/TOPEJ0CqDLvzZ6hpAeANYDL87bOA/YHvpGf79xeu1Ten4MkPQr8PU8/UNK9+f26StJqle1Hfg//nef/Ssn6wGnA6LztFxvs2wF53bPze/CFyrwxkh7LP8P/Ac5S+n/+b+X6Zyt9Bv4qlVXuXFtLnXa6Pi87Pdf2yTx9N6W75r2o9Lu9caWWVSRdrPR7/ZykUxrto2pGsVTTe89tdoikfwP/bmLbR0l6PO/vfZJ2avSz0ikR4S9/LbJfwMPAzh0scwMwroNl/grcSPo/41Vr5q0KzCb1QvuReu4j87yzgT8By5I+FvRfwEF53jhgHvAV0qcpDgB+DlwGrJBfczlwQoOaxgCPVZ6vA8wFPpDr+AZwP7BkpS2mkT5SdECDdQYpeJ8CBuevp/K0qCw3CfhcndePyOvoSwqZbYGXgZ3aWfY00qeijSUdWF0KrES6scnTwPvy8gfm/VmD9LnnFwPn5HkbAHOAHUgfr/qz3LY75/mHk/7H+z15/unAeXVqXgZ4CVg3zxsKbNigra4HPp4fXw08AOxSmbdnfjwR+H699yxPG5/3e1egD3ACcHODbQ7J9e2V3+P/yfv5ucrP1A2Nfv6rtXSiXc7O7TIA2CO/B+vn9voOcFPNz88VpJ+bVYFngA/Vq63B/n0YWJP0s/M+0s/OZpW2mwf8KNc6APg6MANYN79mE+Bdna0lL7tW5flmpJ+9rfJ7sn9uy6Xy8+nASbld+gPbNdpHan5XGmz7GtLv/IAOtr0uaYRwWOU9WrNL/lZ2xUr85a/u+sq/BHNIQ8cvApfWWaaZMF8eOJHUy5xPCsUt8rxvApfUeU0f4DXSOe22aV8AJuXH44BHK/NECuM1K9NGAw81qGkMC4b5d4E/VJ4vATwOjKm0xYEd7GcAawFn5Fq/CPwmT4vKcgv8gapMH5HX8SJpaP5e4LAG22pbdnhl2nPAJyvPLwIOz4//Bny5Mm9d4HVSqBwDnF+ZtwzwX94K83upHFCQQrrttW11tIX5i8DHaXDAU1nH90g3V+kL/If0oTEnkv64vwIMyctNpOMw/2vl+Qakj5Ktt839qAR9/pl5jIUP82baZY3K/L+QD0YrP2MvA6tVfn62q8z/A3B0vdqa/P29FPhqpe3+C/SvzL8P+Gg7P8tN1cLbw/zXwPdq1ncf6QBjNOnAoG+dbb5tH2kuzN/f5LbXIgX9zkC/zrRlR18eZrcS7BERg/PXHguzgoh4ISKOjogNgZVJYX5pHrZbhdQrqzUEWBJ4pDLtEfKtNLOZlccrAksDU/Pw2oukTxBbsckyh1W3FRFv5PU32l57ziYFx8IOsQ+JiOUjYv2IOLmDZavXHrxS53nb3ccW2L/8uC/p/RhGZd8iYi4L3sxkNeCSSrveSzooW7laSH7dJ0kHMU9K+rPyLU7ruI4UMJuReofXkP7gbg3cHxHPtrfTNar/jfAy0F/1T4PU7mfQ/HtaTzPtMrNm+V9Uln+edEBR/Rmr3ZeBNEnSLpJulvR8Xv+upN+jNs9ERPW0WKPfvXday2rA19r2M9eyCqn9VwEeiYh5Ta6rGbVtXHfbEXE/aTRlPPC0pPMrp2reEYe5LXbyH+mfkH6xVyD9Iq5ZZ9FnSb2c1SrTViX1lt9cXc3yr5CGddsOPgZFupCsGU9Ut1U50Gi0vfZMJvXSViaNXCwKFtg/UlvOI4X/k6R9BUDS0qTTHW1mkobAB1e++kdEtW0AiIirIuIDpP3/J2lkop6bSKMDe5JufXpPrunDpKCvp9n2b6R2P1V9vhCaaZeoWf4LNcsPiIibmthWu/suaSnSSMxPgJUjYjDwf1SuCaizjka/e+/UTOAHNfu5dEScl+et2uBgq94+ziUdpLep958ntW3caNtExO8jYjvS70KQTju8Yw5zK5akJSX1J/2x6Kd0UVPdn2lJP5K0kdK/aS1LuqHG/ZHuS30u6UKbvfP8d0kaGek2mH8AfiBp2Xyh0BFA3f8pzj3p3wAnSVopb3e4pA82uUt/AD4saSdJ/Uj/tvYaKXQ6Jff4dgc+kh/X0ze3WdtXv85up5POA/5H0upKtyL9IXBB7iFdCOymdCHikqR/yaq+l6eR3ofVACStKOmjtRtQ+j/sjyhdrPYa6RTN/HrFRMTLpM9gP4S3wvsm0umJRmH+FPAuVS7c66Q/AxtK+lgOk8OoHw7Naqpdapb/pqQN8/KDlG8604SngPfk96eeJUnnhZ8B5knahXQdRXvOAL4naW0lG0t6VwevaVTbGpXnvwG+KGmrvN5lJH04/+7fQjqoOjFP7y9p23b2cRrwMUlLK/3720Ed1NJw25LWlfT+fODzKungv+7PZ2c5zK1kV5N+GbYBJuTHOzRYdmngEtL51AdJR8UfAYiIR0nDgV8jDTtOI12IA+nitrn5NTcAvwfObKemo0gXGN0s6SXShXfrNrMzEXEf8Bngl6Re/u6kf8v7bzOvr7O+uyPi7nYW+TWpzdq+zlqY7XTCmaQr7a8HHiL9MfsKpFpJofp70h/aF0jnktv8gnRh4dWSZpMu+tqqzjaWIL2PT5Dey/eR/n2xketIF6LdUnm+bK7xbSLin6SDkgfzEGqnhkjzqNAnSOfmnyPdG/3GzqyjRrPt0rb9S0g9wfPzz+ddLPhvjO35O+mak/9IetspiIiYTTo4+QPp/ft0rq09P8vLX026MPC3pIvIOms88Lv8nuwdEbcBnwdOybXcTzrXTT5I3510/vpR0s/ZJ9vZx5NI5/qfAn5HOvhvqL1tkw52TiT9fv+HdKHotxZif9/GN1oxMzMrnHvmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoXrdXetsUXfkCFDYsSIEa0uw8ysKFOnTn02Iup+oqTD3HrciBEjuO2221pdhplZUSQ90mieh9nNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnT4CzHvf4i6/wzYtntLoMMyvcCR97b6tLWGS4Z25mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhSs6zCWdJOnwyvOrJJ1Ref5TSUdI+oikoxusY04PlPqOSJokaVQXrGekpF27oqaa9Y6RdEVXr9fMzJpTdJgDNwHbAEhaAhgCbFiZvw1wY0RcFhEntqC+pijpifdiJNClYS6pb1euz8zMOq/0P8Q3AiflxxsCdwFDJS0PvAysD9whaRwwKiIOlbQ68HvSvl9ZXZmkrwN7A0sBl0TEsbUbzD35XwC7Aa8AH42IpyStCJwGrJoXPTwibpQ0HpgTET/Jr78rvxbgL8C1wGhgjzx6sAUwALiw3vZrankY+B2wO9AP+ERE/FPSMsAvgffm/Ryft3U8MEDSdsAJwHeA7YFZwLPA/0TE2ZLOyeu9Afg1MAqYBxwREdfm9vww0B9YJq+3raYtgAnAxyPiwfbqNzNrc+4xB3b6NVNOXqbTr5k0aVKnX1OConvmEfEEME/SqqRe+BTgH6RwHAXcGRH/rXnZL4BfR8QWwH/aJkoaC6wNbEnqwW4uaYc6m10GuDkiNgGuBz5fWe9Jeb0fB86o89pa6wJnR8SmEfEI8O2IGAVsDLxP0sZNrOPZiNiMFLpH5mnfBv6ea9kR+H+ksD8GuCAiRkbEBaSDoW1JB0IPkoIdYGvgZuAQgIh4L7AP8DtJ/fMyo4H9I+L9bYVI2oZ0QPPR2iCXdLCk2yTd9vKsF5rYLTMza1bpPXNIgbRN/voZMDw/nkUahq+1LSlsAc4BfpQfj81fd+TnA0nhfn3N6/8LtJ0fngp8ID/eGdhAUttyy0latoPaH4mImyvP95Z0MOl9GQpsANzZwTourtTyscq+fERSW7j3560Rg6rJwA7AI6SDgYMlDQeej4g5uQf/S4Dc438EWCe/9pqIeL6yrvVJPfKx+SBrARExIc9n6FobRgf7ZGaLmX2PP7PTrznhY+/thkrK1BvCvO28+XtJw+wzga8BLwGNfjrqhYmAEyLi9A6293pEtL1+Pm+14RLA6Ih4ZYGVSvNYcASkf+Xx3Mpyq5N61ltExAuSJtYs28hrdWoRaZj7vppatqp57fWk3veqpN78nsBepJBvW08jc2ueP5nr3RR4W5ibmVn3KXqYPbuRdA76+YiYn3uLg0nDwFMaLP+p/HjfyvSrgAMlDQSQNFzSSp2o42rg0LYnkkbmhw8Dm+VpmwGrN3j9cqSAnCVpZWCXTmy71lXAV5SHCSRtmqfPBt4cLYiImaSLBtfOw+I3kA4o2sL8enIbSVqHFPoLHCBUvEg6j/5DSWPeQe1mZtZJvSHMZ5AC6eaaabMi4tk6y38VOETSrcCgtokRcTXpwrgpkmYAF1IJviYcBoySdKeke4Av5ukXAStImgZ8CfhXvRdHxHTSEP/dpBGFGzux7VrfI50jvzNfcPe9PP1a0qmAaZI+maf9o1LTZNJpihvy81OBPrk9LgDGRUTbSEC9fXiKdDHer+qMApiZWTfRWyPGZj1j6Fobxrgfn9/qMsyscIvbOXNJU/NF0m/TG3rmZmZmizWHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZla4vq0uwBY/wwcP4ISPvbfVZZiZ9RrumZuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeH82ezW82bNhMu/2uoqzHqH3X/R6gpsEeCeuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVrtgwlzRf0jRJd0uaLukIScXuTyOSxks6sgvWM1jSl7uipjrrntMd6zUzs+aUHH6vRMTIiNgQ+ACwK3Bsi2taKJL69MBmBgNdGuZKSv4ZMjPrFfq2uoCuEBFPSzoYuFXSeNJByonAGGAp4FcRcTqApK8De+fpl0TEsZJGAFcC/wA2Bf4F7BcRL1e3I2lSXmZHUjgeFBGTcxi/bXuSxgBHRsRu+fWnALdFxERJDwNnAmOBUyQtCxwMLAncD3y2dvs1tUwEXgJGAe8GvhERFzbax1zfmpKmAdcAywBXRsRlki4BXoiIAyUdBKweEd+RdARwYN7kGRHx89xWfwGuBUYDe1RqGgJcDnw/Iv7cqHZb9I351kWtLsGa9dPpra7AmjRp0qRuW3ev6VVFxIOk/VkJOAiYFRFbAFsAn5e0uqSxwNrAlsBIYHNJO+RVrAtMiIiNSSHZqBfbNyK2BA7nrZGAuttrouxXI2K7iDgfuDgitoiITYB78zo7MhTYDtiNFNa0s49HAw/k0YyvA9cD2+f1DAc2yI+3AyZL2hw4ANgK2Drv06Z5mXWBsyNi04h4JG93ZeDPwDH1glzSwZJuk3TbM7NeaWLXzMysWb2iZ16h/H0ssLGkvfLzQaSAG5u/7sjTB+bpjwIzI+LGPP1/gcOAn9TZxsX5+1RgRAfb+28H9V5QebyRpO+TevwDgas6eC3ApRHxBnBPDtO2WhrtY9Vk4HBJGwD3AMtLGkrqbR9G6pFfEhFzASRdTAr/y4BHIuLmyrr6AX8DDomI6+oVGhETgAkAo9ZeOZrYN2uhST/8eKtLsGbt/otWV2CLgF4T5pLWAOYDT5NC/SsRcVXNMh8ETmgbcq9MHwHUBkyjwHktf5/PW+3XaHvbseDoR/+adc2tPJ4I7BER0yWNIw3Zd+S1ymNVvjfaxzdFxOOSlgc+ROqlr0Aamp8TEbMlicbm1jyfRzq4+SBQN8zNzKz79IphdkkrAqcBp0REkHq1X5LUL89fR9IyefqBkgbm6cMlrZRXs6qk0fnxPsANnSih0fYeATaQtJSkQcBO7axjWeDJvI59O7HterXU28fZeRtVU0inC64n9dSPzN/J0/aQtHTelz0r82oFqSe/nqSj30HtZma2EErumQ/IF3P1I/UMzwF+luedQRoCvz33MJ8h9XqvlrQ+MCV3POcAnyH1su8F9pd0OvBv4NedqKXR9mZK+gNwZ17nHY1XwXdJF9c9Aszg7cHblEb7GBEPSLpR0l3AX/J588nA2Ii4X9IjpN755Lye2/NFdre07WNE3FHbw69sd76kTwGXS3opIk5dmPrNzKzzlDqyi7ccUFdExEatrmVxMGrtleO2n32q1WWY9Q4+Z77YkDQ1IkbVm9crhtnNzMwWZyUPs3eZiHgYcK/czMyK5J65mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVri+rS7AFkODVoHdf9HqKszMeg33zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5w/ztV63BNzn+C4Kce1ugwz6yWOHX1sq0toOffMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwHYa5pDlNLHO4pKW7pqSFI2m8pCPz4+Ml7dzB8uMkDeuZ6hZervOULlrXt7piPXXW+7CkId2xbjMz61hX9cwPBzoV5pL6dNG23yYijomIv3aw2DhgkQhzSX17aFNdHubd+T6amVlzmg5zSWMkTZJ0oaR/SjpXyWGkULxW0rV52bGSpki6XdIfJQ3M0x+WdIykG4BP5Oc/zMveJmkzSVdJekDSFyvb/rqkWyXdKem4yvRvS7pP0l+BdSvTJ0raKz8+Jr/2LkkTcs17AaOAcyVNkzRA0uaSrpM0NdcwtE4bTJR0sqSbJD3Yto1GNUoaIemuyjJHShqfH0/K+34d8FVJu0v6h6Q7JP1V0sodvB/jJZ2Z1/Ngfh/a5n1G0i15306X1EfSicCAPO1cSd9oe42kkyT9PT/eSdL/5sf7SJqR2+5HlfXPyaMf/wBGV6YPkHSlpM+3V7uZmXWtzvYINwU2BJ4AbgS2jYiTJR0B7BgRz+bh1u8AO0fEXElHAUcAx+d1vBoR2wHkgJkZEaMlnQRMBLYF+gN3A6dJGgusDWwJCLhM0g7AXOBTuaa+wO3A1Do1nxIRx+ftnQPsFhEXSjoUODIibpPUD/gl8NGIeEbSJ4EfAAfWWd9QYDtgPeAy4MJ2any0g/YcHBHvy7UtD2wdESHpc8A3gK918Pr1gB2BZYH7JP0aWAv4JOm9eV3SqcC+EXG0pEMjYmTe3tZ5/SeTDmyWyu2wHTBZ6RTEj4DNgReAqyXtERGXAssAd0XEMXldAAOB84GzI+LsDuo2M2vaWYec1e78a5e7tt35kyZN6sJqFk2dDfNbIuIxAEnTgBHADTXLbA1sANyY/8gvCUypzL+gZvnL8vcZwMCImA3MlvSqpMHA2Px1R15uICk4lwUuiYiXcz2XUd+Okr5BOg2wAukg4fKaZdYFNgKuyTX3AZ5ssL5LI+IN4J5K77lRjR2FebUt3gNckEcElgQe6uC1AH+OiNeA1yQ9DawM7EQK4FvzvgwAnq7z2qnA5pKWBV4jHQyNArYHDgO2ACZFxDMAks4FdgAuBeYDF9Ws70/AjyPi3HqFSjoYOBhg0MqDmtg1MzNrVmfD/LXK4/kNXi/gmojYp8E65jZY5xs1638jr1/ACRFx+gIbkQ4Hor1iJfUHTgVGRcTMPMTdv0HNd0fE6DrzalVrVOV7vRrfw4KnMmq3XW2LXwI/i4jLJI0Bxneylrb3Q8DvIuKb7b0w99ofBg4AbgLuJPXy1wTuBdZp5+WvRsT8mmk3ArtI+n1EvO19iYgJwASAYesPa/d9MzOrOuBXB7Q7/9jRx/ZQJYuurroAbjappwxwM7CtpLUAJC0tqb1g6MhVwIF667z7cEkrAdcDe+bztMsCu9d5bVt4Pptfv1dlXrXm+4AVJY3O2+gnacMuqPEpYCVJ75K0FLBbO+sYBDyeH+/fiW3X+huwV94+klaQtFqe93oeSm9zPXBk/j4Z+CIwLYfxP4D3SRqidJHbPsB17Wz3GOA50sGTmZn1oK4K8wnAXyRdm4dlxwHnSbqTFO7rLeyKI+Jq4PfAFEkzgAuBZSPidtIw9TTSkO/kOq99EfgNaQj/UuDWyuyJpHPy00jD6nsBP5I0Pa9zmy6o8XXStQL/AK4A/tnOasYDf5Q0GXi22W3XqeUe0jULV+f2v4Z0nh/S+3RnHjKH1GZDgSkR8RTwap5GRDwJfBO4FpgO3B4Rf+pg84cD/SX9eGHrNzOzzlOdEVGzbjVs/WHxhTO/0OoyzKyXWFyG2SVNjYhR9eb5E+DMzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK1zfVhdgi59hywzj2NHHtroMM7Newz1zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnD+b3Xrc6088wZPH+LPZrbWGHn9cq0sw6zLumZuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4Rb7MJc0X9I0SXdLmi7pCElFtIukEZLu6sL1HS9p5/x4+9wm0yQNl3RhV23HzMy6Vt9WF7AIeCUiRgJIWgn4PTAIOLaVRbVCRBxTebov8JOIOCs/36vZ9UjqExHzu7Q4MzNryGFeERFPSzoYuFXSeGB/YFREHAog6QpSwE2SNAf4FbAz8ALwLeDHwKrA4RFxmaRxwB5AH2Aj4KfAksBngdeAXYHlgT9GxGZ5G2sD50fE5tXaJK0FnAasCMwHPpG/t80fAZwDLJMnHRoRN0kaClwALEd6v78E3AT8FhgFBHBmRJwkaSJwBTAY2Bv4YO6pfxu4IiI2ktQHOBEYAywF/CoiTpc0hnQA9CQwEtigE01v1iM+fvbv3ny85PXXLTBv0qRJPVyNWddxmNeIiAfzMPtKHSy6DDApIo6SdAnwfeADpBD7HXBZXm4jYFOgP3A/cFREbCrpJGC/iPi5pFmSRkbENOAAYGKd7Z0LnBgRl0jqTzpFUq3xaeADEfFqPiA4jxTWnwauiogf5CBemhS2wyNiIwBJg2va4AxJ25EC/MJ8oNDmIGBWRGwhaSngRklX53lbAhtFxEO1xeeDpIMBhg8a1KBJzcxsYTjM61MTy/wXuDI/ngG8FhGvS5oBjKgsd21EzAZmS5oFXF55zcb58RnAAZKOAD5JCsW3ipGWJYXvJQAR8WqeXl2sH3CKpJGkHvs6efqtwJmS+gGXRsQ0SQ8Ca0j6JfBn4GqaNxbYWFLbsPsgYO3cHrfUC/Jc8wRgAsAmw4ZFJ7Zn1mUu2m//Nx8PPf64FlZi1rWKuNCrJ0lagxSGTwPzWLCN+lcevx4RbaH0BmnYnIh4gwUPkl6rPH6j8ry63EXALsBuwNSIeK62rCZK/x/gKWATUo98yVzP9cAOwOPAOZL2i4gX8nKTgENIBxPNEvCViBiZv1aPiLaDgbmdWI+ZmXURh3mFpBVJ56VPyUH9MDBS0hKSVqGmx9xVck/7KuDXwFl15r8EPCZpj1znUpKWrllsEPBkPpj4LOk8PZJWA56OiN+QzpNvJmkIsEREXAR8F9isE+VeBXwp9/SRtI6kZTp4jZmZdSMPs8MASdNIw9TzSBeR/SzPuxF4iDQkfhdwezfWcS7wMRoPeX8WOF3S8cDrpAvg3qjMPxW4SNIngGt5q5c8Bvi6pNeBOcB+wHDgrMq/4H2zE3WeQTqNcLvSOP8zpIv8zMysRfTWSLG1kqQjgUER8d1W19LdNhk2LK783OdbXYYt5nzO3EojaWpEjKo3zz3zRUC+Gn5N4P2trsXMzMrjMF8ERMSera7BzMzK5QvgzMzMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHC+n7n1uH7DhjH0+ONaXYaZWa/hnrmZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVTRLS6BlvMSJoN3NfqOhZxQ4BnW13EIszt0z63T8dKbKPVImLFejP82ezWCvdFxKhWF7Eok3Sb26gxt0/73D4d621t5GF2MzOzwjnMzczMCucwt1aY0OoCCuA2ap/bp31un471qjbyBXBmZmaFc8/czMyscA5zMzOzwjnMrdtI+pCk+yTdL+noOvMl6eQ8/05Jm7WizlZpon32ze1yp6SbJG3SijpbqaM2qiy3haT5kvbqyfparZn2kTRG0jRJd0u6rqdrbLUmfs8GSbpc0vTcRge0os53LCL85a8u/wL6AA8AawBLAtOBDWqW2RX4CyBga+Afra57EWufbYDl8+NdFqf2abaNKsv9Hfg/YK9W170otQ8wGLgHWDU/X6nVdS+CbfQt4Ef58YrA88CSra69s1/umVt32RK4PyIejIj/AucDH61Z5qPA2ZHcDAyWNLSnC22RDtsnIm6KiBfy05uB9/Rwja3WzM8QwFeAi4Cne7K4RUAz7fNp4OKIeBQgItxGb2+jAJaVJGAgKczn9WyZ75zD3LrLcGBm5fljeVpnl+mtOrvvB5FGMRYnHbaRpOHAnsBpPVjXoqKZn6F1gOUlTZI0VdJ+PVbdoqGZNjoFWB94ApgBfDUi3uiZ8rqOP87VuovqTKv9P8hmlumtmt53STuSwny7bq1o0dNMG/0cOCoi5qeO1WKlmfbpC2wO7AQMAKZIujki/tXdxS0immmjDwLTgPcDawLXSJocES91c21dymFu3eUxYJXK8/eQjnw7u0xv1dS+S9oYOAPYJSKe66HaFhXNtNEo4Pwc5EOAXSXNi4hLe6TC1mr2d+zZiJgLzJV0PbAJsLiEeTNtdABwYqST5vdLeghYD7ilZ0rsGh5mt+5yK7C2pNUlLQl8CrisZpnLgP3yVe1bA7Mi4smeLrRFOmwfSasCFwOfXYx6UlUdtlFErB4RIyJiBHAh8OXFJMihud+xPwHbS+oraWlgK+DeHq6zlZppo0dJIxdIWhlYF3iwR6vsAu6ZW7eIiHmSDgWuIl1RemZE3C3pi3n+aaSrj3cF7gdeJh0hLxaabJ9jgHcBp+ae57zoRXd56kiTbbTYaqZ9IuJeSVcCdwJvAGdExF2tq7pnNfkz9D1goqQZpGH5oyKitFuj+uNczczMSudhdjMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNrFj5TmnTKl8jJL1L0rWS5kg6pZ3X7ibpjny3rHskfaEnazfrSv7XNDMrlqQ5ETGwZtoywKbARsBGEXFondf1Ax4BtoyIxyQtBYyIiPveQS0i/U0t7nO9rXzumZtZrxIRcyPiBuDVdhZblvShWc/l17zWFuSSVpZ0Se6xT5e0TZ5+hKS78tfhedoISfdKOhW4HVhF0tcl3ZrvQ39cN+6q2Zsc5mZWsgGVIfZLmn1RRDxP+ljPRySdJ2lfSW1/D08GrouITYDNgLslbU76hMKtgK2Bz0vaNC+/LulWvpvmx2uTbr05Ethc0g7vfDfN2uePczWzkr0SESMX5oUR8TlJ7wV2Bo4EPgCMI909a7+8zHxglqTtgEvyDUuQdDGwPfmAICJuzqsdm7/uyM8HksL9+oWp0axZDnMzW2xFxAxghqRzgIdIYV5Pe/dXnVuz3AkRcXrXVGjWHA+zm9liR9JASWMqk0aSLogD+BvwpbxcH0nLkXrWe0haOl9gtycwuc6qrwIOlDQwv364pJW6ZSfMKtwzN7NeR9LDwHLAkpL2AMZGxD3VRYBvSDodeIXUux6X530VmCDpIGA+8KWImCJpIm/d4/qMiLhD0ojqdiPiaknrA1Pyne7mAJ8Bnu7qfTSr8r+mmZmZFc7D7GZmZoVzmJuZmRXOYW5mZlY4h7lZF8ifGna9pNmSftrqehYlksZIeqzJZcdL+t9urGWOpDXamf+wpJ0Xct0jJIWkvvn5XyTtX5n/fUnPSvpPfr6npJm5pk0brbd0ksZJuqGd+Qu0ky0ch7n1WpImSXohf+527fTP1UxbIHCUHJY/unOupMck/TF/yEg9BwPPAstFxNe6oPZxORh+VjN9jzx9Yn6+QIDULDte0us5LF6UdJOk0e+0tpJFxMCIeBBA0kRJ3+/Gbe0SEb/L21oF+BqwQUS8Oy/yE+DQXNMdjdbTHer9DrRKTTu1G/ydsSjtY09wmFuvlP9laHsggI8sxCp+QfoXpcOAFYB1gEuBDzdYfjXgnliIfw+pF8TZA8Ana+bvB/yrE6u/IN+IZEXgBuDifEMQ61mrAc9FxNM10+5emJW18zPTEpL6tLqGrraotXFHHObWW+0H3AxMBDo1hCdpbeAQYJ+I+Hu+CcfLEXFuRJxYZ/m2bXwj94J3lrSUpJ9LeiJ//bxthKBtFEDSUXnI9awGpfwHmAF8ML9uBWAb0keIdkpEvA78Dng38K46+zA+jzz8bz5VMEPSOpK+KenpPBw8trL8MEmXSXpe0v2SPl+ZNyD3el+QdA+wRc22hkm6SNIzkh6SdFi9miX1z/U8l0cWbpW0cp3lDpB0eeX5/ZL+UHk+U9LI/DgkrSXpYGBf3nrPLq+scqTSTVJmSbpAUv8G9fWR9JM8dP4gNQd6bT1DpWH7a4BheVvnSZoD9AGmS3qgo3bJ78+FuT1eAsZJGiTpt5KelPS40jB+n7z8OEk35PpeyOvbJc/7AelA9xS1c5vY/PPwn9wO10vasDJvoqRfS/o/SXOBHSWtIuniXP9zteutV0tNO60PnAaMznW9mOcvlV/7qKSnJJ0maUDl9R9V+mz+lyQ9IOlD9fZRdUaxVOm95za7UdJJkp4Hxre3bUlDJF2RfzaflzRZb32+f49zmFtvtR9wbv76YL0QaMdOwGMRcUuHSwIRMS5v58d5yPSvwLdJN+QYCWxCuvHGdyovezepx78aaYi+kbPzvgB8CvgT8FqzO9JG6UBiHGm/nm2w2O7AOcDypM8Wv4r0N2I4cDxQ/YjS84DHgGHAXsAPJe2U5x0LrJm/PkjlYCr/sbscmJ7XuxNwuKQP1qlnf2AQsArpAOSLpA94qXUdsL2kJSQNBfoB2+btrUH6fPQ7qy+IiAks+J7tXpm9N/AhYHVgYxp/xOvngd1It1sdldvhbfLPwy7AE3lb+1Ru27pJRKzZZLt8FLgQGJxr/x0wD1gr1zAWqA4rbwXcBwwBfgz8VpIi4tukT69rG+J/2y1is7+QPld+JdId4c6tmf9p4AekO9BNAa4gfYreiLwP53dUS0073Ut6j6fkugbnWT8ijYyNzPs6HDgGQNKWpN+Rr+d22QF4uBP7WGsr4MG8zz9ob9uk0yaPkUa9Vga+RRoJbAmHufU6SjfFWA34Q0RMJQ1Xf7oTq3gX8OQ7LGNf4PiIeDoingGOAz5bmf8GcGzu9dcLqDaXAGMkDSKF+tmdrGPv3MOZCWwO7NHOspMj4qqImAf8kfRH6sTcqz8fGCFpsNL53+2AoyLi1YiYBpxR2b+9gR9ExPMRMZN0F7I2WwArRsTxEfHffP76N6QDlVqvk96LtSJifkRMjYiXahfK65hN+oP7PtJByOOS1svPJ3fyHuMnR8QT+c5ql+f11rM38POImJmXPaET26jVTLtMiYhL874sRzpAODzf8vVp4KSa5R+JiN/km8X8DhhKCp2mRMSZETE7Il4DxgOb5J/DNn+KiBtzPRuTDuy+nut5Nd+G9h3VkgP/88D/5J+n2cAPK/t5EHBmRFwTEW9ExOMR8c9m97GOJyLil/l34NUOtv163o/VIuL1iJi8MKfZukpR5wTMmrQ/cHWlB/r7PO2k/HweqfdW1Y/0ywnpHtdD32ENw3jrs77Jj4dVnj8TEe3dbxuAiHhF0p9JvfohEXFjdYiyCX+IiM80uexTlcevAM/mP75tzyH1cocBbX/c2jxC6p2S58+smddmNdJw84uVaX2o/znn55B65edLGgz8L/DtfHBR6zpgDKn3dB3wIinIR+fnnfGfyuOXWfB9q2pvPzurmXaZWbN8P+DJSgd3iZpl3tyPiHg5LzeQJuTh+h8AnyAd1LUdDA0BZtWpZxVSYM9rsMqFrWVFYGlgamU/RWqbtu3+XxPraVZ1nzra9v8jHeRcnedPqHcarqc4zK1Xyeez9gb6KP8LELAUMFjSJhExHXiUNBRYtToL3mjjV5JGRcRtC1nKEyx4gdOqeVqbzhzBnw38ndS7XxQ8AawgadlKoK8KPJ4fP0n6I1vd9zYzgYciYu2ONpJD+zjgOKULGv+PNFT72zqLX0c6TbA6qff0Iml0ZDRQ95ww73xItG0/26zaaMEmNNMu1Xpnkk63DGknQNvT0b5/mjSsvzPwMOl0xwssePe42npWldR3IetpVNezpAPJDSPi8TrLzySdzmlmXW13t1saaBvheXfNMtXXtLvt/LP/NeBr+XqCayXdGhF/a1BPt/Iwu/U2e5BujrEBaXh0JLA+qYfTdu75AuAASVsqWQf4H/I5voj4N3AqcJ7SxWpLKl2M9SlJRzdZx3nAdyStKGkI6Tzbwv7/9HWke23/sp1llso1tn112+92Hjq/CTghb2tj0nBn2znVPwDflLS8pPcAX6m8/BbgJaWL/wYoXUS2kaQFLpIDkLSjpPfmXuJLpJGT+bXLZdcBOwIDIuIx0vv9IdIwfaN/+3oKaPg/5034A3CYpPdIWh5o9mejnqbbBSAingSuBn4qabl8vcCakt7X5PY62vdlSQcLz5HC74dN1P8kcKKkZfLPxbZN1lJb13skLQmQh/B/A5ykfPc5pTvRtV1L8FvS7/JOuQ2G59Mrb9vHfLrrceAzuX0PpPGBQIfblrSb0sWUIv18zqfxz2e3c5hbb7M/cFZEPBoR/2n7IvXO9s09h6tIf3jPIg0Z/h/pPN6EynoOy6/5FamX9wDptpfVq57b833gNtKFVzNIFxAt1P80R/K3fF62kTmkXkTb1/sXZludsA9pdOMJ0nn9YyPimjzvONIox0OkwDmn7UV52H530kHWQ6Tezxmknl+td5Mu+HoJuJcU2HUPiCLiX6Q2mJyfv0S6kOnGyqmCWr8FNshXI1/a8S6/zW9I5+enk97fixdiHUCn26XNfsCSwD2kXvOFNH966BfAXkpXl59cZ/7ZpPfw8bz+m5usfy3SyNdjwCebrKXq76QRnf9IajtNdhRwP3Cz0pX8fwXWzdu9BTiAdAptFulnZLV29vHzpIvlngM2JB2UtqfhtkkXB/6V9HM3BTg1IiYtxD53Cd81zczMrHDumZuZmRXOYW5mZlY4h7mZmVnhHOZmZmaF8/+ZW48bMmRIjBgxotVlmJkVZerUqc9GxIr15jnMrceNGDGC225b2M9iMTNbPElq+CmDHmY3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucPwHOetzjL77CNy+e0eoyzMwW2gkfe2+rS1iAe+ZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVriiw1zSSZIOrzy/StIZlec/lXSEpI9IOrrBOub0QKnviKRJkkZ1wXpGStq1K2qqWe8YSVd09XrNzKw5RYc5cBOwDYCkJYAhwIaV+dsAN0bEZRFxYgvqa4qSnngvRgJdGuaS+nbl+szMrPNKD/MbyWFOCvG7gNmSlpe0FLA+cIekcZJOAZC0uqQpkm6V9L3qyiR9PU+/U9Jx9TYoaY6kH0iaLulmSSvn6StKuii//lZJ2+bp4yUdWXn9XZJG5K97JZ0K3A6sIunXkm6TdHej7dfU8rCk4yTdLmmGpPXy9GUknZnruEPSRyUtCRwPfFLSNEmfzK8ZnA8mnpO0X379OZJ2ltRf0ll5uTsk7Zjnj5P0R0mXA1fX1LRFXnaNjuo3M7OuUXSvKiKekDRP0qqkUJ8CDAdGA7OAOyPiv5KqL/sF8OuIOFvSIW0TJY0F1ga2BARcJmmHiLi+ZrPLADdHxLcl/Rj4PPD9vN6TIuKGXM9VpIOJ9qwLHBARX841fDsinpfUB/ibpI0j4s4O1vFsRGwm6cvAkcDngG8Df4+IAyUNBm4B/gocA4yKiEPz9nYEtgUeAR4EtgfOBrYGvgQcAhAR780HCldLWidvdzSwca53TF7fNsAvgY9GxKMd1G1mtkg495gDO/2aKScv0+nXTJo0qdOvaVbpPXN4q3feFuZTKs9vqrP8tsB5+fE5lelj89cdpJ7yeqRwr/VfoO388FRgRH68M3CKpGnAZcBykpbtoPZHIuLmyvO9Jd2ea9gQ2KCD1wNcXKeWscDRuZZJQH9g1TqvnQzskL9+DbxX0nDg+YiYA2xHbqOI+Ccp9NvC/JqIeL6yrvWBCcDu9YJc0sF51OG2l2e90MRumZlZs4rumWdt583fSxpmnwl8DXgJOLPBa6LONAEnRMTpHWzv9Yhoe/183mrDJYDREfHKAiuV5rHgQVP/yuO5leVWJ/Wst4iIFyRNrFm2kdfq1CLg4xFxX00tW9W89npS73tVUm9+T2AvUsi3raeRuTXPn8z1bgo8UbtwREwghT1D19qwXvubmbXEvsc3iorGTvjYe7uhkoXXW3rmu5F6k/Nzb3EwaRh4SoPlP5Uf71uZfhVwoKSBAJKGS1qpE3VcDRza9kTSyPzwYWCzPG0zYPUGr1+OFJCz8nn4XTqx7VpXAV9RPr8gadM8fTbw5mhBRMwkXTS4dkQ8CNxAOqBoC/PryW2Uh9dXBRY4QKh4Efgw8MO2YXczM+sZvSHMZ5AC6eaaabMi4tk6y38VOETSrcCgtokRcTXwe2CKpBnAhVSCrwmHAaPyxXP3AF/M0y8CVshD3l8C/lXvxRExnTS8fjdpROHGTmy71veAfsCdku7KzwGuBTZouwAuT/tHpabJpGsObsjPTwX65Pa4ABgXEW0jAfX24Slgd+BXdUYBzMysm+itEWOznjF0rQ1j3I/Pb3UZZmYLrRXD7JKmRkTdzxzpDT1zMzOzxZrD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwfVtdgC1+hg8ewAkfe2+ryzAz6zXcMzczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHD+OFfrebNmwuVfbXUVZtaddv9FqytYrLhnbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVrtgwlzRf0jRJd0uaLukIScXuTyOSxks6sgvWM1jSl7uipjrrntMd6zUzs+aUHH6vRMTIiNgQ+ACwK3Bsi2taKJL69MBmBgNdGuZKSv4ZMjPrFfq2uoCuEBFPSzoYuFXSeNJByonAGGAp4FcRcTqApK8De+fpl0TEsZJGAFcC/wA2Bf4F7BcRL1e3I2lSXmZHUjgeFBGTcxi/bXuSxgBHRsRu+fWnALdFxERJDwNnAmOBUyQtCxwMLAncD3y2dvs1tUwEXgJGAe8GvhERFzbax1zfmpKmAdcAywBXRsRlki4BXoiIAyUdBKweEd+RdARwYN7kGRHx89xWfwGuBUYDe1RqGgJcDnw/Iv7cqHYza2zMty5qdQld46fTW11Bl5g0aVKrS2hKr+lVRcSDpP1ZCTgImBURWwBbAJ+XtLqkscDawJbASGBzSTvkVawLTIiIjUkh2agX2zcitgQO562RgLrba6LsVyNiu4g4H7g4IraIiE2Ae/M6OzIU2A7YjRTWtLOPRwMP5NGMrwPXA9vn9QwHNsiPtwMmS9ocOADYCtg679OmeZl1gbMjYtOIeCRvd2Xgz8Ax9YJc0sGSbpN02zOzXmli18zMrFm9omdeofx9LLCxpL3y80GkgBubv+7I0wfm6Y8CMyPixjz9f4HDgJ/U2cbF+ftUYEQH2/tvB/VeUHm8kaTvk3r8A4GrOngtwKUR8QZwTw7Ttloa7WPVZOBwSRsA9wDLSxpK6m0fRuqRXxIRcwEkXUwK/8uARyLi5sq6+gF/Aw6JiOvqFRoRE4AJAKPWXjma2DezxdKkH3681SV0jd1/0eoKFiu9JswlrQHMB54mhfpXIuKqmmU+CJzQNuRemT4CqA2YRoHzWv4+n7far9H2tmPB0Y/+NeuaW3k8EdgjIqZLGkcasu/Ia5XHqnxvtI9viojHJS0PfIjUS1+BNDQ/JyJmSxKNza15Po90cPNBoG6Ym5lZ9+kVw+ySVgROA06JiCD1ar8kqV+ev46kZfL0AyUNzNOHS1opr2ZVSaPz432AGzpRQqPtPQJsIGkpSYOAndpZx7LAk3kd+3Zi2/VqqbePs/M2qqaQThdcT+qpH5m/k6ftIWnpvC97VubVClJPfj1JR7+D2s3MbCGU3DMfkC/m6kfqGZ4D/CzPO4M0BH577mE+Q+r1Xi1pfWBK7njOAT5D6mXfC+wv6XTg38CvO1FLo+3NlPQH4M68zjsar4Lvki6uewSYwduDtymN9jEiHpB0o6S7gL/k8+aTgbERcb+kR0i988l5Pbfni+xuadvHiLijtodf2e58SZ8CLpf0UkScujD1m5lZ5yl1ZBdvOaCuiIiNWl3L4mDU2ivHbT/7VKvLMLPu5HPmXU7S1IgYVW9erxhmNzMzW5yVPMzeZSLiYcC9cjMzK5J75mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY438/cet6gVWD3X7S6CjOzXsM9czMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5w/m9163BNzn+C4Kce1ugwzs047dvSxrS6hLvfMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwHYa5pDlNLHO4pKW7pqSFI2m8pCPz4+Ml7dzB8uMkDeuZ6hZervOULlrXt7piPXXW+7CkId2xbjMz61hX9cwPBzoV5pL6dNG23yYijomIv3aw2DhgkQhzSX17aFNdHubd+T6amVlzmg4RSWOA8cCzwEbAVOAzwFdIoXitpGcjYkdJY4HjgKWAB4ADImKOpIeBM4GxwCmSTgR+D+wI9AMOBk4A1gL+X0Sclrf9dWDvvL5LIuLYPP3bwH7ATOCZXBOSJgJXRMSFko4BdgcGADcBXwA+DowCzpX0CjAa2AD4GTAw7+O4iHiypg0mAi/l174b+EZEXNioRkkjch0b5WWOBAZGxHhJk3I92wKXSfoX8B1gSeA5YN+IeKqd92M8sCqwRv7+84g4Oc/7DHBYXtc/gC8DPwAGSJoG3A1MB16NiJMlnQRsEhHvl7RTfr8+I2kf0gGAgD9HxFF5/XNyW30Q+FqlpgHAJcBFEfGbRrWbmS1KzjrkrKaXvXa5a5tabtKkSQtZzcLpbM98U1IvfANSiGybA+QJYMcc5ENIobRzRGwG3AYcUVnHqxGxXUScn5/PjIjRwGRgIrAXsDVwPEA+MFgb2BIYCWwuaQdJmwOfyjV9DNiiQc2nRMQWOVAHALvlAL6NFJgjgXnAL4G9ImJz0gHHDxqsbyiwHbAbcGJ7NTZuxjcNjoj3RcRPgRuArSNiU+B84BtNvH49UqBuCRwrqZ+k9YFPkt6bkcD8vJ9HA69ExMiI2Be4Htg+r2cUMFBSv7xvk/MpiB8B78/7tIWkPfLyywB3RcRWEXFDnjYQuBz4fb0gl3SwpNsk3fbyCy83sWtmZtaszg7v3hIRjwHkHt4IUghVbU0K+xslQeodTqnMv6Bm+cvy9xmkXutsYLakVyUNJvXixwJ35OUGkoJzWVIP+OVcz2XUt6Okb5BOA6xA6pVeXrPMuqTRhmtyzX2AJ6nv0oh4A7hH0sp5WqMaH22wjjbVtngPcIGkoaQ2e6iD10LqLb8GvCbpaWBlYCdgc+DWvC8DgKfrvHYq6aBjWeA14HZSqG9P6tVvAUyKiGcAJJ0L7ABcSjpAuKhmfX8CfhwR59YrNCImABMAhq0/LJrYNzOzHnHArw5oetljRx/bjZUsvM6G+WuVx/MbvF7ANRGxT4N1zG2wzjdq1v9GXr+AEyLi9AU2Ih0OtBsKkvoDpwKjImJmHpru36Dmu/MIQUeqNaryvV6N72HB0Y/abVfb4pfAzyLissopjc7U0vZ+CPhdRHyzvRdGxOv5tMcBpOH+O0mnO9YE7gXWaeflr0bE/JppNwK7SPp9RDiszcx6UFddADeb1FMGuBnYVtJaAJKWltReMHTkKuBASQPz+oZLWok0TLynpAG5d7l7nde2heez+fV7Naj5PmBFSaPzNvpJ2rALanwKWEnSuyQtRRqab2QQ8Hh+vH8ntl3rb8BeeftIWkHSanne63kovc31wJH5+2Tgi8C0HMb/AN4naUi+yG0f4Lp2tnsM6Vz/qe+gdjMzWwhdFeYTgL9IujYPy44DzpN0Jync11vYFUfE1aSL5KZImgFcCCwbEbeThqmnkYZ8J9d57YvAb0hD+JcCt1ZmTwROy6cL+pCC/keSpud1btMFNb5OOvf/D+AK4J/trGY88EdJk0kX4C2UiLiHdM3C1bn9ryGd54f0Pt2Zh8whtdlQYEq+2O7VPI188d83gWtJF8vdHhF/6mDzhwP9Jf14Yes3M7POk0dEracNW39YfOHML7S6DDOzTmvlOXNJUyNiVL15/gQ4MzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8L1bXUBtvgZtswwjh19bKvLMDPrNdwzNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwvmz2a3Hvf7EEzx5jD+b3RYdQ48/rtUlmL0j7pmbmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEW+zCXNF/SNEl3S5ou6QhJRbSLpBGS7urC9R0vaef8ePvcJtMkDZd0YVdtx8zMulbfVhewCHglIkYCSFoJ+D0wCDi2lUW1QkQcU3m6L/CTiDgrP9+r2fVI6hMR87u0ODMza8hhXhERT0s6GLhV0nhgf2BURBwKIOkKUsBNkjQH+BWwM/AC8C3gx8CqwOERcZmkccAeQB9gI+CnwJLAZ4HXgF2B5YE/RsRmeRtrA+dHxObV2iStBZwGrAjMBz6Rv7fNHwGcAyyTJx0aETdJGgpcACxHer+/BNwE/BYYBQRwZkScJGkicAUwGNgb+GDuqX8buCIiNpLUBzgRGAMsBfwqIk6XNIZ0APQkMBLYoBNNb9bjPn727958vOT11y0wb9KkST1cjdk74zCvEREP5mH2lTpYdBlgUkQcJekS4PvAB0gh9jvgsrzcRsCmQH/gfuCoiNhU0knAfhHxc0mzJI2MiGnAAcDEOts7FzgxIi6R1J90iqRa49PAByLi1XxAcB4prD8NXBURP8hBvDQpbIdHxEYAkgbXtMEZkrYjBfiF+UChzUHArIjYQtJSwI2Srs7ztgQ2ioiHaovPB0kHAwwfNKhBk5qZ2cJwmNenJpb5L3BlfjwDeC0iXpc0AxhRWe7aiJgNzJY0C7i88pqN8+MzgAMkHQF8khSKbxUjLUsK30sAIuLVPL26WD/gFEkjST32dfL0W4EzJfUDLo2IaZIeBNaQ9Evgz8DVNG8ssLGktmH3QcDauT1uqRfkueYJwASATYYNi05sz6xbXLTf/m8+Hnr8cS2sxOydK+JCr54kaQ1SGD4NzGPBNupfefx6RLSF0hukYXMi4g0WPEh6rfL4jcrz6nIXAbsAuwFTI+K52rKaKP1/gKeATUg98iVzPdcDOwCPA+dI2i8iXsjLTQIOIR1MNEvAVyJiZP5aPSLaDgbmdmI9ZmbWRRzmFZJWJJ2XPiUH9cPASElLSFqFmh5zV8k97auAXwNn1Zn/EvCYpD1ynUtJWrpmsUHAk/lg4rOk8/RIWg14OiJ+QzpPvpmkIcASEXER8F1gs06UexXwpdzTR9I6kpbp4DVmZtaNPMwOAyRNIw1TzyNdRPazPO9G4CHSkPhdwO3dWMe5wMdoPOT9WeB0SccDr5MugHujMv9U4CJJnwCu5a1e8hjg65JeB+YA+wHDgbMq/4L3zU7UeQbpNMLtSuP8z5Au8jMzsxbRWyPF1kqSjgQGRcR3W11Ld9tk2LC48nOfb3UZZm/yOXMrgaSpETGq3jz3zBcB+Wr4NYH3t7oWMzMrj8N8ERARe7a6BjMzK5cvgDMzMyucw9zMzKxwDnMzM7PCOczNzMwK5zA3MzMrnMPczMyscA5zMzOzwjnMzczMCucwNzMzK5zD3MzMrHAOczMzs8I5zM3MzArnMDczMyucw9zMzKxwDnMzM7PCOczNzMwK17fVBdjip9+wYQw9/rhWl2Fm1mu4Z25mZlY4h7mZmVnhHOZmZmaFc5ibmZkVzmFuZmZWOIe5mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEUEa2uwRYzkmYD97W6jkXcEODZVhexCHP7dMxt1LHS2mi1iFix3gx/Nru1wn0RMarVRSzKJN3mNmrM7dMxt1HHelMbeZjdzMyscA5zMzOzwjnMrRUmtLqAAriN2uf26ZjbqGO9po18AZyZmVnh3DM3MzMrnMPczMyscA5z6zaSPiTpPkn3Szq6znxJOjnPv1PSZq2os1WaaJ99c7vcKekmSZu0os5W6qiNKsttIWm+pL16sr5FQTNtJGmMpGmS7pZ0XU/X2EpN/J4NknS5pOm5fQ5oRZ3vWET4y19d/gX0AR4A1gCWBKYDG9QssyvwF0DA1sA/Wl33ItY+2wDL58e7LE7t02wbVZb7O/B/wF6trntRayNgMHAPsGp+vlKr617E2udbwI/y4xWB54ElW117Z7/cM7fusiVwf0Q8GBH/Bc4HPlqzzEeBsyO5GRgsaWhPF9oiHbZPRNwUES/kpzcD7+nhGlutmZ8hgK8AFwFP92Rxi4hm2ujTwMUR8ShARCxO7dRM+wSwrCQBA0lhPq9ny3znHObWXYYDMyvPH8vTOrtMb9XZfT+INIqxOOmwjSQNB/YETuvBuhYlzfwcrQMsL2mSpKmS9uux6lqvmfY5BVgfeAKYAXw1It7omfK6jj/O1bqL6kyr/T/IZpbprZred0k7ksJ8u26taNHTTBv9HDgqIuanjtVip5k26gtsDuwEDACmSLo5Iv7V3cUtApppnw8C04D3A2sC10iaHBEvdXNtXcphbt3lMWCVyvP3kI58O7tMb9XUvkvaGDgD2CUinuuh2hYVzbTRKOD8HORDgF0lzYuIS3ukwtZr9vfs2YiYC8yVdD2wCbA4hHkz7XMAcGKkk+b3S3oIWA+4pWdK7BoeZrfuciuwtqTVJS0JfAq4rGaZy4D98lXtWwOzIuLJni60RTpsH0mrAhcDn11MelG1OmyjiFg9IkZExAjgQuDLi1GQQ3O/Z38CtpfUV9LSwFbAvT1cZ6s00z6PkkYtkLQysC7wYI9W2QXcM7duERHzJB0KXEW6ovTMiLhb0hfz/NNIVx/vCtwPvEw6Ql4sNNk+xwDvAk7NPc950Uvu8NSMJttosdZMG0XEvZKuBO4E3gDOiIi7Wld1z2nyZ+h7wERJM0jD8kdFREm3RQX8ca5mZmbF8zC7mZlZ4RzmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5ma22JC0p6SQtF5+PkbSFTXLTGy7+5qkfpJOlPRvSXdJukXSLq2o3aw9DnMzW5zsA9xA+vCQZnwPGApsFBEbAbsDy3ZTbWYLzWFuZosFSQOBbUmfc99hmOdPS/s88JWIeA0gIp6KiD90a6FmC8FhbmaLiz2AK/NH4z4vabMOll8LeLS0G27Y4slhbmaLi31I97Mmf9+Hxnfp80djWlH82exm1utJehfpFpcbSQrS53QHcDawfM3iKwDPku4ZsKqkZSNidk/Wa9ZZ7pmb2eJgL+DsiFgt32VtFeAhUnAPk7Q+gKTVSLcHnRYRLwO/BU7Od9xC0lBJn2nNLpg15jA3s8XBPsAlNdMuIl0I9xngLEnTSLdR/VxEzMrLfAd4BrhH0l3Apfm52SLFd00zMzMrnHvmZmZmhXOYm5mZFc5hbmZmVjiHuZmZWeEc5mZmZoVzmJuZmRXOYW5mZla4/w/7CZeir2EzDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x1872 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a bar graph to show the mean and standard deviation of the performance metrics of neural networks with different architectures\n",
    "x_labels = ['Wide neural network',\n",
    "            'Deep neural network',\n",
    "            'Intermediate neural network',\n",
    "            'Dummy classifier']\n",
    "n_bars = len(mean_scores_table.iloc[0,:-1])\n",
    "xval = np.arange(n_bars)\n",
    "ax = plt.figure(figsize = (6,26))\n",
    "for k in range(len(mean_scores_table)):\n",
    "   ax = plt.subplot(5,1,k+1)\n",
    "   for j in xval:\n",
    "      plt.barh([j], mean_scores_table.iloc[k,j], xerr=std_scores_table.iloc[k,j], alpha=0.6, align='center')\n",
    "   plt.title('%s for MLP models with different architectures'%mean_scores_table.index[k])\n",
    "   plt.xlabel('%s'%mean_scores_table.index[k])\n",
    "   ax.set_yticks(xval)\n",
    "   ax.invert_yaxis()\n",
    "   ax.set_yticklabels(x_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both cross-validated wide (containing one hidden layer with 9 neurons) and intermediate (containing two hidden layers each with 6 neurons) MLP models showed relatively high AUC score, accuracy, recall, precision and F1 score and low standard deviations. The intermediate MLP model showed more consistency in the predictions for the five validation folds than the wide MLP model, as reflected by the smaller standard deviations.\n",
    "\n",
    "The cross-validated deep MLP model (containing four hidden layers each with 4 neurons) showed the lowest AUC score, accuracy, recall, precicion and F1 score and highest standard deviations amongst the MLP models, indicating the deep MLP model was overfitted.\n",
    "\n",
    "The dummy classifier yielded the lowest AUC score, accuracy, recall, precision and F1 score and standard deviations.\n",
    "\n",
    "I will use one or two hidden layers in my MLP model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare between neural networks consisting of one or two hidden layers and either 3, 6, 9 or 12 neurons in each hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performances of MLP models consisting of one or two hidden layers and either 3, 6, 9 or 12 neurons in each hidden layer in terms of accuracy, precision, recall, F1 score and AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in this section is adapted based on https://towardsdatascience.com/\n",
    "#   machine-learning-classifiers-comparison-with-python-33149aecdbca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network that has only one hidden layer \n",
    "\n",
    "# Set number of neurons in the hidden layer equal to 3\n",
    "hidden_size = 3\n",
    "\n",
    "class Wide3NetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dim=hidden_size,\n",
    "            dropout = 0.2 # Apply mild dropout for regularization\n",
    "    ):\n",
    "        super(Wide3NetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden = nn.Linear(X.shape[1], hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X),dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network that has only one hidden layer \n",
    "\n",
    "# Set number of neurons in the hidden layer equal to 6\n",
    "hidden_size = 6\n",
    "\n",
    "class Wide6NetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dim=hidden_size,\n",
    "            dropout = 0.2 # Apply mild dropout for regularization\n",
    "    ):\n",
    "        super(Wide6NetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden = nn.Linear(X.shape[1], hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X),dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network that has only one hidden layer\n",
    "\n",
    "# Set number of neurons in the hidden layer equal to 9\n",
    "hidden_size = 9\n",
    "\n",
    "class Wide9NetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dim=hidden_size,\n",
    "            dropout = 0.2 # Apply mild dropout for regularization\n",
    "    ):\n",
    "        super(Wide9NetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden = nn.Linear(X.shape[1], hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X),dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network that has only one hidden layer \n",
    "\n",
    "# Set number of neurons in the hidden layer equal to 12\n",
    "hidden_size = 12\n",
    "\n",
    "class Wide12NetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dim=hidden_size,\n",
    "            dropout = 0.2 # Apply mild dropout for regularization\n",
    "    ):\n",
    "        super(Wide12NetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden = nn.Linear(X.shape[1], hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X),dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network that has only two hidden layers \n",
    "\n",
    "# Set number of neurons in each hidden layer equal to 3\n",
    "hidden_sizeA = 3\n",
    "hidden_sizeB = 3\n",
    "\n",
    "class Intermediate3NetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dimA=hidden_sizeA,\n",
    "            hidden_dimB=hidden_sizeB,\n",
    "            dropout = 0.2 # Apply mild dropout for regularization\n",
    "    ):\n",
    "        super(Intermediate3NetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hiddenA = nn.Linear(X.shape[1], hidden_sizeA)\n",
    "        self.hiddenB = nn.Linear(hidden_sizeA, hidden_sizeB)\n",
    "        self.output = nn.Linear(hidden_sizeB, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.hiddenA(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.relu(self.hiddenB(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X),dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network that has only two hidden layers \n",
    "\n",
    "# Set number of neurons in each hidden layer equal to 6\n",
    "hidden_sizeA = 6\n",
    "hidden_sizeB = 6\n",
    "\n",
    "class Intermediate6NetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dimA=hidden_sizeA,\n",
    "            hidden_dimB=hidden_sizeB,\n",
    "            dropout = 0.2 # Apply mild dropout for regularization\n",
    "    ):\n",
    "        super(Intermediate6NetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hiddenA = nn.Linear(X.shape[1], hidden_dimA)\n",
    "        self.hiddenB = nn.Linear(hidden_dimA, hidden_dimB)\n",
    "        self.output = nn.Linear(hidden_dimB, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.hiddenA(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.relu(self.hiddenB(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X),dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network that has two hidden layers \n",
    "\n",
    "# Set number of neurons in each hidden layer equal to 9\n",
    "hidden_sizeA = 9\n",
    "hidden_sizeB = 9\n",
    "\n",
    "class Intermediate9NetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dimA=hidden_sizeA,\n",
    "            hidden_dimB=hidden_sizeB,\n",
    "            dropout=0.2 # Apply mild dropout for regularization\n",
    "    ):\n",
    "        super(Intermediate9NetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hiddenA = nn.Linear(X.shape[1], hidden_dimA)\n",
    "        self.hiddenB = nn.Linear(hidden_dimA, hidden_dimB)\n",
    "        self.output = nn.Linear(hidden_dimB, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.hiddenA(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.relu(self.hiddenB(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network that has two hidden layers \n",
    "\n",
    "# Set number of neurons in each hidden layer equal to 12\n",
    "hidden_sizeA = 12\n",
    "hidden_sizeB = 12\n",
    "\n",
    "class Intermediate12NetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_dimA=hidden_sizeA,\n",
    "            hidden_dimB=hidden_sizeB,\n",
    "            dropout=0.2 # Apply mild dropout for regularization\n",
    "    ):\n",
    "        super(Intermediate12NetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hiddenA = nn.Linear(X.shape[1], hidden_dimA)\n",
    "        self.hiddenB = nn.Linear(hidden_dimA, hidden_dimB)\n",
    "        self.output = nn.Linear(hidden_dimB, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.hiddenA(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.relu(self.hiddenB(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X),dim=-1)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters for each neural network\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "wide3Net = NeuralNetClassifier(module=Wide3NetModule,\n",
    "                                    lr = 0.1,\n",
    "                                    max_epochs=100, \n",
    "                                    callbacks=[EarlyStopping()], # To avoid overfitting\n",
    "                                    device=device, # Set device to 'cpu'\n",
    "                                    iterator_train__shuffle=True, \n",
    "                                    optimizer = torch.optim.SGD, \n",
    "                                    batch_size = 32) \n",
    "                            \n",
    "wide6Net = NeuralNetClassifier(module=Wide6NetModule, \n",
    "                                    lr = 0.1, \n",
    "                                    max_epochs=100, \n",
    "                                    callbacks=[EarlyStopping()], # To avoid overfitting\n",
    "                                    device=device, # Set device to 'cpu'\n",
    "                                    iterator_train__shuffle=True, \n",
    "                                    optimizer = torch.optim.SGD,\n",
    "                                    batch_size = 32) \n",
    "                                \n",
    "wide9Net = NeuralNetClassifier(module=Wide9NetModule,\n",
    "                                    lr = 0.1, \n",
    "                                    max_epochs=100, \n",
    "                                    callbacks=[EarlyStopping()], # To avoid overfitting\n",
    "                                    device=device, # Set device to 'cpu'\n",
    "                                    iterator_train__shuffle=True, \n",
    "                                    optimizer = torch.optim.SGD, \n",
    "                                    batch_size = 32) \n",
    "\n",
    "wide12Net = NeuralNetClassifier(module=Wide12NetModule,\n",
    "                                    lr = 0.1, \n",
    "                                    max_epochs=100, \n",
    "                                    callbacks=[EarlyStopping()], # To avoid overfitting\n",
    "                                    device=device, # Set device to 'cpu'\n",
    "                                    iterator_train__shuffle=True, \n",
    "                                    optimizer = torch.optim.SGD,\n",
    "                                    batch_size = 32) \n",
    "\n",
    "intermediate3Net = NeuralNetClassifier(module=Intermediate3NetModule, \n",
    "                                    lr = 0.1,\n",
    "                                    max_epochs=100, \n",
    "                                    callbacks=[EarlyStopping()], # To avoid overfitting\n",
    "                                    device=device, # Set device to 'cpu'\n",
    "                                    iterator_train__shuffle=True,\n",
    "                                    optimizer = torch.optim.SGD, \n",
    "                                    batch_size = 32) \n",
    "\n",
    "intermediate6Net = NeuralNetClassifier(module=Intermediate6NetModule,\n",
    "                                    lr = 0.1, \n",
    "                                    max_epochs=100, \n",
    "                                    callbacks=[EarlyStopping()], # To avoid overfitting\n",
    "                                    device=device, # Set device to 'cpu'\n",
    "                                    iterator_train__shuffle=True, \n",
    "                                    optimizer = torch.optim.SGD, \n",
    "                                    batch_size = 32) \n",
    "\n",
    "intermediate9Net = NeuralNetClassifier(module=Intermediate9NetModule,\n",
    "                                    lr = 0.1, \n",
    "                                    max_epochs=100, \n",
    "                                    callbacks=[EarlyStopping()], # To avoid overfitting\n",
    "                                    device=device, # Set device to 'cpu'\n",
    "                                    iterator_train__shuffle=True, \n",
    "                                    optimizer = torch.optim.SGD, \n",
    "                                    batch_size = 32) \n",
    "\n",
    "intermediate12Net = NeuralNetClassifier(module=Intermediate12NetModule,\n",
    "                                    lr = 0.1, \n",
    "                                    max_epochs=100, \n",
    "                                    callbacks=[EarlyStopping()], # To avoid overfitting\n",
    "                                    device=device, # Set device to 'cpu'\n",
    "                                    iterator_train__shuffle=True, \n",
    "                                    optimizer = torch.optim.SGD, \n",
    "                                    batch_size = 32) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6606\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5879\u001b[0m  0.0192\n",
      "      2        \u001b[36m0.5915\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.5116\u001b[0m  0.0176\n",
      "      3        \u001b[36m0.5627\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4737\u001b[0m  0.0182\n",
      "      4        \u001b[36m0.5460\u001b[0m       0.8125        \u001b[35m0.4531\u001b[0m  0.0205\n",
      "      5        \u001b[36m0.5411\u001b[0m       0.8125        \u001b[35m0.4421\u001b[0m  0.0237\n",
      "      6        \u001b[36m0.5277\u001b[0m       0.7891        \u001b[35m0.4371\u001b[0m  0.0309\n",
      "      7        \u001b[36m0.5198\u001b[0m       0.8125        \u001b[35m0.4295\u001b[0m  0.0211\n",
      "      8        0.5229       0.8047        \u001b[35m0.4247\u001b[0m  0.0362\n",
      "      9        0.5297       0.7969        \u001b[35m0.4225\u001b[0m  0.0207\n",
      "     10        0.5280       0.7969        0.4226  0.0309\n",
      "     11        0.5233       0.7891        \u001b[35m0.4195\u001b[0m  0.0299\n",
      "     12        \u001b[36m0.5184\u001b[0m       0.8047        0.4205  0.0295\n",
      "     13        \u001b[36m0.5125\u001b[0m       0.7969        \u001b[35m0.4177\u001b[0m  0.0301\n",
      "     14        \u001b[36m0.5079\u001b[0m       0.7969        \u001b[35m0.4133\u001b[0m  0.0336\n",
      "     15        \u001b[36m0.5017\u001b[0m       0.7891        0.4137  0.0254\n",
      "     16        0.5055       0.7891        \u001b[35m0.4115\u001b[0m  0.0256\n",
      "     17        0.5023       0.7969        0.4116  0.0236\n",
      "     18        \u001b[36m0.4990\u001b[0m       0.8047        \u001b[35m0.4087\u001b[0m  0.0302\n",
      "     19        \u001b[36m0.4915\u001b[0m       0.7969        0.4105  0.0241\n",
      "     20        0.5085       0.8047        \u001b[35m0.4077\u001b[0m  0.0318\n",
      "     21        \u001b[36m0.4872\u001b[0m       0.7891        \u001b[35m0.4062\u001b[0m  0.0436\n",
      "     22        0.5007       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4043\u001b[0m  0.0588\n",
      "     23        0.5028       0.8047        \u001b[35m0.4031\u001b[0m  0.0631\n",
      "     24        0.4990       \u001b[32m0.8281\u001b[0m        \u001b[35m0.4026\u001b[0m  0.0441\n",
      "     25        0.4968       0.8281        0.4031  0.0210\n",
      "     26        0.4953       0.8047        0.4091  0.0488\n",
      "     27        0.4933       0.8125        0.4057  0.0445\n",
      "     28        0.5073       0.8125        0.4056  0.0259\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6690\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6229\u001b[0m  0.0378\n",
      "      2        \u001b[36m0.6023\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5838\u001b[0m  0.0249\n",
      "      3        \u001b[36m0.5864\u001b[0m       0.7188        \u001b[35m0.5649\u001b[0m  0.0300\n",
      "      4        \u001b[36m0.5479\u001b[0m       0.7266        \u001b[35m0.5512\u001b[0m  0.0676\n",
      "      5        \u001b[36m0.5315\u001b[0m       0.7188        \u001b[35m0.5436\u001b[0m  0.0790\n",
      "      6        0.5403       0.7109        \u001b[35m0.5392\u001b[0m  0.0674\n",
      "      7        \u001b[36m0.5261\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5353\u001b[0m  0.0544\n",
      "      8        \u001b[36m0.5184\u001b[0m       0.7266        0.5355  0.0317\n",
      "      9        \u001b[36m0.5013\u001b[0m       0.7031        \u001b[35m0.5335\u001b[0m  0.0329\n",
      "     10        0.5120       0.7031        \u001b[35m0.5322\u001b[0m  0.0238\n",
      "     11        0.5064       0.6953        \u001b[35m0.5310\u001b[0m  0.0294\n",
      "     12        \u001b[36m0.4901\u001b[0m       0.6875        \u001b[35m0.5307\u001b[0m  0.0245\n",
      "     13        \u001b[36m0.4871\u001b[0m       0.6953        0.5327  0.0252\n",
      "     14        0.4929       0.6953        0.5312  0.0213\n",
      "     15        0.5000       0.6953        \u001b[35m0.5301\u001b[0m  0.0231\n",
      "     16        \u001b[36m0.4853\u001b[0m       0.6953        0.5304  0.0232\n",
      "     17        0.4927       0.6953        \u001b[35m0.5300\u001b[0m  0.0207\n",
      "     18        0.4962       0.6953        \u001b[35m0.5290\u001b[0m  0.0202\n",
      "     19        \u001b[36m0.4814\u001b[0m       0.6953        0.5304  0.0263\n",
      "     20        0.4875       0.7109        0.5306  0.0298\n",
      "     21        \u001b[36m0.4789\u001b[0m       0.7109        0.5311  0.0325\n",
      "     22        \u001b[36m0.4770\u001b[0m       0.7109        0.5311  0.0529\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6552\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6415\u001b[0m  0.0537\n",
      "      2        \u001b[36m0.5876\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6029\u001b[0m  0.0308\n",
      "      3        \u001b[36m0.5591\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5824\u001b[0m  0.0305\n",
      "      4        \u001b[36m0.5452\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5701\u001b[0m  0.0307\n",
      "      5        \u001b[36m0.5188\u001b[0m       0.7031        \u001b[35m0.5638\u001b[0m  0.0226\n",
      "      6        \u001b[36m0.5080\u001b[0m       0.6875        \u001b[35m0.5576\u001b[0m  0.0185\n",
      "      7        0.5118       0.6797        \u001b[35m0.5538\u001b[0m  0.0263\n",
      "      8        \u001b[36m0.5019\u001b[0m       0.6797        \u001b[35m0.5510\u001b[0m  0.0211\n",
      "      9        \u001b[36m0.4892\u001b[0m       0.6797        \u001b[35m0.5507\u001b[0m  0.0223\n",
      "     10        \u001b[36m0.4835\u001b[0m       0.6797        \u001b[35m0.5484\u001b[0m  0.0179\n",
      "     11        \u001b[36m0.4807\u001b[0m       0.6875        \u001b[35m0.5454\u001b[0m  0.0249\n",
      "     12        0.4841       0.6953        \u001b[35m0.5435\u001b[0m  0.0262\n",
      "     13        0.4849       0.6875        \u001b[35m0.5393\u001b[0m  0.0267\n",
      "     14        0.4808       0.6875        \u001b[35m0.5371\u001b[0m  0.0254\n",
      "     15        0.4862       0.6797        \u001b[35m0.5365\u001b[0m  0.0203\n",
      "     16        \u001b[36m0.4730\u001b[0m       0.6875        \u001b[35m0.5355\u001b[0m  0.0195\n",
      "     17        0.4811       0.6953        \u001b[35m0.5350\u001b[0m  0.0252\n",
      "     18        0.4820       0.6953        \u001b[35m0.5343\u001b[0m  0.0223\n",
      "     19        0.4887       0.6953        \u001b[35m0.5328\u001b[0m  0.0215\n",
      "     20        0.4818       0.6953        \u001b[35m0.5312\u001b[0m  0.0245\n",
      "     21        0.4787       0.7109        \u001b[35m0.5305\u001b[0m  0.0602\n",
      "     22        \u001b[36m0.4682\u001b[0m       0.6875        0.5311  0.0529\n",
      "     23        \u001b[36m0.4599\u001b[0m       0.7109        \u001b[35m0.5302\u001b[0m  0.0322\n",
      "     24        0.4683       0.7031        \u001b[35m0.5296\u001b[0m  0.0237\n",
      "     25        0.4699       0.7109        0.5302  0.0271\n",
      "     26        0.4654       0.7109        0.5297  0.0489\n",
      "     27        0.4654       0.7109        0.5300  0.0457\n",
      "     28        0.4708       0.7109        \u001b[35m0.5295\u001b[0m  0.0341\n",
      "     29        0.4699       0.7109        0.5311  0.0677\n",
      "     30        0.4672       0.7031        0.5320  0.0549\n",
      "     31        0.4775       0.7031        0.5322  0.0410\n",
      "     32        0.4620       0.7266        0.5328  0.0347\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6927\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6488\u001b[0m  0.0272\n",
      "      2        \u001b[36m0.6168\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5937\u001b[0m  0.0255\n",
      "      3        \u001b[36m0.5594\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5555\u001b[0m  0.0200\n",
      "      4        \u001b[36m0.5234\u001b[0m       0.7344        \u001b[35m0.5377\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.5225\u001b[0m       0.7266        \u001b[35m0.5293\u001b[0m  0.0267\n",
      "      6        \u001b[36m0.5109\u001b[0m       0.7266        \u001b[35m0.5263\u001b[0m  0.0186\n",
      "      7        \u001b[36m0.4907\u001b[0m       0.7266        \u001b[35m0.5230\u001b[0m  0.0238\n",
      "      8        0.5093       0.7188        \u001b[35m0.5216\u001b[0m  0.0288\n",
      "      9        \u001b[36m0.4820\u001b[0m       0.7266        \u001b[35m0.5210\u001b[0m  0.0449\n",
      "     10        \u001b[36m0.4813\u001b[0m       0.7266        \u001b[35m0.5200\u001b[0m  0.0277\n",
      "     11        \u001b[36m0.4751\u001b[0m       0.7266        \u001b[35m0.5189\u001b[0m  0.0223\n",
      "     12        0.4845       0.7266        \u001b[35m0.5181\u001b[0m  0.0249\n",
      "     13        0.4783       0.7344        0.5182  0.0166\n",
      "     14        \u001b[36m0.4731\u001b[0m       0.7266        0.5203  0.0175\n",
      "     15        0.4776       0.7344        0.5202  0.0170\n",
      "     16        \u001b[36m0.4551\u001b[0m       0.7344        0.5189  0.0197\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7023\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6461\u001b[0m  0.0555\n",
      "      2        \u001b[36m0.6050\u001b[0m       0.6797        \u001b[35m0.5909\u001b[0m  0.1681\n",
      "      3        \u001b[36m0.5545\u001b[0m       0.6953        \u001b[35m0.5593\u001b[0m  0.0725\n",
      "      4        \u001b[36m0.5358\u001b[0m       0.7188        \u001b[35m0.5437\u001b[0m  0.0428\n",
      "      5        \u001b[36m0.5267\u001b[0m       0.7109        \u001b[35m0.5388\u001b[0m  0.0285\n",
      "      6        \u001b[36m0.5085\u001b[0m       0.7188        \u001b[35m0.5372\u001b[0m  0.0844\n",
      "      7        \u001b[36m0.4986\u001b[0m       0.7188        0.5405  0.0320\n",
      "      8        \u001b[36m0.4821\u001b[0m       0.7109        0.5414  0.0378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9        0.4880       0.7188        0.5416  0.0331\n",
      "     10        0.4833       0.7188        0.5432  0.0684\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6924\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6419\u001b[0m  0.0577\n",
      "      2        \u001b[36m0.6326\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5875\u001b[0m  0.0583\n",
      "      3        \u001b[36m0.6160\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5526\u001b[0m  0.0258\n",
      "      4        \u001b[36m0.5996\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.5272\u001b[0m  0.0308\n",
      "      5        \u001b[36m0.5675\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.5016\u001b[0m  0.0308\n",
      "      6        \u001b[36m0.5648\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4831\u001b[0m  0.0292\n",
      "      7        \u001b[36m0.5496\u001b[0m       0.8047        \u001b[35m0.4668\u001b[0m  0.0294\n",
      "      8        0.5504       0.8047        \u001b[35m0.4566\u001b[0m  0.0295\n",
      "      9        \u001b[36m0.5371\u001b[0m       0.8047        \u001b[35m0.4445\u001b[0m  0.0233\n",
      "     10        0.5376       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4351\u001b[0m  0.0280\n",
      "     11        0.5479       \u001b[32m0.8281\u001b[0m        \u001b[35m0.4314\u001b[0m  0.0280\n",
      "     12        \u001b[36m0.5324\u001b[0m       0.8125        \u001b[35m0.4257\u001b[0m  0.0258\n",
      "     13        \u001b[36m0.5306\u001b[0m       0.8125        \u001b[35m0.4199\u001b[0m  0.0309\n",
      "     14        0.5321       0.8125        \u001b[35m0.4161\u001b[0m  0.0273\n",
      "     15        0.5372       0.8047        \u001b[35m0.4156\u001b[0m  0.0247\n",
      "     16        \u001b[36m0.5295\u001b[0m       0.8125        \u001b[35m0.4120\u001b[0m  0.0244\n",
      "     17        \u001b[36m0.5248\u001b[0m       0.8203        \u001b[35m0.4092\u001b[0m  0.0265\n",
      "     18        \u001b[36m0.5165\u001b[0m       0.8125        \u001b[35m0.4064\u001b[0m  0.0283\n",
      "     19        0.5255       0.8203        0.4078  0.0283\n",
      "     20        \u001b[36m0.5094\u001b[0m       0.8203        \u001b[35m0.4053\u001b[0m  0.0379\n",
      "     21        0.5414       0.8203        0.4065  0.0481\n",
      "     22        0.5258       0.8203        0.4084  0.0535\n",
      "     23        0.5175       0.8281        0.4068  0.1311\n",
      "     24        \u001b[36m0.5056\u001b[0m       \u001b[32m0.8359\u001b[0m        \u001b[35m0.4042\u001b[0m  0.0527\n",
      "     25        0.5269       0.8281        0.4068  0.0642\n",
      "     26        0.5284       0.8203        0.4112  0.0487\n",
      "     27        0.5099       0.8359        0.4085  0.0317\n",
      "     28        0.5161       0.8281        0.4078  0.0442\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6893\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6533\u001b[0m  0.0276\n",
      "      2        \u001b[36m0.6337\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6053\u001b[0m  0.0216\n",
      "      3        \u001b[36m0.5951\u001b[0m       0.7188        \u001b[35m0.5735\u001b[0m  0.0295\n",
      "      4        \u001b[36m0.5501\u001b[0m       0.7266        \u001b[35m0.5548\u001b[0m  0.0237\n",
      "      5        \u001b[36m0.5422\u001b[0m       0.7188        \u001b[35m0.5470\u001b[0m  0.0392\n",
      "      6        \u001b[36m0.5335\u001b[0m       0.7031        \u001b[35m0.5425\u001b[0m  0.0680\n",
      "      7        \u001b[36m0.5280\u001b[0m       0.7031        \u001b[35m0.5396\u001b[0m  0.0399\n",
      "      8        \u001b[36m0.5165\u001b[0m       0.6953        \u001b[35m0.5379\u001b[0m  0.0572\n",
      "      9        \u001b[36m0.5112\u001b[0m       0.6953        \u001b[35m0.5373\u001b[0m  0.0888\n",
      "     10        0.5177       0.6953        0.5403  0.0446\n",
      "     11        0.5118       0.6953        0.5430  0.0309\n",
      "     12        \u001b[36m0.4989\u001b[0m       0.6953        0.5403  0.0261\n",
      "     13        0.5183       0.6953        0.5393  0.0299\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6616\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6286\u001b[0m  0.0212\n",
      "      2        \u001b[36m0.5817\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.5865\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.5587\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5682\u001b[0m  0.0322\n",
      "      4        \u001b[36m0.5386\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5568\u001b[0m  0.0328\n",
      "      5        \u001b[36m0.5129\u001b[0m       0.6875        \u001b[35m0.5538\u001b[0m  0.0259\n",
      "      6        0.5148       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5530\u001b[0m  0.0302\n",
      "      7        \u001b[36m0.5116\u001b[0m       0.7031        \u001b[35m0.5510\u001b[0m  0.0275\n",
      "      8        \u001b[36m0.5018\u001b[0m       0.7031        0.5517  0.0274\n",
      "      9        \u001b[36m0.4937\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5509\u001b[0m  0.0315\n",
      "     10        0.5166       0.7109        \u001b[35m0.5477\u001b[0m  0.0307\n",
      "     11        0.5027       0.7109        \u001b[35m0.5443\u001b[0m  0.0283\n",
      "     12        0.5213       \u001b[32m0.7188\u001b[0m        0.5450  0.0220\n",
      "     13        0.5187       0.7188        \u001b[35m0.5437\u001b[0m  0.0202\n",
      "     14        0.4948       0.7188        0.5440  0.0214\n",
      "     15        0.4981       0.7109        \u001b[35m0.5427\u001b[0m  0.0342\n",
      "     16        0.4953       0.7188        \u001b[35m0.5407\u001b[0m  0.0174\n",
      "     17        0.4992       0.7109        \u001b[35m0.5402\u001b[0m  0.0237\n",
      "     18        0.4969       0.7188        \u001b[35m0.5398\u001b[0m  0.0171\n",
      "     19        0.4986       0.7188        \u001b[35m0.5382\u001b[0m  0.0228\n",
      "     20        \u001b[36m0.4834\u001b[0m       0.7188        0.5406  0.0173\n",
      "     21        \u001b[36m0.4718\u001b[0m       0.7188        0.5414  0.0171\n",
      "     22        0.4771       0.7109        0.5411  0.0171\n",
      "     23        0.4821       0.7188        0.5421  0.0180\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6491\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6034\u001b[0m  0.0295\n",
      "      2        \u001b[36m0.5689\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5632\u001b[0m  0.0250\n",
      "      3        \u001b[36m0.5537\u001b[0m       0.7031        \u001b[35m0.5475\u001b[0m  0.0280\n",
      "      4        \u001b[36m0.5263\u001b[0m       0.7031        \u001b[35m0.5381\u001b[0m  0.0202\n",
      "      5        0.5292       0.6875        \u001b[35m0.5352\u001b[0m  0.0278\n",
      "      6        \u001b[36m0.4986\u001b[0m       0.6875        \u001b[35m0.5336\u001b[0m  0.0288\n",
      "      7        0.4999       0.6797        \u001b[35m0.5330\u001b[0m  0.0175\n",
      "      8        0.5049       0.6875        0.5340  0.0176\n",
      "      9        \u001b[36m0.4849\u001b[0m       0.6797        0.5340  0.0188\n",
      "     10        0.4992       0.6797        \u001b[35m0.5328\u001b[0m  0.0265\n",
      "     11        \u001b[36m0.4739\u001b[0m       0.6797        0.5329  0.0209\n",
      "     12        0.4772       0.6953        0.5336  0.0289\n",
      "     13        0.4773       0.6953        0.5342  0.0292\n",
      "     14        0.4758       0.6953        0.5333  0.0227\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7111\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6857\u001b[0m  0.0220\n",
      "      2        \u001b[36m0.6673\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6483\u001b[0m  0.0247\n",
      "      3        \u001b[36m0.6272\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6088\u001b[0m  0.0264\n",
      "      4        \u001b[36m0.5844\u001b[0m       0.6953        \u001b[35m0.5748\u001b[0m  0.0173\n",
      "      5        \u001b[36m0.5439\u001b[0m       0.6797        \u001b[35m0.5542\u001b[0m  0.0230\n",
      "      6        \u001b[36m0.5283\u001b[0m       0.6797        \u001b[35m0.5436\u001b[0m  0.0281\n",
      "      7        \u001b[36m0.5213\u001b[0m       0.6797        \u001b[35m0.5368\u001b[0m  0.0290\n",
      "      8        \u001b[36m0.5120\u001b[0m       0.6719        0.5375  0.0341\n",
      "      9        \u001b[36m0.4873\u001b[0m       0.6641        \u001b[35m0.5356\u001b[0m  0.0478\n",
      "     10        0.5038       0.6719        \u001b[35m0.5336\u001b[0m  0.0363\n",
      "     11        0.5167       0.6797        \u001b[35m0.5314\u001b[0m  0.0424\n",
      "     12        0.4889       0.6953        \u001b[35m0.5296\u001b[0m  0.0536\n",
      "     13        0.4944       \u001b[32m0.7031\u001b[0m        0.5298  0.0471\n",
      "     14        \u001b[36m0.4863\u001b[0m       0.7031        \u001b[35m0.5275\u001b[0m  0.0180\n",
      "     15        0.4890       \u001b[32m0.7109\u001b[0m        0.5281  0.0304\n",
      "     16        0.4936       0.7031        0.5278  0.0334\n",
      "     17        \u001b[36m0.4598\u001b[0m       \u001b[32m0.7266\u001b[0m        0.5292  0.0196\n",
      "     18        0.4826       0.7266        0.5321  0.0180\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6319\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6003\u001b[0m  0.0454\n",
      "      2        \u001b[36m0.6185\u001b[0m       0.7188        \u001b[35m0.5699\u001b[0m  0.0409\n",
      "      3        \u001b[36m0.6098\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5489\u001b[0m  0.0376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        \u001b[36m0.5881\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5260\u001b[0m  0.0303\n",
      "      5        0.5894       0.7422        \u001b[35m0.5106\u001b[0m  0.0254\n",
      "      6        \u001b[36m0.5850\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4955\u001b[0m  0.0260\n",
      "      7        \u001b[36m0.5694\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4844\u001b[0m  0.0267\n",
      "      8        \u001b[36m0.5591\u001b[0m       0.7812        \u001b[35m0.4737\u001b[0m  0.0236\n",
      "      9        \u001b[36m0.5578\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4642\u001b[0m  0.0269\n",
      "     10        \u001b[36m0.5554\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4557\u001b[0m  0.0199\n",
      "     11        \u001b[36m0.5509\u001b[0m       0.8047        \u001b[35m0.4457\u001b[0m  0.0243\n",
      "     12        0.5548       0.8125        \u001b[35m0.4393\u001b[0m  0.0461\n",
      "     13        \u001b[36m0.5412\u001b[0m       0.8047        \u001b[35m0.4367\u001b[0m  0.0552\n",
      "     14        \u001b[36m0.5371\u001b[0m       0.7969        0.4370  0.0658\n",
      "     15        \u001b[36m0.5286\u001b[0m       0.8125        \u001b[35m0.4337\u001b[0m  0.0273\n",
      "     16        \u001b[36m0.5263\u001b[0m       0.8125        \u001b[35m0.4293\u001b[0m  0.0388\n",
      "     17        \u001b[36m0.5195\u001b[0m       0.8125        \u001b[35m0.4261\u001b[0m  0.0246\n",
      "     18        \u001b[36m0.5186\u001b[0m       0.8047        \u001b[35m0.4227\u001b[0m  0.0256\n",
      "     19        \u001b[36m0.5043\u001b[0m       0.7969        \u001b[35m0.4155\u001b[0m  0.0226\n",
      "     20        0.5258       0.7969        0.4174  0.0215\n",
      "     21        0.5174       0.8047        \u001b[35m0.4138\u001b[0m  0.0268\n",
      "     22        0.5180       0.8047        0.4154  0.0232\n",
      "     23        0.5074       0.7969        \u001b[35m0.4118\u001b[0m  0.0288\n",
      "     24        \u001b[36m0.5033\u001b[0m       0.7969        \u001b[35m0.4106\u001b[0m  0.0300\n",
      "     25        0.5146       0.8047        \u001b[35m0.4105\u001b[0m  0.0253\n",
      "     26        0.5046       0.8125        \u001b[35m0.4062\u001b[0m  0.0571\n",
      "     27        0.5114       0.8125        0.4062  0.0412\n",
      "     28        \u001b[36m0.4997\u001b[0m       0.8047        \u001b[35m0.4054\u001b[0m  0.0704\n",
      "     29        0.5159       0.8047        0.4075  0.0492\n",
      "     30        \u001b[36m0.4997\u001b[0m       0.8125        0.4055  0.0774\n",
      "     31        0.5037       0.8125        0.4056  0.0293\n",
      "     32        \u001b[36m0.4942\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4023\u001b[0m  0.0425\n",
      "     33        0.4998       0.8047        \u001b[35m0.4013\u001b[0m  0.0256\n",
      "     34        0.5080       0.8125        \u001b[35m0.3998\u001b[0m  0.0261\n",
      "     35        \u001b[36m0.4898\u001b[0m       \u001b[32m0.8359\u001b[0m        0.4001  0.0262\n",
      "     36        0.5094       0.8281        0.4003  0.0251\n",
      "     37        0.5022       0.8203        0.4027  0.0263\n",
      "     38        0.5005       0.8125        0.4001  0.0240\n",
      "     39        0.4932       0.8125        \u001b[35m0.3961\u001b[0m  0.0291\n",
      "     40        0.4929       0.8203        0.3972  0.0250\n",
      "     41        0.5007       0.8203        \u001b[35m0.3957\u001b[0m  0.0229\n",
      "     42        0.4913       0.8203        0.3958  0.0228\n",
      "     43        \u001b[36m0.4861\u001b[0m       0.8125        0.3970  0.0219\n",
      "     44        0.4905       0.8203        0.3966  0.0244\n",
      "     45        0.4930       0.8203        \u001b[35m0.3939\u001b[0m  0.0221\n",
      "     46        \u001b[36m0.4849\u001b[0m       0.8203        \u001b[35m0.3926\u001b[0m  0.0199\n",
      "     47        0.4865       0.8203        0.3928  0.0283\n",
      "     48        0.4978       0.8125        0.3944  0.0200\n",
      "     49        0.4915       0.8125        0.3961  0.0226\n",
      "     50        0.4932       0.8125        0.3962  0.0246\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7185\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6436\u001b[0m  0.0178\n",
      "      2        \u001b[36m0.6174\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5854\u001b[0m  0.0199\n",
      "      3        \u001b[36m0.5798\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5610\u001b[0m  0.0336\n",
      "      4        \u001b[36m0.5517\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5520\u001b[0m  0.0225\n",
      "      5        \u001b[36m0.5476\u001b[0m       0.7266        \u001b[35m0.5488\u001b[0m  0.0205\n",
      "      6        \u001b[36m0.5425\u001b[0m       0.7109        \u001b[35m0.5464\u001b[0m  0.0202\n",
      "      7        0.5437       0.7266        \u001b[35m0.5445\u001b[0m  0.0258\n",
      "      8        \u001b[36m0.5164\u001b[0m       0.7188        0.5448  0.0183\n",
      "      9        0.5176       0.7188        \u001b[35m0.5437\u001b[0m  0.0250\n",
      "     10        \u001b[36m0.4993\u001b[0m       0.7109        \u001b[35m0.5431\u001b[0m  0.0206\n",
      "     11        0.5101       0.7031        \u001b[35m0.5428\u001b[0m  0.0279\n",
      "     12        0.5119       0.6953        0.5430  0.0259\n",
      "     13        0.5146       0.6875        \u001b[35m0.5402\u001b[0m  0.0275\n",
      "     14        0.5158       0.6953        0.5412  0.0198\n",
      "     15        0.5077       0.6875        0.5412  0.0265\n",
      "     16        0.5139       0.6875        0.5416  0.0240\n",
      "     17        0.5221       0.6875        0.5412  0.0300\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7428\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6786\u001b[0m  0.0195\n",
      "      2        \u001b[36m0.6558\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6336\u001b[0m  0.0305\n",
      "      3        \u001b[36m0.6034\u001b[0m       0.6953        \u001b[35m0.5956\u001b[0m  0.0265\n",
      "      4        \u001b[36m0.5584\u001b[0m       0.6953        \u001b[35m0.5724\u001b[0m  0.0214\n",
      "      5        \u001b[36m0.5415\u001b[0m       0.7031        \u001b[35m0.5638\u001b[0m  0.0204\n",
      "      6        \u001b[36m0.5406\u001b[0m       0.7109        \u001b[35m0.5622\u001b[0m  0.0241\n",
      "      7        \u001b[36m0.5255\u001b[0m       0.7109        \u001b[35m0.5581\u001b[0m  0.0202\n",
      "      8        \u001b[36m0.5181\u001b[0m       0.7109        \u001b[35m0.5566\u001b[0m  0.0244\n",
      "      9        0.5211       0.7109        \u001b[35m0.5556\u001b[0m  0.0246\n",
      "     10        \u001b[36m0.5176\u001b[0m       0.7109        \u001b[35m0.5528\u001b[0m  0.0199\n",
      "     11        \u001b[36m0.5083\u001b[0m       0.7109        \u001b[35m0.5528\u001b[0m  0.0232\n",
      "     12        \u001b[36m0.4972\u001b[0m       0.7109        0.5543  0.0219\n",
      "     13        0.5238       0.7109        \u001b[35m0.5496\u001b[0m  0.0275\n",
      "     14        0.5003       0.7109        0.5514  0.0219\n",
      "     15        0.5196       0.7109        0.5519  0.0262\n",
      "     16        \u001b[36m0.4911\u001b[0m       0.7109        \u001b[35m0.5493\u001b[0m  0.0181\n",
      "     17        0.5179       0.7109        \u001b[35m0.5449\u001b[0m  0.0262\n",
      "     18        0.4934       0.7109        \u001b[35m0.5445\u001b[0m  0.0277\n",
      "     19        0.5063       0.7109        \u001b[35m0.5421\u001b[0m  0.0266\n",
      "     20        0.4922       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5418\u001b[0m  0.0208\n",
      "     21        0.4979       0.7188        \u001b[35m0.5417\u001b[0m  0.0199\n",
      "     22        0.4939       0.7188        \u001b[35m0.5414\u001b[0m  0.0225\n",
      "     23        0.4982       0.7188        0.5424  0.0244\n",
      "     24        0.4924       0.7188        \u001b[35m0.5402\u001b[0m  0.0188\n",
      "     25        \u001b[36m0.4824\u001b[0m       \u001b[32m0.7266\u001b[0m        0.5413  0.0247\n",
      "     26        0.4851       0.7266        \u001b[35m0.5397\u001b[0m  0.0253\n",
      "     27        0.4849       \u001b[32m0.7344\u001b[0m        0.5403  0.0256\n",
      "     28        0.4955       0.7188        0.5415  0.0249\n",
      "     29        0.4825       0.7266        0.5407  0.0296\n",
      "     30        \u001b[36m0.4810\u001b[0m       0.7188        0.5402  0.0201\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6679\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6331\u001b[0m  0.0177\n",
      "      2        \u001b[36m0.5996\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5904\u001b[0m  0.0217\n",
      "      3        \u001b[36m0.5703\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5747\u001b[0m  0.0264\n",
      "      4        \u001b[36m0.5504\u001b[0m       0.7188        \u001b[35m0.5680\u001b[0m  0.0261\n",
      "      5        \u001b[36m0.5235\u001b[0m       0.7266        \u001b[35m0.5654\u001b[0m  0.0212\n",
      "      6        0.5373       0.7266        0.5671  0.0233\n",
      "      7        \u001b[36m0.5223\u001b[0m       0.7266        0.5702  0.0250\n",
      "      8        0.5249       0.7266        0.5665  0.0214\n",
      "      9        \u001b[36m0.5076\u001b[0m       \u001b[32m0.7344\u001b[0m        0.5661  0.0199\n",
      "     10        0.5210       0.7188        \u001b[35m0.5646\u001b[0m  0.0248\n",
      "     11        \u001b[36m0.5071\u001b[0m       0.7344        0.5708  0.0262\n",
      "     12        \u001b[36m0.5036\u001b[0m       0.7188        0.5666  0.0300\n",
      "     13        \u001b[36m0.5026\u001b[0m       0.7188        0.5657  0.0200\n",
      "     14        \u001b[36m0.4988\u001b[0m       0.7188        \u001b[35m0.5600\u001b[0m  0.0201\n",
      "     15        \u001b[36m0.4896\u001b[0m       0.7188        \u001b[35m0.5596\u001b[0m  0.0269\n",
      "     16        0.4916       0.7188        \u001b[35m0.5560\u001b[0m  0.0359\n",
      "     17        \u001b[36m0.4735\u001b[0m       0.7109        0.5586  0.0728\n",
      "     18        0.4849       0.7109        0.5605  0.0916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19        0.4859       0.7109        0.5583  0.0479\n",
      "     20        \u001b[36m0.4709\u001b[0m       0.7031        \u001b[35m0.5532\u001b[0m  0.0322\n",
      "     21        0.4763       0.7109        0.5546  0.0361\n",
      "     22        \u001b[36m0.4698\u001b[0m       0.7109        0.5562  0.0691\n",
      "     23        \u001b[36m0.4589\u001b[0m       0.7031        0.5560  0.1002\n",
      "     24        0.4605       0.7109        0.5547  0.0550\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6661\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6403\u001b[0m  0.0158\n",
      "      2        \u001b[36m0.5920\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.5936\u001b[0m  0.0184\n",
      "      3        \u001b[36m0.5503\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5624\u001b[0m  0.0280\n",
      "      4        \u001b[36m0.5150\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5453\u001b[0m  0.0250\n",
      "      5        \u001b[36m0.4993\u001b[0m       0.7031        \u001b[35m0.5353\u001b[0m  0.0251\n",
      "      6        \u001b[36m0.4770\u001b[0m       0.6953        \u001b[35m0.5299\u001b[0m  0.0239\n",
      "      7        \u001b[36m0.4715\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5252\u001b[0m  0.0239\n",
      "      8        \u001b[36m0.4634\u001b[0m       0.7031        \u001b[35m0.5247\u001b[0m  0.0217\n",
      "      9        \u001b[36m0.4607\u001b[0m       0.7031        \u001b[35m0.5246\u001b[0m  0.0212\n",
      "     10        \u001b[36m0.4474\u001b[0m       0.7109        0.5254  0.0203\n",
      "     11        0.4502       0.7109        \u001b[35m0.5244\u001b[0m  0.0219\n",
      "     12        0.4564       0.7109        0.5246  0.0203\n",
      "     13        0.4509       0.7031        0.5283  0.0312\n",
      "     14        \u001b[36m0.4363\u001b[0m       0.7109        0.5299  0.0417\n",
      "     15        0.4461       0.7109        0.5290  0.0530\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6605\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5733\u001b[0m  0.0492\n",
      "      2        \u001b[36m0.5935\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5160\u001b[0m  0.0582\n",
      "      3        \u001b[36m0.5748\u001b[0m       0.7500        \u001b[35m0.4822\u001b[0m  0.0359\n",
      "      4        \u001b[36m0.5735\u001b[0m       0.7656        \u001b[35m0.4671\u001b[0m  0.0193\n",
      "      5        \u001b[36m0.5709\u001b[0m       0.7656        \u001b[35m0.4566\u001b[0m  0.0372\n",
      "      6        \u001b[36m0.5610\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4484\u001b[0m  0.0246\n",
      "      7        \u001b[36m0.5558\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4391\u001b[0m  0.0267\n",
      "      8        \u001b[36m0.5281\u001b[0m       0.7891        \u001b[35m0.4310\u001b[0m  0.0241\n",
      "      9        0.5481       0.7891        \u001b[35m0.4308\u001b[0m  0.0257\n",
      "     10        \u001b[36m0.5176\u001b[0m       0.7891        \u001b[35m0.4221\u001b[0m  0.0283\n",
      "     11        0.5229       0.7969        \u001b[35m0.4182\u001b[0m  0.0236\n",
      "     12        0.5220       0.7969        \u001b[35m0.4144\u001b[0m  0.0246\n",
      "     13        0.5177       0.7969        0.4145  0.0249\n",
      "     14        0.5195       0.7891        \u001b[35m0.4107\u001b[0m  0.0250\n",
      "     15        0.5219       0.7891        \u001b[35m0.4092\u001b[0m  0.0204\n",
      "     16        0.5289       0.7969        0.4107  0.0295\n",
      "     17        0.5276       0.7969        0.4100  0.0202\n",
      "     18        0.5178       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4079\u001b[0m  0.0271\n",
      "     19        \u001b[36m0.5069\u001b[0m       0.7891        \u001b[35m0.4022\u001b[0m  0.0265\n",
      "     20        0.5128       0.8047        0.4026  0.0267\n",
      "     21        0.5093       0.8047        0.4025  0.0366\n",
      "     22        0.5160       0.7891        0.4025  0.0195\n",
      "     23        \u001b[36m0.4955\u001b[0m       0.7969        \u001b[35m0.3995\u001b[0m  0.0253\n",
      "     24        0.5014       0.8047        0.4010  0.0263\n",
      "     25        \u001b[36m0.4948\u001b[0m       0.8047        \u001b[35m0.3985\u001b[0m  0.0273\n",
      "     26        0.4990       0.8047        \u001b[35m0.3977\u001b[0m  0.0188\n",
      "     27        \u001b[36m0.4908\u001b[0m       0.8047        \u001b[35m0.3937\u001b[0m  0.0268\n",
      "     28        0.5009       0.8047        \u001b[35m0.3931\u001b[0m  0.0274\n",
      "     29        \u001b[36m0.4907\u001b[0m       0.8047        0.3934  0.0486\n",
      "     30        \u001b[36m0.4826\u001b[0m       0.8047        \u001b[35m0.3894\u001b[0m  0.0776\n",
      "     31        0.4960       0.8047        0.3933  0.0425\n",
      "     32        0.4979       0.8047        0.3935  0.0475\n",
      "     33        0.4878       0.8125        0.3949  0.0276\n",
      "     34        0.4936       0.8125        0.3969  0.0282\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6779\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6293\u001b[0m  0.0201\n",
      "      2        \u001b[36m0.6213\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5845\u001b[0m  0.0228\n",
      "      3        \u001b[36m0.5794\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5547\u001b[0m  0.0197\n",
      "      4        \u001b[36m0.5576\u001b[0m       0.7266        \u001b[35m0.5405\u001b[0m  0.0258\n",
      "      5        \u001b[36m0.5396\u001b[0m       0.7188        \u001b[35m0.5345\u001b[0m  0.0273\n",
      "      6        \u001b[36m0.5275\u001b[0m       0.7266        \u001b[35m0.5312\u001b[0m  0.0266\n",
      "      7        \u001b[36m0.5207\u001b[0m       0.7266        \u001b[35m0.5305\u001b[0m  0.0538\n",
      "      8        \u001b[36m0.5154\u001b[0m       0.7266        \u001b[35m0.5302\u001b[0m  0.0455\n",
      "      9        0.5158       0.7188        \u001b[35m0.5294\u001b[0m  0.0232\n",
      "     10        \u001b[36m0.5148\u001b[0m       0.7188        \u001b[35m0.5289\u001b[0m  0.0219\n",
      "     11        \u001b[36m0.5043\u001b[0m       0.7031        0.5304  0.0249\n",
      "     12        \u001b[36m0.4900\u001b[0m       0.6953        0.5296  0.0210\n",
      "     13        0.4910       0.6875        0.5297  0.0351\n",
      "     14        \u001b[36m0.4853\u001b[0m       0.6875        0.5290  0.0297\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7231\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6437\u001b[0m  0.0180\n",
      "      2        \u001b[36m0.6157\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5924\u001b[0m  0.0185\n",
      "      3        \u001b[36m0.5855\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5664\u001b[0m  0.0369\n",
      "      4        \u001b[36m0.5616\u001b[0m       0.6953        \u001b[35m0.5527\u001b[0m  0.0271\n",
      "      5        \u001b[36m0.5502\u001b[0m       0.7109        \u001b[35m0.5471\u001b[0m  0.0298\n",
      "      6        \u001b[36m0.5271\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5435\u001b[0m  0.0237\n",
      "      7        \u001b[36m0.5216\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5417\u001b[0m  0.0211\n",
      "      8        0.5272       0.7109        \u001b[35m0.5408\u001b[0m  0.0210\n",
      "      9        0.5267       0.7188        \u001b[35m0.5406\u001b[0m  0.0207\n",
      "     10        0.5256       0.6953        \u001b[35m0.5389\u001b[0m  0.0251\n",
      "     11        0.5298       0.7031        0.5403  0.0259\n",
      "     12        \u001b[36m0.5011\u001b[0m       0.7031        0.5399  0.0264\n",
      "     13        0.5072       0.7109        \u001b[35m0.5382\u001b[0m  0.0272\n",
      "     14        \u001b[36m0.4876\u001b[0m       0.7031        0.5384  0.0272\n",
      "     15        0.5018       0.7031        0.5382  0.0320\n",
      "     16        0.4989       0.7109        \u001b[35m0.5362\u001b[0m  0.0322\n",
      "     17        0.4930       0.6953        0.5367  0.0314\n",
      "     18        \u001b[36m0.4871\u001b[0m       0.7031        0.5372  0.0341\n",
      "     19        \u001b[36m0.4738\u001b[0m       0.6953        0.5372  0.0203\n",
      "     20        0.4819       0.7266        \u001b[35m0.5360\u001b[0m  0.0317\n",
      "     21        0.4774       0.7188        \u001b[35m0.5349\u001b[0m  0.0247\n",
      "     22        \u001b[36m0.4641\u001b[0m       0.7344        \u001b[35m0.5345\u001b[0m  0.0236\n",
      "     23        0.4837       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5309\u001b[0m  0.0261\n",
      "     24        \u001b[36m0.4539\u001b[0m       0.7422        0.5335  0.0265\n",
      "     25        0.4748       0.7422        0.5314  0.0267\n",
      "     26        0.4822       0.7422        \u001b[35m0.5297\u001b[0m  0.0352\n",
      "     27        0.4887       0.7422        \u001b[35m0.5273\u001b[0m  0.0191\n",
      "     28        0.4794       0.7422        0.5279  0.0346\n",
      "     29        0.4561       0.7344        0.5297  0.0204\n",
      "     30        \u001b[36m0.4532\u001b[0m       0.7422        0.5289  0.0261\n",
      "     31        0.4654       0.7344        0.5279  0.0266\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6511\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6243\u001b[0m  0.0174\n",
      "      2        \u001b[36m0.5942\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5934\u001b[0m  0.0183\n",
      "      3        \u001b[36m0.5685\u001b[0m       0.7266        \u001b[35m0.5777\u001b[0m  0.0214\n",
      "      4        \u001b[36m0.5476\u001b[0m       0.7266        \u001b[35m0.5667\u001b[0m  0.0315\n",
      "      5        \u001b[36m0.5208\u001b[0m       0.7109        \u001b[35m0.5620\u001b[0m  0.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6        0.5232       0.7109        \u001b[35m0.5594\u001b[0m  0.0192\n",
      "      7        \u001b[36m0.5175\u001b[0m       0.7109        \u001b[35m0.5569\u001b[0m  0.0261\n",
      "      8        \u001b[36m0.4995\u001b[0m       0.7031        \u001b[35m0.5568\u001b[0m  0.0298\n",
      "      9        \u001b[36m0.4904\u001b[0m       0.7109        \u001b[35m0.5548\u001b[0m  0.0238\n",
      "     10        0.5091       0.7031        \u001b[35m0.5498\u001b[0m  0.0270\n",
      "     11        0.4970       0.7031        \u001b[35m0.5488\u001b[0m  0.0207\n",
      "     12        0.4966       0.6875        0.5491  0.0256\n",
      "     13        0.4946       0.6875        \u001b[35m0.5478\u001b[0m  0.0237\n",
      "     14        0.4942       0.7031        \u001b[35m0.5470\u001b[0m  0.0230\n",
      "     15        0.5088       0.7031        \u001b[35m0.5463\u001b[0m  0.0262\n",
      "     16        \u001b[36m0.4725\u001b[0m       0.7031        0.5465  0.0396\n",
      "     17        0.4768       0.6953        \u001b[35m0.5442\u001b[0m  0.0366\n",
      "     18        0.4929       0.7031        \u001b[35m0.5420\u001b[0m  0.0248\n",
      "     19        0.4836       0.6875        \u001b[35m0.5412\u001b[0m  0.0253\n",
      "     20        0.4777       0.7031        \u001b[35m0.5398\u001b[0m  0.0249\n",
      "     21        \u001b[36m0.4596\u001b[0m       0.7031        \u001b[35m0.5366\u001b[0m  0.0262\n",
      "     22        0.4808       0.7031        \u001b[35m0.5351\u001b[0m  0.0204\n",
      "     23        0.4772       0.7031        0.5351  0.0257\n",
      "     24        \u001b[36m0.4546\u001b[0m       0.6953        0.5355  0.0217\n",
      "     25        0.4666       0.6953        0.5358  0.0194\n",
      "     26        0.4804       0.6953        \u001b[35m0.5328\u001b[0m  0.0209\n",
      "     27        0.4688       0.6875        0.5332  0.0253\n",
      "     28        0.4588       0.6875        \u001b[35m0.5321\u001b[0m  0.0262\n",
      "     29        0.4567       0.7031        \u001b[35m0.5320\u001b[0m  0.0232\n",
      "     30        0.4647       0.6953        0.5330  0.0232\n",
      "     31        0.4700       0.6797        \u001b[35m0.5302\u001b[0m  0.0201\n",
      "     32        0.4584       0.6797        \u001b[35m0.5296\u001b[0m  0.0229\n",
      "     33        \u001b[36m0.4483\u001b[0m       0.6797        0.5309  0.0234\n",
      "     34        0.4520       0.7031        0.5314  0.0218\n",
      "     35        0.4590       0.6875        \u001b[35m0.5284\u001b[0m  0.0255\n",
      "     36        0.4610       0.6953        \u001b[35m0.5281\u001b[0m  0.0204\n",
      "     37        0.4674       0.6953        \u001b[35m0.5279\u001b[0m  0.0271\n",
      "     38        0.4613       0.6953        0.5282  0.0285\n",
      "     39        0.4513       0.6953        0.5279  0.0276\n",
      "     40        0.4491       0.6953        0.5281  0.0243\n",
      "     41        0.4628       0.6953        0.5282  0.0219\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6949\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6524\u001b[0m  0.0179\n",
      "      2        \u001b[36m0.6171\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5962\u001b[0m  0.0261\n",
      "      3        \u001b[36m0.5709\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5564\u001b[0m  0.0246\n",
      "      4        \u001b[36m0.5396\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5324\u001b[0m  0.0204\n",
      "      5        \u001b[36m0.5281\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5203\u001b[0m  0.0231\n",
      "      6        \u001b[36m0.4982\u001b[0m       0.7500        \u001b[35m0.5149\u001b[0m  0.0249\n",
      "      7        \u001b[36m0.4870\u001b[0m       0.7500        \u001b[35m0.5128\u001b[0m  0.0425\n",
      "      8        0.4907       0.7578        \u001b[35m0.5100\u001b[0m  0.0579\n",
      "      9        \u001b[36m0.4735\u001b[0m       0.7422        0.5111  0.0316\n",
      "     10        0.4804       0.7266        0.5138  0.0356\n",
      "     11        \u001b[36m0.4673\u001b[0m       0.7266        0.5174  0.0467\n",
      "     12        \u001b[36m0.4647\u001b[0m       0.7266        0.5196  0.0377\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6946\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6789\u001b[0m  0.0195\n",
      "      2        \u001b[36m0.6761\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6583\u001b[0m  0.0243\n",
      "      3        \u001b[36m0.6599\u001b[0m       0.7422        \u001b[35m0.6312\u001b[0m  0.0322\n",
      "      4        \u001b[36m0.6436\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6045\u001b[0m  0.0293\n",
      "      5        \u001b[36m0.6353\u001b[0m       0.7578        \u001b[35m0.5803\u001b[0m  0.0411\n",
      "      6        \u001b[36m0.6171\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5557\u001b[0m  0.0250\n",
      "      7        \u001b[36m0.6038\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5351\u001b[0m  0.0307\n",
      "      8        \u001b[36m0.5776\u001b[0m       0.7500        \u001b[35m0.5154\u001b[0m  0.0302\n",
      "      9        \u001b[36m0.5732\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4980\u001b[0m  0.0269\n",
      "     10        0.5884       0.7656        \u001b[35m0.4933\u001b[0m  0.0278\n",
      "     11        0.5828       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4847\u001b[0m  0.0284\n",
      "     12        \u001b[36m0.5649\u001b[0m       0.7891        \u001b[35m0.4760\u001b[0m  0.0258\n",
      "     13        \u001b[36m0.5648\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4689\u001b[0m  0.0293\n",
      "     14        \u001b[36m0.5615\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4567\u001b[0m  0.0282\n",
      "     15        0.5785       0.8047        \u001b[35m0.4557\u001b[0m  0.0293\n",
      "     16        \u001b[36m0.5392\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4550\u001b[0m  0.0328\n",
      "     17        0.5633       0.7969        \u001b[35m0.4501\u001b[0m  0.0411\n",
      "     18        0.5584       0.7891        \u001b[35m0.4498\u001b[0m  0.0416\n",
      "     19        0.5446       0.8047        \u001b[35m0.4434\u001b[0m  0.0848\n",
      "     20        \u001b[36m0.5335\u001b[0m       0.8125        \u001b[35m0.4395\u001b[0m  0.0513\n",
      "     21        0.5552       0.8125        0.4446  0.0557\n",
      "     22        0.5729       0.8125        \u001b[35m0.4393\u001b[0m  0.0368\n",
      "     23        \u001b[36m0.5314\u001b[0m       0.8125        \u001b[35m0.4272\u001b[0m  0.0304\n",
      "     24        0.5432       0.8047        0.4296  0.0256\n",
      "     25        \u001b[36m0.5150\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4214\u001b[0m  0.0255\n",
      "     26        0.5551       0.8125        0.4303  0.0276\n",
      "     27        0.5324       0.8203        0.4264  0.0271\n",
      "     28        0.5452       0.8047        0.4357  0.0258\n",
      "     29        0.5228       0.8203        0.4263  0.0264\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6572\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6482\u001b[0m  0.0219\n",
      "      2        \u001b[36m0.6351\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6153\u001b[0m  0.0278\n",
      "      3        \u001b[36m0.5911\u001b[0m       0.7422        \u001b[35m0.5808\u001b[0m  0.0326\n",
      "      4        \u001b[36m0.5724\u001b[0m       0.7266        \u001b[35m0.5573\u001b[0m  0.0297\n",
      "      5        \u001b[36m0.5447\u001b[0m       0.7188        \u001b[35m0.5425\u001b[0m  0.0642\n",
      "      6        0.5490       0.7266        \u001b[35m0.5346\u001b[0m  0.0806\n",
      "      7        \u001b[36m0.5111\u001b[0m       0.7266        \u001b[35m0.5284\u001b[0m  0.0469\n",
      "      8        \u001b[36m0.5054\u001b[0m       0.7266        \u001b[35m0.5209\u001b[0m  0.0230\n",
      "      9        0.5060       0.7266        0.5230  0.0280\n",
      "     10        0.5162       0.7500        \u001b[35m0.5158\u001b[0m  0.0304\n",
      "     11        0.5081       0.7500        0.5176  0.0308\n",
      "     12        \u001b[36m0.4936\u001b[0m       0.7500        0.5182  0.0267\n",
      "     13        0.4950       0.7266        0.5248  0.0282\n",
      "     14        \u001b[36m0.4866\u001b[0m       0.7188        0.5255  0.0299\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6875\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6741\u001b[0m  0.0187\n",
      "      2        \u001b[36m0.6667\u001b[0m       0.6797        \u001b[35m0.6526\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6496\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6272\u001b[0m  0.0309\n",
      "      4        \u001b[36m0.6129\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5974\u001b[0m  0.0285\n",
      "      5        \u001b[36m0.5880\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5741\u001b[0m  0.0244\n",
      "      6        \u001b[36m0.5677\u001b[0m       0.7188        \u001b[35m0.5595\u001b[0m  0.0329\n",
      "      7        \u001b[36m0.5614\u001b[0m       0.7188        \u001b[35m0.5504\u001b[0m  0.0267\n",
      "      8        \u001b[36m0.5526\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5444\u001b[0m  0.0291\n",
      "      9        \u001b[36m0.5358\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5388\u001b[0m  0.0275\n",
      "     10        0.5458       0.7500        0.5392  0.0233\n",
      "     11        \u001b[36m0.5300\u001b[0m       0.7344        \u001b[35m0.5313\u001b[0m  0.0285\n",
      "     12        0.5331       0.7266        \u001b[35m0.5291\u001b[0m  0.0283\n",
      "     13        \u001b[36m0.5078\u001b[0m       0.7344        0.5302  0.0287\n",
      "     14        0.5150       0.7344        \u001b[35m0.5263\u001b[0m  0.0280\n",
      "     15        0.5280       0.7344        0.5273  0.0276\n",
      "     16        0.5258       0.7266        0.5272  0.0284\n",
      "     17        \u001b[36m0.5057\u001b[0m       0.7500        \u001b[35m0.5248\u001b[0m  0.0265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        0.5077       0.7188        \u001b[35m0.5228\u001b[0m  0.0288\n",
      "     19        0.5278       0.7422        0.5259  0.0276\n",
      "     20        \u001b[36m0.4956\u001b[0m       0.7109        0.5243  0.0248\n",
      "     21        0.5013       0.7188        0.5274  0.0288\n",
      "     22        \u001b[36m0.4930\u001b[0m       0.7031        0.5315  0.0293\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6653\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6323\u001b[0m  0.0218\n",
      "      2        \u001b[36m0.6210\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5940\u001b[0m  0.0301\n",
      "      3        \u001b[36m0.5959\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5693\u001b[0m  0.0320\n",
      "      4        \u001b[36m0.5630\u001b[0m       0.7266        \u001b[35m0.5543\u001b[0m  0.0330\n",
      "      5        \u001b[36m0.5501\u001b[0m       0.7188        \u001b[35m0.5503\u001b[0m  0.0302\n",
      "      6        \u001b[36m0.5295\u001b[0m       0.7344        \u001b[35m0.5484\u001b[0m  0.0284\n",
      "      7        \u001b[36m0.5200\u001b[0m       0.7344        0.5488  0.0288\n",
      "      8        0.5204       0.7266        \u001b[35m0.5476\u001b[0m  0.0285\n",
      "      9        \u001b[36m0.5121\u001b[0m       0.7188        \u001b[35m0.5466\u001b[0m  0.0270\n",
      "     10        \u001b[36m0.4963\u001b[0m       0.7344        0.5477  0.0297\n",
      "     11        0.5086       0.7266        \u001b[35m0.5432\u001b[0m  0.0259\n",
      "     12        0.5020       0.7344        \u001b[35m0.5417\u001b[0m  0.0266\n",
      "     13        0.5053       0.7344        0.5466  0.0214\n",
      "     14        0.5016       0.7344        0.5457  0.0216\n",
      "     15        \u001b[36m0.4852\u001b[0m       0.7344        0.5526  0.0222\n",
      "     16        0.4886       0.6953        0.5509  0.0231\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6715\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6648\u001b[0m  0.0229\n",
      "      2        \u001b[36m0.6516\u001b[0m       0.7109        \u001b[35m0.6461\u001b[0m  0.0219\n",
      "      3        \u001b[36m0.6315\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6259\u001b[0m  0.0229\n",
      "      4        \u001b[36m0.6077\u001b[0m       0.7031        \u001b[35m0.6068\u001b[0m  0.0223\n",
      "      5        \u001b[36m0.5889\u001b[0m       0.7031        \u001b[35m0.5929\u001b[0m  0.0224\n",
      "      6        \u001b[36m0.5602\u001b[0m       0.7266        \u001b[35m0.5801\u001b[0m  0.0299\n",
      "      7        \u001b[36m0.5590\u001b[0m       0.7031        \u001b[35m0.5791\u001b[0m  0.0343\n",
      "      8        \u001b[36m0.5396\u001b[0m       0.6953        0.5813  0.0236\n",
      "      9        \u001b[36m0.5369\u001b[0m       0.7266        \u001b[35m0.5705\u001b[0m  0.0233\n",
      "     10        \u001b[36m0.5184\u001b[0m       0.6875        0.5777  0.0226\n",
      "     11        \u001b[36m0.5133\u001b[0m       0.6875        0.5790  0.0290\n",
      "     12        \u001b[36m0.4934\u001b[0m       0.6953        0.5770  0.0240\n",
      "     13        0.5299       0.6953        \u001b[35m0.5703\u001b[0m  0.0462\n",
      "     14        0.4938       0.7031        0.5714  0.0270\n",
      "     15        0.5089       0.7031        0.5728  0.0318\n",
      "     16        0.4956       0.6875        \u001b[35m0.5663\u001b[0m  0.0279\n",
      "     17        0.4965       0.6875        \u001b[35m0.5633\u001b[0m  0.0280\n",
      "     18        \u001b[36m0.4910\u001b[0m       0.6875        0.5671  0.0763\n",
      "     19        0.5069       0.7031        \u001b[35m0.5591\u001b[0m  0.0269\n",
      "     20        0.5120       0.6953        \u001b[35m0.5549\u001b[0m  0.0220\n",
      "     21        0.5042       0.6875        \u001b[35m0.5497\u001b[0m  0.0288\n",
      "     22        \u001b[36m0.4853\u001b[0m       0.6797        0.5514  0.0332\n",
      "     23        0.5027       0.6953        \u001b[35m0.5492\u001b[0m  0.0226\n",
      "     24        \u001b[36m0.4676\u001b[0m       0.6875        0.5512  0.0285\n",
      "     25        \u001b[36m0.4660\u001b[0m       0.6875        0.5539  0.0224\n",
      "     26        0.4759       0.6797        0.5508  0.0269\n",
      "     27        \u001b[36m0.4578\u001b[0m       0.6797        0.5493  0.0285\n",
      "     28        0.4916       0.6953        \u001b[35m0.5457\u001b[0m  0.0291\n",
      "     29        0.4722       0.6953        0.5532  0.0296\n",
      "     30        0.4820       0.7031        0.5522  0.0373\n",
      "     31        0.4849       0.7031        0.5508  0.0332\n",
      "     32        0.4831       0.7031        0.5512  0.0350\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7051\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6782\u001b[0m  0.0268\n",
      "      2        \u001b[36m0.6729\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.6336\u001b[0m  0.0297\n",
      "      3        \u001b[36m0.6322\u001b[0m       \u001b[32m0.8359\u001b[0m        \u001b[35m0.5793\u001b[0m  0.0258\n",
      "      4        \u001b[36m0.6029\u001b[0m       0.7734        \u001b[35m0.5364\u001b[0m  0.0241\n",
      "      5        \u001b[36m0.5923\u001b[0m       0.8047        \u001b[35m0.5121\u001b[0m  0.0333\n",
      "      6        \u001b[36m0.5772\u001b[0m       0.7812        \u001b[35m0.4884\u001b[0m  0.0303\n",
      "      7        \u001b[36m0.5743\u001b[0m       0.8047        \u001b[35m0.4778\u001b[0m  0.0311\n",
      "      8        \u001b[36m0.5432\u001b[0m       0.8047        \u001b[35m0.4566\u001b[0m  0.0311\n",
      "      9        0.5520       0.7891        \u001b[35m0.4475\u001b[0m  0.0282\n",
      "     10        0.5475       0.7969        \u001b[35m0.4454\u001b[0m  0.0304\n",
      "     11        0.5569       0.7969        \u001b[35m0.4408\u001b[0m  0.0334\n",
      "     12        0.5521       0.8203        \u001b[35m0.4381\u001b[0m  0.0311\n",
      "     13        0.5441       0.8203        \u001b[35m0.4305\u001b[0m  0.0333\n",
      "     14        0.5613       0.8125        \u001b[35m0.4282\u001b[0m  0.0329\n",
      "     15        0.5451       0.8125        0.4293  0.0323\n",
      "     16        \u001b[36m0.5391\u001b[0m       0.8125        \u001b[35m0.4248\u001b[0m  0.0381\n",
      "     17        0.5514       0.8203        \u001b[35m0.4242\u001b[0m  0.0228\n",
      "     18        \u001b[36m0.5341\u001b[0m       0.8203        \u001b[35m0.4208\u001b[0m  0.0232\n",
      "     19        \u001b[36m0.5195\u001b[0m       0.8359        \u001b[35m0.4147\u001b[0m  0.0245\n",
      "     20        \u001b[36m0.5194\u001b[0m       0.8281        0.4166  0.0255\n",
      "     21        0.5303       0.8203        \u001b[35m0.4090\u001b[0m  0.0341\n",
      "     22        0.5254       0.8281        \u001b[35m0.4086\u001b[0m  0.0225\n",
      "     23        \u001b[36m0.5163\u001b[0m       0.8281        \u001b[35m0.4055\u001b[0m  0.0281\n",
      "     24        0.5278       0.8203        0.4093  0.0214\n",
      "     25        0.5308       0.8281        0.4098  0.0210\n",
      "     26        0.5301       0.8281        0.4130  0.0237\n",
      "     27        0.5183       0.8281        0.4076  0.0281\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6986\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.6917\u001b[0m  0.0197\n",
      "      2        \u001b[36m0.6914\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6880\u001b[0m  0.0234\n",
      "      3        \u001b[36m0.6873\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6814\u001b[0m  0.0417\n",
      "      4        \u001b[36m0.6782\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6705\u001b[0m  0.0252\n",
      "      5        \u001b[36m0.6636\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6518\u001b[0m  0.0258\n",
      "      6        \u001b[36m0.6485\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6252\u001b[0m  0.0252\n",
      "      7        \u001b[36m0.6219\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5945\u001b[0m  0.0255\n",
      "      8        \u001b[36m0.5860\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5651\u001b[0m  0.0239\n",
      "      9        0.5909       0.7266        \u001b[35m0.5466\u001b[0m  0.0228\n",
      "     10        \u001b[36m0.5682\u001b[0m       0.7188        \u001b[35m0.5342\u001b[0m  0.0249\n",
      "     11        \u001b[36m0.5613\u001b[0m       0.7266        \u001b[35m0.5270\u001b[0m  0.0341\n",
      "     12        \u001b[36m0.5586\u001b[0m       0.7422        \u001b[35m0.5252\u001b[0m  0.0231\n",
      "     13        \u001b[36m0.5309\u001b[0m       0.7266        \u001b[35m0.5221\u001b[0m  0.0321\n",
      "     14        0.5342       0.7266        \u001b[35m0.5217\u001b[0m  0.0415\n",
      "     15        0.5442       0.7266        0.5241  0.0357\n",
      "     16        \u001b[36m0.5254\u001b[0m       0.7266        0.5218  0.0345\n",
      "     17        0.5439       0.7188        0.5223  0.0347\n",
      "     18        \u001b[36m0.5190\u001b[0m       0.7188        0.5260  0.0322\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6753\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6635\u001b[0m  0.0255\n",
      "      2        \u001b[36m0.6629\u001b[0m       0.6797        \u001b[35m0.6446\u001b[0m  0.0317\n",
      "      3        \u001b[36m0.6395\u001b[0m       0.7109        \u001b[35m0.6206\u001b[0m  0.0251\n",
      "      4        \u001b[36m0.6022\u001b[0m       0.7031        \u001b[35m0.5975\u001b[0m  0.0226\n",
      "      5        \u001b[36m0.5842\u001b[0m       0.7109        \u001b[35m0.5811\u001b[0m  0.0230\n",
      "      6        \u001b[36m0.5650\u001b[0m       0.7188        \u001b[35m0.5715\u001b[0m  0.0264\n",
      "      7        \u001b[36m0.5450\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5615\u001b[0m  0.0277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        0.5758       0.7188        0.5617  0.0214\n",
      "      9        0.5591       0.7031        \u001b[35m0.5593\u001b[0m  0.0228\n",
      "     10        0.5462       0.7109        \u001b[35m0.5571\u001b[0m  0.0268\n",
      "     11        \u001b[36m0.5424\u001b[0m       0.7188        \u001b[35m0.5548\u001b[0m  0.0206\n",
      "     12        \u001b[36m0.5303\u001b[0m       0.7188        \u001b[35m0.5518\u001b[0m  0.0205\n",
      "     13        \u001b[36m0.5267\u001b[0m       0.7266        \u001b[35m0.5515\u001b[0m  0.0228\n",
      "     14        0.5364       0.7109        \u001b[35m0.5505\u001b[0m  0.0277\n",
      "     15        \u001b[36m0.5253\u001b[0m       0.7109        \u001b[35m0.5494\u001b[0m  0.0212\n",
      "     16        \u001b[36m0.5152\u001b[0m       0.7031        0.5509  0.0202\n",
      "     17        0.5368       0.7109        \u001b[35m0.5473\u001b[0m  0.0205\n",
      "     18        0.5321       0.7109        \u001b[35m0.5456\u001b[0m  0.0258\n",
      "     19        0.5380       0.7031        \u001b[35m0.5440\u001b[0m  0.0209\n",
      "     20        0.5201       0.7109        \u001b[35m0.5435\u001b[0m  0.0200\n",
      "     21        0.5168       0.7266        \u001b[35m0.5385\u001b[0m  0.0199\n",
      "     22        \u001b[36m0.5002\u001b[0m       0.7109        0.5429  0.0206\n",
      "     23        0.5084       0.7266        0.5434  0.0201\n",
      "     24        0.5032       0.7266        0.5424  0.0201\n",
      "     25        0.5312       0.7266        0.5426  0.0211\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6791\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6811\u001b[0m  0.0194\n",
      "      2        \u001b[36m0.6743\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6656\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6528\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6436\u001b[0m  0.0307\n",
      "      4        \u001b[36m0.6234\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6129\u001b[0m  0.0243\n",
      "      5        \u001b[36m0.5968\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5828\u001b[0m  0.0249\n",
      "      6        \u001b[36m0.5908\u001b[0m       0.7266        \u001b[35m0.5671\u001b[0m  0.0285\n",
      "      7        \u001b[36m0.5774\u001b[0m       0.7344        \u001b[35m0.5497\u001b[0m  0.0236\n",
      "      8        \u001b[36m0.5597\u001b[0m       0.7344        \u001b[35m0.5382\u001b[0m  0.0234\n",
      "      9        \u001b[36m0.5488\u001b[0m       0.7266        \u001b[35m0.5309\u001b[0m  0.0251\n",
      "     10        \u001b[36m0.5449\u001b[0m       0.7344        \u001b[35m0.5248\u001b[0m  0.0215\n",
      "     11        \u001b[36m0.5438\u001b[0m       0.7422        \u001b[35m0.5218\u001b[0m  0.0241\n",
      "     12        \u001b[36m0.5324\u001b[0m       0.7344        \u001b[35m0.5209\u001b[0m  0.0237\n",
      "     13        0.5369       0.7344        \u001b[35m0.5191\u001b[0m  0.0233\n",
      "     14        0.5383       0.7422        \u001b[35m0.5166\u001b[0m  0.0249\n",
      "     15        \u001b[36m0.5254\u001b[0m       0.7422        \u001b[35m0.5148\u001b[0m  0.0219\n",
      "     16        0.5410       0.7422        \u001b[35m0.5136\u001b[0m  0.0233\n",
      "     17        \u001b[36m0.5205\u001b[0m       0.7422        \u001b[35m0.5129\u001b[0m  0.0259\n",
      "     18        \u001b[36m0.5193\u001b[0m       0.7422        0.5159  0.0245\n",
      "     19        \u001b[36m0.5097\u001b[0m       0.7422        0.5138  0.0244\n",
      "     20        0.5164       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5121\u001b[0m  0.0245\n",
      "     21        \u001b[36m0.5094\u001b[0m       \u001b[32m0.7578\u001b[0m        0.5143  0.0220\n",
      "     22        0.5262       0.7578        \u001b[35m0.5116\u001b[0m  0.0234\n",
      "     23        0.5152       0.7578        0.5157  0.0238\n",
      "     24        \u001b[36m0.4921\u001b[0m       0.7500        0.5153  0.0236\n",
      "     25        0.5224       0.7578        0.5128  0.0286\n",
      "     26        0.5048       0.7500        0.5118  0.0221\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7164\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6847\u001b[0m  0.0197\n",
      "      2        \u001b[36m0.6865\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6708\u001b[0m  0.0221\n",
      "      3        \u001b[36m0.6823\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6592\u001b[0m  0.0316\n",
      "      4        \u001b[36m0.6676\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6459\u001b[0m  0.0285\n",
      "      5        \u001b[36m0.6533\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6295\u001b[0m  0.0246\n",
      "      6        \u001b[36m0.6304\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.6126\u001b[0m  0.0221\n",
      "      7        \u001b[36m0.6271\u001b[0m       0.7578        \u001b[35m0.6023\u001b[0m  0.0228\n",
      "      8        \u001b[36m0.5921\u001b[0m       0.7578        \u001b[35m0.5898\u001b[0m  0.0270\n",
      "      9        0.5964       0.7578        \u001b[35m0.5845\u001b[0m  0.0280\n",
      "     10        0.6010       0.7500        \u001b[35m0.5808\u001b[0m  0.0225\n",
      "     11        \u001b[36m0.5847\u001b[0m       0.7188        \u001b[35m0.5742\u001b[0m  0.0261\n",
      "     12        0.5893       0.7109        \u001b[35m0.5702\u001b[0m  0.0227\n",
      "     13        \u001b[36m0.5710\u001b[0m       0.7031        \u001b[35m0.5670\u001b[0m  0.0253\n",
      "     14        \u001b[36m0.5602\u001b[0m       0.7031        \u001b[35m0.5643\u001b[0m  0.0257\n",
      "     15        \u001b[36m0.5468\u001b[0m       0.6953        \u001b[35m0.5627\u001b[0m  0.0220\n",
      "     16        \u001b[36m0.5346\u001b[0m       0.7031        \u001b[35m0.5616\u001b[0m  0.0324\n",
      "     17        \u001b[36m0.5276\u001b[0m       0.6875        \u001b[35m0.5608\u001b[0m  0.0280\n",
      "     18        \u001b[36m0.5229\u001b[0m       0.7031        \u001b[35m0.5589\u001b[0m  0.0266\n",
      "     19        \u001b[36m0.5161\u001b[0m       0.7031        \u001b[35m0.5568\u001b[0m  0.0282\n",
      "     20        \u001b[36m0.5100\u001b[0m       0.7031        0.5591  0.0378\n",
      "     21        \u001b[36m0.5063\u001b[0m       0.6953        0.5579  0.0342\n",
      "     22        0.5137       0.6953        0.5586  0.0290\n",
      "     23        \u001b[36m0.4927\u001b[0m       0.6953        0.5590  0.0231\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6894\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6718\u001b[0m  0.0187\n",
      "      2        \u001b[36m0.6763\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6553\u001b[0m  0.0203\n",
      "      3        \u001b[36m0.6678\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6396\u001b[0m  0.0266\n",
      "      4        \u001b[36m0.6464\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6176\u001b[0m  0.0251\n",
      "      5        \u001b[36m0.6373\u001b[0m       0.7344        \u001b[35m0.5928\u001b[0m  0.0234\n",
      "      6        \u001b[36m0.6266\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5671\u001b[0m  0.0247\n",
      "      7        \u001b[36m0.5936\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5385\u001b[0m  0.0237\n",
      "      8        \u001b[36m0.5814\u001b[0m       0.7656        \u001b[35m0.5210\u001b[0m  0.0237\n",
      "      9        \u001b[36m0.5570\u001b[0m       0.7656        \u001b[35m0.5029\u001b[0m  0.0261\n",
      "     10        \u001b[36m0.5470\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4876\u001b[0m  0.0255\n",
      "     11        \u001b[36m0.5401\u001b[0m       0.7734        \u001b[35m0.4763\u001b[0m  0.0237\n",
      "     12        0.5475       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4689\u001b[0m  0.0238\n",
      "     13        0.5472       0.7812        \u001b[35m0.4605\u001b[0m  0.0215\n",
      "     14        0.5499       0.7812        0.4634  0.0331\n",
      "     15        0.5675       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4598\u001b[0m  0.0227\n",
      "     16        \u001b[36m0.5380\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4501\u001b[0m  0.0217\n",
      "     17        0.5435       0.7891        \u001b[35m0.4496\u001b[0m  0.0250\n",
      "     18        0.5383       0.7969        \u001b[35m0.4440\u001b[0m  0.0239\n",
      "     19        \u001b[36m0.5302\u001b[0m       0.7969        \u001b[35m0.4407\u001b[0m  0.0291\n",
      "     20        \u001b[36m0.5184\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4316\u001b[0m  0.0225\n",
      "     21        0.5367       0.8203        \u001b[35m0.4306\u001b[0m  0.0248\n",
      "     22        0.5314       0.8203        \u001b[35m0.4251\u001b[0m  0.0262\n",
      "     23        0.5239       \u001b[32m0.8281\u001b[0m        \u001b[35m0.4219\u001b[0m  0.0305\n",
      "     24        \u001b[36m0.4969\u001b[0m       \u001b[32m0.8359\u001b[0m        \u001b[35m0.4137\u001b[0m  0.0258\n",
      "     25        0.5121       0.8281        \u001b[35m0.4115\u001b[0m  0.0263\n",
      "     26        0.4978       0.8281        \u001b[35m0.4099\u001b[0m  0.0246\n",
      "     27        0.5028       0.8281        \u001b[35m0.4089\u001b[0m  0.0213\n",
      "     28        0.5050       0.8281        \u001b[35m0.4055\u001b[0m  0.0225\n",
      "     29        0.5133       \u001b[32m0.8438\u001b[0m        \u001b[35m0.4011\u001b[0m  0.0317\n",
      "     30        0.5193       0.8438        0.4050  0.0276\n",
      "     31        0.5033       0.8359        \u001b[35m0.4001\u001b[0m  0.0231\n",
      "     32        0.5218       0.8359        0.4041  0.0224\n",
      "     33        0.5214       0.8438        0.4051  0.0240\n",
      "     34        0.5073       0.8438        0.4063  0.0249\n",
      "     35        0.5044       0.8359        0.4031  0.0239\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6872\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6745\u001b[0m  0.0199\n",
      "      2        \u001b[36m0.6511\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6482\u001b[0m  0.0245\n",
      "      3        \u001b[36m0.6279\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6224\u001b[0m  0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        \u001b[36m0.6126\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6024\u001b[0m  0.0218\n",
      "      5        \u001b[36m0.5948\u001b[0m       0.6797        \u001b[35m0.5856\u001b[0m  0.0272\n",
      "      6        \u001b[36m0.5916\u001b[0m       0.6875        \u001b[35m0.5740\u001b[0m  0.0233\n",
      "      7        \u001b[36m0.5729\u001b[0m       0.6875        \u001b[35m0.5632\u001b[0m  0.0224\n",
      "      8        \u001b[36m0.5614\u001b[0m       0.6875        \u001b[35m0.5544\u001b[0m  0.0244\n",
      "      9        0.5724       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5497\u001b[0m  0.0258\n",
      "     10        \u001b[36m0.5447\u001b[0m       0.6875        \u001b[35m0.5440\u001b[0m  0.0275\n",
      "     11        \u001b[36m0.5363\u001b[0m       0.6797        \u001b[35m0.5416\u001b[0m  0.0206\n",
      "     12        0.5455       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5387\u001b[0m  0.0271\n",
      "     13        0.5488       0.6797        0.5420  0.0236\n",
      "     14        0.5405       0.7109        0.5389  0.0252\n",
      "     15        0.5376       0.7109        \u001b[35m0.5357\u001b[0m  0.0332\n",
      "     16        0.5387       0.7031        \u001b[35m0.5354\u001b[0m  0.0231\n",
      "     17        \u001b[36m0.5344\u001b[0m       0.7031        \u001b[35m0.5350\u001b[0m  0.0253\n",
      "     18        \u001b[36m0.5281\u001b[0m       0.7109        \u001b[35m0.5340\u001b[0m  0.0223\n",
      "     19        \u001b[36m0.5250\u001b[0m       0.7031        0.5361  0.0239\n",
      "     20        \u001b[36m0.5095\u001b[0m       0.6953        0.5403  0.0246\n",
      "     21        0.5215       0.7109        0.5345  0.0259\n",
      "     22        0.5224       0.7266        \u001b[35m0.5315\u001b[0m  0.0282\n",
      "     23        0.5138       0.7188        0.5351  0.0231\n",
      "     24        \u001b[36m0.5031\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5309\u001b[0m  0.0279\n",
      "     25        0.5166       0.7422        \u001b[35m0.5308\u001b[0m  0.0255\n",
      "     26        0.5078       0.7266        0.5357  0.0226\n",
      "     27        0.5282       0.7422        \u001b[35m0.5292\u001b[0m  0.0235\n",
      "     28        0.5290       0.7344        0.5310  0.0267\n",
      "     29        0.5083       0.7344        0.5297  0.0247\n",
      "     30        0.5121       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5248\u001b[0m  0.0271\n",
      "     31        \u001b[36m0.5020\u001b[0m       0.7422        0.5255  0.0281\n",
      "     32        \u001b[36m0.4921\u001b[0m       0.7266        0.5302  0.0203\n",
      "     33        0.4953       0.7422        0.5259  0.0361\n",
      "     34        0.5067       0.7188        0.5366  0.0311\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7244\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6901\u001b[0m  0.0191\n",
      "      2        \u001b[36m0.6860\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6751\u001b[0m  0.0221\n",
      "      3        \u001b[36m0.6708\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6591\u001b[0m  0.0256\n",
      "      4        \u001b[36m0.6515\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6376\u001b[0m  0.0301\n",
      "      5        \u001b[36m0.6267\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6089\u001b[0m  0.0249\n",
      "      6        \u001b[36m0.6034\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5845\u001b[0m  0.0299\n",
      "      7        \u001b[36m0.5770\u001b[0m       0.7031        \u001b[35m0.5668\u001b[0m  0.0248\n",
      "      8        \u001b[36m0.5729\u001b[0m       0.7109        \u001b[35m0.5600\u001b[0m  0.0203\n",
      "      9        \u001b[36m0.5599\u001b[0m       0.7188        \u001b[35m0.5527\u001b[0m  0.0232\n",
      "     10        \u001b[36m0.5451\u001b[0m       0.7109        \u001b[35m0.5522\u001b[0m  0.0293\n",
      "     11        \u001b[36m0.5443\u001b[0m       0.7031        0.5523  0.0259\n",
      "     12        \u001b[36m0.5218\u001b[0m       0.7031        0.5569  0.0259\n",
      "     13        0.5304       0.7031        0.5563  0.0232\n",
      "     14        0.5236       0.7031        0.5569  0.0244\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6920\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6827\u001b[0m  0.0195\n",
      "      2        \u001b[36m0.6688\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6608\u001b[0m  0.0212\n",
      "      3        \u001b[36m0.6507\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6401\u001b[0m  0.0264\n",
      "      4        \u001b[36m0.6350\u001b[0m       0.6953        \u001b[35m0.6231\u001b[0m  0.0276\n",
      "      5        \u001b[36m0.6068\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6090\u001b[0m  0.0284\n",
      "      6        \u001b[36m0.5793\u001b[0m       0.7031        \u001b[35m0.6010\u001b[0m  0.0241\n",
      "      7        0.5979       0.6875        \u001b[35m0.5973\u001b[0m  0.0223\n",
      "      8        \u001b[36m0.5741\u001b[0m       0.6953        \u001b[35m0.5932\u001b[0m  0.0265\n",
      "      9        0.5817       0.6953        \u001b[35m0.5908\u001b[0m  0.0348\n",
      "     10        \u001b[36m0.5563\u001b[0m       0.6953        0.5920  0.0251\n",
      "     11        \u001b[36m0.5559\u001b[0m       0.6953        \u001b[35m0.5903\u001b[0m  0.0236\n",
      "     12        0.5588       0.7031        \u001b[35m0.5875\u001b[0m  0.0223\n",
      "     13        \u001b[36m0.5480\u001b[0m       0.6953        \u001b[35m0.5875\u001b[0m  0.0307\n",
      "     14        0.5570       0.6797        0.5883  0.0302\n",
      "     15        0.5578       0.7031        \u001b[35m0.5858\u001b[0m  0.0233\n",
      "     16        \u001b[36m0.5330\u001b[0m       0.7031        \u001b[35m0.5854\u001b[0m  0.0246\n",
      "     17        0.5694       0.6875        \u001b[35m0.5834\u001b[0m  0.0286\n",
      "     18        0.5609       0.6875        \u001b[35m0.5826\u001b[0m  0.0278\n",
      "     19        0.5640       0.6875        0.5831  0.0264\n",
      "     20        \u001b[36m0.5214\u001b[0m       0.6953        0.5835  0.0315\n",
      "     21        0.5478       0.6953        0.5840  0.0329\n",
      "     22        0.5299       0.6875        0.5857  0.0324\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6897\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6763\u001b[0m  0.0343\n",
      "      2        \u001b[36m0.6622\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6503\u001b[0m  0.0376\n",
      "      3        \u001b[36m0.6271\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6126\u001b[0m  0.0244\n",
      "      4        \u001b[36m0.5743\u001b[0m       0.7031        \u001b[35m0.5708\u001b[0m  0.0405\n",
      "      5        \u001b[36m0.5383\u001b[0m       0.7031        \u001b[35m0.5494\u001b[0m  0.0455\n",
      "      6        \u001b[36m0.5377\u001b[0m       0.7188        \u001b[35m0.5407\u001b[0m  0.0216\n",
      "      7        \u001b[36m0.4972\u001b[0m       0.7266        \u001b[35m0.5377\u001b[0m  0.0235\n",
      "      8        0.5115       0.7266        \u001b[35m0.5358\u001b[0m  0.0317\n",
      "      9        \u001b[36m0.4852\u001b[0m       0.7188        0.5421  0.0244\n",
      "     10        0.5130       0.7031        0.5437  0.0325\n",
      "     11        0.4960       0.6953        0.5463  0.0325\n",
      "     12        \u001b[36m0.4831\u001b[0m       0.7109        0.5459  0.0286\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6868\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6731\u001b[0m  0.0191\n",
      "      2        \u001b[36m0.6734\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6554\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6521\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6287\u001b[0m  0.0303\n",
      "      4        \u001b[36m0.6311\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5965\u001b[0m  0.0277\n",
      "      5        \u001b[36m0.6096\u001b[0m       0.7422        \u001b[35m0.5612\u001b[0m  0.0265\n",
      "      6        \u001b[36m0.5924\u001b[0m       0.7422        \u001b[35m0.5334\u001b[0m  0.0268\n",
      "      7        \u001b[36m0.5670\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5151\u001b[0m  0.0263\n",
      "      8        \u001b[36m0.5414\u001b[0m       0.7578        \u001b[35m0.4925\u001b[0m  0.0234\n",
      "      9        0.5507       0.7656        \u001b[35m0.4836\u001b[0m  0.0316\n",
      "     10        0.5503       0.7656        \u001b[35m0.4719\u001b[0m  0.0342\n",
      "     11        \u001b[36m0.5285\u001b[0m       0.7656        \u001b[35m0.4590\u001b[0m  0.0320\n",
      "     12        \u001b[36m0.5250\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4476\u001b[0m  0.0286\n",
      "     13        \u001b[36m0.5099\u001b[0m       0.7891        \u001b[35m0.4448\u001b[0m  0.0287\n",
      "     14        0.5329       0.7812        \u001b[35m0.4356\u001b[0m  0.0307\n",
      "     15        0.5189       0.7891        \u001b[35m0.4306\u001b[0m  0.0249\n",
      "     16        \u001b[36m0.5092\u001b[0m       0.7969        \u001b[35m0.4291\u001b[0m  0.0233\n",
      "     17        \u001b[36m0.5081\u001b[0m       0.7969        \u001b[35m0.4241\u001b[0m  0.0256\n",
      "     18        0.5373       0.7969        0.4248  0.0250\n",
      "     19        0.5122       0.7891        \u001b[35m0.4206\u001b[0m  0.0288\n",
      "     20        \u001b[36m0.5029\u001b[0m       0.7969        \u001b[35m0.4170\u001b[0m  0.0289\n",
      "     21        0.5083       0.7891        \u001b[35m0.4138\u001b[0m  0.0291\n",
      "     22        \u001b[36m0.4918\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4085\u001b[0m  0.0307\n",
      "     23        0.5068       0.7969        0.4086  0.0265\n",
      "     24        0.5052       0.8047        \u001b[35m0.4083\u001b[0m  0.0410\n",
      "     25        \u001b[36m0.4915\u001b[0m       0.8125        \u001b[35m0.4044\u001b[0m  0.0336\n",
      "     26        \u001b[36m0.4841\u001b[0m       0.8125        \u001b[35m0.4007\u001b[0m  0.0264\n",
      "     27        0.4980       0.8125        \u001b[35m0.3993\u001b[0m  0.0305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     28        \u001b[36m0.4790\u001b[0m       0.8125        \u001b[35m0.3979\u001b[0m  0.0251\n",
      "     29        0.4921       0.8047        0.3992  0.0466\n",
      "     30        0.4931       0.8125        0.3985  0.0273\n",
      "     31        \u001b[36m0.4741\u001b[0m       0.8203        0.3981  0.0283\n",
      "     32        \u001b[36m0.4678\u001b[0m       0.8203        \u001b[35m0.3935\u001b[0m  0.0287\n",
      "     33        0.4845       0.8203        \u001b[35m0.3903\u001b[0m  0.0267\n",
      "     34        0.4864       0.8203        0.3978  0.0320\n",
      "     35        0.4978       0.8125        0.3982  0.0300\n",
      "     36        0.4888       0.8203        0.3946  0.0384\n",
      "     37        0.4892       0.8203        0.3952  0.0469\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6602\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6378\u001b[0m  0.0313\n",
      "      2        \u001b[36m0.6288\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6030\u001b[0m  0.0397\n",
      "      3        \u001b[36m0.5944\u001b[0m       0.7188        \u001b[35m0.5764\u001b[0m  0.0340\n",
      "      4        \u001b[36m0.5880\u001b[0m       0.7188        \u001b[35m0.5620\u001b[0m  0.0260\n",
      "      5        \u001b[36m0.5734\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5463\u001b[0m  0.0328\n",
      "      6        \u001b[36m0.5508\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5379\u001b[0m  0.0451\n",
      "      7        0.5568       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5344\u001b[0m  0.0300\n",
      "      8        \u001b[36m0.5303\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5274\u001b[0m  0.0288\n",
      "      9        \u001b[36m0.5193\u001b[0m       0.7422        0.5281  0.0249\n",
      "     10        0.5244       0.7266        \u001b[35m0.5239\u001b[0m  0.0301\n",
      "     11        0.5279       0.7266        0.5282  0.0288\n",
      "     12        \u001b[36m0.5051\u001b[0m       0.7188        0.5241  0.0295\n",
      "     13        0.5094       0.7188        \u001b[35m0.5232\u001b[0m  0.0298\n",
      "     14        0.5125       0.7188        \u001b[35m0.5220\u001b[0m  0.0274\n",
      "     15        0.5080       0.7266        0.5246  0.0443\n",
      "     16        \u001b[36m0.4881\u001b[0m       0.7266        0.5275  0.0338\n",
      "     17        0.4895       0.7266        0.5305  0.0287\n",
      "     18        \u001b[36m0.4762\u001b[0m       0.7188        0.5317  0.0286\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6691\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6579\u001b[0m  0.0223\n",
      "      2        \u001b[36m0.6556\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6383\u001b[0m  0.0279\n",
      "      3        \u001b[36m0.6399\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6162\u001b[0m  0.0286\n",
      "      4        \u001b[36m0.6136\u001b[0m       0.7422        \u001b[35m0.5945\u001b[0m  0.0268\n",
      "      5        \u001b[36m0.5890\u001b[0m       0.7344        \u001b[35m0.5762\u001b[0m  0.0256\n",
      "      6        \u001b[36m0.5662\u001b[0m       0.7266        \u001b[35m0.5648\u001b[0m  0.0298\n",
      "      7        \u001b[36m0.5489\u001b[0m       0.7188        \u001b[35m0.5587\u001b[0m  0.0300\n",
      "      8        \u001b[36m0.5405\u001b[0m       0.7031        \u001b[35m0.5571\u001b[0m  0.0266\n",
      "      9        \u001b[36m0.5242\u001b[0m       0.7031        \u001b[35m0.5567\u001b[0m  0.0250\n",
      "     10        0.5254       0.7344        0.5596  0.0246\n",
      "     11        0.5324       0.7109        \u001b[35m0.5553\u001b[0m  0.0276\n",
      "     12        \u001b[36m0.5218\u001b[0m       0.7188        0.5585  0.0229\n",
      "     13        0.5316       0.7266        \u001b[35m0.5548\u001b[0m  0.0291\n",
      "     14        \u001b[36m0.5182\u001b[0m       0.7344        \u001b[35m0.5537\u001b[0m  0.0281\n",
      "     15        \u001b[36m0.5155\u001b[0m       0.7344        \u001b[35m0.5528\u001b[0m  0.0281\n",
      "     16        0.5338       0.7188        0.5531  0.0240\n",
      "     17        0.5244       0.7266        \u001b[35m0.5501\u001b[0m  0.0252\n",
      "     18        0.5211       0.7344        0.5511  0.0221\n",
      "     19        0.5234       0.7109        \u001b[35m0.5482\u001b[0m  0.0242\n",
      "     20        \u001b[36m0.5101\u001b[0m       0.7109        \u001b[35m0.5481\u001b[0m  0.0278\n",
      "     21        \u001b[36m0.5048\u001b[0m       0.7109        \u001b[35m0.5457\u001b[0m  0.0268\n",
      "     22        0.5243       0.7109        \u001b[35m0.5437\u001b[0m  0.0278\n",
      "     23        0.5277       0.7109        \u001b[35m0.5409\u001b[0m  0.0277\n",
      "     24        \u001b[36m0.5006\u001b[0m       0.7109        0.5435  0.0258\n",
      "     25        \u001b[36m0.4981\u001b[0m       0.7109        0.5416  0.0294\n",
      "     26        0.5037       0.7109        \u001b[35m0.5384\u001b[0m  0.0225\n",
      "     27        \u001b[36m0.4932\u001b[0m       0.7109        0.5394  0.0274\n",
      "     28        0.4933       0.7109        0.5432  0.0258\n",
      "     29        0.5004       0.7109        0.5418  0.0263\n",
      "     30        0.5104       0.7188        \u001b[35m0.5355\u001b[0m  0.0231\n",
      "     31        0.5000       0.7266        \u001b[35m0.5311\u001b[0m  0.0221\n",
      "     32        \u001b[36m0.4835\u001b[0m       0.7422        \u001b[35m0.5294\u001b[0m  0.0302\n",
      "     33        \u001b[36m0.4730\u001b[0m       0.7344        0.5298  0.0260\n",
      "     34        0.4801       0.7422        0.5319  0.0242\n",
      "     35        0.4754       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5267\u001b[0m  0.0249\n",
      "     36        0.4730       0.7500        \u001b[35m0.5260\u001b[0m  0.0238\n",
      "     37        0.4795       0.7422        0.5264  0.0233\n",
      "     38        0.4741       0.7422        \u001b[35m0.5246\u001b[0m  0.0261\n",
      "     39        0.4877       0.7266        0.5251  0.0235\n",
      "     40        0.4758       0.7422        0.5251  0.0246\n",
      "     41        \u001b[36m0.4723\u001b[0m       0.7344        \u001b[35m0.5199\u001b[0m  0.0265\n",
      "     42        0.4802       0.7422        \u001b[35m0.5166\u001b[0m  0.0239\n",
      "     43        0.4855       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5152\u001b[0m  0.0245\n",
      "     44        \u001b[36m0.4637\u001b[0m       0.7344        0.5186  0.0239\n",
      "     45        0.4660       0.7344        0.5208  0.0267\n",
      "     46        \u001b[36m0.4540\u001b[0m       0.7500        0.5245  0.0216\n",
      "     47        0.4922       0.6953        0.5175  0.0267\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6980\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6787\u001b[0m  0.0222\n",
      "      2        \u001b[36m0.6751\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6564\u001b[0m  0.0242\n",
      "      3        \u001b[36m0.6505\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6290\u001b[0m  0.0235\n",
      "      4        \u001b[36m0.6202\u001b[0m       0.7344        \u001b[35m0.5961\u001b[0m  0.0224\n",
      "      5        \u001b[36m0.5993\u001b[0m       0.7422        \u001b[35m0.5672\u001b[0m  0.0244\n",
      "      6        \u001b[36m0.5886\u001b[0m       0.7422        \u001b[35m0.5492\u001b[0m  0.0275\n",
      "      7        \u001b[36m0.5626\u001b[0m       0.7344        \u001b[35m0.5357\u001b[0m  0.0233\n",
      "      8        \u001b[36m0.5557\u001b[0m       0.7344        \u001b[35m0.5336\u001b[0m  0.0257\n",
      "      9        \u001b[36m0.5380\u001b[0m       0.7031        \u001b[35m0.5260\u001b[0m  0.0226\n",
      "     10        \u001b[36m0.5218\u001b[0m       0.7109        \u001b[35m0.5260\u001b[0m  0.0287\n",
      "     11        \u001b[36m0.5091\u001b[0m       0.7188        \u001b[35m0.5236\u001b[0m  0.0231\n",
      "     12        0.5288       0.7031        0.5242  0.0257\n",
      "     13        \u001b[36m0.5046\u001b[0m       0.7031        0.5285  0.0286\n",
      "     14        0.5070       0.7031        0.5300  0.0225\n",
      "     15        0.5323       0.7031        0.5259  0.0281\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7041\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m0.6956\u001b[0m  0.0226\n",
      "      2        \u001b[36m0.6911\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6873\u001b[0m  0.0317\n",
      "      3        \u001b[36m0.6808\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6762\u001b[0m  0.0284\n",
      "      4        \u001b[36m0.6670\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6560\u001b[0m  0.0235\n",
      "      5        \u001b[36m0.6393\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6263\u001b[0m  0.0232\n",
      "      6        \u001b[36m0.6141\u001b[0m       0.7109        \u001b[35m0.5959\u001b[0m  0.0308\n",
      "      7        \u001b[36m0.5676\u001b[0m       0.7188        \u001b[35m0.5664\u001b[0m  0.0240\n",
      "      8        \u001b[36m0.5627\u001b[0m       0.7188        \u001b[35m0.5492\u001b[0m  0.0244\n",
      "      9        \u001b[36m0.5339\u001b[0m       0.7109        \u001b[35m0.5384\u001b[0m  0.0262\n",
      "     10        \u001b[36m0.5176\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5308\u001b[0m  0.0222\n",
      "     11        \u001b[36m0.5152\u001b[0m       0.7109        0.5334  0.0255\n",
      "     12        \u001b[36m0.5055\u001b[0m       0.7031        0.5325  0.0240\n",
      "     13        \u001b[36m0.4906\u001b[0m       0.6875        0.5359  0.0264\n",
      "     14        0.5079       0.7188        \u001b[35m0.5264\u001b[0m  0.0247\n",
      "     15        0.5085       0.7031        0.5334  0.0241\n",
      "     16        0.5077       0.7109        \u001b[35m0.5257\u001b[0m  0.0251\n",
      "     17        \u001b[36m0.4605\u001b[0m       0.7188        0.5297  0.0257\n",
      "     18        0.4777       0.7109        \u001b[35m0.5247\u001b[0m  0.0232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19        0.4678       0.7188        0.5251  0.0251\n",
      "     20        \u001b[36m0.4571\u001b[0m       0.7109        \u001b[35m0.5220\u001b[0m  0.0223\n",
      "     21        0.4651       0.7266        0.5266  0.0335\n",
      "     22        0.4725       0.7109        \u001b[35m0.5203\u001b[0m  0.0238\n",
      "     23        0.4597       0.7188        \u001b[35m0.5191\u001b[0m  0.0249\n",
      "     24        0.4673       0.7109        \u001b[35m0.5181\u001b[0m  0.0215\n",
      "     25        \u001b[36m0.4342\u001b[0m       0.7109        0.5198  0.0244\n",
      "     26        0.4446       0.7109        0.5202  0.0248\n",
      "     27        \u001b[36m0.4211\u001b[0m       0.7188        0.5310  0.0221\n",
      "     28        0.4292       0.7188        0.5279  0.0241\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "           One hidden layer with 3 neurons  One hidden layer with 6 neurons  \\\n",
      "Accuracy                          0.762500                         0.751250   \n",
      "Precision                         0.756547                         0.745801   \n",
      "Recall                            0.772500                         0.762500   \n",
      "F1 Score                          0.763907                         0.753652   \n",
      "AUC                               0.844094                         0.839922   \n",
      "\n",
      "           One hidden layer with 9 neurons  One hidden layer with 12 neurons  \\\n",
      "Accuracy                          0.758750                          0.767500   \n",
      "Precision                         0.751515                          0.755248   \n",
      "Recall                            0.775000                          0.792500   \n",
      "F1 Score                          0.762711                          0.773236   \n",
      "AUC                               0.846203                          0.846500   \n",
      "\n",
      "           Two hidden layers each with 3 neurons  \\\n",
      "Accuracy                                0.766250   \n",
      "Precision                               0.748866   \n",
      "Recall                                  0.800000   \n",
      "F1 Score                                0.772490   \n",
      "AUC                                     0.844844   \n",
      "\n",
      "           Two hidden layers each with 6 neurons  \\\n",
      "Accuracy                                0.763750   \n",
      "Precision                               0.744166   \n",
      "Recall                                  0.807500   \n",
      "F1 Score                                0.773185   \n",
      "AUC                                     0.845062   \n",
      "\n",
      "           Two hidden layers each with 9 neurons  \\\n",
      "Accuracy                                0.761250   \n",
      "Precision                               0.755619   \n",
      "Recall                                  0.777500   \n",
      "F1 Score                                0.765207   \n",
      "AUC                                     0.835625   \n",
      "\n",
      "           Two hidden layers each with 12 neurons  \\\n",
      "Accuracy                                 0.772500   \n",
      "Precision                                0.756455   \n",
      "Recall                                   0.805000   \n",
      "F1 Score                                 0.779839   \n",
      "AUC                                      0.845438   \n",
      "\n",
      "                                       Best Score  \n",
      "Accuracy   Two hidden layers each with 12 neurons  \n",
      "Precision         One hidden layer with 3 neurons  \n",
      "Recall      Two hidden layers each with 6 neurons  \n",
      "F1 Score   Two hidden layers each with 12 neurons  \n",
      "AUC              One hidden layer with 12 neurons  \n",
      "           One hidden layer with 3 neurons  One hidden layer with 6 neurons  \\\n",
      "Accuracy                          0.041269                         0.039011   \n",
      "Precision                         0.032625                         0.037007   \n",
      "Recall                            0.063443                         0.050621   \n",
      "F1 Score                          0.045618                         0.040319   \n",
      "AUC                               0.037250                         0.032704   \n",
      "\n",
      "           One hidden layer with 9 neurons  One hidden layer with 12 neurons  \\\n",
      "Accuracy                          0.019605                          0.050374   \n",
      "Precision                         0.026544                          0.049543   \n",
      "Recall                            0.020917                          0.050374   \n",
      "F1 Score                          0.017295                          0.048655   \n",
      "AUC                               0.021688                          0.033317   \n",
      "\n",
      "           Two hidden layers each with 3 neurons  \\\n",
      "Accuracy                                0.044826   \n",
      "Precision                               0.032987   \n",
      "Recall                                  0.075416   \n",
      "F1 Score                                0.049693   \n",
      "AUC                                     0.031171   \n",
      "\n",
      "           Two hidden layers each with 6 neurons  \\\n",
      "Accuracy                                0.034095   \n",
      "Precision                               0.039936   \n",
      "Recall                                  0.057337   \n",
      "F1 Score                                0.035988   \n",
      "AUC                                     0.031665   \n",
      "\n",
      "           Two hidden layers each with 9 neurons  \\\n",
      "Accuracy                                0.034324   \n",
      "Precision                               0.043573   \n",
      "Recall                                  0.041382   \n",
      "F1 Score                                0.030624   \n",
      "AUC                                     0.027757   \n",
      "\n",
      "           Two hidden layers each with 12 neurons  \\\n",
      "Accuracy                                 0.028395   \n",
      "Precision                                0.031451   \n",
      "Recall                                   0.023184   \n",
      "F1 Score                                 0.026057   \n",
      "AUC                                      0.027029   \n",
      "\n",
      "                Minimum standard deviation  \n",
      "Accuracy   One hidden layer with 9 neurons  \n",
      "Precision  One hidden layer with 9 neurons  \n",
      "Recall     One hidden layer with 9 neurons  \n",
      "F1 Score   One hidden layer with 9 neurons  \n",
      "AUC        One hidden layer with 9 neurons  \n"
     ]
    }
   ],
   "source": [
    "# Create function that performs cross-validation and evaluates each MLP model\n",
    "def models_evaluation(X_train, y_train):\n",
    "    \n",
    "    # Perform cross-validation on each MLP model\n",
    "    cv_wide3Net = cross_validate(wide3Net, X_train, y_train, cv=5, scoring=scoring)\n",
    "    cv_wide6Net = cross_validate(wide6Net, X_train, y_train, cv=5, scoring=scoring)\n",
    "    cv_wide9Net = cross_validate(wide9Net, X_train, y_train, cv=5, scoring=scoring)\n",
    "    cv_wide12Net = cross_validate(wide12Net, X_train, y_train, cv=5, scoring=scoring)\n",
    "    cv_intermediate3Net = cross_validate(intermediate3Net, X_train, y_train, cv=5, scoring=scoring)\n",
    "    cv_intermediate6Net = cross_validate(intermediate6Net, X_train, y_train, cv=5, scoring=scoring)\n",
    "    cv_intermediate9Net = cross_validate(intermediate9Net, X_train, y_train, cv=5, scoring=scoring)\n",
    "    cv_intermediate12Net = cross_validate(intermediate12Net, X_train, y_train, cv=5, scoring=scoring)\n",
    "    \n",
    "    # Create 'mean_scores_table' DataFrame with mean performance metric scores for each classifier\n",
    "    mean_scores_table = pd.DataFrame({'One hidden layer with 3 neurons':[cv_wide3Net['test_accuracy'].mean(),\n",
    "                                                         cv_wide3Net['test_precision'].mean(),\n",
    "                                                         cv_wide3Net['test_recall'].mean(),\n",
    "                                                         cv_wide3Net['test_f1_score'].mean(),\n",
    "                                                         cv_wide3Net['test_AUC'].mean()],\n",
    "                                      'One hidden layer with 6 neurons':[cv_wide6Net['test_accuracy'].mean(),\n",
    "                                                         cv_wide6Net['test_precision'].mean(),\n",
    "                                                         cv_wide6Net['test_recall'].mean(),\n",
    "                                                         cv_wide6Net['test_f1_score'].mean(),\n",
    "                                                         cv_wide6Net['test_AUC'].mean()],\n",
    "                                      'One hidden layer with 9 neurons':[cv_wide9Net['test_accuracy'].mean(),\n",
    "                                                         cv_wide9Net['test_precision'].mean(),\n",
    "                                                         cv_wide9Net['test_recall'].mean(),\n",
    "                                                         cv_wide9Net['test_f1_score'].mean(),\n",
    "                                                         cv_wide9Net['test_AUC'].mean()],\n",
    "                                      'One hidden layer with 12 neurons':[cv_wide12Net['test_accuracy'].mean(),\n",
    "                                                         cv_wide12Net['test_precision'].mean(),\n",
    "                                                         cv_wide12Net['test_recall'].mean(),\n",
    "                                                         cv_wide12Net['test_f1_score'].mean(),\n",
    "                                                         cv_wide12Net['test_AUC'].mean()],\n",
    "                                      'Two hidden layers each with 3 neurons':[cv_intermediate3Net['test_accuracy'].mean(),\n",
    "                                                         cv_intermediate3Net['test_precision'].mean(),\n",
    "                                                         cv_intermediate3Net['test_recall'].mean(),\n",
    "                                                         cv_intermediate3Net['test_f1_score'].mean(),\n",
    "                                                         cv_intermediate3Net['test_AUC'].mean()],\n",
    "                                      'Two hidden layers each with 6 neurons':[cv_intermediate6Net['test_accuracy'].mean(),\n",
    "                                                         cv_intermediate6Net['test_precision'].mean(),\n",
    "                                                         cv_intermediate6Net['test_recall'].mean(),\n",
    "                                                         cv_intermediate6Net['test_f1_score'].mean(),\n",
    "                                                         cv_intermediate6Net['test_AUC'].mean()],\n",
    "                                      'Two hidden layers each with 9 neurons':[cv_intermediate9Net['test_accuracy'].mean(),\n",
    "                                                         cv_intermediate9Net['test_precision'].mean(),\n",
    "                                                         cv_intermediate9Net['test_recall'].mean(),\n",
    "                                                         cv_intermediate9Net['test_f1_score'].mean(),\n",
    "                                                         cv_intermediate9Net['test_AUC'].mean()],\n",
    "                                      'Two hidden layers each with 12 neurons':[cv_intermediate12Net['test_accuracy'].mean(),\n",
    "                                                         cv_intermediate12Net['test_precision'].mean(),\n",
    "                                                         cv_intermediate12Net['test_recall'].mean(),\n",
    "                                                         cv_intermediate12Net['test_f1_score'].mean(),\n",
    "                                                         cv_intermediate12Net['test_AUC'].mean()]},\n",
    "                                      index=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'])\n",
    "    \n",
    "    # Add 'Best Score' column to 'mean_scores_table'\n",
    "    mean_scores_table['Best Score'] = mean_scores_table.idxmax(axis=1)  \n",
    "\n",
    "    # Create 'std_scores_table' DataFrame with standard deviation of performance metric scores for each classifier\n",
    "    std_scores_table = pd.DataFrame({'One hidden layer with 3 neurons':[cv_wide3Net['test_accuracy'].std(),\n",
    "                                                         cv_wide3Net['test_precision'].std(),\n",
    "                                                         cv_wide3Net['test_recall'].std(),\n",
    "                                                         cv_wide3Net['test_f1_score'].std(),\n",
    "                                                         cv_wide3Net['test_AUC'].std()],\n",
    "                                    'One hidden layer with 6 neurons':[cv_wide6Net['test_accuracy'].std(),\n",
    "                                                         cv_wide6Net['test_precision'].std(),\n",
    "                                                         cv_wide6Net['test_recall'].std(),\n",
    "                                                         cv_wide6Net['test_f1_score'].std(),\n",
    "                                                         cv_wide6Net['test_AUC'].std()],\n",
    "                                     'One hidden layer with 9 neurons':[cv_wide9Net['test_accuracy'].std(),\n",
    "                                                         cv_wide9Net['test_precision'].std(),\n",
    "                                                         cv_wide9Net['test_recall'].std(),\n",
    "                                                         cv_wide9Net['test_f1_score'].std(),\n",
    "                                                         cv_wide9Net['test_AUC'].std()],\n",
    "                                     'One hidden layer with 12 neurons':[cv_wide12Net['test_accuracy'].std(),\n",
    "                                                         cv_wide12Net['test_precision'].std(),\n",
    "                                                         cv_wide12Net['test_recall'].std(),\n",
    "                                                         cv_wide12Net['test_f1_score'].std(),\n",
    "                                                         cv_wide12Net['test_AUC'].std()],\n",
    "                                     'Two hidden layers each with 3 neurons':[cv_intermediate3Net['test_accuracy'].std(),\n",
    "                                                         cv_intermediate3Net['test_precision'].std(),\n",
    "                                                         cv_intermediate3Net['test_recall'].std(),\n",
    "                                                         cv_intermediate3Net['test_f1_score'].std(),\n",
    "                                                         cv_intermediate3Net['test_AUC'].std()],\n",
    "                                     'Two hidden layers each with 6 neurons':[cv_intermediate6Net['test_accuracy'].std(),\n",
    "                                                         cv_intermediate6Net['test_precision'].std(),\n",
    "                                                         cv_intermediate6Net['test_recall'].std(),\n",
    "                                                         cv_intermediate6Net['test_f1_score'].std(),\n",
    "                                                         cv_intermediate6Net['test_AUC'].std()],\n",
    "                                     'Two hidden layers each with 9 neurons':[cv_intermediate9Net['test_accuracy'].std(),\n",
    "                                                         cv_intermediate9Net['test_precision'].std(),\n",
    "                                                         cv_intermediate9Net['test_recall'].std(),\n",
    "                                                         cv_intermediate9Net['test_f1_score'].std(),\n",
    "                                                         cv_intermediate9Net['test_AUC'].std()],\n",
    "                                     'Two hidden layers each with 12 neurons':[cv_intermediate12Net['test_accuracy'].std(),\n",
    "                                                         cv_intermediate12Net['test_precision'].std(),\n",
    "                                                         cv_intermediate12Net['test_recall'].std(),\n",
    "                                                         cv_intermediate12Net['test_f1_score'].std(),\n",
    "                                                         cv_intermediate12Net['test_AUC'].std()]},\n",
    "                                     index=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'])\n",
    "   \n",
    "    # Add 'Minimum standard deviation' column to 'std_scores_table'\n",
    "    std_scores_table['Minimum standard deviation'] = std_scores_table.idxmin(axis=1)  \n",
    "\n",
    "    # Return DataFrames with mean and standard deviation performance metrics scores for each classifier\n",
    "    return mean_scores_table, std_scores_table\n",
    "    \n",
    "                                       \n",
    "# Evaluate 5-fold cross-validated MLP models with either one or two hidden layers and either 3,6,9 or 12 neurons in each hidden layer\n",
    "mean_scores_table, std_scores_table = models_evaluation(X_train_smote, y_train_smote)\n",
    "\n",
    "# Display the mean cross-validation scores\n",
    "print(mean_scores_table)\n",
    "\n",
    "# Display the standard deviation of the cross-validation scores\n",
    "print(std_scores_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x1872 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a bar graph to show the mean and standard deviation of the performance metrics of the MLP models\n",
    "x_labels = ['One hidden layer with 3 neurons',\n",
    "            'One hidden layer with 6 neurons',\n",
    "            'One hidden layer with 9 neurons',\n",
    "            'One hidden layer with 12 neurons',\n",
    "            'Two hidden layers each with 3 neurons',\n",
    "            'Two hidden layers each with 6 neurons',\n",
    "            'Two hidden layers each with 9 neurons',\n",
    "            'Two hidden layers each with 12 neurons']\n",
    "n_bars = len(mean_scores_table.iloc[0,:-1])\n",
    "xval = np.arange(n_bars)\n",
    "ax = plt.figure(figsize = (6,26))\n",
    "for k in range(len(mean_scores_table)):\n",
    "   ax = plt.subplot(5,1,k+1)\n",
    "   for j in xval:\n",
    "      plt.barh([j], mean_scores_table.iloc[k,j], xerr=std_scores_table.iloc[k,j], alpha=0.6, align='center')\n",
    "   plt.title('%s for SVC models with different kernels'%mean_scores_table.index[k])\n",
    "   plt.xlabel('%s'%mean_scores_table.index[k])\n",
    "   ax.set_yticks(xval)\n",
    "   ax.invert_yaxis()\n",
    "   ax.set_yticklabels(x_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were small differences in AUC score, accuracy, precision, recall and F1 score between models with one or two hidden layers and either 3, 6, 9 or 12 neurons in each hidden layer. It is better to find the optimal number of neurons along with optimal values of other hyperparameters using Randomized Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Randomized Search on MLP models with one hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Randomized Search on combinations of the following hyperparameters for the 5-fold cross-validated MLP model with a single hidden layer.\n",
    "- number of neurons 'num_units': seven options, 3, 4, 5, 6, 7, 8 or 9.\n",
    "- optimizer momentum 'optimizer__momentum': four options, 0.1, 0.3, 0.6 or 0.9.\n",
    "- learning rate 'lr': three options, 1, 0.1 or 0.01.\n",
    "- dropout 'module__dropout': three options, 0.0, 0.2 or 0.5.\n",
    "- batch size 'batch_size': three options, 16, 32 or 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network with a single hidden layer\n",
    "class NetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=3,\n",
    "            dropout = 0.5\n",
    "    ):\n",
    "        super(NetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden = nn.Linear(X.shape[1],num_units)\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X),dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the neural network\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "searchNet = NeuralNetClassifier(module=NetModule, \n",
    "                    max_epochs=100,\n",
    "                    callbacks=[EarlyStopping()],\n",
    "                    device=device,\n",
    "                    iterator_train__shuffle=True,# Shuffle training data on each epoch\n",
    "                    batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6421\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5361\u001b[0m  0.0178\n",
      "      2        \u001b[36m0.5637\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4721\u001b[0m  0.0192\n",
      "      3        \u001b[36m0.5341\u001b[0m       0.7578        \u001b[35m0.4421\u001b[0m  0.0177\n",
      "      4        \u001b[36m0.5181\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4237\u001b[0m  0.0183\n",
      "      5        \u001b[36m0.5116\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4207\u001b[0m  0.0318\n",
      "      6        \u001b[36m0.5034\u001b[0m       0.7891        \u001b[35m0.4156\u001b[0m  0.0214\n",
      "      7        \u001b[36m0.4981\u001b[0m       0.7812        0.4197  0.0316\n",
      "      8        \u001b[36m0.4953\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4095\u001b[0m  0.0259\n",
      "      9        \u001b[36m0.4886\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4016\u001b[0m  0.0266\n",
      "     10        \u001b[36m0.4841\u001b[0m       0.8125        0.4089  0.0357\n",
      "     11        0.4857       0.8047        \u001b[35m0.3957\u001b[0m  0.0199\n",
      "     12        \u001b[36m0.4819\u001b[0m       0.8047        0.3978  0.0254\n",
      "     13        \u001b[36m0.4770\u001b[0m       0.8125        \u001b[35m0.3916\u001b[0m  0.0328\n",
      "     14        \u001b[36m0.4760\u001b[0m       0.7969        \u001b[35m0.3909\u001b[0m  0.0338\n",
      "     15        \u001b[36m0.4719\u001b[0m       0.7891        0.3965  0.0521\n",
      "     16        \u001b[36m0.4666\u001b[0m       0.7969        0.3932  0.0475\n",
      "     17        \u001b[36m0.4641\u001b[0m       0.7656        0.3954  0.0543\n",
      "     18        \u001b[36m0.4604\u001b[0m       0.7578        0.3962  0.0740\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6360\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5832\u001b[0m  0.0686\n",
      "      2        \u001b[36m0.5310\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5449\u001b[0m  0.0517\n",
      "      3        \u001b[36m0.4968\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5418\u001b[0m  0.0472\n",
      "      4        \u001b[36m0.4872\u001b[0m       0.7031        0.5421  0.0234\n",
      "      5        \u001b[36m0.4824\u001b[0m       0.6797        0.5545  0.0594\n",
      "      6        \u001b[36m0.4798\u001b[0m       0.7031        0.5481  0.0654\n",
      "      7        \u001b[36m0.4793\u001b[0m       0.6875        0.5522  0.0424\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5809\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5517\u001b[0m  0.0547\n",
      "      2        \u001b[36m0.5041\u001b[0m       0.6797        \u001b[35m0.5503\u001b[0m  0.0445\n",
      "      3        \u001b[36m0.4866\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5496\u001b[0m  0.0786\n",
      "      4        \u001b[36m0.4795\u001b[0m       0.6797        0.5505  0.0561\n",
      "      5        \u001b[36m0.4744\u001b[0m       0.6875        \u001b[35m0.5434\u001b[0m  0.0402\n",
      "      6        \u001b[36m0.4672\u001b[0m       \u001b[32m0.7031\u001b[0m        0.5460  0.0515\n",
      "      7        \u001b[36m0.4622\u001b[0m       \u001b[32m0.7188\u001b[0m        0.5453  0.0326\n",
      "      8        \u001b[36m0.4603\u001b[0m       0.7188        0.5475  0.0383\n",
      "      9        \u001b[36m0.4576\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5390\u001b[0m  0.0271\n",
      "     10        \u001b[36m0.4544\u001b[0m       0.7188        0.5456  0.0519\n",
      "     11        \u001b[36m0.4497\u001b[0m       0.7344        0.5405  0.0475\n",
      "     12        \u001b[36m0.4496\u001b[0m       0.7266        0.5415  0.0317\n",
      "     13        \u001b[36m0.4465\u001b[0m       0.7188        0.5486  0.0328\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6345\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5672\u001b[0m  0.0229\n",
      "      2        \u001b[36m0.5209\u001b[0m       0.7188        \u001b[35m0.5263\u001b[0m  0.0313\n",
      "      3        \u001b[36m0.4844\u001b[0m       0.7031        \u001b[35m0.5210\u001b[0m  0.0373\n",
      "      4        \u001b[36m0.4706\u001b[0m       0.6953        \u001b[35m0.5207\u001b[0m  0.0300\n",
      "      5        \u001b[36m0.4662\u001b[0m       0.7031        0.5210  0.0321\n",
      "      6        \u001b[36m0.4570\u001b[0m       0.7109        0.5273  0.0290\n",
      "      7        \u001b[36m0.4518\u001b[0m       0.7109        0.5232  0.0327\n",
      "      8        \u001b[36m0.4477\u001b[0m       0.7109        0.5251  0.0319\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5674\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5690\u001b[0m  0.0310\n",
      "      2        \u001b[36m0.4884\u001b[0m       \u001b[32m0.7031\u001b[0m        0.5732  0.0277\n",
      "      3        \u001b[36m0.4684\u001b[0m       0.7031        0.5782  0.0304\n",
      "      4        \u001b[36m0.4623\u001b[0m       0.7031        0.5794  0.0330\n",
      "      5        0.4634       0.6953        0.5759  0.0361\n",
      "      6        \u001b[36m0.4569\u001b[0m       0.6953        \u001b[35m0.5685\u001b[0m  0.0281\n",
      "      7        \u001b[36m0.4503\u001b[0m       0.7031        0.5718  0.0298\n",
      "      8        \u001b[36m0.4489\u001b[0m       0.7031        \u001b[35m0.5632\u001b[0m  0.0272\n",
      "      9        \u001b[36m0.4452\u001b[0m       0.7031        \u001b[35m0.5630\u001b[0m  0.0310\n",
      "     10        \u001b[36m0.4435\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5618\u001b[0m  0.0322\n",
      "     11        0.4437       0.7031        0.5680  0.0325\n",
      "     12        \u001b[36m0.4433\u001b[0m       0.7031        0.5632  0.0265\n",
      "     13        \u001b[36m0.4385\u001b[0m       0.7109        0.5659  0.0328\n",
      "     14        \u001b[36m0.4365\u001b[0m       0.7031        \u001b[35m0.5600\u001b[0m  0.0359\n",
      "     15        0.4372       \u001b[32m0.7188\u001b[0m        0.5602  0.0324\n",
      "     16        0.4373       0.6953        \u001b[35m0.5591\u001b[0m  0.0891\n",
      "     17        \u001b[36m0.4306\u001b[0m       0.7031        0.5608  0.0409\n",
      "     18        \u001b[36m0.4282\u001b[0m       0.7031        0.5608  0.0193\n",
      "     19        0.4314       0.6953        0.5717  0.0264\n",
      "     20        0.4325       0.7109        0.5630  0.0255\n",
      "     21        \u001b[36m0.4269\u001b[0m       0.6953        \u001b[35m0.5571\u001b[0m  0.0247\n",
      "     22        0.4298       0.7031        \u001b[35m0.5555\u001b[0m  0.0232\n",
      "     23        0.4276       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5482\u001b[0m  0.0297\n",
      "     24        \u001b[36m0.4255\u001b[0m       0.6953        0.5544  0.0315\n",
      "     25        \u001b[36m0.4227\u001b[0m       0.6875        0.5583  0.0599\n",
      "     26        0.4260       0.7344        0.5507  0.0479\n",
      "     27        \u001b[36m0.4203\u001b[0m       0.7188        0.5520  0.0218\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7519\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7170\u001b[0m  0.0232\n",
      "      2        \u001b[36m0.6943\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6756\u001b[0m  0.0139\n",
      "      3        \u001b[36m0.6606\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6391\u001b[0m  0.0182\n",
      "      4        \u001b[36m0.6343\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6041\u001b[0m  0.0181\n",
      "      5        \u001b[36m0.6115\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5712\u001b[0m  0.0118\n",
      "      6        \u001b[36m0.5937\u001b[0m       0.7500        \u001b[35m0.5449\u001b[0m  0.0116\n",
      "      7        \u001b[36m0.5689\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5217\u001b[0m  0.0114\n",
      "      8        0.5708       0.7578        \u001b[35m0.5041\u001b[0m  0.0113\n",
      "      9        \u001b[36m0.5544\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4889\u001b[0m  0.0224\n",
      "     10        \u001b[36m0.5441\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4772\u001b[0m  0.0145\n",
      "     11        \u001b[36m0.5400\u001b[0m       0.7812        \u001b[35m0.4652\u001b[0m  0.0184\n",
      "     12        \u001b[36m0.5284\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4557\u001b[0m  0.0155\n",
      "     13        0.5362       0.7969        \u001b[35m0.4503\u001b[0m  0.0147\n",
      "     14        \u001b[36m0.5161\u001b[0m       0.7969        \u001b[35m0.4425\u001b[0m  0.0197\n",
      "     15        0.5286       0.7969        \u001b[35m0.4374\u001b[0m  0.0136\n",
      "     16        0.5169       0.7969        \u001b[35m0.4336\u001b[0m  0.0176\n",
      "     17        0.5407       0.7969        \u001b[35m0.4323\u001b[0m  0.0205\n",
      "     18        0.5186       0.7969        \u001b[35m0.4290\u001b[0m  0.0132\n",
      "     19        \u001b[36m0.5026\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4253\u001b[0m  0.0151\n",
      "     20        0.5193       0.8047        \u001b[35m0.4233\u001b[0m  0.0150\n",
      "     21        0.5148       0.8047        \u001b[35m0.4208\u001b[0m  0.0175\n",
      "     22        0.5167       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4183\u001b[0m  0.0237\n",
      "     23        0.5120       0.8125        \u001b[35m0.4150\u001b[0m  0.0203\n",
      "     24        0.5065       0.8125        \u001b[35m0.4125\u001b[0m  0.0340\n",
      "     25        0.5213       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4120\u001b[0m  0.0227\n",
      "     26        0.5226       \u001b[32m0.8281\u001b[0m        0.4135  0.0244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     27        0.5137       0.8281        0.4133  0.0630\n",
      "     28        0.5134       0.8125        \u001b[35m0.4117\u001b[0m  0.0268\n",
      "     29        0.5063       0.8281        \u001b[35m0.4103\u001b[0m  0.0386\n",
      "     30        0.5094       0.8281        \u001b[35m0.4085\u001b[0m  0.0312\n",
      "     31        0.5143       0.8203        0.4089  0.0251\n",
      "     32        \u001b[36m0.4961\u001b[0m       0.8125        0.4087  0.0303\n",
      "     33        \u001b[36m0.4955\u001b[0m       0.8125        \u001b[35m0.4066\u001b[0m  0.0286\n",
      "     34        \u001b[36m0.4900\u001b[0m       0.8125        \u001b[35m0.4036\u001b[0m  0.0426\n",
      "     35        \u001b[36m0.4884\u001b[0m       0.8125        \u001b[35m0.4017\u001b[0m  0.0555\n",
      "     36        \u001b[36m0.4878\u001b[0m       0.8125        \u001b[35m0.4001\u001b[0m  0.0359\n",
      "     37        \u001b[36m0.4878\u001b[0m       0.8203        \u001b[35m0.3986\u001b[0m  0.0163\n",
      "     38        0.5133       0.8203        0.4001  0.0353\n",
      "     39        0.4910       0.8203        0.3993  0.0288\n",
      "     40        0.4919       0.8203        \u001b[35m0.3972\u001b[0m  0.0314\n",
      "     41        0.4930       0.8125        \u001b[35m0.3953\u001b[0m  0.0212\n",
      "     42        0.5071       0.8125        0.3965  0.0148\n",
      "     43        \u001b[36m0.4812\u001b[0m       0.8203        \u001b[35m0.3950\u001b[0m  0.0155\n",
      "     44        0.4947       0.8203        0.3959  0.0193\n",
      "     45        0.5000       0.8203        0.3957  0.0159\n",
      "     46        0.4864       0.8203        \u001b[35m0.3949\u001b[0m  0.0278\n",
      "     47        0.4978       0.8203        0.3961  0.0138\n",
      "     48        0.4872       0.8203        0.3962  0.0158\n",
      "     49        0.4989       0.8203        0.3969  0.0294\n",
      "     50        0.4834       0.8203        0.3965  0.0550\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7221\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6990\u001b[0m  0.0248\n",
      "      2        \u001b[36m0.6831\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6775\u001b[0m  0.0308\n",
      "      3        \u001b[36m0.6655\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6617\u001b[0m  0.0282\n",
      "      4        \u001b[36m0.6356\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6448\u001b[0m  0.0349\n",
      "      5        \u001b[36m0.6272\u001b[0m       0.6875        \u001b[35m0.6315\u001b[0m  0.0264\n",
      "      6        \u001b[36m0.6164\u001b[0m       0.6797        \u001b[35m0.6186\u001b[0m  0.0327\n",
      "      7        \u001b[36m0.6024\u001b[0m       0.6875        \u001b[35m0.6080\u001b[0m  0.0208\n",
      "      8        \u001b[36m0.5911\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5980\u001b[0m  0.0225\n",
      "      9        0.5947       0.6875        \u001b[35m0.5906\u001b[0m  0.0240\n",
      "     10        \u001b[36m0.5661\u001b[0m       0.6875        \u001b[35m0.5831\u001b[0m  0.0256\n",
      "     11        \u001b[36m0.5643\u001b[0m       0.6875        \u001b[35m0.5772\u001b[0m  0.0221\n",
      "     12        0.5666       0.6875        \u001b[35m0.5720\u001b[0m  0.0170\n",
      "     13        \u001b[36m0.5589\u001b[0m       0.6953        \u001b[35m0.5675\u001b[0m  0.0240\n",
      "     14        0.5616       0.6875        \u001b[35m0.5635\u001b[0m  0.0245\n",
      "     15        \u001b[36m0.5470\u001b[0m       0.6953        \u001b[35m0.5603\u001b[0m  0.0144\n",
      "     16        \u001b[36m0.5459\u001b[0m       0.6953        \u001b[35m0.5579\u001b[0m  0.0394\n",
      "     17        \u001b[36m0.5300\u001b[0m       0.6953        \u001b[35m0.5555\u001b[0m  0.0343\n",
      "     18        0.5430       0.6953        \u001b[35m0.5539\u001b[0m  0.0318\n",
      "     19        0.5374       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5518\u001b[0m  0.0349\n",
      "     20        \u001b[36m0.5287\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5497\u001b[0m  0.0290\n",
      "     21        \u001b[36m0.5269\u001b[0m       0.7188        \u001b[35m0.5490\u001b[0m  0.0224\n",
      "     22        \u001b[36m0.5243\u001b[0m       0.7188        \u001b[35m0.5481\u001b[0m  0.0412\n",
      "     23        0.5289       0.7109        \u001b[35m0.5469\u001b[0m  0.0893\n",
      "     24        \u001b[36m0.5152\u001b[0m       0.7109        \u001b[35m0.5459\u001b[0m  0.0245\n",
      "     25        0.5185       0.7109        0.5461  0.0274\n",
      "     26        \u001b[36m0.5128\u001b[0m       0.7188        \u001b[35m0.5454\u001b[0m  0.0241\n",
      "     27        \u001b[36m0.5056\u001b[0m       0.7031        0.5473  0.0235\n",
      "     28        0.5097       0.7109        0.5470  0.0303\n",
      "     29        0.5058       0.7109        0.5467  0.0297\n",
      "     30        0.5185       0.7266        0.5469  0.0337\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7022\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6675\u001b[0m  0.0298\n",
      "      2        \u001b[36m0.6622\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6428\u001b[0m  0.0258\n",
      "      3        \u001b[36m0.6430\u001b[0m       0.6953        \u001b[35m0.6218\u001b[0m  0.0219\n",
      "      4        \u001b[36m0.6239\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6040\u001b[0m  0.0266\n",
      "      5        \u001b[36m0.6007\u001b[0m       0.6875        \u001b[35m0.5874\u001b[0m  0.0169\n",
      "      6        \u001b[36m0.5787\u001b[0m       0.6797        \u001b[35m0.5756\u001b[0m  0.0188\n",
      "      7        \u001b[36m0.5636\u001b[0m       0.6562        \u001b[35m0.5666\u001b[0m  0.0146\n",
      "      8        \u001b[36m0.5483\u001b[0m       0.6562        \u001b[35m0.5609\u001b[0m  0.0221\n",
      "      9        \u001b[36m0.5339\u001b[0m       0.6719        \u001b[35m0.5577\u001b[0m  0.0209\n",
      "     10        \u001b[36m0.5326\u001b[0m       0.6641        \u001b[35m0.5549\u001b[0m  0.0261\n",
      "     11        0.5345       0.6562        \u001b[35m0.5542\u001b[0m  0.0241\n",
      "     12        \u001b[36m0.5243\u001b[0m       0.6641        \u001b[35m0.5529\u001b[0m  0.0242\n",
      "     13        0.5247       0.6953        0.5531  0.0137\n",
      "     14        \u001b[36m0.5186\u001b[0m       0.6953        \u001b[35m0.5520\u001b[0m  0.0147\n",
      "     15        0.5209       0.6953        \u001b[35m0.5516\u001b[0m  0.0129\n",
      "     16        \u001b[36m0.5146\u001b[0m       0.6875        \u001b[35m0.5498\u001b[0m  0.0253\n",
      "     17        \u001b[36m0.5096\u001b[0m       0.6875        \u001b[35m0.5487\u001b[0m  0.0228\n",
      "     18        \u001b[36m0.5051\u001b[0m       0.6797        \u001b[35m0.5482\u001b[0m  0.0153\n",
      "     19        0.5156       0.6797        \u001b[35m0.5465\u001b[0m  0.0211\n",
      "     20        0.5139       0.6797        \u001b[35m0.5458\u001b[0m  0.0269\n",
      "     21        0.5253       0.6797        \u001b[35m0.5449\u001b[0m  0.0269\n",
      "     22        0.5163       0.6875        \u001b[35m0.5439\u001b[0m  0.0486\n",
      "     23        0.5062       0.6875        0.5445  0.0155\n",
      "     24        \u001b[36m0.4919\u001b[0m       0.6875        0.5450  0.0183\n",
      "     25        0.5046       0.6875        0.5447  0.0382\n",
      "     26        0.5138       0.6875        \u001b[35m0.5431\u001b[0m  0.0220\n",
      "     27        0.4957       0.6875        \u001b[35m0.5429\u001b[0m  0.0254\n",
      "     28        0.4971       0.6875        0.5430  0.0269\n",
      "     29        0.5019       0.6875        0.5437  0.0244\n",
      "     30        0.4987       0.6875        \u001b[35m0.5424\u001b[0m  0.0285\n",
      "     31        0.4924       0.6875        0.5439  0.0394\n",
      "     32        0.5056       0.6875        \u001b[35m0.5415\u001b[0m  0.0281\n",
      "     33        0.4955       0.7031        0.5423  0.0221\n",
      "     34        0.4946       0.7031        \u001b[35m0.5411\u001b[0m  0.0259\n",
      "     35        0.4931       0.7031        0.5414  0.0241\n",
      "     36        0.4981       0.6953        \u001b[35m0.5410\u001b[0m  0.0245\n",
      "     37        \u001b[36m0.4915\u001b[0m       0.7031        \u001b[35m0.5394\u001b[0m  0.0280\n",
      "     38        0.5090       0.7031        \u001b[35m0.5380\u001b[0m  0.0345\n",
      "     39        0.4919       0.7031        0.5382  0.0361\n",
      "     40        0.4962       \u001b[32m0.7109\u001b[0m        0.5380  0.0201\n",
      "     41        \u001b[36m0.4914\u001b[0m       0.7031        \u001b[35m0.5379\u001b[0m  0.0383\n",
      "     42        0.5157       0.7031        \u001b[35m0.5376\u001b[0m  0.0284\n",
      "     43        0.4924       0.7031        0.5384  0.0202\n",
      "     44        \u001b[36m0.4737\u001b[0m       0.7031        0.5394  0.0512\n",
      "     45        0.4964       0.7031        0.5390  0.0703\n",
      "     46        0.4847       0.7109        0.5392  0.0624\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7346\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.6977\u001b[0m  0.0175\n",
      "      2        \u001b[36m0.6936\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6669\u001b[0m  0.0241\n",
      "      3        \u001b[36m0.6660\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6458\u001b[0m  0.0140\n",
      "      4        \u001b[36m0.6409\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6265\u001b[0m  0.0132\n",
      "      5        \u001b[36m0.6322\u001b[0m       0.7266        \u001b[35m0.6093\u001b[0m  0.0140\n",
      "      6        \u001b[36m0.6127\u001b[0m       0.7188        \u001b[35m0.5912\u001b[0m  0.0144\n",
      "      7        \u001b[36m0.5774\u001b[0m       0.7188        \u001b[35m0.5744\u001b[0m  0.0131\n",
      "      8        \u001b[36m0.5692\u001b[0m       0.7266        \u001b[35m0.5624\u001b[0m  0.0135\n",
      "      9        \u001b[36m0.5558\u001b[0m       0.7344        \u001b[35m0.5538\u001b[0m  0.0165\n",
      "     10        \u001b[36m0.5346\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5464\u001b[0m  0.0147\n",
      "     11        \u001b[36m0.5235\u001b[0m       0.7344        \u001b[35m0.5423\u001b[0m  0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12        0.5263       0.7422        \u001b[35m0.5394\u001b[0m  0.0138\n",
      "     13        \u001b[36m0.5228\u001b[0m       0.7422        \u001b[35m0.5365\u001b[0m  0.0133\n",
      "     14        \u001b[36m0.5106\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5345\u001b[0m  0.0159\n",
      "     15        \u001b[36m0.4975\u001b[0m       0.7422        \u001b[35m0.5344\u001b[0m  0.0138\n",
      "     16        0.5115       0.7500        \u001b[35m0.5328\u001b[0m  0.0148\n",
      "     17        0.5064       0.7422        \u001b[35m0.5316\u001b[0m  0.0224\n",
      "     18        \u001b[36m0.4910\u001b[0m       0.7188        0.5322  0.0157\n",
      "     19        0.5027       0.7344        \u001b[35m0.5303\u001b[0m  0.0212\n",
      "     20        0.5000       0.7266        \u001b[35m0.5296\u001b[0m  0.0133\n",
      "     21        0.4957       0.7188        0.5299  0.0128\n",
      "     22        0.4984       0.7266        \u001b[35m0.5283\u001b[0m  0.0205\n",
      "     23        0.5019       0.7188        \u001b[35m0.5276\u001b[0m  0.0170\n",
      "     24        \u001b[36m0.4846\u001b[0m       0.7109        0.5282  0.0221\n",
      "     25        0.4943       0.7188        0.5287  0.0413\n",
      "     26        0.4969       0.7188        0.5279  0.0255\n",
      "     27        0.4852       0.7188        \u001b[35m0.5268\u001b[0m  0.0311\n",
      "     28        0.4982       0.7188        \u001b[35m0.5265\u001b[0m  0.0316\n",
      "     29        0.4863       0.7188        0.5273  0.0459\n",
      "     30        0.4966       0.7188        \u001b[35m0.5249\u001b[0m  0.0184\n",
      "     31        0.4900       0.7188        \u001b[35m0.5245\u001b[0m  0.0366\n",
      "     32        0.4968       0.7188        \u001b[35m0.5245\u001b[0m  0.0560\n",
      "     33        \u001b[36m0.4785\u001b[0m       0.7188        \u001b[35m0.5222\u001b[0m  0.0417\n",
      "     34        0.4875       0.7188        0.5225  0.0308\n",
      "     35        0.4953       0.7109        \u001b[35m0.5216\u001b[0m  0.0210\n",
      "     36        0.4863       0.7188        0.5225  0.0144\n",
      "     37        0.4834       0.7266        0.5219  0.0381\n",
      "     38        0.4824       0.7266        0.5218  0.0179\n",
      "     39        0.4873       0.7188        0.5222  0.0259\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6995\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6581\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6444\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6191\u001b[0m  0.0253\n",
      "      3        \u001b[36m0.6069\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5925\u001b[0m  0.0271\n",
      "      4        \u001b[36m0.5664\u001b[0m       0.7109        \u001b[35m0.5724\u001b[0m  0.0177\n",
      "      5        \u001b[36m0.5439\u001b[0m       0.7031        \u001b[35m0.5609\u001b[0m  0.0251\n",
      "      6        \u001b[36m0.5378\u001b[0m       0.6953        \u001b[35m0.5548\u001b[0m  0.0328\n",
      "      7        \u001b[36m0.5265\u001b[0m       0.7109        \u001b[35m0.5500\u001b[0m  0.0229\n",
      "      8        \u001b[36m0.5239\u001b[0m       0.7031        \u001b[35m0.5486\u001b[0m  0.0181\n",
      "      9        \u001b[36m0.4883\u001b[0m       0.6953        \u001b[35m0.5478\u001b[0m  0.0243\n",
      "     10        0.5211       0.7109        0.5479  0.0292\n",
      "     11        0.5131       0.7109        0.5496  0.0238\n",
      "     12        0.5235       0.7109        0.5495  0.0181\n",
      "     13        0.4946       0.7109        0.5500  0.0150\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6834\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6601\u001b[0m  0.0242\n",
      "      2        \u001b[36m0.6529\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6273\u001b[0m  0.0330\n",
      "      3        \u001b[36m0.6437\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.6039\u001b[0m  0.0387\n",
      "      4        \u001b[36m0.6272\u001b[0m       0.7656        \u001b[35m0.5830\u001b[0m  0.0334\n",
      "      5        \u001b[36m0.6074\u001b[0m       0.7656        \u001b[35m0.5644\u001b[0m  0.0649\n",
      "      6        \u001b[36m0.6004\u001b[0m       0.7422        \u001b[35m0.5467\u001b[0m  0.0620\n",
      "      7        \u001b[36m0.5980\u001b[0m       0.7500        \u001b[35m0.5297\u001b[0m  0.0622\n",
      "      8        0.6014       0.7578        \u001b[35m0.5163\u001b[0m  0.0213\n",
      "      9        \u001b[36m0.5826\u001b[0m       0.7578        \u001b[35m0.5074\u001b[0m  0.0670\n",
      "     10        0.5841       0.7578        \u001b[35m0.4962\u001b[0m  0.0386\n",
      "     11        \u001b[36m0.5768\u001b[0m       0.7578        \u001b[35m0.4878\u001b[0m  0.0185\n",
      "     12        \u001b[36m0.5576\u001b[0m       0.7656        \u001b[35m0.4783\u001b[0m  0.0190\n",
      "     13        \u001b[36m0.5418\u001b[0m       0.7656        \u001b[35m0.4699\u001b[0m  0.0160\n",
      "     14        0.5749       0.7734        \u001b[35m0.4668\u001b[0m  0.0169\n",
      "     15        0.5747       0.7656        \u001b[35m0.4654\u001b[0m  0.0159\n",
      "     16        0.5532       0.7656        \u001b[35m0.4639\u001b[0m  0.0196\n",
      "     17        0.5727       0.7734        \u001b[35m0.4633\u001b[0m  0.0354\n",
      "     18        0.5435       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4569\u001b[0m  0.0310\n",
      "     19        0.5534       0.7812        \u001b[35m0.4533\u001b[0m  0.0265\n",
      "     20        0.5582       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4509\u001b[0m  0.0162\n",
      "     21        0.5567       0.7891        \u001b[35m0.4470\u001b[0m  0.0240\n",
      "     22        0.5491       0.7891        \u001b[35m0.4453\u001b[0m  0.0204\n",
      "     23        0.5646       \u001b[32m0.7969\u001b[0m        0.4462  0.0195\n",
      "     24        \u001b[36m0.5251\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4434\u001b[0m  0.0225\n",
      "     25        0.5637       0.8047        \u001b[35m0.4423\u001b[0m  0.0218\n",
      "     26        0.5300       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4387\u001b[0m  0.0180\n",
      "     27        0.5583       0.8047        0.4388  0.0161\n",
      "     28        \u001b[36m0.5233\u001b[0m       0.8125        \u001b[35m0.4340\u001b[0m  0.0184\n",
      "     29        0.5345       0.8125        \u001b[35m0.4322\u001b[0m  0.0197\n",
      "     30        0.5563       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4316\u001b[0m  0.0168\n",
      "     31        0.5371       0.8203        \u001b[35m0.4307\u001b[0m  0.0236\n",
      "     32        0.5615       \u001b[32m0.8281\u001b[0m        0.4310  0.0162\n",
      "     33        0.5464       0.8281        \u001b[35m0.4307\u001b[0m  0.0228\n",
      "     34        \u001b[36m0.5179\u001b[0m       0.8203        \u001b[35m0.4268\u001b[0m  0.0250\n",
      "     35        0.5360       0.8125        \u001b[35m0.4261\u001b[0m  0.0234\n",
      "     36        0.5506       0.8203        0.4268  0.0246\n",
      "     37        \u001b[36m0.5175\u001b[0m       0.8125        \u001b[35m0.4255\u001b[0m  0.0224\n",
      "     38        0.5490       0.8125        0.4285  0.0190\n",
      "     39        0.5515       0.8125        0.4299  0.0173\n",
      "     40        \u001b[36m0.5056\u001b[0m       0.8125        \u001b[35m0.4238\u001b[0m  0.0188\n",
      "     41        0.5462       0.8125        \u001b[35m0.4235\u001b[0m  0.0266\n",
      "     42        0.5213       0.8047        \u001b[35m0.4216\u001b[0m  0.0168\n",
      "     43        0.5332       0.7969        0.4224  0.0136\n",
      "     44        0.5477       0.7891        0.4247  0.0251\n",
      "     45        0.5529       0.8047        0.4282  0.0151\n",
      "     46        0.5310       0.8203        0.4266  0.0167\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6729\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6212\u001b[0m  0.0240\n",
      "      2        \u001b[36m0.6137\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5999\u001b[0m  0.0270\n",
      "      3        \u001b[36m0.6079\u001b[0m       0.6953        \u001b[35m0.5905\u001b[0m  0.0249\n",
      "      4        \u001b[36m0.6006\u001b[0m       0.6875        \u001b[35m0.5842\u001b[0m  0.0154\n",
      "      5        \u001b[36m0.5858\u001b[0m       0.6797        \u001b[35m0.5788\u001b[0m  0.0155\n",
      "      6        \u001b[36m0.5778\u001b[0m       0.6719        \u001b[35m0.5740\u001b[0m  0.0338\n",
      "      7        \u001b[36m0.5736\u001b[0m       0.6875        \u001b[35m0.5695\u001b[0m  0.0238\n",
      "      8        \u001b[36m0.5434\u001b[0m       0.6719        \u001b[35m0.5652\u001b[0m  0.0143\n",
      "      9        0.5707       0.6797        \u001b[35m0.5626\u001b[0m  0.0143\n",
      "     10        0.5734       0.6875        \u001b[35m0.5597\u001b[0m  0.0256\n",
      "     11        0.5593       0.6875        0.5602  0.0170\n",
      "     12        0.5783       0.6875        \u001b[35m0.5576\u001b[0m  0.0194\n",
      "     13        0.5460       0.6875        \u001b[35m0.5547\u001b[0m  0.0401\n",
      "     14        \u001b[36m0.5398\u001b[0m       0.6875        \u001b[35m0.5541\u001b[0m  0.0237\n",
      "     15        0.5476       0.6875        \u001b[35m0.5532\u001b[0m  0.0295\n",
      "     16        0.5761       0.6875        \u001b[35m0.5527\u001b[0m  0.0202\n",
      "     17        0.5570       0.6875        0.5530  0.0163\n",
      "     18        0.5937       0.6953        \u001b[35m0.5525\u001b[0m  0.0225\n",
      "     19        0.5544       0.6797        \u001b[35m0.5502\u001b[0m  0.0271\n",
      "     20        \u001b[36m0.5329\u001b[0m       0.6797        \u001b[35m0.5472\u001b[0m  0.0312\n",
      "     21        0.5464       0.6797        0.5475  0.0167\n",
      "     22        0.5454       0.6797        \u001b[35m0.5462\u001b[0m  0.0178\n",
      "     23        0.5450       0.6797        \u001b[35m0.5454\u001b[0m  0.0196\n",
      "     24        0.5492       0.6797        \u001b[35m0.5433\u001b[0m  0.0175\n",
      "     25        0.5514       0.6797        \u001b[35m0.5427\u001b[0m  0.0246\n",
      "     26        \u001b[36m0.5276\u001b[0m       0.6797        \u001b[35m0.5422\u001b[0m  0.0161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     27        0.5466       0.6719        0.5441  0.0176\n",
      "     28        0.5360       0.6719        \u001b[35m0.5420\u001b[0m  0.0183\n",
      "     29        0.5334       0.6719        \u001b[35m0.5418\u001b[0m  0.0177\n",
      "     30        0.5375       0.6719        \u001b[35m0.5413\u001b[0m  0.0227\n",
      "     31        0.5517       0.6719        \u001b[35m0.5387\u001b[0m  0.0231\n",
      "     32        0.5356       0.6797        \u001b[35m0.5376\u001b[0m  0.0256\n",
      "     33        0.5311       0.6797        \u001b[35m0.5362\u001b[0m  0.0144\n",
      "     34        \u001b[36m0.5210\u001b[0m       0.6797        \u001b[35m0.5362\u001b[0m  0.0190\n",
      "     35        0.5383       0.6797        \u001b[35m0.5348\u001b[0m  0.0298\n",
      "     36        0.5283       0.6875        \u001b[35m0.5337\u001b[0m  0.0145\n",
      "     37        0.5414       0.6875        0.5340  0.0227\n",
      "     38        0.5289       0.6797        0.5345  0.0211\n",
      "     39        \u001b[36m0.5186\u001b[0m       0.6797        0.5349  0.0246\n",
      "     40        0.5439       0.6875        0.5338  0.0256\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6881\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6618\u001b[0m  0.0139\n",
      "      2        \u001b[36m0.6468\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6236\u001b[0m  0.0201\n",
      "      3        \u001b[36m0.6082\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5930\u001b[0m  0.0168\n",
      "      4        \u001b[36m0.5890\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5734\u001b[0m  0.0279\n",
      "      5        \u001b[36m0.5754\u001b[0m       0.7344        \u001b[35m0.5594\u001b[0m  0.0185\n",
      "      6        \u001b[36m0.5676\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5469\u001b[0m  0.0382\n",
      "      7        \u001b[36m0.5568\u001b[0m       0.7422        \u001b[35m0.5396\u001b[0m  0.0165\n",
      "      8        \u001b[36m0.5480\u001b[0m       0.7422        \u001b[35m0.5365\u001b[0m  0.0378\n",
      "      9        \u001b[36m0.5406\u001b[0m       0.7422        \u001b[35m0.5344\u001b[0m  0.0259\n",
      "     10        0.5541       0.7344        \u001b[35m0.5325\u001b[0m  0.0144\n",
      "     11        \u001b[36m0.5361\u001b[0m       0.7266        \u001b[35m0.5298\u001b[0m  0.0253\n",
      "     12        0.5376       0.7109        \u001b[35m0.5275\u001b[0m  0.0279\n",
      "     13        \u001b[36m0.5245\u001b[0m       0.6875        \u001b[35m0.5274\u001b[0m  0.0170\n",
      "     14        0.5492       0.6953        \u001b[35m0.5270\u001b[0m  0.0211\n",
      "     15        0.5312       0.6953        0.5274  0.0300\n",
      "     16        0.5471       0.6953        0.5290  0.0256\n",
      "     17        0.5329       0.7031        0.5284  0.0254\n",
      "     18        0.5364       0.7031        0.5271  0.0254\n",
      "     19        0.5255       0.7109        \u001b[35m0.5265\u001b[0m  0.0184\n",
      "     20        0.5397       0.7031        0.5270  0.0197\n",
      "     21        0.5371       0.7031        0.5275  0.0263\n",
      "     22        0.5377       0.7109        \u001b[35m0.5263\u001b[0m  0.0171\n",
      "     23        0.5401       0.7031        0.5290  0.0217\n",
      "     24        \u001b[36m0.5147\u001b[0m       0.6953        0.5294  0.0162\n",
      "     25        0.5255       0.7031        \u001b[35m0.5259\u001b[0m  0.0317\n",
      "     26        0.5310       0.7031        0.5263  0.0163\n",
      "     27        \u001b[36m0.5009\u001b[0m       0.7188        0.5266  0.0239\n",
      "     28        0.5464       0.7109        0.5290  0.0206\n",
      "     29        0.5171       0.7109        0.5274  0.0170\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7427\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.6891\u001b[0m  0.0258\n",
      "      2        \u001b[36m0.6835\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6571\u001b[0m  0.0233\n",
      "      3        \u001b[36m0.6434\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6307\u001b[0m  0.0236\n",
      "      4        \u001b[36m0.6232\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6061\u001b[0m  0.0125\n",
      "      5        \u001b[36m0.6119\u001b[0m       0.7188        \u001b[35m0.5858\u001b[0m  0.0324\n",
      "      6        \u001b[36m0.6028\u001b[0m       0.7188        \u001b[35m0.5738\u001b[0m  0.0228\n",
      "      7        \u001b[36m0.5950\u001b[0m       0.7188        \u001b[35m0.5654\u001b[0m  0.0400\n",
      "      8        \u001b[36m0.5773\u001b[0m       0.7188        \u001b[35m0.5566\u001b[0m  0.0227\n",
      "      9        \u001b[36m0.5696\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5502\u001b[0m  0.0347\n",
      "     10        0.5701       0.7266        \u001b[35m0.5469\u001b[0m  0.0225\n",
      "     11        \u001b[36m0.5583\u001b[0m       0.7344        \u001b[35m0.5422\u001b[0m  0.0161\n",
      "     12        \u001b[36m0.5535\u001b[0m       0.7266        \u001b[35m0.5385\u001b[0m  0.0323\n",
      "     13        0.5605       0.7266        \u001b[35m0.5378\u001b[0m  0.0171\n",
      "     14        0.5626       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5375\u001b[0m  0.0206\n",
      "     15        0.5610       0.7422        \u001b[35m0.5369\u001b[0m  0.0209\n",
      "     16        \u001b[36m0.5294\u001b[0m       0.7344        \u001b[35m0.5349\u001b[0m  0.0291\n",
      "     17        0.5350       0.7109        \u001b[35m0.5331\u001b[0m  0.0218\n",
      "     18        0.5411       0.7266        \u001b[35m0.5311\u001b[0m  0.0248\n",
      "     19        0.5403       0.7422        \u001b[35m0.5294\u001b[0m  0.0215\n",
      "     20        \u001b[36m0.5272\u001b[0m       0.7266        \u001b[35m0.5278\u001b[0m  0.0391\n",
      "     21        0.5320       0.7266        \u001b[35m0.5278\u001b[0m  0.0264\n",
      "     22        \u001b[36m0.5169\u001b[0m       0.7266        \u001b[35m0.5265\u001b[0m  0.0167\n",
      "     23        0.5469       0.7266        \u001b[35m0.5264\u001b[0m  0.0246\n",
      "     24        0.5693       0.7266        0.5277  0.0245\n",
      "     25        0.5422       0.7266        0.5282  0.0380\n",
      "     26        0.5394       0.7188        \u001b[35m0.5261\u001b[0m  0.0238\n",
      "     27        0.5379       0.7188        0.5265  0.0248\n",
      "     28        0.5306       0.7109        \u001b[35m0.5251\u001b[0m  0.0141\n",
      "     29        \u001b[36m0.5026\u001b[0m       0.7109        \u001b[35m0.5230\u001b[0m  0.0249\n",
      "     30        0.5373       0.7109        0.5232  0.0184\n",
      "     31        0.5364       0.7266        0.5239  0.0198\n",
      "     32        0.5123       0.7266        \u001b[35m0.5223\u001b[0m  0.0179\n",
      "     33        0.5410       0.7188        \u001b[35m0.5221\u001b[0m  0.0368\n",
      "     34        0.5307       0.7188        0.5223  0.0205\n",
      "     35        0.5343       0.7109        0.5225  0.0186\n",
      "     36        0.5228       0.7109        \u001b[35m0.5210\u001b[0m  0.0176\n",
      "     37        0.5033       0.7109        \u001b[35m0.5197\u001b[0m  0.0240\n",
      "     38        0.5177       0.7188        0.5203  0.0252\n",
      "     39        0.5231       0.7109        0.5205  0.0221\n",
      "     40        0.5095       0.7109        0.5215  0.0171\n",
      "     41        0.5331       0.7109        0.5198  0.0181\n",
      "     42        \u001b[36m0.4973\u001b[0m       0.7188        \u001b[35m0.5188\u001b[0m  0.0244\n",
      "     43        \u001b[36m0.4903\u001b[0m       0.7109        \u001b[35m0.5178\u001b[0m  0.0220\n",
      "     44        0.5148       0.7109        \u001b[35m0.5168\u001b[0m  0.0202\n",
      "     45        0.5173       0.7188        \u001b[35m0.5164\u001b[0m  0.0261\n",
      "     46        0.5060       0.7266        \u001b[35m0.5155\u001b[0m  0.0231\n",
      "     47        0.5088       0.7188        \u001b[35m0.5154\u001b[0m  0.0269\n",
      "     48        0.5185       0.7109        \u001b[35m0.5149\u001b[0m  0.0291\n",
      "     49        0.5115       0.7109        0.5156  0.0396\n",
      "     50        0.4991       0.7109        0.5172  0.0322\n",
      "     51        0.4930       0.7188        0.5172  0.0413\n",
      "     52        0.4908       0.7109        0.5171  0.0353\n",
      "     53        0.5152       0.7109        \u001b[35m0.5144\u001b[0m  0.0315\n",
      "     54        0.5130       0.7109        \u001b[35m0.5139\u001b[0m  0.0243\n",
      "     55        0.5087       0.7188        \u001b[35m0.5132\u001b[0m  0.0329\n",
      "     56        0.4927       0.7188        0.5141  0.0430\n",
      "     57        0.4946       0.7188        0.5139  0.0226\n",
      "     58        0.5041       0.7188        \u001b[35m0.5125\u001b[0m  0.0268\n",
      "     59        \u001b[36m0.4864\u001b[0m       0.7188        0.5129  0.0167\n",
      "     60        0.4888       0.7266        0.5132  0.0294\n",
      "     61        0.4938       0.7266        \u001b[35m0.5122\u001b[0m  0.0229\n",
      "     62        0.4928       0.7266        0.5124  0.0149\n",
      "     63        0.4976       0.7266        0.5135  0.0261\n",
      "     64        0.5003       0.7266        0.5134  0.0184\n",
      "     65        0.4963       0.7344        0.5130  0.0239\n",
      "     66        0.4895       0.7344        \u001b[35m0.5121\u001b[0m  0.0156\n",
      "     67        \u001b[36m0.4810\u001b[0m       0.7344        0.5142  0.0163\n",
      "     68        0.4909       0.7344        0.5128  0.0250\n",
      "     69        0.5118       0.7344        0.5121  0.0349\n",
      "     70        0.4993       0.7266        \u001b[35m0.5120\u001b[0m  0.0173\n",
      "     71        0.4889       0.7266        0.5152  0.0162\n",
      "     72        0.4867       0.7266        0.5159  0.0171\n",
      "     73        \u001b[36m0.4760\u001b[0m       0.7344        0.5171  0.0160\n",
      "     74        0.4893       0.7266        0.5173  0.0261\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6593\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5941\u001b[0m  0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.6448\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5738\u001b[0m  0.0409\n",
      "      3        \u001b[36m0.5977\u001b[0m       0.7500        \u001b[35m0.5595\u001b[0m  0.0171\n",
      "      4        \u001b[36m0.5906\u001b[0m       0.7422        \u001b[35m0.5523\u001b[0m  0.0306\n",
      "      5        \u001b[36m0.5630\u001b[0m       0.7344        \u001b[35m0.5432\u001b[0m  0.0317\n",
      "      6        \u001b[36m0.5483\u001b[0m       0.7344        \u001b[35m0.5371\u001b[0m  0.0402\n",
      "      7        \u001b[36m0.5386\u001b[0m       0.7422        \u001b[35m0.5351\u001b[0m  0.0174\n",
      "      8        0.5424       0.7266        \u001b[35m0.5302\u001b[0m  0.0213\n",
      "      9        0.5462       0.7266        \u001b[35m0.5278\u001b[0m  0.0301\n",
      "     10        \u001b[36m0.5294\u001b[0m       0.7266        \u001b[35m0.5238\u001b[0m  0.0150\n",
      "     11        \u001b[36m0.5262\u001b[0m       0.7266        \u001b[35m0.5206\u001b[0m  0.0366\n",
      "     12        0.5272       0.7266        0.5209  0.0159\n",
      "     13        0.5276       0.7266        0.5207  0.0254\n",
      "     14        \u001b[36m0.5174\u001b[0m       0.7031        \u001b[35m0.5201\u001b[0m  0.0152\n",
      "     15        0.5285       0.7344        \u001b[35m0.5187\u001b[0m  0.0292\n",
      "     16        0.5255       0.7266        0.5190  0.0160\n",
      "     17        0.5305       0.7266        \u001b[35m0.5186\u001b[0m  0.0241\n",
      "     18        \u001b[36m0.5171\u001b[0m       0.7266        \u001b[35m0.5178\u001b[0m  0.0133\n",
      "     19        \u001b[36m0.4964\u001b[0m       0.7266        \u001b[35m0.5172\u001b[0m  0.0130\n",
      "     20        0.5169       0.7188        0.5182  0.0345\n",
      "     21        0.5297       0.7188        0.5174  0.0151\n",
      "     22        0.5022       0.7188        0.5183  0.0364\n",
      "     23        \u001b[36m0.4944\u001b[0m       0.7188        0.5194  0.0216\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6934\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5167\u001b[0m  0.0251\n",
      "      2        \u001b[36m0.6327\u001b[0m       0.7031        0.5364  0.0183\n",
      "      3        0.7091       0.7500        0.7335  0.0152\n",
      "      4        0.6862       0.5000        0.6513  0.0295\n",
      "      5        \u001b[36m0.6294\u001b[0m       0.7109        0.5993  0.0153\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5794\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5408\u001b[0m  0.0169\n",
      "      2        \u001b[36m0.5153\u001b[0m       0.6875        0.6234  0.0244\n",
      "      3        0.5278       0.6797        0.5440  0.0153\n",
      "      4        0.5848       0.6641        0.5719  0.0248\n",
      "      5        0.5269       \u001b[32m0.7109\u001b[0m        0.7101  0.0267\n",
      "      6        0.5374       0.7109        \u001b[35m0.5221\u001b[0m  0.0160\n",
      "      7        0.5398       0.6953        0.5719  0.0315\n",
      "      8        \u001b[36m0.5029\u001b[0m       0.6953        0.5239  0.0182\n",
      "      9        \u001b[36m0.5004\u001b[0m       0.6719        0.5748  0.0180\n",
      "     10        0.5239       0.6484        0.5691  0.0290\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5973\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6724\u001b[0m  0.0184\n",
      "      2        \u001b[36m0.5510\u001b[0m       \u001b[32m0.7500\u001b[0m        0.7616  0.0300\n",
      "      3        0.5874       0.7109        \u001b[35m0.6101\u001b[0m  0.0154\n",
      "      4        \u001b[36m0.5306\u001b[0m       0.7422        0.6431  0.0166\n",
      "      5        \u001b[36m0.5260\u001b[0m       0.7188        \u001b[35m0.5595\u001b[0m  0.0381\n",
      "      6        \u001b[36m0.5066\u001b[0m       0.7422        0.6271  0.0218\n",
      "      7        0.5655       0.6719        0.6737  0.0245\n",
      "      8        0.5374       0.7109        0.5825  0.0145\n",
      "      9        0.5335       0.7266        0.6271  0.0174\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5932\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6383\u001b[0m  0.0162\n",
      "      2        0.6393       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5361\u001b[0m  0.0325\n",
      "      3        \u001b[36m0.5875\u001b[0m       0.6953        0.5466  0.0135\n",
      "      4        \u001b[36m0.5149\u001b[0m       0.7266        0.6961  0.0291\n",
      "      5        \u001b[36m0.5022\u001b[0m       0.6953        \u001b[35m0.5343\u001b[0m  0.0479\n",
      "      6        0.5340       0.6484        0.6168  0.0383\n",
      "      7        0.5166       0.6875        0.5464  0.0416\n",
      "      8        0.5190       0.7344        \u001b[35m0.5303\u001b[0m  0.0402\n",
      "      9        \u001b[36m0.4925\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4960\u001b[0m  0.0164\n",
      "     10        0.5083       0.7344        0.5140  0.0226\n",
      "     11        \u001b[36m0.4762\u001b[0m       0.7578        0.5791  0.0777\n",
      "     12        \u001b[36m0.4723\u001b[0m       0.7344        0.5384  0.0166\n",
      "     13        0.5052       0.7344        0.5408  0.0281\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6139\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6907\u001b[0m  0.0235\n",
      "      2        0.6726       0.6406        0.7505  0.0162\n",
      "      3        0.7123       \u001b[32m0.7422\u001b[0m        0.7759  0.0128\n",
      "      4        \u001b[36m0.5357\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5366\u001b[0m  0.0249\n",
      "      5        \u001b[36m0.5237\u001b[0m       0.6797        0.6372  0.0355\n",
      "      6        0.5465       0.7344        0.6705  0.0154\n",
      "      7        \u001b[36m0.4880\u001b[0m       0.7031        0.7091  0.0222\n",
      "      8        \u001b[36m0.4851\u001b[0m       0.7188        0.5556  0.0131\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7009\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6461\u001b[0m  0.0422\n",
      "      2        \u001b[36m0.6381\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5709\u001b[0m  0.0770\n",
      "      3        \u001b[36m0.5819\u001b[0m       0.7500        \u001b[35m0.5104\u001b[0m  0.1011\n",
      "      4        \u001b[36m0.5498\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4709\u001b[0m  0.0916\n",
      "      5        \u001b[36m0.5289\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4416\u001b[0m  0.0434\n",
      "      6        \u001b[36m0.5286\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4322\u001b[0m  0.0534\n",
      "      7        \u001b[36m0.5221\u001b[0m       0.8125        \u001b[35m0.4242\u001b[0m  0.0638\n",
      "      8        \u001b[36m0.5176\u001b[0m       0.8125        \u001b[35m0.4180\u001b[0m  0.0439\n",
      "      9        \u001b[36m0.5009\u001b[0m       0.8125        \u001b[35m0.4075\u001b[0m  0.0460\n",
      "     10        \u001b[36m0.4919\u001b[0m       \u001b[32m0.8281\u001b[0m        0.4080  0.0481\n",
      "     11        0.5048       \u001b[32m0.8359\u001b[0m        \u001b[35m0.4031\u001b[0m  0.0438\n",
      "     12        0.4942       0.8281        0.4044  0.0429\n",
      "     13        0.5015       0.8359        0.4064  0.0360\n",
      "     14        \u001b[36m0.4857\u001b[0m       0.8359        \u001b[35m0.3957\u001b[0m  0.0370\n",
      "     15        \u001b[36m0.4809\u001b[0m       0.8203        \u001b[35m0.3948\u001b[0m  0.0404\n",
      "     16        \u001b[36m0.4727\u001b[0m       0.8281        0.3996  0.0359\n",
      "     17        0.4916       0.8281        0.3967  0.0421\n",
      "     18        0.4870       0.8125        0.4039  0.0331\n",
      "     19        0.4884       0.8125        0.4043  0.0383\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6859\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6488\u001b[0m  0.0387\n",
      "      2        \u001b[36m0.6141\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5690\u001b[0m  0.0427\n",
      "      3        \u001b[36m0.5768\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5379\u001b[0m  0.0431\n",
      "      4        \u001b[36m0.5649\u001b[0m       0.7266        \u001b[35m0.5326\u001b[0m  0.0443\n",
      "      5        \u001b[36m0.5284\u001b[0m       0.7188        \u001b[35m0.5295\u001b[0m  0.0403\n",
      "      6        0.5350       0.7266        \u001b[35m0.5279\u001b[0m  0.0418\n",
      "      7        0.5331       0.7266        \u001b[35m0.5277\u001b[0m  0.0363\n",
      "      8        0.5469       0.7266        0.5282  0.0420\n",
      "      9        0.5317       0.7109        0.5321  0.0339\n",
      "     10        0.5394       0.7109        0.5312  0.0408\n",
      "     11        \u001b[36m0.5116\u001b[0m       0.7031        0.5356  0.0464\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7142\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6841\u001b[0m  0.0311\n",
      "      2        \u001b[36m0.6866\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6637\u001b[0m  0.0314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        \u001b[36m0.6552\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6196\u001b[0m  0.0448\n",
      "      4        \u001b[36m0.6051\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5680\u001b[0m  0.0407\n",
      "      5        \u001b[36m0.5730\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5385\u001b[0m  0.0359\n",
      "      6        \u001b[36m0.5632\u001b[0m       0.7188        \u001b[35m0.5280\u001b[0m  0.0399\n",
      "      7        \u001b[36m0.5412\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5218\u001b[0m  0.0346\n",
      "      8        \u001b[36m0.5129\u001b[0m       0.7266        \u001b[35m0.5179\u001b[0m  0.0384\n",
      "      9        0.5210       0.7266        \u001b[35m0.5168\u001b[0m  0.0359\n",
      "     10        0.5282       0.7188        0.5186  0.0333\n",
      "     11        0.5248       0.7344        0.5209  0.0419\n",
      "     12        \u001b[36m0.4936\u001b[0m       0.7109        0.5251  0.0327\n",
      "     13        0.5032       0.7188        0.5260  0.0386\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6467\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6158\u001b[0m  0.0319\n",
      "      2        \u001b[36m0.5730\u001b[0m       0.7031        \u001b[35m0.5548\u001b[0m  0.0329\n",
      "      3        \u001b[36m0.5423\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5336\u001b[0m  0.0414\n",
      "      4        \u001b[36m0.5223\u001b[0m       0.7188        \u001b[35m0.5270\u001b[0m  0.0344\n",
      "      5        \u001b[36m0.5187\u001b[0m       0.7031        0.5291  0.0420\n",
      "      6        \u001b[36m0.4964\u001b[0m       0.7188        0.5292  0.0348\n",
      "      7        \u001b[36m0.4929\u001b[0m       0.7031        0.5300  0.0374\n",
      "      8        \u001b[36m0.4843\u001b[0m       0.7031        0.5299  0.0396\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6914\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6585\u001b[0m  0.0290\n",
      "      2        \u001b[36m0.6243\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5865\u001b[0m  0.0327\n",
      "      3        \u001b[36m0.5348\u001b[0m       0.7031        \u001b[35m0.5471\u001b[0m  0.0382\n",
      "      4        \u001b[36m0.4943\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5397\u001b[0m  0.0326\n",
      "      5        \u001b[36m0.4906\u001b[0m       0.7109        \u001b[35m0.5387\u001b[0m  0.0398\n",
      "      6        \u001b[36m0.4797\u001b[0m       0.7109        \u001b[35m0.5313\u001b[0m  0.0384\n",
      "      7        0.4920       0.7188        \u001b[35m0.5305\u001b[0m  0.0321\n",
      "      8        \u001b[36m0.4684\u001b[0m       0.7109        0.5347  0.0404\n",
      "      9        \u001b[36m0.4607\u001b[0m       0.7266        0.5323  0.0328\n",
      "     10        \u001b[36m0.4544\u001b[0m       0.7188        0.5331  0.0403\n",
      "     11        0.4588       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5260\u001b[0m  0.0333\n",
      "     12        0.4589       0.7344        0.5281  0.0460\n",
      "     13        0.4674       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5240\u001b[0m  0.0418\n",
      "     14        0.4549       0.7422        \u001b[35m0.5238\u001b[0m  0.0335\n",
      "     15        \u001b[36m0.4461\u001b[0m       0.7344        0.5273  0.0393\n",
      "     16        0.4515       0.7344        0.5239  0.0326\n",
      "     17        0.4594       0.7344        \u001b[35m0.5197\u001b[0m  0.0412\n",
      "     18        0.4536       0.7344        0.5227  0.0426\n",
      "     19        0.4574       0.7422        0.5262  0.0326\n",
      "     20        \u001b[36m0.4455\u001b[0m       0.7422        \u001b[35m0.5190\u001b[0m  0.0393\n",
      "     21        \u001b[36m0.4452\u001b[0m       0.7422        0.5258  0.0332\n",
      "     22        0.4511       0.7422        0.5242  0.0391\n",
      "     23        0.4459       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5181\u001b[0m  0.0342\n",
      "     24        \u001b[36m0.4371\u001b[0m       0.7422        0.5217  0.0412\n",
      "     25        \u001b[36m0.4244\u001b[0m       0.7422        \u001b[35m0.5172\u001b[0m  0.0397\n",
      "     26        0.4395       0.7422        0.5223  0.0407\n",
      "     27        0.4245       0.7344        0.5215  0.0436\n",
      "     28        \u001b[36m0.4096\u001b[0m       0.7344        0.5238  0.0391\n",
      "     29        0.4312       0.7344        0.5184  0.0455\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6873\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6351\u001b[0m  0.0144\n",
      "      2        \u001b[36m0.6305\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5830\u001b[0m  0.0168\n",
      "      3        \u001b[36m0.6002\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.5441\u001b[0m  0.0325\n",
      "      4        \u001b[36m0.5861\u001b[0m       0.8047        \u001b[35m0.5165\u001b[0m  0.0164\n",
      "      5        \u001b[36m0.5536\u001b[0m       0.7969        \u001b[35m0.4936\u001b[0m  0.0191\n",
      "      6        \u001b[36m0.5391\u001b[0m       0.7969        \u001b[35m0.4765\u001b[0m  0.0311\n",
      "      7        0.5444       0.7891        \u001b[35m0.4642\u001b[0m  0.0163\n",
      "      8        \u001b[36m0.5272\u001b[0m       0.8047        \u001b[35m0.4523\u001b[0m  0.0238\n",
      "      9        0.5288       0.8047        \u001b[35m0.4453\u001b[0m  0.0189\n",
      "     10        0.5369       0.8047        \u001b[35m0.4407\u001b[0m  0.0292\n",
      "     11        \u001b[36m0.5205\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4370\u001b[0m  0.0222\n",
      "     12        0.5241       0.8125        \u001b[35m0.4331\u001b[0m  0.0224\n",
      "     13        \u001b[36m0.5197\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4301\u001b[0m  0.0248\n",
      "     14        0.5228       0.8203        \u001b[35m0.4291\u001b[0m  0.0171\n",
      "     15        0.5269       0.8203        \u001b[35m0.4279\u001b[0m  0.0134\n",
      "     16        0.5199       0.8203        \u001b[35m0.4262\u001b[0m  0.0334\n",
      "     17        \u001b[36m0.5046\u001b[0m       0.8125        \u001b[35m0.4233\u001b[0m  0.0191\n",
      "     18        0.5057       0.8203        \u001b[35m0.4199\u001b[0m  0.0137\n",
      "     19        0.5119       0.8125        \u001b[35m0.4188\u001b[0m  0.0323\n",
      "     20        0.5093       0.8125        \u001b[35m0.4174\u001b[0m  0.0162\n",
      "     21        0.5155       \u001b[32m0.8281\u001b[0m        0.4179  0.0158\n",
      "     22        \u001b[36m0.5032\u001b[0m       0.8281        \u001b[35m0.4144\u001b[0m  0.0328\n",
      "     23        \u001b[36m0.4949\u001b[0m       0.8281        \u001b[35m0.4116\u001b[0m  0.0205\n",
      "     24        0.5075       \u001b[32m0.8359\u001b[0m        \u001b[35m0.4101\u001b[0m  0.0160\n",
      "     25        0.5116       \u001b[32m0.8438\u001b[0m        \u001b[35m0.4082\u001b[0m  0.0166\n",
      "     26        0.5031       0.8359        \u001b[35m0.4066\u001b[0m  0.0252\n",
      "     27        0.4979       0.8438        0.4075  0.0183\n",
      "     28        \u001b[36m0.4876\u001b[0m       \u001b[32m0.8516\u001b[0m        \u001b[35m0.4035\u001b[0m  0.0212\n",
      "     29        0.4944       0.8438        \u001b[35m0.4017\u001b[0m  0.0356\n",
      "     30        0.4936       0.8438        \u001b[35m0.4017\u001b[0m  0.0413\n",
      "     31        0.4929       0.8438        \u001b[35m0.4007\u001b[0m  0.0208\n",
      "     32        0.4889       0.8438        \u001b[35m0.3991\u001b[0m  0.0341\n",
      "     33        0.4991       0.8438        \u001b[35m0.3964\u001b[0m  0.0332\n",
      "     34        \u001b[36m0.4834\u001b[0m       0.8438        \u001b[35m0.3956\u001b[0m  0.0230\n",
      "     35        0.4860       0.8438        \u001b[35m0.3939\u001b[0m  0.0169\n",
      "     36        0.4870       0.8438        \u001b[35m0.3923\u001b[0m  0.0226\n",
      "     37        0.4888       0.8359        0.3936  0.0203\n",
      "     38        0.4875       0.8438        0.3930  0.0263\n",
      "     39        \u001b[36m0.4780\u001b[0m       0.8438        \u001b[35m0.3904\u001b[0m  0.0190\n",
      "     40        0.4905       0.8438        0.3905  0.0160\n",
      "     41        \u001b[36m0.4759\u001b[0m       0.8359        0.3912  0.0295\n",
      "     42        0.4935       0.8438        0.3921  0.0224\n",
      "     43        0.4800       0.8516        0.3920  0.0261\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6861\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6304\u001b[0m  0.0306\n",
      "      2        \u001b[36m0.6169\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5752\u001b[0m  0.0156\n",
      "      3        \u001b[36m0.5924\u001b[0m       0.7500        \u001b[35m0.5481\u001b[0m  0.0233\n",
      "      4        \u001b[36m0.5501\u001b[0m       0.7422        \u001b[35m0.5336\u001b[0m  0.0266\n",
      "      5        \u001b[36m0.5459\u001b[0m       0.7500        \u001b[35m0.5260\u001b[0m  0.0312\n",
      "      6        \u001b[36m0.5285\u001b[0m       0.7500        \u001b[35m0.5220\u001b[0m  0.0152\n",
      "      7        0.5305       0.7500        \u001b[35m0.5191\u001b[0m  0.0183\n",
      "      8        \u001b[36m0.5219\u001b[0m       0.7500        \u001b[35m0.5171\u001b[0m  0.0267\n",
      "      9        \u001b[36m0.5076\u001b[0m       0.7500        \u001b[35m0.5158\u001b[0m  0.0178\n",
      "     10        0.5152       0.7500        \u001b[35m0.5152\u001b[0m  0.0261\n",
      "     11        \u001b[36m0.5041\u001b[0m       0.7578        \u001b[35m0.5135\u001b[0m  0.0197\n",
      "     12        \u001b[36m0.4997\u001b[0m       0.7500        \u001b[35m0.5124\u001b[0m  0.0161\n",
      "     13        0.5082       0.7500        \u001b[35m0.5124\u001b[0m  0.0172\n",
      "     14        0.5063       0.7344        \u001b[35m0.5117\u001b[0m  0.0240\n",
      "     15        0.5034       0.7344        0.5125  0.0221\n",
      "     16        0.5036       0.7344        0.5128  0.0259\n",
      "     17        \u001b[36m0.4914\u001b[0m       0.7344        0.5119  0.0161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        0.4921       0.7500        0.5125  0.0307\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6416\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6205\u001b[0m  0.0293\n",
      "      2        \u001b[36m0.5879\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5853\u001b[0m  0.0206\n",
      "      3        \u001b[36m0.5678\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5649\u001b[0m  0.0279\n",
      "      4        \u001b[36m0.5374\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5515\u001b[0m  0.0338\n",
      "      5        \u001b[36m0.5225\u001b[0m       0.7188        \u001b[35m0.5449\u001b[0m  0.0259\n",
      "      6        \u001b[36m0.5087\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5427\u001b[0m  0.0220\n",
      "      7        \u001b[36m0.5036\u001b[0m       0.7031        \u001b[35m0.5407\u001b[0m  0.0540\n",
      "      8        \u001b[36m0.5005\u001b[0m       0.7188        \u001b[35m0.5396\u001b[0m  0.0253\n",
      "      9        \u001b[36m0.4855\u001b[0m       0.7188        0.5405  0.0350\n",
      "     10        0.4923       0.7109        0.5396  0.0252\n",
      "     11        0.5033       0.7031        \u001b[35m0.5393\u001b[0m  0.0318\n",
      "     12        0.4892       0.7188        0.5411  0.0171\n",
      "     13        0.5039       0.7109        \u001b[35m0.5388\u001b[0m  0.0230\n",
      "     14        0.4954       0.7031        \u001b[35m0.5366\u001b[0m  0.0135\n",
      "     15        0.4920       0.7109        \u001b[35m0.5360\u001b[0m  0.0300\n",
      "     16        0.4860       0.7109        \u001b[35m0.5355\u001b[0m  0.0173\n",
      "     17        \u001b[36m0.4777\u001b[0m       0.7031        \u001b[35m0.5354\u001b[0m  0.0165\n",
      "     18        0.4938       0.6953        0.5370  0.0382\n",
      "     19        0.4833       0.7109        0.5366  0.0156\n",
      "     20        \u001b[36m0.4761\u001b[0m       0.7031        \u001b[35m0.5346\u001b[0m  0.0177\n",
      "     21        0.4834       0.7031        0.5359  0.0374\n",
      "     22        0.4779       0.7031        \u001b[35m0.5341\u001b[0m  0.0182\n",
      "     23        \u001b[36m0.4701\u001b[0m       0.7109        0.5345  0.0338\n",
      "     24        0.4808       0.7109        \u001b[35m0.5327\u001b[0m  0.0199\n",
      "     25        0.4750       0.7188        \u001b[35m0.5321\u001b[0m  0.0153\n",
      "     26        \u001b[36m0.4661\u001b[0m       0.7031        0.5323  0.0209\n",
      "     27        \u001b[36m0.4605\u001b[0m       0.7109        0.5331  0.0234\n",
      "     28        0.4738       0.7188        \u001b[35m0.5318\u001b[0m  0.0145\n",
      "     29        \u001b[36m0.4535\u001b[0m       0.7031        0.5327  0.0219\n",
      "     30        0.4637       0.7109        0.5333  0.0168\n",
      "     31        0.4604       0.7031        0.5323  0.0161\n",
      "     32        0.4714       0.7109        0.5325  0.0236\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7312\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6724\u001b[0m  0.0162\n",
      "      2        \u001b[36m0.6572\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6361\u001b[0m  0.0172\n",
      "      3        \u001b[36m0.6220\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6096\u001b[0m  0.0186\n",
      "      4        \u001b[36m0.5957\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5899\u001b[0m  0.0383\n",
      "      5        \u001b[36m0.5648\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5736\u001b[0m  0.0284\n",
      "      6        \u001b[36m0.5523\u001b[0m       0.7109        \u001b[35m0.5619\u001b[0m  0.0262\n",
      "      7        \u001b[36m0.5444\u001b[0m       0.7109        \u001b[35m0.5543\u001b[0m  0.0183\n",
      "      8        \u001b[36m0.5308\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5499\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.5188\u001b[0m       0.7266        \u001b[35m0.5465\u001b[0m  0.0249\n",
      "     10        \u001b[36m0.5118\u001b[0m       0.7031        \u001b[35m0.5431\u001b[0m  0.0212\n",
      "     11        0.5134       0.6953        \u001b[35m0.5414\u001b[0m  0.0259\n",
      "     12        \u001b[36m0.5021\u001b[0m       0.7031        \u001b[35m0.5393\u001b[0m  0.0248\n",
      "     13        \u001b[36m0.4903\u001b[0m       0.7031        \u001b[35m0.5381\u001b[0m  0.0173\n",
      "     14        0.4948       0.6953        \u001b[35m0.5363\u001b[0m  0.0200\n",
      "     15        \u001b[36m0.4859\u001b[0m       0.6875        0.5363  0.0167\n",
      "     16        0.4964       0.6797        \u001b[35m0.5349\u001b[0m  0.0279\n",
      "     17        0.4998       0.6875        \u001b[35m0.5333\u001b[0m  0.0290\n",
      "     18        0.4915       0.6797        \u001b[35m0.5325\u001b[0m  0.0264\n",
      "     19        \u001b[36m0.4769\u001b[0m       0.6797        0.5332  0.0199\n",
      "     20        0.4902       0.6875        0.5338  0.0194\n",
      "     21        0.4879       0.6719        0.5330  0.0164\n",
      "     22        0.4802       0.6797        \u001b[35m0.5324\u001b[0m  0.0229\n",
      "     23        \u001b[36m0.4664\u001b[0m       0.6953        0.5335  0.0157\n",
      "     24        0.4734       0.6953        0.5342  0.0252\n",
      "     25        0.4736       0.6953        0.5346  0.0235\n",
      "     26        0.4710       0.6953        0.5364  0.0164\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6663\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6500\u001b[0m  0.0117\n",
      "      2        \u001b[36m0.6215\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6179\u001b[0m  0.0133\n",
      "      3        \u001b[36m0.5917\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5947\u001b[0m  0.0160\n",
      "      4        \u001b[36m0.5593\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5793\u001b[0m  0.0371\n",
      "      5        \u001b[36m0.5393\u001b[0m       0.6953        \u001b[35m0.5687\u001b[0m  0.0210\n",
      "      6        \u001b[36m0.5079\u001b[0m       0.6953        \u001b[35m0.5621\u001b[0m  0.0181\n",
      "      7        \u001b[36m0.5022\u001b[0m       0.6953        \u001b[35m0.5593\u001b[0m  0.0182\n",
      "      8        \u001b[36m0.4971\u001b[0m       0.6953        \u001b[35m0.5579\u001b[0m  0.0202\n",
      "      9        0.5016       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5557\u001b[0m  0.0370\n",
      "     10        \u001b[36m0.4674\u001b[0m       0.7031        \u001b[35m0.5545\u001b[0m  0.0270\n",
      "     11        0.4763       0.6953        \u001b[35m0.5533\u001b[0m  0.0271\n",
      "     12        0.4684       0.7031        0.5534  0.0158\n",
      "     13        \u001b[36m0.4666\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5515\u001b[0m  0.0368\n",
      "     14        \u001b[36m0.4605\u001b[0m       0.7109        \u001b[35m0.5508\u001b[0m  0.0189\n",
      "     15        0.4665       0.7031        \u001b[35m0.5506\u001b[0m  0.0159\n",
      "     16        \u001b[36m0.4605\u001b[0m       0.7031        0.5517  0.0157\n",
      "     17        \u001b[36m0.4553\u001b[0m       0.7031        0.5521  0.0247\n",
      "     18        0.4573       0.7031        \u001b[35m0.5504\u001b[0m  0.0169\n",
      "     19        0.4672       0.7031        \u001b[35m0.5476\u001b[0m  0.0217\n",
      "     20        \u001b[36m0.4466\u001b[0m       0.6953        0.5491  0.0258\n",
      "     21        0.4660       0.6953        0.5481  0.0174\n",
      "     22        0.4585       0.6953        0.5508  0.0268\n",
      "     23        0.4502       0.7031        0.5517  0.0281\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8616\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8616\u001b[0m  0.0292\n",
      "      2        \u001b[36m0.8054\u001b[0m       0.4922        \u001b[35m0.8081\u001b[0m  0.0329\n",
      "      3        \u001b[36m0.7638\u001b[0m       0.4922        \u001b[35m0.7678\u001b[0m  0.0312\n",
      "      4        \u001b[36m0.7326\u001b[0m       0.4766        \u001b[35m0.7366\u001b[0m  0.0295\n",
      "      5        \u001b[36m0.7086\u001b[0m       0.4844        \u001b[35m0.7117\u001b[0m  0.0257\n",
      "      6        \u001b[36m0.6894\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6916\u001b[0m  0.0310\n",
      "      7        \u001b[36m0.6737\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6745\u001b[0m  0.0292\n",
      "      8        \u001b[36m0.6607\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6600\u001b[0m  0.0314\n",
      "      9        \u001b[36m0.6496\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6473\u001b[0m  0.0309\n",
      "     10        \u001b[36m0.6397\u001b[0m       0.6172        \u001b[35m0.6359\u001b[0m  0.0295\n",
      "     11        \u001b[36m0.6310\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6254\u001b[0m  0.0248\n",
      "     12        \u001b[36m0.6230\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6158\u001b[0m  0.0327\n",
      "     13        \u001b[36m0.6157\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6067\u001b[0m  0.0295\n",
      "     14        \u001b[36m0.6088\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5980\u001b[0m  0.0255\n",
      "     15        \u001b[36m0.6023\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5898\u001b[0m  0.0314\n",
      "     16        \u001b[36m0.5962\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5821\u001b[0m  0.0309\n",
      "     17        \u001b[36m0.5907\u001b[0m       0.7266        \u001b[35m0.5748\u001b[0m  0.0272\n",
      "     18        \u001b[36m0.5853\u001b[0m       0.7344        \u001b[35m0.5677\u001b[0m  0.0296\n",
      "     19        \u001b[36m0.5804\u001b[0m       0.7344        \u001b[35m0.5611\u001b[0m  0.0262\n",
      "     20        \u001b[36m0.5756\u001b[0m       0.7344        \u001b[35m0.5546\u001b[0m  0.0307\n",
      "     21        \u001b[36m0.5711\u001b[0m       0.7344        \u001b[35m0.5484\u001b[0m  0.0234\n",
      "     22        \u001b[36m0.5668\u001b[0m       0.7344        \u001b[35m0.5426\u001b[0m  0.0232\n",
      "     23        \u001b[36m0.5629\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5370\u001b[0m  0.0225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24        \u001b[36m0.5591\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5318\u001b[0m  0.0223\n",
      "     25        \u001b[36m0.5556\u001b[0m       0.7500        \u001b[35m0.5267\u001b[0m  0.0272\n",
      "     26        \u001b[36m0.5525\u001b[0m       0.7500        \u001b[35m0.5219\u001b[0m  0.0286\n",
      "     27        \u001b[36m0.5495\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5173\u001b[0m  0.0270\n",
      "     28        \u001b[36m0.5466\u001b[0m       0.7578        \u001b[35m0.5129\u001b[0m  0.0570\n",
      "     29        \u001b[36m0.5439\u001b[0m       0.7578        \u001b[35m0.5088\u001b[0m  0.0910\n",
      "     30        \u001b[36m0.5412\u001b[0m       0.7578        \u001b[35m0.5048\u001b[0m  0.0795\n",
      "     31        \u001b[36m0.5388\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5011\u001b[0m  0.0366\n",
      "     32        \u001b[36m0.5366\u001b[0m       0.7734        \u001b[35m0.4975\u001b[0m  0.0297\n",
      "     33        \u001b[36m0.5345\u001b[0m       0.7734        \u001b[35m0.4940\u001b[0m  0.0939\n",
      "     34        \u001b[36m0.5328\u001b[0m       0.7734        \u001b[35m0.4907\u001b[0m  0.0508\n",
      "     35        \u001b[36m0.5309\u001b[0m       0.7734        \u001b[35m0.4876\u001b[0m  0.0255\n",
      "     36        \u001b[36m0.5291\u001b[0m       0.7734        \u001b[35m0.4845\u001b[0m  0.0275\n",
      "     37        \u001b[36m0.5275\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4816\u001b[0m  0.0277\n",
      "     38        \u001b[36m0.5260\u001b[0m       0.7812        \u001b[35m0.4788\u001b[0m  0.0254\n",
      "     39        \u001b[36m0.5248\u001b[0m       0.7812        \u001b[35m0.4761\u001b[0m  0.0260\n",
      "     40        \u001b[36m0.5234\u001b[0m       0.7812        \u001b[35m0.4736\u001b[0m  0.0295\n",
      "     41        \u001b[36m0.5222\u001b[0m       0.7812        \u001b[35m0.4712\u001b[0m  0.0342\n",
      "     42        \u001b[36m0.5211\u001b[0m       0.7812        \u001b[35m0.4689\u001b[0m  0.0319\n",
      "     43        \u001b[36m0.5201\u001b[0m       0.7812        \u001b[35m0.4667\u001b[0m  0.0324\n",
      "     44        \u001b[36m0.5190\u001b[0m       0.7812        \u001b[35m0.4645\u001b[0m  0.0425\n",
      "     45        \u001b[36m0.5182\u001b[0m       0.7812        \u001b[35m0.4624\u001b[0m  0.0295\n",
      "     46        \u001b[36m0.5172\u001b[0m       0.7812        \u001b[35m0.4604\u001b[0m  0.0257\n",
      "     47        \u001b[36m0.5164\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4585\u001b[0m  0.0200\n",
      "     48        \u001b[36m0.5157\u001b[0m       0.7812        \u001b[35m0.4566\u001b[0m  0.0419\n",
      "     49        \u001b[36m0.5151\u001b[0m       0.7812        \u001b[35m0.4550\u001b[0m  0.0301\n",
      "     50        \u001b[36m0.5144\u001b[0m       0.7891        \u001b[35m0.4533\u001b[0m  0.0203\n",
      "     51        \u001b[36m0.5136\u001b[0m       0.7891        \u001b[35m0.4517\u001b[0m  0.0204\n",
      "     52        \u001b[36m0.5129\u001b[0m       0.7891        \u001b[35m0.4501\u001b[0m  0.0227\n",
      "     53        \u001b[36m0.5124\u001b[0m       0.7891        \u001b[35m0.4486\u001b[0m  0.0299\n",
      "     54        \u001b[36m0.5118\u001b[0m       0.7812        \u001b[35m0.4471\u001b[0m  0.0243\n",
      "     55        \u001b[36m0.5112\u001b[0m       0.7891        \u001b[35m0.4457\u001b[0m  0.0227\n",
      "     56        \u001b[36m0.5108\u001b[0m       0.7891        \u001b[35m0.4444\u001b[0m  0.0223\n",
      "     57        \u001b[36m0.5103\u001b[0m       0.7891        \u001b[35m0.4431\u001b[0m  0.0241\n",
      "     58        \u001b[36m0.5098\u001b[0m       0.7891        \u001b[35m0.4419\u001b[0m  0.1696\n",
      "     59        \u001b[36m0.5094\u001b[0m       0.7812        \u001b[35m0.4407\u001b[0m  0.0305\n",
      "     60        \u001b[36m0.5090\u001b[0m       0.7812        \u001b[35m0.4396\u001b[0m  0.0264\n",
      "     61        \u001b[36m0.5087\u001b[0m       0.7812        \u001b[35m0.4385\u001b[0m  0.0366\n",
      "     62        \u001b[36m0.5083\u001b[0m       0.7812        \u001b[35m0.4375\u001b[0m  0.0233\n",
      "     63        \u001b[36m0.5079\u001b[0m       0.7812        \u001b[35m0.4365\u001b[0m  0.0425\n",
      "     64        \u001b[36m0.5078\u001b[0m       0.7812        \u001b[35m0.4356\u001b[0m  0.0210\n",
      "     65        \u001b[36m0.5073\u001b[0m       0.7812        \u001b[35m0.4347\u001b[0m  0.0296\n",
      "     66        \u001b[36m0.5068\u001b[0m       0.7812        \u001b[35m0.4338\u001b[0m  0.0295\n",
      "     67        \u001b[36m0.5066\u001b[0m       0.7891        \u001b[35m0.4330\u001b[0m  0.0293\n",
      "     68        \u001b[36m0.5063\u001b[0m       0.7812        \u001b[35m0.4322\u001b[0m  0.0224\n",
      "     69        \u001b[36m0.5061\u001b[0m       0.7891        \u001b[35m0.4315\u001b[0m  0.0323\n",
      "     70        \u001b[36m0.5059\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4308\u001b[0m  0.0304\n",
      "     71        \u001b[36m0.5056\u001b[0m       0.7969        \u001b[35m0.4302\u001b[0m  0.0238\n",
      "     72        \u001b[36m0.5053\u001b[0m       0.7969        \u001b[35m0.4295\u001b[0m  0.0319\n",
      "     73        \u001b[36m0.5051\u001b[0m       0.7969        \u001b[35m0.4290\u001b[0m  0.0233\n",
      "     74        \u001b[36m0.5050\u001b[0m       0.7969        \u001b[35m0.4284\u001b[0m  0.0289\n",
      "     75        \u001b[36m0.5046\u001b[0m       0.7969        \u001b[35m0.4278\u001b[0m  0.0281\n",
      "     76        \u001b[36m0.5045\u001b[0m       0.7969        \u001b[35m0.4272\u001b[0m  0.0237\n",
      "     77        \u001b[36m0.5042\u001b[0m       0.7969        \u001b[35m0.4267\u001b[0m  0.0219\n",
      "     78        \u001b[36m0.5040\u001b[0m       0.7969        \u001b[35m0.4261\u001b[0m  0.0211\n",
      "     79        \u001b[36m0.5038\u001b[0m       0.7969        \u001b[35m0.4257\u001b[0m  0.0291\n",
      "     80        \u001b[36m0.5038\u001b[0m       0.7969        \u001b[35m0.4252\u001b[0m  0.0315\n",
      "     81        \u001b[36m0.5036\u001b[0m       0.7969        \u001b[35m0.4248\u001b[0m  0.0251\n",
      "     82        \u001b[36m0.5032\u001b[0m       0.7969        \u001b[35m0.4244\u001b[0m  0.0301\n",
      "     83        0.5033       0.7969        \u001b[35m0.4240\u001b[0m  0.0280\n",
      "     84        \u001b[36m0.5030\u001b[0m       0.7969        \u001b[35m0.4236\u001b[0m  0.0584\n",
      "     85        \u001b[36m0.5028\u001b[0m       0.7969        \u001b[35m0.4233\u001b[0m  0.0202\n",
      "     86        \u001b[36m0.5027\u001b[0m       0.7969        \u001b[35m0.4230\u001b[0m  0.0282\n",
      "     87        \u001b[36m0.5025\u001b[0m       0.7969        \u001b[35m0.4226\u001b[0m  0.0256\n",
      "     88        0.5026       0.7969        \u001b[35m0.4223\u001b[0m  0.0213\n",
      "     89        \u001b[36m0.5023\u001b[0m       0.7969        \u001b[35m0.4221\u001b[0m  0.0263\n",
      "     90        \u001b[36m0.5022\u001b[0m       0.7969        \u001b[35m0.4218\u001b[0m  0.0252\n",
      "     91        \u001b[36m0.5020\u001b[0m       0.7969        \u001b[35m0.4215\u001b[0m  0.0212\n",
      "     92        \u001b[36m0.5018\u001b[0m       0.7969        \u001b[35m0.4212\u001b[0m  0.0304\n",
      "     93        \u001b[36m0.5016\u001b[0m       0.7969        \u001b[35m0.4209\u001b[0m  0.0252\n",
      "     94        0.5018       0.7969        \u001b[35m0.4206\u001b[0m  0.0265\n",
      "     95        \u001b[36m0.5016\u001b[0m       0.7969        \u001b[35m0.4203\u001b[0m  0.0256\n",
      "     96        \u001b[36m0.5014\u001b[0m       0.7969        \u001b[35m0.4200\u001b[0m  0.0276\n",
      "     97        \u001b[36m0.5013\u001b[0m       0.7969        \u001b[35m0.4197\u001b[0m  0.0234\n",
      "     98        \u001b[36m0.5011\u001b[0m       0.7969        \u001b[35m0.4195\u001b[0m  0.0263\n",
      "     99        \u001b[36m0.5010\u001b[0m       0.7969        \u001b[35m0.4192\u001b[0m  0.0269\n",
      "    100        \u001b[36m0.5008\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4188\u001b[0m  0.0188\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7711\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7481\u001b[0m  0.0202\n",
      "      2        \u001b[36m0.7470\u001b[0m       0.5000        \u001b[35m0.7272\u001b[0m  0.0253\n",
      "      3        \u001b[36m0.7283\u001b[0m       0.5000        \u001b[35m0.7109\u001b[0m  0.0217\n",
      "      4        \u001b[36m0.7136\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6979\u001b[0m  0.0226\n",
      "      5        \u001b[36m0.7021\u001b[0m       0.4922        \u001b[35m0.6874\u001b[0m  0.0281\n",
      "      6        \u001b[36m0.6928\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6787\u001b[0m  0.2278\n",
      "      7        \u001b[36m0.6851\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6715\u001b[0m  0.0267\n",
      "      8        \u001b[36m0.6786\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6653\u001b[0m  0.0250\n",
      "      9        \u001b[36m0.6731\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6600\u001b[0m  0.0448\n",
      "     10        \u001b[36m0.6682\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6551\u001b[0m  0.0375\n",
      "     11        \u001b[36m0.6639\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6508\u001b[0m  0.0260\n",
      "     12        \u001b[36m0.6597\u001b[0m       0.6719        \u001b[35m0.6468\u001b[0m  0.0364\n",
      "     13        \u001b[36m0.6559\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6430\u001b[0m  0.0238\n",
      "     14        \u001b[36m0.6522\u001b[0m       0.6719        \u001b[35m0.6395\u001b[0m  0.0348\n",
      "     15        \u001b[36m0.6487\u001b[0m       0.6641        \u001b[35m0.6361\u001b[0m  0.0313\n",
      "     16        \u001b[36m0.6452\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6329\u001b[0m  0.0339\n",
      "     17        \u001b[36m0.6419\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6297\u001b[0m  0.0209\n",
      "     18        \u001b[36m0.6385\u001b[0m       0.6953        \u001b[35m0.6266\u001b[0m  0.0294\n",
      "     19        \u001b[36m0.6353\u001b[0m       0.6953        \u001b[35m0.6236\u001b[0m  0.0372\n",
      "     20        \u001b[36m0.6320\u001b[0m       0.6953        \u001b[35m0.6206\u001b[0m  0.0355\n",
      "     21        \u001b[36m0.6288\u001b[0m       0.6953        \u001b[35m0.6177\u001b[0m  0.0363\n",
      "     22        \u001b[36m0.6256\u001b[0m       0.6953        \u001b[35m0.6149\u001b[0m  0.0284\n",
      "     23        \u001b[36m0.6225\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6121\u001b[0m  0.0325\n",
      "     24        \u001b[36m0.6192\u001b[0m       0.6953        \u001b[35m0.6094\u001b[0m  0.0321\n",
      "     25        \u001b[36m0.6161\u001b[0m       0.6953        \u001b[35m0.6067\u001b[0m  0.0324\n",
      "     26        \u001b[36m0.6128\u001b[0m       0.6953        \u001b[35m0.6041\u001b[0m  0.0312\n",
      "     27        \u001b[36m0.6095\u001b[0m       0.6875        \u001b[35m0.6016\u001b[0m  0.0213\n",
      "     28        \u001b[36m0.6063\u001b[0m       0.6875        \u001b[35m0.5991\u001b[0m  0.0252\n",
      "     29        \u001b[36m0.6031\u001b[0m       0.6875        \u001b[35m0.5966\u001b[0m  0.0380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     30        \u001b[36m0.5997\u001b[0m       0.6953        \u001b[35m0.5942\u001b[0m  0.0269\n",
      "     31        \u001b[36m0.5965\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5919\u001b[0m  0.0318\n",
      "     32        \u001b[36m0.5932\u001b[0m       0.7109        \u001b[35m0.5896\u001b[0m  0.0528\n",
      "     33        \u001b[36m0.5901\u001b[0m       0.7109        \u001b[35m0.5873\u001b[0m  0.0705\n",
      "     34        \u001b[36m0.5868\u001b[0m       0.7109        \u001b[35m0.5852\u001b[0m  0.1303\n",
      "     35        \u001b[36m0.5835\u001b[0m       0.7109        \u001b[35m0.5831\u001b[0m  0.0771\n",
      "     36        \u001b[36m0.5804\u001b[0m       0.7109        \u001b[35m0.5810\u001b[0m  0.0352\n",
      "     37        \u001b[36m0.5772\u001b[0m       0.7031        \u001b[35m0.5789\u001b[0m  0.0715\n",
      "     38        \u001b[36m0.5742\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5770\u001b[0m  0.0385\n",
      "     39        \u001b[36m0.5713\u001b[0m       0.7266        \u001b[35m0.5751\u001b[0m  0.0287\n",
      "     40        \u001b[36m0.5685\u001b[0m       0.7266        \u001b[35m0.5733\u001b[0m  0.0293\n",
      "     41        \u001b[36m0.5655\u001b[0m       0.7266        \u001b[35m0.5715\u001b[0m  0.0299\n",
      "     42        \u001b[36m0.5627\u001b[0m       0.7266        \u001b[35m0.5698\u001b[0m  0.0363\n",
      "     43        \u001b[36m0.5599\u001b[0m       0.7266        \u001b[35m0.5683\u001b[0m  0.0412\n",
      "     44        \u001b[36m0.5572\u001b[0m       0.7266        \u001b[35m0.5667\u001b[0m  0.0546\n",
      "     45        \u001b[36m0.5545\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5652\u001b[0m  0.0406\n",
      "     46        \u001b[36m0.5521\u001b[0m       0.7344        \u001b[35m0.5638\u001b[0m  0.0590\n",
      "     47        \u001b[36m0.5496\u001b[0m       0.7344        \u001b[35m0.5624\u001b[0m  0.0495\n",
      "     48        \u001b[36m0.5473\u001b[0m       0.7344        \u001b[35m0.5612\u001b[0m  0.0400\n",
      "     49        \u001b[36m0.5451\u001b[0m       0.7344        \u001b[35m0.5599\u001b[0m  0.0353\n",
      "     50        \u001b[36m0.5430\u001b[0m       0.7344        \u001b[35m0.5588\u001b[0m  0.0379\n",
      "     51        \u001b[36m0.5408\u001b[0m       0.7344        \u001b[35m0.5577\u001b[0m  0.0462\n",
      "     52        \u001b[36m0.5388\u001b[0m       0.7266        \u001b[35m0.5566\u001b[0m  0.0226\n",
      "     53        \u001b[36m0.5369\u001b[0m       0.7266        \u001b[35m0.5556\u001b[0m  0.0335\n",
      "     54        \u001b[36m0.5352\u001b[0m       0.7266        \u001b[35m0.5547\u001b[0m  0.0286\n",
      "     55        \u001b[36m0.5334\u001b[0m       0.7344        \u001b[35m0.5539\u001b[0m  0.0330\n",
      "     56        \u001b[36m0.5315\u001b[0m       0.7344        \u001b[35m0.5531\u001b[0m  0.0321\n",
      "     57        \u001b[36m0.5299\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5522\u001b[0m  0.0319\n",
      "     58        \u001b[36m0.5283\u001b[0m       0.7422        \u001b[35m0.5514\u001b[0m  0.0420\n",
      "     59        \u001b[36m0.5270\u001b[0m       0.7422        \u001b[35m0.5507\u001b[0m  0.0341\n",
      "     60        \u001b[36m0.5253\u001b[0m       0.7422        \u001b[35m0.5500\u001b[0m  0.0310\n",
      "     61        \u001b[36m0.5239\u001b[0m       0.7422        \u001b[35m0.5493\u001b[0m  0.0405\n",
      "     62        \u001b[36m0.5226\u001b[0m       0.7422        \u001b[35m0.5486\u001b[0m  0.0356\n",
      "     63        \u001b[36m0.5212\u001b[0m       0.7422        \u001b[35m0.5479\u001b[0m  0.0340\n",
      "     64        \u001b[36m0.5200\u001b[0m       0.7422        \u001b[35m0.5473\u001b[0m  0.0472\n",
      "     65        \u001b[36m0.5187\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5467\u001b[0m  0.0271\n",
      "     66        \u001b[36m0.5176\u001b[0m       0.7500        \u001b[35m0.5462\u001b[0m  0.0263\n",
      "     67        \u001b[36m0.5166\u001b[0m       0.7422        \u001b[35m0.5457\u001b[0m  0.0348\n",
      "     68        \u001b[36m0.5156\u001b[0m       0.7344        \u001b[35m0.5452\u001b[0m  0.0320\n",
      "     69        \u001b[36m0.5144\u001b[0m       0.7344        \u001b[35m0.5446\u001b[0m  0.0320\n",
      "     70        \u001b[36m0.5133\u001b[0m       0.7344        \u001b[35m0.5440\u001b[0m  0.0225\n",
      "     71        \u001b[36m0.5122\u001b[0m       0.7344        \u001b[35m0.5434\u001b[0m  0.0293\n",
      "     72        \u001b[36m0.5112\u001b[0m       0.7344        \u001b[35m0.5429\u001b[0m  0.0280\n",
      "     73        \u001b[36m0.5102\u001b[0m       0.7344        \u001b[35m0.5423\u001b[0m  0.0304\n",
      "     74        \u001b[36m0.5093\u001b[0m       0.7344        \u001b[35m0.5419\u001b[0m  0.0229\n",
      "     75        \u001b[36m0.5084\u001b[0m       0.7344        \u001b[35m0.5414\u001b[0m  0.0230\n",
      "     76        \u001b[36m0.5073\u001b[0m       0.7344        \u001b[35m0.5409\u001b[0m  0.0274\n",
      "     77        \u001b[36m0.5066\u001b[0m       0.7266        \u001b[35m0.5404\u001b[0m  0.0294\n",
      "     78        \u001b[36m0.5058\u001b[0m       0.7266        \u001b[35m0.5401\u001b[0m  0.0226\n",
      "     79        \u001b[36m0.5051\u001b[0m       0.7266        \u001b[35m0.5397\u001b[0m  0.0224\n",
      "     80        \u001b[36m0.5044\u001b[0m       0.7266        \u001b[35m0.5394\u001b[0m  0.0295\n",
      "     81        \u001b[36m0.5035\u001b[0m       0.7266        \u001b[35m0.5390\u001b[0m  0.0292\n",
      "     82        \u001b[36m0.5029\u001b[0m       0.7266        \u001b[35m0.5387\u001b[0m  0.0243\n",
      "     83        \u001b[36m0.5021\u001b[0m       0.7266        \u001b[35m0.5384\u001b[0m  0.0212\n",
      "     84        \u001b[36m0.5016\u001b[0m       0.7266        \u001b[35m0.5381\u001b[0m  0.0261\n",
      "     85        \u001b[36m0.5009\u001b[0m       0.7266        \u001b[35m0.5379\u001b[0m  0.0275\n",
      "     86        \u001b[36m0.5002\u001b[0m       0.7188        \u001b[35m0.5376\u001b[0m  0.0253\n",
      "     87        \u001b[36m0.4996\u001b[0m       0.7188        \u001b[35m0.5374\u001b[0m  0.0313\n",
      "     88        \u001b[36m0.4991\u001b[0m       0.7109        \u001b[35m0.5372\u001b[0m  0.0354\n",
      "     89        \u001b[36m0.4984\u001b[0m       0.7109        \u001b[35m0.5370\u001b[0m  0.0263\n",
      "     90        \u001b[36m0.4979\u001b[0m       0.7109        \u001b[35m0.5368\u001b[0m  0.0331\n",
      "     91        \u001b[36m0.4973\u001b[0m       0.7109        \u001b[35m0.5366\u001b[0m  0.0298\n",
      "     92        \u001b[36m0.4968\u001b[0m       0.7109        \u001b[35m0.5365\u001b[0m  0.0260\n",
      "     93        \u001b[36m0.4961\u001b[0m       0.7109        \u001b[35m0.5363\u001b[0m  0.0306\n",
      "     94        \u001b[36m0.4954\u001b[0m       0.7109        \u001b[35m0.5361\u001b[0m  0.0297\n",
      "     95        \u001b[36m0.4949\u001b[0m       0.7109        \u001b[35m0.5359\u001b[0m  0.0196\n",
      "     96        \u001b[36m0.4944\u001b[0m       0.7109        \u001b[35m0.5357\u001b[0m  0.0288\n",
      "     97        \u001b[36m0.4937\u001b[0m       0.7109        \u001b[35m0.5355\u001b[0m  0.0287\n",
      "     98        \u001b[36m0.4931\u001b[0m       0.7109        \u001b[35m0.5354\u001b[0m  0.0279\n",
      "     99        \u001b[36m0.4927\u001b[0m       0.7109        \u001b[35m0.5353\u001b[0m  0.0357\n",
      "    100        \u001b[36m0.4922\u001b[0m       0.7109        \u001b[35m0.5351\u001b[0m  0.0285\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6792\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6793\u001b[0m  0.0194\n",
      "      2        \u001b[36m0.6730\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6728\u001b[0m  0.0280\n",
      "      3        \u001b[36m0.6669\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6665\u001b[0m  0.0216\n",
      "      4        \u001b[36m0.6608\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6604\u001b[0m  0.0423\n",
      "      5        \u001b[36m0.6547\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6544\u001b[0m  0.0240\n",
      "      6        \u001b[36m0.6488\u001b[0m       0.6484        \u001b[35m0.6484\u001b[0m  0.0334\n",
      "      7        \u001b[36m0.6427\u001b[0m       0.6406        \u001b[35m0.6425\u001b[0m  0.0187\n",
      "      8        \u001b[36m0.6368\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6368\u001b[0m  0.0254\n",
      "      9        \u001b[36m0.6308\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6312\u001b[0m  0.0306\n",
      "     10        \u001b[36m0.6251\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6257\u001b[0m  0.0189\n",
      "     11        \u001b[36m0.6192\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6204\u001b[0m  0.0192\n",
      "     12        \u001b[36m0.6136\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6152\u001b[0m  0.0212\n",
      "     13        \u001b[36m0.6080\u001b[0m       0.7188        \u001b[35m0.6103\u001b[0m  0.0310\n",
      "     14        \u001b[36m0.6028\u001b[0m       0.7188        \u001b[35m0.6054\u001b[0m  0.0429\n",
      "     15        \u001b[36m0.5974\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6008\u001b[0m  0.0339\n",
      "     16        \u001b[36m0.5924\u001b[0m       0.7344        \u001b[35m0.5965\u001b[0m  0.0455\n",
      "     17        \u001b[36m0.5875\u001b[0m       0.7344        \u001b[35m0.5924\u001b[0m  0.0216\n",
      "     18        \u001b[36m0.5828\u001b[0m       0.7344        \u001b[35m0.5886\u001b[0m  0.0280\n",
      "     19        \u001b[36m0.5784\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5850\u001b[0m  0.0296\n",
      "     20        \u001b[36m0.5741\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5815\u001b[0m  0.0300\n",
      "     21        \u001b[36m0.5697\u001b[0m       0.7578        \u001b[35m0.5782\u001b[0m  0.0212\n",
      "     22        \u001b[36m0.5656\u001b[0m       0.7578        \u001b[35m0.5751\u001b[0m  0.0312\n",
      "     23        \u001b[36m0.5618\u001b[0m       0.7578        \u001b[35m0.5722\u001b[0m  0.0309\n",
      "     24        \u001b[36m0.5580\u001b[0m       0.7578        \u001b[35m0.5695\u001b[0m  0.0319\n",
      "     25        \u001b[36m0.5544\u001b[0m       0.7578        \u001b[35m0.5669\u001b[0m  0.0399\n",
      "     26        \u001b[36m0.5509\u001b[0m       0.7578        \u001b[35m0.5644\u001b[0m  0.0413\n",
      "     27        \u001b[36m0.5476\u001b[0m       0.7422        \u001b[35m0.5621\u001b[0m  0.0320\n",
      "     28        \u001b[36m0.5444\u001b[0m       0.7422        \u001b[35m0.5599\u001b[0m  0.0267\n",
      "     29        \u001b[36m0.5415\u001b[0m       0.7344        \u001b[35m0.5579\u001b[0m  0.0213\n",
      "     30        \u001b[36m0.5385\u001b[0m       0.7344        \u001b[35m0.5561\u001b[0m  0.0292\n",
      "     31        \u001b[36m0.5359\u001b[0m       0.7344        \u001b[35m0.5543\u001b[0m  0.0309\n",
      "     32        \u001b[36m0.5333\u001b[0m       0.7344        \u001b[35m0.5527\u001b[0m  0.0293\n",
      "     33        \u001b[36m0.5309\u001b[0m       0.7266        \u001b[35m0.5512\u001b[0m  0.0220\n",
      "     34        \u001b[36m0.5285\u001b[0m       0.7266        \u001b[35m0.5498\u001b[0m  0.0218\n",
      "     35        \u001b[36m0.5263\u001b[0m       0.7266        \u001b[35m0.5486\u001b[0m  0.0430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     36        \u001b[36m0.5241\u001b[0m       0.7266        \u001b[35m0.5474\u001b[0m  0.0222\n",
      "     37        \u001b[36m0.5221\u001b[0m       0.7266        \u001b[35m0.5463\u001b[0m  0.0292\n",
      "     38        \u001b[36m0.5201\u001b[0m       0.7344        \u001b[35m0.5453\u001b[0m  0.0214\n",
      "     39        \u001b[36m0.5184\u001b[0m       0.7422        \u001b[35m0.5443\u001b[0m  0.0275\n",
      "     40        \u001b[36m0.5165\u001b[0m       0.7422        \u001b[35m0.5433\u001b[0m  0.0594\n",
      "     41        \u001b[36m0.5149\u001b[0m       0.7422        \u001b[35m0.5424\u001b[0m  0.0267\n",
      "     42        \u001b[36m0.5132\u001b[0m       0.7422        \u001b[35m0.5415\u001b[0m  0.0456\n",
      "     43        \u001b[36m0.5118\u001b[0m       0.7422        \u001b[35m0.5407\u001b[0m  0.0281\n",
      "     44        \u001b[36m0.5103\u001b[0m       0.7422        \u001b[35m0.5399\u001b[0m  0.0202\n",
      "     45        \u001b[36m0.5090\u001b[0m       0.7500        \u001b[35m0.5392\u001b[0m  0.0469\n",
      "     46        \u001b[36m0.5077\u001b[0m       0.7422        \u001b[35m0.5385\u001b[0m  0.0356\n",
      "     47        \u001b[36m0.5064\u001b[0m       0.7422        \u001b[35m0.5379\u001b[0m  0.0382\n",
      "     48        \u001b[36m0.5052\u001b[0m       0.7344        \u001b[35m0.5372\u001b[0m  0.0200\n",
      "     49        \u001b[36m0.5041\u001b[0m       0.7422        \u001b[35m0.5367\u001b[0m  0.0356\n",
      "     50        \u001b[36m0.5029\u001b[0m       0.7422        \u001b[35m0.5361\u001b[0m  0.0359\n",
      "     51        \u001b[36m0.5019\u001b[0m       0.7422        \u001b[35m0.5356\u001b[0m  0.0195\n",
      "     52        \u001b[36m0.5008\u001b[0m       0.7344        \u001b[35m0.5351\u001b[0m  0.0267\n",
      "     53        \u001b[36m0.4998\u001b[0m       0.7344        \u001b[35m0.5347\u001b[0m  0.0271\n",
      "     54        \u001b[36m0.4988\u001b[0m       0.7344        \u001b[35m0.5343\u001b[0m  0.0300\n",
      "     55        \u001b[36m0.4977\u001b[0m       0.7344        \u001b[35m0.5339\u001b[0m  0.0280\n",
      "     56        \u001b[36m0.4969\u001b[0m       0.7344        \u001b[35m0.5335\u001b[0m  0.0250\n",
      "     57        \u001b[36m0.4959\u001b[0m       0.7266        \u001b[35m0.5332\u001b[0m  0.0438\n",
      "     58        \u001b[36m0.4950\u001b[0m       0.7266        \u001b[35m0.5329\u001b[0m  0.0482\n",
      "     59        \u001b[36m0.4942\u001b[0m       0.7344        \u001b[35m0.5326\u001b[0m  0.0298\n",
      "     60        \u001b[36m0.4935\u001b[0m       0.7344        \u001b[35m0.5324\u001b[0m  0.0329\n",
      "     61        \u001b[36m0.4927\u001b[0m       0.7344        \u001b[35m0.5321\u001b[0m  0.0381\n",
      "     62        \u001b[36m0.4921\u001b[0m       0.7422        \u001b[35m0.5319\u001b[0m  0.0371\n",
      "     63        \u001b[36m0.4915\u001b[0m       0.7422        \u001b[35m0.5316\u001b[0m  0.0391\n",
      "     64        \u001b[36m0.4907\u001b[0m       0.7422        \u001b[35m0.5314\u001b[0m  0.0478\n",
      "     65        \u001b[36m0.4902\u001b[0m       0.7422        \u001b[35m0.5312\u001b[0m  0.0231\n",
      "     66        \u001b[36m0.4896\u001b[0m       0.7422        \u001b[35m0.5310\u001b[0m  0.0302\n",
      "     67        \u001b[36m0.4891\u001b[0m       0.7422        \u001b[35m0.5308\u001b[0m  0.0324\n",
      "     68        \u001b[36m0.4885\u001b[0m       0.7422        \u001b[35m0.5305\u001b[0m  0.0299\n",
      "     69        \u001b[36m0.4879\u001b[0m       0.7422        \u001b[35m0.5303\u001b[0m  0.0460\n",
      "     70        \u001b[36m0.4875\u001b[0m       0.7422        \u001b[35m0.5301\u001b[0m  0.0254\n",
      "     71        \u001b[36m0.4869\u001b[0m       0.7500        \u001b[35m0.5300\u001b[0m  0.0352\n",
      "     72        \u001b[36m0.4863\u001b[0m       0.7500        \u001b[35m0.5298\u001b[0m  0.0462\n",
      "     73        \u001b[36m0.4859\u001b[0m       0.7500        \u001b[35m0.5296\u001b[0m  0.0296\n",
      "     74        \u001b[36m0.4856\u001b[0m       0.7500        \u001b[35m0.5295\u001b[0m  0.0471\n",
      "     75        \u001b[36m0.4851\u001b[0m       0.7500        \u001b[35m0.5294\u001b[0m  0.0268\n",
      "     76        \u001b[36m0.4847\u001b[0m       0.7500        \u001b[35m0.5293\u001b[0m  0.0262\n",
      "     77        \u001b[36m0.4843\u001b[0m       0.7500        \u001b[35m0.5292\u001b[0m  0.0287\n",
      "     78        \u001b[36m0.4839\u001b[0m       0.7500        \u001b[35m0.5291\u001b[0m  0.0249\n",
      "     79        \u001b[36m0.4836\u001b[0m       0.7500        \u001b[35m0.5291\u001b[0m  0.0236\n",
      "     80        \u001b[36m0.4832\u001b[0m       0.7500        \u001b[35m0.5290\u001b[0m  0.0287\n",
      "     81        \u001b[36m0.4831\u001b[0m       0.7500        \u001b[35m0.5290\u001b[0m  0.0191\n",
      "     82        \u001b[36m0.4827\u001b[0m       0.7500        \u001b[35m0.5289\u001b[0m  0.0194\n",
      "     83        \u001b[36m0.4823\u001b[0m       0.7500        \u001b[35m0.5288\u001b[0m  0.0221\n",
      "     84        \u001b[36m0.4822\u001b[0m       0.7500        \u001b[35m0.5288\u001b[0m  0.0236\n",
      "     85        \u001b[36m0.4818\u001b[0m       0.7500        \u001b[35m0.5287\u001b[0m  0.0212\n",
      "     86        \u001b[36m0.4816\u001b[0m       0.7500        \u001b[35m0.5287\u001b[0m  0.1041\n",
      "     87        \u001b[36m0.4813\u001b[0m       0.7500        \u001b[35m0.5287\u001b[0m  0.0336\n",
      "     88        \u001b[36m0.4811\u001b[0m       0.7500        \u001b[35m0.5286\u001b[0m  0.0228\n",
      "     89        \u001b[36m0.4808\u001b[0m       0.7422        \u001b[35m0.5286\u001b[0m  0.0318\n",
      "     90        \u001b[36m0.4807\u001b[0m       0.7422        \u001b[35m0.5285\u001b[0m  0.0231\n",
      "     91        \u001b[36m0.4805\u001b[0m       0.7422        \u001b[35m0.5285\u001b[0m  0.0300\n",
      "     92        \u001b[36m0.4802\u001b[0m       0.7422        \u001b[35m0.5285\u001b[0m  0.0296\n",
      "     93        \u001b[36m0.4799\u001b[0m       0.7422        \u001b[35m0.5284\u001b[0m  0.0313\n",
      "     94        \u001b[36m0.4796\u001b[0m       0.7422        \u001b[35m0.5284\u001b[0m  0.0260\n",
      "     95        \u001b[36m0.4794\u001b[0m       0.7422        \u001b[35m0.5284\u001b[0m  0.0239\n",
      "     96        \u001b[36m0.4791\u001b[0m       0.7422        \u001b[35m0.5283\u001b[0m  0.0266\n",
      "     97        \u001b[36m0.4790\u001b[0m       0.7422        \u001b[35m0.5283\u001b[0m  0.0411\n",
      "     98        \u001b[36m0.4786\u001b[0m       0.7344        \u001b[35m0.5283\u001b[0m  0.0244\n",
      "     99        \u001b[36m0.4785\u001b[0m       0.7344        \u001b[35m0.5282\u001b[0m  0.0273\n",
      "    100        \u001b[36m0.4781\u001b[0m       0.7344        \u001b[35m0.5282\u001b[0m  0.0301\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7211\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m0.7055\u001b[0m  0.0201\n",
      "      2        \u001b[36m0.7135\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m0.6987\u001b[0m  0.0258\n",
      "      3        \u001b[36m0.7063\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6924\u001b[0m  0.0231\n",
      "      4        \u001b[36m0.6993\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6862\u001b[0m  0.0295\n",
      "      5        \u001b[36m0.6925\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6802\u001b[0m  0.0277\n",
      "      6        \u001b[36m0.6858\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6744\u001b[0m  0.0254\n",
      "      7        \u001b[36m0.6790\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6686\u001b[0m  0.0315\n",
      "      8        \u001b[36m0.6722\u001b[0m       0.6094        \u001b[35m0.6628\u001b[0m  0.0264\n",
      "      9        \u001b[36m0.6655\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6571\u001b[0m  0.0251\n",
      "     10        \u001b[36m0.6587\u001b[0m       0.6484        \u001b[35m0.6515\u001b[0m  0.0388\n",
      "     11        \u001b[36m0.6518\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6457\u001b[0m  0.0427\n",
      "     12        \u001b[36m0.6451\u001b[0m       0.6719        \u001b[35m0.6399\u001b[0m  0.0235\n",
      "     13        \u001b[36m0.6382\u001b[0m       0.6641        \u001b[35m0.6342\u001b[0m  0.0206\n",
      "     14        \u001b[36m0.6314\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6284\u001b[0m  0.0347\n",
      "     15        \u001b[36m0.6246\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6226\u001b[0m  0.0285\n",
      "     16        \u001b[36m0.6179\u001b[0m       0.6953        \u001b[35m0.6169\u001b[0m  0.0282\n",
      "     17        \u001b[36m0.6113\u001b[0m       0.6953        \u001b[35m0.6113\u001b[0m  0.0301\n",
      "     18        \u001b[36m0.6046\u001b[0m       0.7109        \u001b[35m0.6058\u001b[0m  0.0300\n",
      "     19        \u001b[36m0.5981\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6005\u001b[0m  0.0286\n",
      "     20        \u001b[36m0.5917\u001b[0m       0.7188        \u001b[35m0.5954\u001b[0m  0.0261\n",
      "     21        \u001b[36m0.5855\u001b[0m       0.7188        \u001b[35m0.5904\u001b[0m  0.0266\n",
      "     22        \u001b[36m0.5795\u001b[0m       0.7188        \u001b[35m0.5856\u001b[0m  0.0245\n",
      "     23        \u001b[36m0.5737\u001b[0m       0.7109        \u001b[35m0.5811\u001b[0m  0.0216\n",
      "     24        \u001b[36m0.5682\u001b[0m       0.7109        \u001b[35m0.5769\u001b[0m  0.0217\n",
      "     25        \u001b[36m0.5630\u001b[0m       0.7031        \u001b[35m0.5729\u001b[0m  0.0224\n",
      "     26        \u001b[36m0.5581\u001b[0m       0.7031        \u001b[35m0.5692\u001b[0m  0.0239\n",
      "     27        \u001b[36m0.5533\u001b[0m       0.7109        \u001b[35m0.5658\u001b[0m  0.0196\n",
      "     28        \u001b[36m0.5490\u001b[0m       0.7109        \u001b[35m0.5625\u001b[0m  0.0230\n",
      "     29        \u001b[36m0.5449\u001b[0m       0.7109        \u001b[35m0.5595\u001b[0m  0.0309\n",
      "     30        \u001b[36m0.5411\u001b[0m       0.7109        \u001b[35m0.5565\u001b[0m  0.0302\n",
      "     31        \u001b[36m0.5375\u001b[0m       0.7109        \u001b[35m0.5538\u001b[0m  0.0229\n",
      "     32        \u001b[36m0.5340\u001b[0m       0.7031        \u001b[35m0.5513\u001b[0m  0.0202\n",
      "     33        \u001b[36m0.5308\u001b[0m       0.7031        \u001b[35m0.5488\u001b[0m  0.0285\n",
      "     34        \u001b[36m0.5278\u001b[0m       0.7031        \u001b[35m0.5466\u001b[0m  0.0191\n",
      "     35        \u001b[36m0.5249\u001b[0m       0.7109        \u001b[35m0.5445\u001b[0m  0.0253\n",
      "     36        \u001b[36m0.5221\u001b[0m       0.7188        \u001b[35m0.5425\u001b[0m  0.0205\n",
      "     37        \u001b[36m0.5195\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5407\u001b[0m  0.0767\n",
      "     38        \u001b[36m0.5171\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5389\u001b[0m  0.0338\n",
      "     39        \u001b[36m0.5149\u001b[0m       0.7422        \u001b[35m0.5373\u001b[0m  0.0283\n",
      "     40        \u001b[36m0.5129\u001b[0m       0.7422        \u001b[35m0.5358\u001b[0m  0.0304\n",
      "     41        \u001b[36m0.5110\u001b[0m       0.7422        \u001b[35m0.5344\u001b[0m  0.0270\n",
      "     42        \u001b[36m0.5091\u001b[0m       0.7422        \u001b[35m0.5331\u001b[0m  0.0223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     43        \u001b[36m0.5074\u001b[0m       0.7422        \u001b[35m0.5320\u001b[0m  0.0204\n",
      "     44        \u001b[36m0.5059\u001b[0m       0.7422        \u001b[35m0.5310\u001b[0m  0.0228\n",
      "     45        \u001b[36m0.5042\u001b[0m       0.7422        \u001b[35m0.5299\u001b[0m  0.0214\n",
      "     46        \u001b[36m0.5027\u001b[0m       0.7422        \u001b[35m0.5291\u001b[0m  0.0219\n",
      "     47        \u001b[36m0.5015\u001b[0m       0.7422        \u001b[35m0.5283\u001b[0m  0.0400\n",
      "     48        \u001b[36m0.5001\u001b[0m       0.7422        \u001b[35m0.5276\u001b[0m  0.0210\n",
      "     49        \u001b[36m0.4989\u001b[0m       0.7422        \u001b[35m0.5270\u001b[0m  0.0249\n",
      "     50        \u001b[36m0.4977\u001b[0m       0.7422        \u001b[35m0.5264\u001b[0m  0.0261\n",
      "     51        \u001b[36m0.4965\u001b[0m       0.7422        \u001b[35m0.5259\u001b[0m  0.0236\n",
      "     52        \u001b[36m0.4955\u001b[0m       0.7422        \u001b[35m0.5255\u001b[0m  0.0241\n",
      "     53        \u001b[36m0.4945\u001b[0m       0.7422        \u001b[35m0.5251\u001b[0m  0.0222\n",
      "     54        \u001b[36m0.4935\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5248\u001b[0m  0.0215\n",
      "     55        \u001b[36m0.4926\u001b[0m       0.7500        \u001b[35m0.5245\u001b[0m  0.0330\n",
      "     56        \u001b[36m0.4917\u001b[0m       0.7500        \u001b[35m0.5242\u001b[0m  0.0216\n",
      "     57        \u001b[36m0.4909\u001b[0m       0.7500        \u001b[35m0.5240\u001b[0m  0.0242\n",
      "     58        \u001b[36m0.4901\u001b[0m       0.7500        \u001b[35m0.5237\u001b[0m  0.0298\n",
      "     59        \u001b[36m0.4894\u001b[0m       0.7500        \u001b[35m0.5236\u001b[0m  0.0253\n",
      "     60        \u001b[36m0.4886\u001b[0m       0.7500        \u001b[35m0.5235\u001b[0m  0.0245\n",
      "     61        \u001b[36m0.4880\u001b[0m       0.7422        \u001b[35m0.5234\u001b[0m  0.0253\n",
      "     62        \u001b[36m0.4874\u001b[0m       0.7422        \u001b[35m0.5234\u001b[0m  0.0266\n",
      "     63        \u001b[36m0.4869\u001b[0m       0.7422        \u001b[35m0.5233\u001b[0m  0.0222\n",
      "     64        \u001b[36m0.4863\u001b[0m       0.7422        \u001b[35m0.5233\u001b[0m  0.0454\n",
      "     65        \u001b[36m0.4858\u001b[0m       0.7422        \u001b[35m0.5233\u001b[0m  0.0366\n",
      "     66        \u001b[36m0.4852\u001b[0m       0.7422        0.5233  0.0470\n",
      "     67        \u001b[36m0.4848\u001b[0m       0.7422        0.5233  0.0428\n",
      "     68        \u001b[36m0.4843\u001b[0m       0.7422        0.5233  0.0351\n",
      "     69        \u001b[36m0.4839\u001b[0m       0.7422        0.5233  0.0280\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6513\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6623\u001b[0m  0.0176\n",
      "      2        \u001b[36m0.6402\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6545\u001b[0m  0.0194\n",
      "      3        \u001b[36m0.6301\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6474\u001b[0m  0.0216\n",
      "      4        \u001b[36m0.6207\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6408\u001b[0m  0.0236\n",
      "      5        \u001b[36m0.6119\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6346\u001b[0m  0.0325\n",
      "      6        \u001b[36m0.6032\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6286\u001b[0m  0.0408\n",
      "      7        \u001b[36m0.5949\u001b[0m       0.6562        \u001b[35m0.6229\u001b[0m  0.0477\n",
      "      8        \u001b[36m0.5870\u001b[0m       0.6562        \u001b[35m0.6175\u001b[0m  0.0408\n",
      "      9        \u001b[36m0.5792\u001b[0m       0.6562        \u001b[35m0.6123\u001b[0m  0.0243\n",
      "     10        \u001b[36m0.5717\u001b[0m       0.6641        \u001b[35m0.6074\u001b[0m  0.0343\n",
      "     11        \u001b[36m0.5645\u001b[0m       0.6641        \u001b[35m0.6027\u001b[0m  0.0302\n",
      "     12        \u001b[36m0.5574\u001b[0m       0.6562        \u001b[35m0.5983\u001b[0m  0.0350\n",
      "     13        \u001b[36m0.5506\u001b[0m       0.6484        \u001b[35m0.5941\u001b[0m  0.0506\n",
      "     14        \u001b[36m0.5441\u001b[0m       0.6641        \u001b[35m0.5902\u001b[0m  0.0498\n",
      "     15        \u001b[36m0.5379\u001b[0m       0.6641        \u001b[35m0.5866\u001b[0m  0.0495\n",
      "     16        \u001b[36m0.5321\u001b[0m       0.6719        \u001b[35m0.5833\u001b[0m  0.0429\n",
      "     17        \u001b[36m0.5267\u001b[0m       0.6719        \u001b[35m0.5803\u001b[0m  0.0369\n",
      "     18        \u001b[36m0.5214\u001b[0m       0.6797        \u001b[35m0.5776\u001b[0m  0.0321\n",
      "     19        \u001b[36m0.5166\u001b[0m       0.6797        \u001b[35m0.5751\u001b[0m  0.0243\n",
      "     20        \u001b[36m0.5120\u001b[0m       0.6797        \u001b[35m0.5730\u001b[0m  0.0276\n",
      "     21        \u001b[36m0.5079\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5711\u001b[0m  0.0301\n",
      "     22        \u001b[36m0.5039\u001b[0m       0.6797        \u001b[35m0.5695\u001b[0m  0.0372\n",
      "     23        \u001b[36m0.5004\u001b[0m       0.6797        \u001b[35m0.5682\u001b[0m  0.0328\n",
      "     24        \u001b[36m0.4970\u001b[0m       0.6797        \u001b[35m0.5671\u001b[0m  0.0506\n",
      "     25        \u001b[36m0.4939\u001b[0m       0.6875        \u001b[35m0.5662\u001b[0m  0.0427\n",
      "     26        \u001b[36m0.4912\u001b[0m       0.6875        \u001b[35m0.5655\u001b[0m  0.0479\n",
      "     27        \u001b[36m0.4883\u001b[0m       0.6875        \u001b[35m0.5649\u001b[0m  0.0360\n",
      "     28        \u001b[36m0.4859\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5645\u001b[0m  0.0411\n",
      "     29        \u001b[36m0.4835\u001b[0m       0.6953        \u001b[35m0.5642\u001b[0m  0.0389\n",
      "     30        \u001b[36m0.4813\u001b[0m       0.6953        \u001b[35m0.5639\u001b[0m  0.0436\n",
      "     31        \u001b[36m0.4793\u001b[0m       0.6953        \u001b[35m0.5638\u001b[0m  0.0402\n",
      "     32        \u001b[36m0.4776\u001b[0m       0.6953        \u001b[35m0.5637\u001b[0m  0.0390\n",
      "     33        \u001b[36m0.4758\u001b[0m       0.6875        0.5638  0.0220\n",
      "     34        \u001b[36m0.4742\u001b[0m       0.6875        0.5638  0.0230\n",
      "     35        \u001b[36m0.4727\u001b[0m       0.6875        0.5640  0.0241\n",
      "     36        \u001b[36m0.4713\u001b[0m       0.6875        0.5642  0.0252\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6699\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5872\u001b[0m  0.0310\n",
      "      2        \u001b[36m0.5750\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4980\u001b[0m  0.0441\n",
      "      3        \u001b[36m0.5365\u001b[0m       0.7578        \u001b[35m0.4611\u001b[0m  0.0507\n",
      "      4        \u001b[36m0.5208\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4437\u001b[0m  0.0616\n",
      "      5        \u001b[36m0.5148\u001b[0m       0.7734        \u001b[35m0.4371\u001b[0m  0.0349\n",
      "      6        \u001b[36m0.5148\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4323\u001b[0m  0.0383\n",
      "      7        \u001b[36m0.5049\u001b[0m       0.7812        \u001b[35m0.4237\u001b[0m  0.0606\n",
      "      8        \u001b[36m0.5003\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4221\u001b[0m  0.0616\n",
      "      9        \u001b[36m0.4975\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4102\u001b[0m  0.0608\n",
      "     10        \u001b[36m0.4922\u001b[0m       0.7969        0.4106  0.0622\n",
      "     11        \u001b[36m0.4916\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4063\u001b[0m  0.0535\n",
      "     12        \u001b[36m0.4871\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4021\u001b[0m  0.0588\n",
      "     13        \u001b[36m0.4852\u001b[0m       0.8047        \u001b[35m0.4011\u001b[0m  0.0366\n",
      "     14        \u001b[36m0.4807\u001b[0m       0.8047        \u001b[35m0.3961\u001b[0m  0.0393\n",
      "     15        \u001b[36m0.4798\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.3913\u001b[0m  0.0333\n",
      "     16        \u001b[36m0.4764\u001b[0m       0.8125        \u001b[35m0.3866\u001b[0m  0.0381\n",
      "     17        \u001b[36m0.4727\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m0.3854\u001b[0m  0.0441\n",
      "     18        \u001b[36m0.4701\u001b[0m       0.8203        \u001b[35m0.3842\u001b[0m  0.0453\n",
      "     19        \u001b[36m0.4680\u001b[0m       0.8203        \u001b[35m0.3819\u001b[0m  0.0382\n",
      "     20        \u001b[36m0.4636\u001b[0m       0.8125        0.3858  0.0407\n",
      "     21        \u001b[36m0.4631\u001b[0m       0.8203        \u001b[35m0.3800\u001b[0m  0.0393\n",
      "     22        \u001b[36m0.4579\u001b[0m       0.8125        0.3807  0.0353\n",
      "     23        \u001b[36m0.4565\u001b[0m       0.8203        0.3819  0.0474\n",
      "     24        \u001b[36m0.4543\u001b[0m       0.8125        0.3823  0.0405\n",
      "     25        \u001b[36m0.4531\u001b[0m       0.8203        0.3807  0.0332\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6923\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6617\u001b[0m  0.0580\n",
      "      2        \u001b[36m0.6132\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6032\u001b[0m  0.0600\n",
      "      3        \u001b[36m0.5475\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5584\u001b[0m  0.0616\n",
      "      4        \u001b[36m0.5112\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5441\u001b[0m  0.0518\n",
      "      5        \u001b[36m0.4953\u001b[0m       \u001b[32m0.7031\u001b[0m        0.5458  0.0534\n",
      "      6        \u001b[36m0.4859\u001b[0m       \u001b[32m0.7109\u001b[0m        0.5446  0.0522\n",
      "      7        \u001b[36m0.4839\u001b[0m       0.6953        0.5474  0.0551\n",
      "      8        \u001b[36m0.4786\u001b[0m       0.6953        0.5460  0.0577\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6750\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6492\u001b[0m  0.0457\n",
      "      2        \u001b[36m0.6047\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6099\u001b[0m  0.0556\n",
      "      3        \u001b[36m0.5610\u001b[0m       0.6719        \u001b[35m0.5919\u001b[0m  0.0383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        \u001b[36m0.5388\u001b[0m       0.6875        \u001b[35m0.5906\u001b[0m  0.0453\n",
      "      5        \u001b[36m0.5228\u001b[0m       0.6875        \u001b[35m0.5798\u001b[0m  0.0529\n",
      "      6        \u001b[36m0.5135\u001b[0m       0.6875        \u001b[35m0.5726\u001b[0m  0.0453\n",
      "      7        \u001b[36m0.5050\u001b[0m       0.6719        \u001b[35m0.5693\u001b[0m  0.0528\n",
      "      8        \u001b[36m0.4998\u001b[0m       0.6719        \u001b[35m0.5617\u001b[0m  0.0483\n",
      "      9        \u001b[36m0.4927\u001b[0m       0.6875        \u001b[35m0.5553\u001b[0m  0.0593\n",
      "     10        \u001b[36m0.4889\u001b[0m       0.6797        \u001b[35m0.5507\u001b[0m  0.0439\n",
      "     11        \u001b[36m0.4865\u001b[0m       0.6953        \u001b[35m0.5448\u001b[0m  0.0386\n",
      "     12        \u001b[36m0.4833\u001b[0m       0.6875        \u001b[35m0.5426\u001b[0m  0.0321\n",
      "     13        \u001b[36m0.4803\u001b[0m       0.6875        \u001b[35m0.5378\u001b[0m  0.0406\n",
      "     14        \u001b[36m0.4797\u001b[0m       0.6953        \u001b[35m0.5372\u001b[0m  0.0322\n",
      "     15        0.4799       0.6953        \u001b[35m0.5332\u001b[0m  0.0395\n",
      "     16        \u001b[36m0.4772\u001b[0m       0.6953        \u001b[35m0.5311\u001b[0m  0.0567\n",
      "     17        \u001b[36m0.4743\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5266\u001b[0m  0.0380\n",
      "     18        \u001b[36m0.4720\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5251\u001b[0m  0.0320\n",
      "     19        \u001b[36m0.4689\u001b[0m       0.7188        \u001b[35m0.5209\u001b[0m  0.0371\n",
      "     20        \u001b[36m0.4658\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5187\u001b[0m  0.0318\n",
      "     21        \u001b[36m0.4644\u001b[0m       0.7188        \u001b[35m0.5175\u001b[0m  0.0600\n",
      "     22        \u001b[36m0.4622\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5154\u001b[0m  0.0559\n",
      "     23        \u001b[36m0.4588\u001b[0m       0.7266        0.5155  0.0542\n",
      "     24        \u001b[36m0.4560\u001b[0m       0.7188        \u001b[35m0.5095\u001b[0m  0.0472\n",
      "     25        \u001b[36m0.4530\u001b[0m       0.7266        0.5100  0.0452\n",
      "     26        \u001b[36m0.4513\u001b[0m       0.7422        \u001b[35m0.5077\u001b[0m  0.0533\n",
      "     27        \u001b[36m0.4468\u001b[0m       0.7422        0.5080  0.0499\n",
      "     28        \u001b[36m0.4462\u001b[0m       0.7422        \u001b[35m0.5053\u001b[0m  0.0349\n",
      "     29        \u001b[36m0.4446\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5049\u001b[0m  0.0388\n",
      "     30        0.4450       0.7344        0.5051  0.0520\n",
      "     31        \u001b[36m0.4414\u001b[0m       0.7500        0.5070  0.0556\n",
      "     32        0.4416       0.7422        0.5102  0.0374\n",
      "     33        0.4415       0.7422        0.5101  0.0404\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7281\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6379\u001b[0m  0.0299\n",
      "      2        \u001b[36m0.5912\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5612\u001b[0m  0.0460\n",
      "      3        \u001b[36m0.5179\u001b[0m       0.6953        \u001b[35m0.5430\u001b[0m  0.0622\n",
      "      4        \u001b[36m0.4923\u001b[0m       0.6953        0.5452  0.0544\n",
      "      5        \u001b[36m0.4817\u001b[0m       0.6797        \u001b[35m0.5414\u001b[0m  0.0578\n",
      "      6        \u001b[36m0.4757\u001b[0m       0.6875        0.5435  0.0486\n",
      "      7        \u001b[36m0.4693\u001b[0m       0.6953        \u001b[35m0.5410\u001b[0m  0.0393\n",
      "      8        \u001b[36m0.4654\u001b[0m       0.6797        0.5425  0.0369\n",
      "      9        \u001b[36m0.4637\u001b[0m       0.6719        0.5442  0.0450\n",
      "     10        \u001b[36m0.4582\u001b[0m       0.6797        0.5415  0.0324\n",
      "     11        \u001b[36m0.4577\u001b[0m       0.6719        0.5442  0.0394\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6812\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6274\u001b[0m  0.0299\n",
      "      2        \u001b[36m0.5893\u001b[0m       0.7109        \u001b[35m0.5979\u001b[0m  0.0375\n",
      "      3        \u001b[36m0.5414\u001b[0m       0.7031        \u001b[35m0.5853\u001b[0m  0.0413\n",
      "      4        \u001b[36m0.5119\u001b[0m       0.7031        \u001b[35m0.5763\u001b[0m  0.0340\n",
      "      5        \u001b[36m0.4963\u001b[0m       0.7031        0.5849  0.0406\n",
      "      6        \u001b[36m0.4867\u001b[0m       0.6875        0.5995  0.0344\n",
      "      7        \u001b[36m0.4836\u001b[0m       0.6953        0.5910  0.0340\n",
      "      8        \u001b[36m0.4726\u001b[0m       0.6953        0.5898  0.0426\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6699\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5796\u001b[0m  0.0121\n",
      "      2        \u001b[36m0.5843\u001b[0m       0.7500        \u001b[35m0.4894\u001b[0m  0.0134\n",
      "      3        \u001b[36m0.5438\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4409\u001b[0m  0.0158\n",
      "      4        0.5504       0.7969        \u001b[35m0.4297\u001b[0m  0.0211\n",
      "      5        \u001b[36m0.5348\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4219\u001b[0m  0.0225\n",
      "      6        \u001b[36m0.5206\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4027\u001b[0m  0.0267\n",
      "      7        \u001b[36m0.5150\u001b[0m       0.8203        \u001b[35m0.3980\u001b[0m  0.0230\n",
      "      8        \u001b[36m0.5112\u001b[0m       \u001b[32m0.8438\u001b[0m        \u001b[35m0.3967\u001b[0m  0.0207\n",
      "      9        0.5149       0.8359        \u001b[35m0.3898\u001b[0m  0.0223\n",
      "     10        \u001b[36m0.4968\u001b[0m       0.8281        \u001b[35m0.3815\u001b[0m  0.0389\n",
      "     11        0.5009       0.8438        0.3908  0.0477\n",
      "     12        \u001b[36m0.4960\u001b[0m       0.8438        \u001b[35m0.3674\u001b[0m  0.0365\n",
      "     13        \u001b[36m0.4943\u001b[0m       \u001b[32m0.8516\u001b[0m        \u001b[35m0.3671\u001b[0m  0.0349\n",
      "     14        \u001b[36m0.4877\u001b[0m       \u001b[32m0.8594\u001b[0m        0.3698  0.0307\n",
      "     15        0.4956       0.8438        \u001b[35m0.3660\u001b[0m  0.0385\n",
      "     16        \u001b[36m0.4796\u001b[0m       0.8516        0.3693  0.0278\n",
      "     17        0.4860       0.8359        \u001b[35m0.3602\u001b[0m  0.0288\n",
      "     18        0.4919       0.8594        \u001b[35m0.3526\u001b[0m  0.0253\n",
      "     19        0.4877       0.8594        0.3749  0.0164\n",
      "     20        0.4811       0.8359        0.3723  0.0544\n",
      "     21        \u001b[36m0.4765\u001b[0m       0.8438        0.3707  0.0186\n",
      "     22        \u001b[36m0.4727\u001b[0m       0.8438        0.3727  0.0193\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7396\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6385\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.5909\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5587\u001b[0m  0.0162\n",
      "      3        \u001b[36m0.5460\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5453\u001b[0m  0.0295\n",
      "      4        \u001b[36m0.5213\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5325\u001b[0m  0.0144\n",
      "      5        0.5304       0.7344        \u001b[35m0.5237\u001b[0m  0.0223\n",
      "      6        \u001b[36m0.4957\u001b[0m       0.7422        \u001b[35m0.5222\u001b[0m  0.0229\n",
      "      7        0.4980       0.7109        0.5326  0.0159\n",
      "      8        0.4994       0.7344        \u001b[35m0.5064\u001b[0m  0.0297\n",
      "      9        \u001b[36m0.4639\u001b[0m       0.7344        0.5122  0.0317\n",
      "     10        0.4825       0.7344        0.5083  0.0575\n",
      "     11        0.4722       0.7266        0.5090  0.0421\n",
      "     12        0.4751       0.7188        0.5088  0.0242\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6388\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.5982\u001b[0m  0.0222\n",
      "      2        \u001b[36m0.5561\u001b[0m       \u001b[32m0.6875\u001b[0m        0.5989  0.0145\n",
      "      3        \u001b[36m0.5283\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5677\u001b[0m  0.0379\n",
      "      4        \u001b[36m0.4917\u001b[0m       0.7031        \u001b[35m0.5602\u001b[0m  0.0194\n",
      "      5        0.4966       0.6797        \u001b[35m0.5464\u001b[0m  0.0137\n",
      "      6        \u001b[36m0.4864\u001b[0m       0.6797        0.5556  0.0232\n",
      "      7        \u001b[36m0.4697\u001b[0m       0.6797        0.5704  0.0161\n",
      "      8        0.4799       0.6953        \u001b[35m0.5430\u001b[0m  0.0165\n",
      "      9        \u001b[36m0.4657\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5382\u001b[0m  0.0514\n",
      "     10        \u001b[36m0.4629\u001b[0m       0.7109        \u001b[35m0.5354\u001b[0m  0.0487\n",
      "     11        \u001b[36m0.4566\u001b[0m       0.7188        0.5375  0.0365\n",
      "     12        0.4668       \u001b[32m0.7344\u001b[0m        0.5371  0.0264\n",
      "     13        \u001b[36m0.4417\u001b[0m       0.7266        0.5375  0.0241\n",
      "     14        0.4498       0.7266        0.5398  0.0153\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6652\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5899\u001b[0m  0.0160\n",
      "      2        \u001b[36m0.5480\u001b[0m       0.7500        \u001b[35m0.5290\u001b[0m  0.0199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        \u001b[36m0.5275\u001b[0m       0.7500        0.5357  0.0158\n",
      "      4        \u001b[36m0.5109\u001b[0m       0.7344        \u001b[35m0.5120\u001b[0m  0.0650\n",
      "      5        \u001b[36m0.4936\u001b[0m       0.7266        \u001b[35m0.5060\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.4793\u001b[0m       0.7266        0.5086  0.0164\n",
      "      7        0.4822       0.7188        0.5153  0.0307\n",
      "      8        \u001b[36m0.4720\u001b[0m       0.6875        0.5233  0.0223\n",
      "      9        \u001b[36m0.4635\u001b[0m       0.6953        0.5169  0.0222\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6679\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6307\u001b[0m  0.0128\n",
      "      2        \u001b[36m0.5830\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5555\u001b[0m  0.0163\n",
      "      3        \u001b[36m0.5134\u001b[0m       0.7031        \u001b[35m0.5419\u001b[0m  0.0251\n",
      "      4        \u001b[36m0.4860\u001b[0m       0.6953        0.5531  0.0176\n",
      "      5        \u001b[36m0.4670\u001b[0m       \u001b[32m0.7109\u001b[0m        0.5501  0.0162\n",
      "      6        0.4717       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5298\u001b[0m  0.0160\n",
      "      7        0.4705       0.6875        0.5366  0.0252\n",
      "      8        \u001b[36m0.4394\u001b[0m       0.6953        0.5475  0.0183\n",
      "      9        0.4608       0.7109        0.5473  0.0163\n",
      "     10        0.4441       0.7266        0.5387  0.0286\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6362\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4680\u001b[0m  0.0288\n",
      "      2        \u001b[36m0.5922\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4580\u001b[0m  0.0328\n",
      "      3        \u001b[36m0.5508\u001b[0m       0.6953        0.5076  0.0310\n",
      "      4        \u001b[36m0.5411\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4035\u001b[0m  0.0282\n",
      "      5        0.5624       0.7969        0.4448  0.0454\n",
      "      6        0.5430       0.8047        0.4294  0.0387\n",
      "      7        0.5539       0.7656        0.4262  0.0321\n",
      "      8        0.5533       0.7500        \u001b[35m0.3984\u001b[0m  0.0327\n",
      "      9        \u001b[36m0.5317\u001b[0m       0.7969        0.4231  0.0263\n",
      "     10        \u001b[36m0.5299\u001b[0m       0.7656        0.4333  0.0286\n",
      "     11        0.5479       \u001b[32m0.8281\u001b[0m        0.4312  0.0254\n",
      "     12        0.5456       0.8047        0.4254  0.0265\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5948\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5345\u001b[0m  0.0199\n",
      "      2        \u001b[36m0.5091\u001b[0m       0.7031        0.5667  0.0226\n",
      "      3        0.5225       0.7109        0.5466  0.0302\n",
      "      4        0.5178       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5258\u001b[0m  0.0244\n",
      "      5        \u001b[36m0.4971\u001b[0m       0.7500        0.5298  0.0273\n",
      "      6        \u001b[36m0.4776\u001b[0m       0.7422        \u001b[35m0.4989\u001b[0m  0.0280\n",
      "      7        0.4900       0.7266        0.5647  0.0263\n",
      "      8        0.4848       0.7188        0.5264  0.0256\n",
      "      9        0.4876       0.7422        0.5245  0.0283\n",
      "     10        0.4902       0.7188        0.5492  0.0237\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6041\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5405\u001b[0m  0.0181\n",
      "      2        \u001b[36m0.5323\u001b[0m       0.6875        \u001b[35m0.5360\u001b[0m  0.0199\n",
      "      3        \u001b[36m0.5091\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5294\u001b[0m  0.0286\n",
      "      4        0.5196       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5146\u001b[0m  0.0264\n",
      "      5        0.5295       0.6875        0.5250  0.0271\n",
      "      6        \u001b[36m0.4905\u001b[0m       0.7266        0.5250  0.0261\n",
      "      7        0.4982       0.7266        0.5361  0.0358\n",
      "      8        0.5015       0.7344        0.5435  0.0323\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5984\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5377\u001b[0m  0.0207\n",
      "      2        \u001b[36m0.5168\u001b[0m       0.6875        0.5468  0.0247\n",
      "      3        \u001b[36m0.5144\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5176\u001b[0m  0.0266\n",
      "      4        \u001b[36m0.4947\u001b[0m       0.6875        0.5734  0.0293\n",
      "      5        0.4981       0.7266        0.5385  0.0263\n",
      "      6        0.4975       0.6797        0.5729  0.0257\n",
      "      7        \u001b[36m0.4824\u001b[0m       0.6953        0.5523  0.0287\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5942\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5131\u001b[0m  0.0196\n",
      "      2        \u001b[36m0.5005\u001b[0m       \u001b[32m0.7500\u001b[0m        0.5195  0.0195\n",
      "      3        \u001b[36m0.4815\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5044\u001b[0m  0.0246\n",
      "      4        0.5167       0.7266        0.5289  0.0279\n",
      "      5        \u001b[36m0.4776\u001b[0m       0.7344        0.5168  0.0228\n",
      "      6        \u001b[36m0.4714\u001b[0m       0.7344        0.5081  0.0300\n",
      "      7        0.4792       0.7344        0.5274  0.0236\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6028\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5441\u001b[0m  0.0246\n",
      "      2        \u001b[36m0.5242\u001b[0m       \u001b[32m0.7438\u001b[0m        \u001b[35m0.4995\u001b[0m  0.0178\n",
      "      3        \u001b[36m0.5088\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.4966\u001b[0m  0.0192\n",
      "      4        \u001b[36m0.4824\u001b[0m       0.7188        0.4980  0.0351\n",
      "      5        \u001b[36m0.4692\u001b[0m       \u001b[32m0.7625\u001b[0m        0.4981  0.0263\n",
      "      6        0.4821       0.7250        0.5031  0.0306\n",
      "      7        \u001b[36m0.4682\u001b[0m       0.7438        0.5154  0.0260\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best parameters found:\n",
      "\n",
      "{'optimizer__momentum': 0.9, 'module__num_units': 9, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 64}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.769 (+/-0.054) for {'optimizer__momentum': 0.6, 'module__num_units': 7, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 32}\n",
      "0.742 (+/-0.062) for {'optimizer__momentum': 0.1, 'module__num_units': 6, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 64}\n",
      "0.749 (+/-0.066) for {'optimizer__momentum': 0.3, 'module__num_units': 9, 'module__dropout': 0.5, 'lr': 0.1, 'batch_size': 64}\n",
      "0.722 (+/-0.065) for {'optimizer__momentum': 0.9, 'module__num_units': 3, 'module__dropout': 0.0, 'lr': 1, 'batch_size': 64}\n",
      "0.751 (+/-0.058) for {'optimizer__momentum': 0.9, 'module__num_units': 7, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 16}\n",
      "0.762 (+/-0.029) for {'optimizer__momentum': 0.3, 'module__num_units': 9, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 64}\n",
      "0.736 (+/-0.039) for {'optimizer__momentum': 0.1, 'module__num_units': 6, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 32}\n",
      "0.758 (+/-0.062) for {'optimizer__momentum': 0.9, 'module__num_units': 8, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 16}\n",
      "0.771 (+/-0.058) for {'optimizer__momentum': 0.9, 'module__num_units': 9, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 64}\n",
      "0.756 (+/-0.095) for {'optimizer__momentum': 0.3, 'module__num_units': 5, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 32}\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6681\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6140\u001b[0m  0.0252\n",
      "      2        \u001b[36m0.6142\u001b[0m       0.7422        \u001b[35m0.5383\u001b[0m  0.0246\n",
      "      3        \u001b[36m0.5704\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4863\u001b[0m  0.0254\n",
      "      4        \u001b[36m0.5392\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4608\u001b[0m  0.0264\n",
      "      5        0.5442       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4443\u001b[0m  0.0236\n",
      "      6        0.5407       0.7969        \u001b[35m0.4411\u001b[0m  0.0274\n",
      "      7        \u001b[36m0.5221\u001b[0m       0.7812        \u001b[35m0.4329\u001b[0m  0.0284\n",
      "      8        0.5239       0.7656        \u001b[35m0.4299\u001b[0m  0.0276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9        0.5333       0.7578        0.4312  0.0289\n",
      "     10        \u001b[36m0.5170\u001b[0m       0.7578        0.4317  0.0272\n",
      "     11        \u001b[36m0.5078\u001b[0m       0.7656        \u001b[35m0.4271\u001b[0m  0.0372\n",
      "     12        0.5132       0.7734        \u001b[35m0.4224\u001b[0m  0.0441\n",
      "     13        0.5186       0.7656        0.4300  0.0308\n",
      "     14        0.5121       0.7656        0.4242  0.0265\n",
      "     15        \u001b[36m0.5040\u001b[0m       0.7656        \u001b[35m0.4211\u001b[0m  0.0228\n",
      "     16        0.5139       0.7656        \u001b[35m0.4155\u001b[0m  0.0290\n",
      "     17        0.5098       0.7734        0.4183  0.0343\n",
      "     18        \u001b[36m0.5035\u001b[0m       0.7734        \u001b[35m0.4083\u001b[0m  0.0321\n",
      "     19        0.5166       0.7812        0.4135  0.0254\n",
      "     20        0.5099       0.7812        0.4175  0.0268\n",
      "     21        \u001b[36m0.4891\u001b[0m       0.7969        0.4090  0.0263\n",
      "     22        0.5115       0.7812        0.4124  0.0229\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6873\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6243\u001b[0m  0.0186\n",
      "      2        \u001b[36m0.5881\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5614\u001b[0m  0.0333\n",
      "      3        \u001b[36m0.5427\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5451\u001b[0m  0.0312\n",
      "      4        \u001b[36m0.5190\u001b[0m       0.7188        \u001b[35m0.5397\u001b[0m  0.0277\n",
      "      5        \u001b[36m0.4965\u001b[0m       0.7266        \u001b[35m0.5370\u001b[0m  0.0289\n",
      "      6        0.4978       0.7188        0.5376  0.0221\n",
      "      7        \u001b[36m0.4893\u001b[0m       0.7188        0.5394  0.0224\n",
      "      8        0.5010       0.7031        0.5425  0.0301\n",
      "      9        0.4939       0.6953        0.5387  0.0451\n",
      "     10        \u001b[36m0.4863\u001b[0m       0.6953        \u001b[35m0.5363\u001b[0m  0.0366\n",
      "     11        0.4931       0.7031        \u001b[35m0.5350\u001b[0m  0.0315\n",
      "     12        0.4903       0.7109        \u001b[35m0.5308\u001b[0m  0.0255\n",
      "     13        \u001b[36m0.4829\u001b[0m       0.7031        0.5314  0.0266\n",
      "     14        \u001b[36m0.4823\u001b[0m       0.7109        0.5341  0.0216\n",
      "     15        \u001b[36m0.4790\u001b[0m       0.7109        \u001b[35m0.5281\u001b[0m  0.0271\n",
      "     16        0.4925       0.7109        0.5314  0.0305\n",
      "     17        \u001b[36m0.4676\u001b[0m       0.7031        \u001b[35m0.5276\u001b[0m  0.0288\n",
      "     18        0.4724       0.7266        0.5302  0.0264\n",
      "     19        0.4703       0.7109        0.5293  0.0256\n",
      "     20        0.4719       0.7266        0.5276  0.0281\n",
      "     21        \u001b[36m0.4537\u001b[0m       0.7109        0.5319  0.0274\n",
      "     22        0.4744       0.7188        \u001b[35m0.5265\u001b[0m  0.0273\n",
      "     23        0.4779       0.7031        0.5295  0.0207\n",
      "     24        0.4674       0.7188        0.5293  0.0264\n",
      "     25        0.4755       0.7188        \u001b[35m0.5233\u001b[0m  0.0342\n",
      "     26        0.4676       0.7188        \u001b[35m0.5215\u001b[0m  0.0313\n",
      "     27        0.4701       0.7188        0.5265  0.0287\n",
      "     28        \u001b[36m0.4533\u001b[0m       0.7188        0.5231  0.0439\n",
      "     29        \u001b[36m0.4493\u001b[0m       0.7188        0.5270  0.0339\n",
      "     30        0.4603       0.7188        0.5333  0.0497\n",
      "     31        0.4663       0.7266        \u001b[35m0.5193\u001b[0m  0.0337\n",
      "     32        0.4751       0.7344        \u001b[35m0.5113\u001b[0m  0.0290\n",
      "     33        0.4577       0.7266        0.5154  0.0327\n",
      "     34        0.4518       0.7266        0.5171  0.0349\n",
      "     35        0.4636       0.7188        0.5198  0.0307\n",
      "     36        0.4520       0.7188        0.5189  0.0229\n",
      "     37        0.4739       0.7422        \u001b[35m0.5100\u001b[0m  0.0259\n",
      "     38        \u001b[36m0.4465\u001b[0m       0.7266        0.5188  0.0241\n",
      "     39        0.4555       0.7266        0.5171  0.0201\n",
      "     40        0.4633       0.7188        0.5195  0.0245\n",
      "     41        0.4542       0.7422        0.5151  0.0265\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6721\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6212\u001b[0m  0.0309\n",
      "      2        \u001b[36m0.5757\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5865\u001b[0m  0.0448\n",
      "      3        \u001b[36m0.5481\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5740\u001b[0m  0.0400\n",
      "      4        \u001b[36m0.5308\u001b[0m       0.6953        0.5759  0.0325\n",
      "      5        0.5396       0.6953        \u001b[35m0.5670\u001b[0m  0.0289\n",
      "      6        0.5317       0.6953        \u001b[35m0.5619\u001b[0m  0.0358\n",
      "      7        \u001b[36m0.5259\u001b[0m       0.6875        0.5647  0.0363\n",
      "      8        \u001b[36m0.5176\u001b[0m       0.6953        0.5654  0.0340\n",
      "      9        0.5266       0.6953        \u001b[35m0.5603\u001b[0m  0.0315\n",
      "     10        \u001b[36m0.5134\u001b[0m       0.7031        \u001b[35m0.5503\u001b[0m  0.0484\n",
      "     11        0.5182       0.6875        0.5512  0.0425\n",
      "     12        0.5153       0.6953        \u001b[35m0.5480\u001b[0m  0.0402\n",
      "     13        0.5144       0.6875        \u001b[35m0.5428\u001b[0m  0.0306\n",
      "     14        \u001b[36m0.4979\u001b[0m       0.6875        0.5432  0.0290\n",
      "     15        \u001b[36m0.4957\u001b[0m       0.6875        0.5433  0.0262\n",
      "     16        0.5114       0.6953        \u001b[35m0.5367\u001b[0m  0.0276\n",
      "     17        0.5051       0.7031        \u001b[35m0.5355\u001b[0m  0.0290\n",
      "     18        \u001b[36m0.4902\u001b[0m       0.6875        0.5356  0.0291\n",
      "     19        \u001b[36m0.4853\u001b[0m       0.6953        0.5457  0.0286\n",
      "     20        \u001b[36m0.4730\u001b[0m       0.7031        0.5453  0.0278\n",
      "     21        0.4949       0.7109        0.5518  0.0277\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6182\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5567\u001b[0m  0.0206\n",
      "      2        \u001b[36m0.5495\u001b[0m       0.7578        \u001b[35m0.5228\u001b[0m  0.0246\n",
      "      3        \u001b[36m0.5235\u001b[0m       0.7578        \u001b[35m0.5131\u001b[0m  0.0272\n",
      "      4        0.5298       0.7422        0.5220  0.0298\n",
      "      5        \u001b[36m0.4853\u001b[0m       0.7266        0.5215  0.0284\n",
      "      6        \u001b[36m0.4814\u001b[0m       0.7266        0.5235  0.0277\n",
      "      7        \u001b[36m0.4758\u001b[0m       0.7109        0.5274  0.0222\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7163\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6322\u001b[0m  0.0187\n",
      "      2        \u001b[36m0.5659\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5540\u001b[0m  0.0202\n",
      "      3        \u001b[36m0.5135\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5425\u001b[0m  0.0224\n",
      "      4        \u001b[36m0.4962\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5299\u001b[0m  0.0327\n",
      "      5        \u001b[36m0.4824\u001b[0m       0.7266        0.5309  0.0288\n",
      "      6        0.4867       0.7109        0.5327  0.0232\n",
      "      7        0.4873       0.7188        0.5360  0.0355\n",
      "      8        \u001b[36m0.4672\u001b[0m       0.7109        0.5446  0.0454\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6613\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5739\u001b[0m  0.0451\n",
      "      2        \u001b[36m0.5682\u001b[0m       0.7656        \u001b[35m0.4463\u001b[0m  0.0476\n",
      "      3        \u001b[36m0.5096\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4175\u001b[0m  0.0468\n",
      "      4        \u001b[36m0.4949\u001b[0m       \u001b[32m0.8203\u001b[0m        0.4189  0.0479\n",
      "      5        \u001b[36m0.4848\u001b[0m       0.8047        \u001b[35m0.3917\u001b[0m  0.0447\n",
      "      6        \u001b[36m0.4840\u001b[0m       0.7891        0.4176  0.0492\n",
      "      7        \u001b[36m0.4785\u001b[0m       0.8203        0.4074  0.0470\n",
      "      8        \u001b[36m0.4774\u001b[0m       0.7969        0.3948  0.0246\n",
      "      9        \u001b[36m0.4682\u001b[0m       0.8125        0.3977  0.0305\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6128\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5685\u001b[0m  0.0271\n",
      "      2        \u001b[36m0.5297\u001b[0m       0.7031        \u001b[35m0.5334\u001b[0m  0.0314\n",
      "      3        \u001b[36m0.4962\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5207\u001b[0m  0.0244\n",
      "      4        \u001b[36m0.4845\u001b[0m       0.7109        \u001b[35m0.5189\u001b[0m  0.0281\n",
      "      5        \u001b[36m0.4690\u001b[0m       0.7344        \u001b[35m0.5065\u001b[0m  0.0362\n",
      "      6        \u001b[36m0.4588\u001b[0m       \u001b[32m0.7500\u001b[0m        0.5091  0.0482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7        \u001b[36m0.4520\u001b[0m       0.7344        \u001b[35m0.4998\u001b[0m  0.0211\n",
      "      8        \u001b[36m0.4414\u001b[0m       0.7500        0.5102  0.0230\n",
      "      9        0.4485       0.7344        0.5089  0.0224\n",
      "     10        \u001b[36m0.4407\u001b[0m       0.7188        0.5049  0.0287\n",
      "     11        \u001b[36m0.4377\u001b[0m       0.7422        \u001b[35m0.4937\u001b[0m  0.0257\n",
      "     12        \u001b[36m0.4278\u001b[0m       0.7344        \u001b[35m0.4905\u001b[0m  0.0277\n",
      "     13        0.4309       0.7188        0.4951  0.0282\n",
      "     14        \u001b[36m0.4224\u001b[0m       0.7344        \u001b[35m0.4805\u001b[0m  0.0271\n",
      "     15        0.4278       0.7031        0.4892  0.0214\n",
      "     16        \u001b[36m0.4218\u001b[0m       0.7188        0.5014  0.0269\n",
      "     17        0.4253       0.7109        0.4996  0.0250\n",
      "     18        0.4240       0.7031        0.5482  0.0241\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6457\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5949\u001b[0m  0.0174\n",
      "      2        \u001b[36m0.5146\u001b[0m       0.6953        0.6149  0.0198\n",
      "      3        \u001b[36m0.5076\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5742\u001b[0m  0.0249\n",
      "      4        \u001b[36m0.4741\u001b[0m       0.6953        \u001b[35m0.5694\u001b[0m  0.0247\n",
      "      5        \u001b[36m0.4734\u001b[0m       0.6562        0.5811  0.0292\n",
      "      6        \u001b[36m0.4551\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5587\u001b[0m  0.0259\n",
      "      7        \u001b[36m0.4478\u001b[0m       \u001b[32m0.7422\u001b[0m        0.5720  0.0295\n",
      "      8        \u001b[36m0.4474\u001b[0m       0.7109        0.5820  0.0283\n",
      "      9        0.4516       0.7031        0.5968  0.0262\n",
      "     10        \u001b[36m0.4439\u001b[0m       0.7188        0.5776  0.0265\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6407\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.5820\u001b[0m  0.0187\n",
      "      2        \u001b[36m0.5147\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5406\u001b[0m  0.0200\n",
      "      3        \u001b[36m0.4794\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5301\u001b[0m  0.0218\n",
      "      4        \u001b[36m0.4636\u001b[0m       0.6797        0.5519  0.0290\n",
      "      5        \u001b[36m0.4595\u001b[0m       0.6875        0.5604  0.0282\n",
      "      6        \u001b[36m0.4464\u001b[0m       0.6953        0.5563  0.0239\n",
      "      7        \u001b[36m0.4457\u001b[0m       0.6719        0.5648  0.0250\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6245\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5620\u001b[0m  0.0189\n",
      "      2        \u001b[36m0.4966\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5390\u001b[0m  0.0208\n",
      "      3        \u001b[36m0.4649\u001b[0m       0.7188        0.5407  0.0327\n",
      "      4        0.4693       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5277\u001b[0m  0.0268\n",
      "      5        \u001b[36m0.4524\u001b[0m       0.7344        0.5307  0.0262\n",
      "      6        \u001b[36m0.4384\u001b[0m       0.7188        \u001b[35m0.5233\u001b[0m  0.0224\n",
      "      7        0.4406       0.6875        0.5445  0.0319\n",
      "      8        \u001b[36m0.4300\u001b[0m       0.7344        0.5277  0.0257\n",
      "      9        0.4321       0.7422        0.5509  0.0268\n",
      "     10        \u001b[36m0.4261\u001b[0m       0.7500        0.5443  0.0260\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6818\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5434\u001b[0m  0.0116\n",
      "      2        \u001b[36m0.6294\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.5344\u001b[0m  0.0136\n",
      "      3        0.6465       0.7969        \u001b[35m0.5121\u001b[0m  0.0284\n",
      "      4        0.6298       0.8203        0.5407  0.0422\n",
      "      5        0.6404       0.7891        0.5175  0.0378\n",
      "      6        \u001b[36m0.6248\u001b[0m       0.7734        0.5215  0.0323\n",
      "      7        0.6486       0.7656        0.5564  0.0371\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6905\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6306\u001b[0m  0.0271\n",
      "      2        \u001b[36m0.6374\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5943\u001b[0m  0.0381\n",
      "      3        \u001b[36m0.6083\u001b[0m       0.7109        \u001b[35m0.5414\u001b[0m  0.0403\n",
      "      4        \u001b[36m0.5897\u001b[0m       0.6641        0.5659  0.0325\n",
      "      5        0.6146       0.6641        0.5573  0.0364\n",
      "      6        \u001b[36m0.5724\u001b[0m       0.6953        0.5586  0.0343\n",
      "      7        0.6062       0.6250        0.5946  0.0297\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6567\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5412\u001b[0m  0.0208\n",
      "      2        \u001b[36m0.5721\u001b[0m       0.7344        \u001b[35m0.5345\u001b[0m  0.0278\n",
      "      3        0.5832       0.6797        \u001b[35m0.5327\u001b[0m  0.0162\n",
      "      4        0.5858       0.7344        0.5506  0.0165\n",
      "      5        \u001b[36m0.5687\u001b[0m       0.7031        0.5473  0.0188\n",
      "      6        0.5964       \u001b[32m0.7422\u001b[0m        0.5393  0.0185\n",
      "      7        \u001b[36m0.5578\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5320\u001b[0m  0.0151\n",
      "      8        0.5684       0.7109        0.5329  0.0167\n",
      "      9        \u001b[36m0.5563\u001b[0m       0.7422        \u001b[35m0.5039\u001b[0m  0.0197\n",
      "     10        0.5712       0.7500        0.5276  0.0201\n",
      "     11        0.5773       \u001b[32m0.7578\u001b[0m        0.5267  0.0370\n",
      "     12        0.5864       0.7344        0.5408  0.0397\n",
      "     13        0.5828       0.7109        0.5303  0.0346\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6811\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6014\u001b[0m  0.0342\n",
      "      2        \u001b[36m0.6207\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5327\u001b[0m  0.0320\n",
      "      3        \u001b[36m0.6148\u001b[0m       0.6953        0.5435  0.0270\n",
      "      4        \u001b[36m0.5747\u001b[0m       0.6875        \u001b[35m0.5327\u001b[0m  0.0280\n",
      "      5        \u001b[36m0.5662\u001b[0m       0.6641        0.5386  0.0335\n",
      "      6        \u001b[36m0.5484\u001b[0m       0.6562        0.5455  0.0175\n",
      "      7        0.6103       \u001b[32m0.7656\u001b[0m        0.5345  0.0156\n",
      "      8        0.5825       0.7500        \u001b[35m0.5188\u001b[0m  0.0174\n",
      "      9        0.6105       0.6875        0.5523  0.0238\n",
      "     10        0.5852       0.7422        0.5243  0.0158\n",
      "     11        0.5973       0.7188        0.5351  0.0315\n",
      "     12        0.5884       0.7031        0.5469  0.0159\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6136\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5326\u001b[0m  0.0236\n",
      "      2        \u001b[36m0.5757\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5158\u001b[0m  0.0168\n",
      "      3        \u001b[36m0.5683\u001b[0m       \u001b[32m0.7578\u001b[0m        0.5167  0.0227\n",
      "      4        \u001b[36m0.5598\u001b[0m       \u001b[32m0.7656\u001b[0m        0.5159  0.0274\n",
      "      5        \u001b[36m0.5577\u001b[0m       0.7578        \u001b[35m0.5153\u001b[0m  0.0151\n",
      "      6        \u001b[36m0.5332\u001b[0m       0.7578        0.5187  0.0219\n",
      "      7        0.5431       0.7422        \u001b[35m0.5053\u001b[0m  0.0208\n",
      "      8        0.5457       0.7344        0.5084  0.0200\n",
      "      9        0.5619       0.7344        0.5386  0.0193\n",
      "     10        0.5604       0.7422        0.5235  0.0185\n",
      "     11        0.5639       0.7266        0.5281  0.0207\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6575\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4538\u001b[0m  0.0204\n",
      "      2        \u001b[36m0.5264\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4220\u001b[0m  0.0238\n",
      "      3        \u001b[36m0.5230\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m0.4208\u001b[0m  0.0242\n",
      "      4        \u001b[36m0.5006\u001b[0m       0.8203        \u001b[35m0.3874\u001b[0m  0.0237\n",
      "      5        0.5065       0.7969        0.3998  0.0241\n",
      "      6        \u001b[36m0.4919\u001b[0m       0.8203        \u001b[35m0.3807\u001b[0m  0.0152\n",
      "      7        0.5004       0.8203        0.4276  0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        0.5008       0.7812        0.4019  0.0157\n",
      "      9        \u001b[36m0.4772\u001b[0m       0.8203        0.3816  0.0233\n",
      "     10        0.4907       0.7812        0.4173  0.0224\n",
      "     11        0.4975       0.8281        \u001b[35m0.3709\u001b[0m  0.0193\n",
      "     12        0.4818       0.8203        0.3958  0.0241\n",
      "     13        0.4865       0.7969        0.3962  0.0133\n",
      "     14        0.5089       0.7969        0.3795  0.0189\n",
      "     15        \u001b[36m0.4502\u001b[0m       0.7969        0.3922  0.0152\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5942\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5927\u001b[0m  0.0212\n",
      "      2        \u001b[36m0.5271\u001b[0m       0.7344        \u001b[35m0.5244\u001b[0m  0.0160\n",
      "      3        0.5306       0.7109        \u001b[35m0.5121\u001b[0m  0.0178\n",
      "      4        0.5441       0.7109        0.5207  0.0311\n",
      "      5        \u001b[36m0.5076\u001b[0m       0.7344        0.5325  0.0182\n",
      "      6        \u001b[36m0.5025\u001b[0m       0.7422        0.5180  0.0224\n",
      "      7        \u001b[36m0.4716\u001b[0m       0.7266        0.5162  0.0250\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5985\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5629\u001b[0m  0.0224\n",
      "      2        \u001b[36m0.5403\u001b[0m       \u001b[32m0.7109\u001b[0m        0.5805  0.0499\n",
      "      3        \u001b[36m0.5226\u001b[0m       0.6719        \u001b[35m0.5394\u001b[0m  0.0182\n",
      "      4        0.5264       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5347\u001b[0m  0.0188\n",
      "      5        \u001b[36m0.4960\u001b[0m       0.7266        0.5523  0.0378\n",
      "      6        \u001b[36m0.4890\u001b[0m       0.7344        0.5401  0.0213\n",
      "      7        0.4947       0.7344        \u001b[35m0.5103\u001b[0m  0.0169\n",
      "      8        \u001b[36m0.4747\u001b[0m       \u001b[32m0.7422\u001b[0m        0.5141  0.0172\n",
      "      9        0.4881       0.7188        0.5497  0.0201\n",
      "     10        \u001b[36m0.4650\u001b[0m       0.7422        0.5127  0.0162\n",
      "     11        \u001b[36m0.4632\u001b[0m       0.7422        0.5149  0.0215\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6325\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5916\u001b[0m  0.0140\n",
      "      2        \u001b[36m0.5057\u001b[0m       0.7344        \u001b[35m0.5357\u001b[0m  0.0167\n",
      "      3        \u001b[36m0.4879\u001b[0m       0.7500        \u001b[35m0.5061\u001b[0m  0.0164\n",
      "      4        0.5020       0.7422        0.5324  0.0207\n",
      "      5        \u001b[36m0.4729\u001b[0m       0.7109        \u001b[35m0.5051\u001b[0m  0.0213\n",
      "      6        0.4733       0.7344        0.5051  0.0156\n",
      "      7        \u001b[36m0.4697\u001b[0m       0.7344        0.5506  0.0228\n",
      "      8        0.4773       0.7188        0.5114  0.0310\n",
      "      9        0.4726       0.7344        0.5421  0.0192\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5946\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5330\u001b[0m  0.0271\n",
      "      2        \u001b[36m0.5021\u001b[0m       0.6875        0.5475  0.0183\n",
      "      3        \u001b[36m0.4693\u001b[0m       0.7031        0.5415  0.0215\n",
      "      4        \u001b[36m0.4648\u001b[0m       \u001b[32m0.7188\u001b[0m        0.5441  0.0160\n",
      "      5        \u001b[36m0.4498\u001b[0m       0.7031        0.5656  0.0196\n",
      "      6        0.4608       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5249\u001b[0m  0.0155\n",
      "      7        0.4604       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5122\u001b[0m  0.0229\n",
      "      8        0.4509       0.7031        0.5606  0.0155\n",
      "      9        \u001b[36m0.4430\u001b[0m       0.7109        0.5557  0.0203\n",
      "     10        \u001b[36m0.4389\u001b[0m       0.6953        0.5731  0.0158\n",
      "     11        0.4414       0.7266        0.6113  0.0193\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6657\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6274\u001b[0m  0.0291\n",
      "      2        \u001b[36m0.6513\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6202\u001b[0m  0.0299\n",
      "      3        0.6550       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6143\u001b[0m  0.0312\n",
      "      4        \u001b[36m0.6435\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6088\u001b[0m  0.0321\n",
      "      5        \u001b[36m0.6411\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6037\u001b[0m  0.0310\n",
      "      6        0.6439       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5993\u001b[0m  0.0236\n",
      "      7        \u001b[36m0.6255\u001b[0m       0.7266        \u001b[35m0.5950\u001b[0m  0.0264\n",
      "      8        0.6272       0.7109        \u001b[35m0.5906\u001b[0m  0.0287\n",
      "      9        0.6265       0.7266        \u001b[35m0.5867\u001b[0m  0.0233\n",
      "     10        \u001b[36m0.6220\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5830\u001b[0m  0.0290\n",
      "     11        0.6289       0.7422        \u001b[35m0.5800\u001b[0m  0.0290\n",
      "     12        0.6292       0.7500        \u001b[35m0.5771\u001b[0m  0.0298\n",
      "     13        \u001b[36m0.6118\u001b[0m       0.7500        \u001b[35m0.5737\u001b[0m  0.0308\n",
      "     14        0.6176       0.7500        \u001b[35m0.5705\u001b[0m  0.0314\n",
      "     15        0.6187       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5678\u001b[0m  0.0282\n",
      "     16        \u001b[36m0.5989\u001b[0m       0.7422        \u001b[35m0.5642\u001b[0m  0.0289\n",
      "     17        0.6112       0.7344        \u001b[35m0.5610\u001b[0m  0.0289\n",
      "     18        0.6030       0.7344        \u001b[35m0.5580\u001b[0m  0.0248\n",
      "     19        0.5998       0.7422        \u001b[35m0.5547\u001b[0m  0.0259\n",
      "     20        0.6035       0.7422        \u001b[35m0.5515\u001b[0m  0.0239\n",
      "     21        \u001b[36m0.5967\u001b[0m       0.7344        \u001b[35m0.5489\u001b[0m  0.0277\n",
      "     22        \u001b[36m0.5921\u001b[0m       0.7344        \u001b[35m0.5457\u001b[0m  0.0251\n",
      "     23        \u001b[36m0.5862\u001b[0m       0.7344        \u001b[35m0.5421\u001b[0m  0.0269\n",
      "     24        0.5954       0.7422        \u001b[35m0.5391\u001b[0m  0.0494\n",
      "     25        0.5927       0.7500        \u001b[35m0.5363\u001b[0m  0.0515\n",
      "     26        0.5936       0.7500        \u001b[35m0.5336\u001b[0m  0.0424\n",
      "     27        \u001b[36m0.5782\u001b[0m       0.7578        \u001b[35m0.5303\u001b[0m  0.0308\n",
      "     28        0.5854       0.7578        \u001b[35m0.5274\u001b[0m  0.0240\n",
      "     29        0.5880       0.7578        \u001b[35m0.5246\u001b[0m  0.0264\n",
      "     30        0.5789       0.7578        \u001b[35m0.5222\u001b[0m  0.0215\n",
      "     31        0.5938       0.7578        \u001b[35m0.5202\u001b[0m  0.0278\n",
      "     32        0.5788       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5183\u001b[0m  0.0279\n",
      "     33        0.5962       0.7656        \u001b[35m0.5169\u001b[0m  0.0233\n",
      "     34        0.5858       0.7656        \u001b[35m0.5151\u001b[0m  0.0293\n",
      "     35        0.5851       0.7656        \u001b[35m0.5131\u001b[0m  0.0481\n",
      "     36        0.5785       0.7656        \u001b[35m0.5109\u001b[0m  0.0519\n",
      "     37        \u001b[36m0.5769\u001b[0m       0.7656        \u001b[35m0.5087\u001b[0m  0.0439\n",
      "     38        \u001b[36m0.5677\u001b[0m       0.7656        \u001b[35m0.5063\u001b[0m  0.0482\n",
      "     39        \u001b[36m0.5581\u001b[0m       0.7656        \u001b[35m0.5038\u001b[0m  0.0248\n",
      "     40        0.5714       0.7656        \u001b[35m0.5018\u001b[0m  0.0298\n",
      "     41        0.5662       0.7656        \u001b[35m0.5002\u001b[0m  0.0256\n",
      "     42        0.5743       0.7656        \u001b[35m0.4986\u001b[0m  0.0291\n",
      "     43        0.5805       0.7656        \u001b[35m0.4971\u001b[0m  0.0325\n",
      "     44        0.5758       0.7656        \u001b[35m0.4958\u001b[0m  0.0475\n",
      "     45        0.5664       0.7656        \u001b[35m0.4940\u001b[0m  0.0504\n",
      "     46        0.5788       0.7656        \u001b[35m0.4927\u001b[0m  0.0449\n",
      "     47        0.5771       0.7656        \u001b[35m0.4915\u001b[0m  0.0401\n",
      "     48        0.5725       0.7656        \u001b[35m0.4901\u001b[0m  0.0489\n",
      "     49        0.5617       0.7656        \u001b[35m0.4885\u001b[0m  0.0511\n",
      "     50        \u001b[36m0.5495\u001b[0m       0.7656        \u001b[35m0.4866\u001b[0m  0.0455\n",
      "     51        \u001b[36m0.5475\u001b[0m       0.7656        \u001b[35m0.4849\u001b[0m  0.0424\n",
      "     52        0.5597       0.7656        \u001b[35m0.4835\u001b[0m  0.0430\n",
      "     53        0.5666       0.7656        \u001b[35m0.4825\u001b[0m  0.0429\n",
      "     54        0.5531       0.7656        \u001b[35m0.4814\u001b[0m  0.0470\n",
      "     55        0.5626       0.7656        \u001b[35m0.4804\u001b[0m  0.0475\n",
      "     56        \u001b[36m0.5336\u001b[0m       0.7656        \u001b[35m0.4787\u001b[0m  0.0436\n",
      "     57        0.5670       0.7656        \u001b[35m0.4778\u001b[0m  0.0476\n",
      "     58        0.5482       0.7656        \u001b[35m0.4767\u001b[0m  0.0373\n",
      "     59        0.5532       0.7656        \u001b[35m0.4759\u001b[0m  0.0205\n",
      "     60        0.5648       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4753\u001b[0m  0.0285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     61        0.5674       0.7734        \u001b[35m0.4747\u001b[0m  0.0339\n",
      "     62        0.5422       0.7734        \u001b[35m0.4735\u001b[0m  0.0293\n",
      "     63        0.5535       0.7734        \u001b[35m0.4725\u001b[0m  0.0321\n",
      "     64        0.5460       0.7734        \u001b[35m0.4717\u001b[0m  0.0269\n",
      "     65        0.5597       0.7734        \u001b[35m0.4712\u001b[0m  0.0242\n",
      "     66        0.5509       0.7656        \u001b[35m0.4703\u001b[0m  0.0289\n",
      "     67        0.5679       0.7656        \u001b[35m0.4697\u001b[0m  0.0257\n",
      "     68        0.5578       0.7656        \u001b[35m0.4690\u001b[0m  0.0211\n",
      "     69        0.5490       0.7578        \u001b[35m0.4683\u001b[0m  0.0286\n",
      "     70        0.5440       0.7656        \u001b[35m0.4675\u001b[0m  0.0200\n",
      "     71        0.5585       0.7656        \u001b[35m0.4669\u001b[0m  0.0227\n",
      "     72        0.5440       0.7578        \u001b[35m0.4660\u001b[0m  0.0411\n",
      "     73        0.5558       0.7578        \u001b[35m0.4654\u001b[0m  0.0216\n",
      "     74        0.5577       0.7500        \u001b[35m0.4651\u001b[0m  0.0304\n",
      "     75        0.5633       0.7500        \u001b[35m0.4648\u001b[0m  0.0292\n",
      "     76        0.5351       0.7656        \u001b[35m0.4636\u001b[0m  0.0234\n",
      "     77        0.5575       0.7656        \u001b[35m0.4632\u001b[0m  0.0271\n",
      "     78        0.5506       0.7656        \u001b[35m0.4624\u001b[0m  0.0262\n",
      "     79        0.5643       0.7656        \u001b[35m0.4621\u001b[0m  0.0206\n",
      "     80        0.5684       0.7656        \u001b[35m0.4617\u001b[0m  0.0294\n",
      "     81        0.5387       0.7656        \u001b[35m0.4611\u001b[0m  0.0247\n",
      "     82        0.5531       0.7656        \u001b[35m0.4605\u001b[0m  0.0231\n",
      "     83        0.5374       0.7734        \u001b[35m0.4595\u001b[0m  0.0226\n",
      "     84        0.5471       0.7734        \u001b[35m0.4587\u001b[0m  0.0253\n",
      "     85        0.5455       0.7734        \u001b[35m0.4582\u001b[0m  0.0268\n",
      "     86        0.5467       0.7734        \u001b[35m0.4578\u001b[0m  0.0242\n",
      "     87        0.5606       0.7656        0.4580  0.0240\n",
      "     88        0.5563       0.7734        \u001b[35m0.4577\u001b[0m  0.0207\n",
      "     89        0.5533       0.7734        \u001b[35m0.4574\u001b[0m  0.0269\n",
      "     90        0.5560       0.7656        \u001b[35m0.4568\u001b[0m  0.0285\n",
      "     91        0.5439       0.7656        \u001b[35m0.4562\u001b[0m  0.0217\n",
      "     92        0.5554       0.7656        \u001b[35m0.4559\u001b[0m  0.0264\n",
      "     93        0.5556       0.7656        \u001b[35m0.4558\u001b[0m  0.0299\n",
      "     94        0.5556       0.7656        \u001b[35m0.4556\u001b[0m  0.0249\n",
      "     95        0.5419       0.7656        \u001b[35m0.4550\u001b[0m  0.0326\n",
      "     96        0.5423       0.7656        \u001b[35m0.4545\u001b[0m  0.0271\n",
      "     97        \u001b[36m0.5306\u001b[0m       0.7656        \u001b[35m0.4539\u001b[0m  0.0297\n",
      "     98        0.5338       0.7656        \u001b[35m0.4531\u001b[0m  0.0264\n",
      "     99        0.5348       0.7656        \u001b[35m0.4522\u001b[0m  0.0257\n",
      "    100        0.5561       0.7656        0.4524  0.0272\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8335\u001b[0m       \u001b[32m0.3047\u001b[0m        \u001b[35m0.8786\u001b[0m  0.0212\n",
      "      2        \u001b[36m0.8175\u001b[0m       \u001b[32m0.3438\u001b[0m        \u001b[35m0.8407\u001b[0m  0.0220\n",
      "      3        \u001b[36m0.7914\u001b[0m       \u001b[32m0.3750\u001b[0m        \u001b[35m0.8115\u001b[0m  0.0264\n",
      "      4        \u001b[36m0.7577\u001b[0m       0.3750        \u001b[35m0.7902\u001b[0m  0.0310\n",
      "      5        \u001b[36m0.7502\u001b[0m       \u001b[32m0.3984\u001b[0m        \u001b[35m0.7719\u001b[0m  0.0292\n",
      "      6        \u001b[36m0.7333\u001b[0m       \u001b[32m0.4297\u001b[0m        \u001b[35m0.7571\u001b[0m  0.0259\n",
      "      7        \u001b[36m0.7249\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m0.7436\u001b[0m  0.0299\n",
      "      8        \u001b[36m0.7193\u001b[0m       \u001b[32m0.4844\u001b[0m        \u001b[35m0.7329\u001b[0m  0.0219\n",
      "      9        \u001b[36m0.7075\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.7239\u001b[0m  0.0284\n",
      "     10        \u001b[36m0.7014\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.7158\u001b[0m  0.0284\n",
      "     11        \u001b[36m0.6931\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.7086\u001b[0m  0.0290\n",
      "     12        \u001b[36m0.6863\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.7021\u001b[0m  0.0227\n",
      "     13        \u001b[36m0.6758\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6959\u001b[0m  0.0294\n",
      "     14        0.6760       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6904\u001b[0m  0.0287\n",
      "     15        0.6786       0.6250        \u001b[35m0.6855\u001b[0m  0.0288\n",
      "     16        \u001b[36m0.6682\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6810\u001b[0m  0.0236\n",
      "     17        \u001b[36m0.6641\u001b[0m       0.6328        \u001b[35m0.6769\u001b[0m  0.0283\n",
      "     18        \u001b[36m0.6605\u001b[0m       0.6250        \u001b[35m0.6725\u001b[0m  0.0261\n",
      "     19        0.6606       0.6328        \u001b[35m0.6684\u001b[0m  0.0264\n",
      "     20        \u001b[36m0.6585\u001b[0m       0.6328        \u001b[35m0.6643\u001b[0m  0.0259\n",
      "     21        \u001b[36m0.6551\u001b[0m       0.6250        \u001b[35m0.6600\u001b[0m  0.0261\n",
      "     22        \u001b[36m0.6462\u001b[0m       0.6250        \u001b[35m0.6559\u001b[0m  0.0275\n",
      "     23        \u001b[36m0.6454\u001b[0m       0.6328        \u001b[35m0.6517\u001b[0m  0.0274\n",
      "     24        \u001b[36m0.6385\u001b[0m       0.6328        \u001b[35m0.6475\u001b[0m  0.0287\n",
      "     25        \u001b[36m0.6364\u001b[0m       0.6406        \u001b[35m0.6437\u001b[0m  0.0260\n",
      "     26        \u001b[36m0.6307\u001b[0m       0.6328        \u001b[35m0.6400\u001b[0m  0.0312\n",
      "     27        \u001b[36m0.6306\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6361\u001b[0m  0.0288\n",
      "     28        \u001b[36m0.6245\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6322\u001b[0m  0.0237\n",
      "     29        \u001b[36m0.6206\u001b[0m       0.6484        \u001b[35m0.6285\u001b[0m  0.0296\n",
      "     30        0.6208       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6250\u001b[0m  0.0249\n",
      "     31        \u001b[36m0.6147\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6217\u001b[0m  0.0351\n",
      "     32        \u001b[36m0.6101\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6188\u001b[0m  0.0308\n",
      "     33        0.6159       0.6797        \u001b[35m0.6163\u001b[0m  0.0229\n",
      "     34        \u001b[36m0.6048\u001b[0m       0.6719        \u001b[35m0.6136\u001b[0m  0.0506\n",
      "     35        \u001b[36m0.6015\u001b[0m       0.6719        \u001b[35m0.6110\u001b[0m  0.0222\n",
      "     36        \u001b[36m0.6009\u001b[0m       0.6797        \u001b[35m0.6084\u001b[0m  0.0315\n",
      "     37        0.6017       0.6797        \u001b[35m0.6061\u001b[0m  0.0271\n",
      "     38        0.6026       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6039\u001b[0m  0.0301\n",
      "     39        \u001b[36m0.5904\u001b[0m       0.6875        \u001b[35m0.6016\u001b[0m  0.0295\n",
      "     40        0.5996       0.6875        \u001b[35m0.5999\u001b[0m  0.0292\n",
      "     41        0.5935       0.6875        \u001b[35m0.5982\u001b[0m  0.0296\n",
      "     42        \u001b[36m0.5851\u001b[0m       0.6875        \u001b[35m0.5965\u001b[0m  0.0236\n",
      "     43        0.5859       0.6875        \u001b[35m0.5947\u001b[0m  0.0283\n",
      "     44        \u001b[36m0.5813\u001b[0m       0.6875        \u001b[35m0.5930\u001b[0m  0.0238\n",
      "     45        \u001b[36m0.5771\u001b[0m       0.6875        \u001b[35m0.5915\u001b[0m  0.0251\n",
      "     46        0.5848       0.6875        \u001b[35m0.5900\u001b[0m  0.0372\n",
      "     47        \u001b[36m0.5659\u001b[0m       0.6875        \u001b[35m0.5884\u001b[0m  0.0376\n",
      "     48        0.5878       0.6875        \u001b[35m0.5871\u001b[0m  0.0282\n",
      "     49        0.5825       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5859\u001b[0m  0.0252\n",
      "     50        0.5878       0.6953        \u001b[35m0.5850\u001b[0m  0.0255\n",
      "     51        0.5703       0.6953        \u001b[35m0.5836\u001b[0m  0.0249\n",
      "     52        0.5767       0.6953        \u001b[35m0.5824\u001b[0m  0.0326\n",
      "     53        \u001b[36m0.5592\u001b[0m       0.6953        \u001b[35m0.5812\u001b[0m  0.0260\n",
      "     54        0.5730       0.6953        \u001b[35m0.5800\u001b[0m  0.0320\n",
      "     55        \u001b[36m0.5588\u001b[0m       0.6953        \u001b[35m0.5786\u001b[0m  0.0199\n",
      "     56        0.5684       0.6953        \u001b[35m0.5774\u001b[0m  0.0242\n",
      "     57        0.5698       0.6953        \u001b[35m0.5760\u001b[0m  0.0263\n",
      "     58        0.5674       0.6953        \u001b[35m0.5752\u001b[0m  0.0260\n",
      "     59        \u001b[36m0.5575\u001b[0m       0.6953        \u001b[35m0.5742\u001b[0m  0.0271\n",
      "     60        0.5617       0.6953        \u001b[35m0.5732\u001b[0m  0.0283\n",
      "     61        \u001b[36m0.5558\u001b[0m       0.6953        \u001b[35m0.5720\u001b[0m  0.0226\n",
      "     62        0.5693       0.6953        \u001b[35m0.5711\u001b[0m  0.0248\n",
      "     63        0.5612       0.6953        \u001b[35m0.5701\u001b[0m  0.0257\n",
      "     64        \u001b[36m0.5474\u001b[0m       0.6953        \u001b[35m0.5692\u001b[0m  0.0239\n",
      "     65        \u001b[36m0.5437\u001b[0m       0.6953        \u001b[35m0.5681\u001b[0m  0.0249\n",
      "     66        0.5682       0.6953        \u001b[35m0.5672\u001b[0m  0.0288\n",
      "     67        \u001b[36m0.5308\u001b[0m       0.6953        \u001b[35m0.5663\u001b[0m  0.0216\n",
      "     68        0.5642       0.6953        \u001b[35m0.5656\u001b[0m  0.0249\n",
      "     69        0.5410       0.6953        \u001b[35m0.5647\u001b[0m  0.0260\n",
      "     70        0.5553       0.6953        \u001b[35m0.5639\u001b[0m  0.0277\n",
      "     71        0.5540       0.6953        \u001b[35m0.5630\u001b[0m  0.0239\n",
      "     72        0.5485       0.6953        \u001b[35m0.5622\u001b[0m  0.0223\n",
      "     73        0.5558       0.6953        \u001b[35m0.5616\u001b[0m  0.0211\n",
      "     74        0.5527       0.6953        \u001b[35m0.5609\u001b[0m  0.0268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     75        0.5615       0.6953        \u001b[35m0.5603\u001b[0m  0.0261\n",
      "     76        0.5547       0.6953        \u001b[35m0.5598\u001b[0m  0.0279\n",
      "     77        0.5383       0.6953        \u001b[35m0.5589\u001b[0m  0.0233\n",
      "     78        0.5501       0.6953        \u001b[35m0.5582\u001b[0m  0.0226\n",
      "     79        0.5427       0.6953        \u001b[35m0.5576\u001b[0m  0.0265\n",
      "     80        0.5354       0.6953        \u001b[35m0.5569\u001b[0m  0.0192\n",
      "     81        0.5448       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5564\u001b[0m  0.0217\n",
      "     82        0.5443       0.7031        \u001b[35m0.5557\u001b[0m  0.0203\n",
      "     83        0.5335       0.7031        \u001b[35m0.5551\u001b[0m  0.0225\n",
      "     84        0.5465       0.7031        \u001b[35m0.5545\u001b[0m  0.0216\n",
      "     85        0.5489       0.7031        \u001b[35m0.5540\u001b[0m  0.0214\n",
      "     86        0.5350       0.7031        \u001b[35m0.5533\u001b[0m  0.0262\n",
      "     87        0.5339       0.7031        \u001b[35m0.5526\u001b[0m  0.0367\n",
      "     88        0.5468       0.7031        \u001b[35m0.5520\u001b[0m  0.0256\n",
      "     89        0.5339       0.7031        \u001b[35m0.5514\u001b[0m  0.0230\n",
      "     90        0.5434       0.7031        \u001b[35m0.5509\u001b[0m  0.0339\n",
      "     91        0.5663       0.7031        \u001b[35m0.5507\u001b[0m  0.0234\n",
      "     92        0.5553       0.7031        \u001b[35m0.5503\u001b[0m  0.0238\n",
      "     93        0.5340       0.7031        \u001b[35m0.5499\u001b[0m  0.0515\n",
      "     94        0.5485       0.7031        \u001b[35m0.5494\u001b[0m  0.0187\n",
      "     95        0.5523       0.7031        \u001b[35m0.5490\u001b[0m  0.0256\n",
      "     96        0.5501       0.7031        \u001b[35m0.5485\u001b[0m  0.0206\n",
      "     97        0.5497       0.7031        \u001b[35m0.5480\u001b[0m  0.0197\n",
      "     98        0.5541       0.7031        \u001b[35m0.5475\u001b[0m  0.0195\n",
      "     99        0.5421       0.7031        \u001b[35m0.5471\u001b[0m  0.0304\n",
      "    100        0.5422       0.7031        \u001b[35m0.5468\u001b[0m  0.0233\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6665\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6443\u001b[0m  0.0182\n",
      "      2        0.6740       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6397\u001b[0m  0.0373\n",
      "      3        \u001b[36m0.6631\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6355\u001b[0m  0.0212\n",
      "      4        \u001b[36m0.6617\u001b[0m       0.6797        \u001b[35m0.6319\u001b[0m  0.0213\n",
      "      5        \u001b[36m0.6596\u001b[0m       0.6797        \u001b[35m0.6285\u001b[0m  0.0271\n",
      "      6        \u001b[36m0.6459\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6250\u001b[0m  0.0228\n",
      "      7        \u001b[36m0.6445\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6217\u001b[0m  0.0255\n",
      "      8        \u001b[36m0.6443\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6190\u001b[0m  0.0212\n",
      "      9        \u001b[36m0.6381\u001b[0m       0.7344        \u001b[35m0.6163\u001b[0m  0.0222\n",
      "     10        \u001b[36m0.6370\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6138\u001b[0m  0.0225\n",
      "     11        \u001b[36m0.6367\u001b[0m       0.7578        \u001b[35m0.6118\u001b[0m  0.0210\n",
      "     12        \u001b[36m0.6215\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.6095\u001b[0m  0.0228\n",
      "     13        0.6263       0.7656        \u001b[35m0.6075\u001b[0m  0.0210\n",
      "     14        0.6231       0.7500        \u001b[35m0.6056\u001b[0m  0.0229\n",
      "     15        \u001b[36m0.6146\u001b[0m       0.7578        \u001b[35m0.6039\u001b[0m  0.0231\n",
      "     16        \u001b[36m0.6114\u001b[0m       0.7578        \u001b[35m0.6020\u001b[0m  0.0222\n",
      "     17        \u001b[36m0.6113\u001b[0m       0.7578        \u001b[35m0.6005\u001b[0m  0.0205\n",
      "     18        0.6120       0.7578        \u001b[35m0.5990\u001b[0m  0.0247\n",
      "     19        \u001b[36m0.6100\u001b[0m       0.7578        \u001b[35m0.5977\u001b[0m  0.0223\n",
      "     20        0.6116       0.7578        \u001b[35m0.5966\u001b[0m  0.0219\n",
      "     21        \u001b[36m0.5924\u001b[0m       0.7578        \u001b[35m0.5951\u001b[0m  0.0209\n",
      "     22        0.6067       0.7500        \u001b[35m0.5942\u001b[0m  0.0237\n",
      "     23        0.6093       0.7500        \u001b[35m0.5933\u001b[0m  0.0234\n",
      "     24        \u001b[36m0.5859\u001b[0m       0.7422        \u001b[35m0.5921\u001b[0m  0.0217\n",
      "     25        0.6223       0.7344        \u001b[35m0.5917\u001b[0m  0.0227\n",
      "     26        0.5885       0.7344        \u001b[35m0.5905\u001b[0m  0.0250\n",
      "     27        0.5880       0.7344        \u001b[35m0.5896\u001b[0m  0.0207\n",
      "     28        0.5998       0.7266        \u001b[35m0.5891\u001b[0m  0.0250\n",
      "     29        0.5975       0.7188        \u001b[35m0.5884\u001b[0m  0.0252\n",
      "     30        \u001b[36m0.5844\u001b[0m       0.7188        \u001b[35m0.5876\u001b[0m  0.0226\n",
      "     31        \u001b[36m0.5825\u001b[0m       0.7188        \u001b[35m0.5869\u001b[0m  0.0212\n",
      "     32        0.6000       0.7188        \u001b[35m0.5865\u001b[0m  0.0263\n",
      "     33        0.5926       0.7188        \u001b[35m0.5860\u001b[0m  0.0305\n",
      "     34        \u001b[36m0.5787\u001b[0m       0.7266        \u001b[35m0.5854\u001b[0m  0.0318\n",
      "     35        0.5800       0.7266        \u001b[35m0.5851\u001b[0m  0.0284\n",
      "     36        0.5812       0.7266        \u001b[35m0.5845\u001b[0m  0.0246\n",
      "     37        0.5991       0.7266        \u001b[35m0.5844\u001b[0m  0.0246\n",
      "     38        \u001b[36m0.5783\u001b[0m       0.7266        \u001b[35m0.5838\u001b[0m  0.0270\n",
      "     39        \u001b[36m0.5771\u001b[0m       0.7266        \u001b[35m0.5834\u001b[0m  0.0252\n",
      "     40        0.5997       0.7266        \u001b[35m0.5832\u001b[0m  0.0260\n",
      "     41        0.5907       0.7266        \u001b[35m0.5830\u001b[0m  0.0266\n",
      "     42        \u001b[36m0.5690\u001b[0m       0.7188        \u001b[35m0.5826\u001b[0m  0.0282\n",
      "     43        0.5795       0.7266        0.5826  0.0245\n",
      "     44        0.5707       0.7266        \u001b[35m0.5823\u001b[0m  0.0307\n",
      "     45        \u001b[36m0.5561\u001b[0m       0.7266        \u001b[35m0.5819\u001b[0m  0.0324\n",
      "     46        0.5927       0.7266        0.5820  0.0274\n",
      "     47        0.5753       0.7188        \u001b[35m0.5818\u001b[0m  0.0277\n",
      "     48        0.5754       0.7188        \u001b[35m0.5817\u001b[0m  0.0242\n",
      "     49        0.5813       0.7188        0.5818  0.0269\n",
      "     50        0.5909       0.7031        \u001b[35m0.5817\u001b[0m  0.0231\n",
      "     51        0.5654       0.7031        \u001b[35m0.5817\u001b[0m  0.0296\n",
      "     52        0.5626       0.7031        \u001b[35m0.5816\u001b[0m  0.0331\n",
      "     53        \u001b[36m0.5502\u001b[0m       0.7031        \u001b[35m0.5812\u001b[0m  0.0239\n",
      "     54        0.5890       0.7031        \u001b[35m0.5812\u001b[0m  0.0257\n",
      "     55        0.5559       0.7109        \u001b[35m0.5808\u001b[0m  0.0267\n",
      "     56        0.5724       0.7109        0.5808  0.0244\n",
      "     57        0.5719       0.7109        \u001b[35m0.5807\u001b[0m  0.0246\n",
      "     58        0.5672       0.7109        \u001b[35m0.5807\u001b[0m  0.0258\n",
      "     59        0.5633       0.7109        \u001b[35m0.5804\u001b[0m  0.0314\n",
      "     60        0.5715       0.7109        \u001b[35m0.5804\u001b[0m  0.0360\n",
      "     61        0.5760       0.7109        \u001b[35m0.5804\u001b[0m  0.0328\n",
      "     62        0.5738       0.7031        0.5806  0.0218\n",
      "     63        0.5683       0.7031        0.5807  0.0344\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7111\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7049\u001b[0m  0.0198\n",
      "      2        \u001b[36m0.7077\u001b[0m       0.5000        \u001b[35m0.7022\u001b[0m  0.0225\n",
      "      3        \u001b[36m0.7045\u001b[0m       0.5000        \u001b[35m0.7000\u001b[0m  0.0340\n",
      "      4        \u001b[36m0.7025\u001b[0m       0.5000        \u001b[35m0.6979\u001b[0m  0.0322\n",
      "      5        \u001b[36m0.7005\u001b[0m       0.5000        \u001b[35m0.6959\u001b[0m  0.0314\n",
      "      6        \u001b[36m0.6973\u001b[0m       0.5000        \u001b[35m0.6940\u001b[0m  0.0270\n",
      "      7        \u001b[36m0.6945\u001b[0m       0.5000        \u001b[35m0.6925\u001b[0m  0.0312\n",
      "      8        \u001b[36m0.6924\u001b[0m       0.5000        \u001b[35m0.6910\u001b[0m  0.0290\n",
      "      9        \u001b[36m0.6907\u001b[0m       0.5000        \u001b[35m0.6895\u001b[0m  0.0315\n",
      "     10        \u001b[36m0.6879\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6880\u001b[0m  0.0320\n",
      "     11        \u001b[36m0.6857\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6863\u001b[0m  0.0266\n",
      "     12        \u001b[36m0.6837\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6847\u001b[0m  0.0277\n",
      "     13        \u001b[36m0.6819\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6831\u001b[0m  0.0284\n",
      "     14        \u001b[36m0.6776\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6812\u001b[0m  0.0275\n",
      "     15        0.6782       0.6641        \u001b[35m0.6795\u001b[0m  0.0447\n",
      "     16        \u001b[36m0.6754\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6776\u001b[0m  0.0199\n",
      "     17        \u001b[36m0.6702\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6754\u001b[0m  0.0218\n",
      "     18        \u001b[36m0.6678\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6731\u001b[0m  0.0199\n",
      "     19        \u001b[36m0.6670\u001b[0m       0.6875        \u001b[35m0.6708\u001b[0m  0.0539\n",
      "     20        \u001b[36m0.6628\u001b[0m       0.6797        \u001b[35m0.6683\u001b[0m  0.0269\n",
      "     21        \u001b[36m0.6611\u001b[0m       0.6719        \u001b[35m0.6659\u001b[0m  0.0196\n",
      "     22        \u001b[36m0.6559\u001b[0m       0.6719        \u001b[35m0.6630\u001b[0m  0.0237\n",
      "     23        \u001b[36m0.6539\u001b[0m       0.6719        \u001b[35m0.6601\u001b[0m  0.0373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24        \u001b[36m0.6479\u001b[0m       0.6562        \u001b[35m0.6569\u001b[0m  0.0221\n",
      "     25        \u001b[36m0.6465\u001b[0m       0.6562        \u001b[35m0.6538\u001b[0m  0.0208\n",
      "     26        \u001b[36m0.6429\u001b[0m       0.6562        \u001b[35m0.6505\u001b[0m  0.0229\n",
      "     27        \u001b[36m0.6374\u001b[0m       0.6562        \u001b[35m0.6470\u001b[0m  0.0202\n",
      "     28        \u001b[36m0.6344\u001b[0m       0.6562        \u001b[35m0.6436\u001b[0m  0.0220\n",
      "     29        \u001b[36m0.6314\u001b[0m       0.6562        \u001b[35m0.6402\u001b[0m  0.0271\n",
      "     30        \u001b[36m0.6285\u001b[0m       0.6562        \u001b[35m0.6367\u001b[0m  0.0274\n",
      "     31        \u001b[36m0.6194\u001b[0m       0.6562        \u001b[35m0.6332\u001b[0m  0.0303\n",
      "     32        \u001b[36m0.6157\u001b[0m       0.6562        \u001b[35m0.6295\u001b[0m  0.0257\n",
      "     33        \u001b[36m0.6125\u001b[0m       0.6562        \u001b[35m0.6259\u001b[0m  0.0265\n",
      "     34        \u001b[36m0.6039\u001b[0m       0.6641        \u001b[35m0.6223\u001b[0m  0.0336\n",
      "     35        0.6055       0.6641        \u001b[35m0.6189\u001b[0m  0.0235\n",
      "     36        0.6128       0.6641        \u001b[35m0.6160\u001b[0m  0.0246\n",
      "     37        \u001b[36m0.5998\u001b[0m       0.6562        \u001b[35m0.6127\u001b[0m  0.0237\n",
      "     38        \u001b[36m0.5941\u001b[0m       0.6562        \u001b[35m0.6094\u001b[0m  0.0235\n",
      "     39        \u001b[36m0.5860\u001b[0m       0.6562        \u001b[35m0.6062\u001b[0m  0.0269\n",
      "     40        0.5879       0.6641        \u001b[35m0.6033\u001b[0m  0.0194\n",
      "     41        \u001b[36m0.5858\u001b[0m       0.6641        \u001b[35m0.6003\u001b[0m  0.0306\n",
      "     42        0.5910       0.6641        \u001b[35m0.5981\u001b[0m  0.0227\n",
      "     43        \u001b[36m0.5764\u001b[0m       0.6641        \u001b[35m0.5954\u001b[0m  0.0238\n",
      "     44        \u001b[36m0.5669\u001b[0m       0.6641        \u001b[35m0.5927\u001b[0m  0.0283\n",
      "     45        0.5737       0.6641        \u001b[35m0.5906\u001b[0m  0.0235\n",
      "     46        0.5691       0.6641        \u001b[35m0.5885\u001b[0m  0.0258\n",
      "     47        \u001b[36m0.5614\u001b[0m       0.6641        \u001b[35m0.5862\u001b[0m  0.0240\n",
      "     48        \u001b[36m0.5612\u001b[0m       0.6719        \u001b[35m0.5843\u001b[0m  0.0215\n",
      "     49        \u001b[36m0.5561\u001b[0m       0.6719        \u001b[35m0.5825\u001b[0m  0.0231\n",
      "     50        0.5591       0.6719        \u001b[35m0.5809\u001b[0m  0.0225\n",
      "     51        0.5583       0.6797        \u001b[35m0.5792\u001b[0m  0.0288\n",
      "     52        \u001b[36m0.5483\u001b[0m       0.6797        \u001b[35m0.5775\u001b[0m  0.0247\n",
      "     53        0.5528       0.6797        \u001b[35m0.5761\u001b[0m  0.0258\n",
      "     54        0.5622       0.6797        \u001b[35m0.5748\u001b[0m  0.0267\n",
      "     55        0.5669       0.6875        \u001b[35m0.5739\u001b[0m  0.0238\n",
      "     56        \u001b[36m0.5478\u001b[0m       0.6875        \u001b[35m0.5729\u001b[0m  0.0277\n",
      "     57        0.5511       0.6875        \u001b[35m0.5720\u001b[0m  0.0192\n",
      "     58        \u001b[36m0.5427\u001b[0m       0.6875        \u001b[35m0.5710\u001b[0m  0.0258\n",
      "     59        \u001b[36m0.5264\u001b[0m       0.6875        \u001b[35m0.5701\u001b[0m  0.0208\n",
      "     60        0.5424       0.6875        \u001b[35m0.5692\u001b[0m  0.0274\n",
      "     61        0.5340       0.6953        \u001b[35m0.5685\u001b[0m  0.0219\n",
      "     62        0.5418       0.6953        \u001b[35m0.5676\u001b[0m  0.0268\n",
      "     63        0.5468       0.6953        \u001b[35m0.5670\u001b[0m  0.0219\n",
      "     64        0.5619       0.6953        \u001b[35m0.5665\u001b[0m  0.0223\n",
      "     65        0.5436       0.6953        \u001b[35m0.5660\u001b[0m  0.0281\n",
      "     66        0.5326       0.6953        \u001b[35m0.5653\u001b[0m  0.0204\n",
      "     67        0.5422       0.6953        \u001b[35m0.5650\u001b[0m  0.0290\n",
      "     68        0.5318       0.6953        \u001b[35m0.5647\u001b[0m  0.0287\n",
      "     69        0.5447       0.6953        \u001b[35m0.5644\u001b[0m  0.0224\n",
      "     70        0.5446       0.6953        \u001b[35m0.5642\u001b[0m  0.0216\n",
      "     71        0.5382       0.6953        \u001b[35m0.5641\u001b[0m  0.0223\n",
      "     72        0.5386       0.6953        \u001b[35m0.5639\u001b[0m  0.0242\n",
      "     73        0.5400       0.6953        \u001b[35m0.5635\u001b[0m  0.0205\n",
      "     74        0.5297       0.6953        \u001b[35m0.5632\u001b[0m  0.0298\n",
      "     75        0.5381       0.6953        \u001b[35m0.5630\u001b[0m  0.0206\n",
      "     76        0.5397       0.6953        \u001b[35m0.5627\u001b[0m  0.0287\n",
      "     77        0.5278       0.6953        \u001b[35m0.5626\u001b[0m  0.0240\n",
      "     78        0.5347       0.6797        \u001b[35m0.5624\u001b[0m  0.0241\n",
      "     79        0.5440       0.6797        0.5624  0.0208\n",
      "     80        0.5457       0.6797        \u001b[35m0.5623\u001b[0m  0.0267\n",
      "     81        0.5303       0.6797        \u001b[35m0.5622\u001b[0m  0.0221\n",
      "     82        0.5323       0.6797        0.5623  0.0217\n",
      "     83        0.5374       0.6797        0.5622  0.0317\n",
      "     84        0.5399       0.6797        \u001b[35m0.5621\u001b[0m  0.0225\n",
      "     85        0.5315       0.6797        0.5622  0.0226\n",
      "     86        0.5323       0.6797        \u001b[35m0.5619\u001b[0m  0.0237\n",
      "     87        0.5373       0.6797        \u001b[35m0.5616\u001b[0m  0.0223\n",
      "     88        0.5428       0.6797        \u001b[35m0.5615\u001b[0m  0.0201\n",
      "     89        0.5346       0.6797        \u001b[35m0.5612\u001b[0m  0.0218\n",
      "     90        0.5273       0.6797        0.5612  0.0228\n",
      "     91        0.5274       0.6797        0.5615  0.0223\n",
      "     92        0.5416       0.6875        0.5617  0.0220\n",
      "     93        \u001b[36m0.5103\u001b[0m       0.6875        0.5617  0.0218\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8990\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.9032\u001b[0m  0.0202\n",
      "      2        \u001b[36m0.8605\u001b[0m       0.5000        \u001b[35m0.8626\u001b[0m  0.0416\n",
      "      3        \u001b[36m0.8226\u001b[0m       0.5000        \u001b[35m0.8309\u001b[0m  0.0264\n",
      "      4        \u001b[36m0.7951\u001b[0m       0.5000        \u001b[35m0.8062\u001b[0m  0.0233\n",
      "      5        \u001b[36m0.7760\u001b[0m       0.5000        \u001b[35m0.7851\u001b[0m  0.0247\n",
      "      6        \u001b[36m0.7596\u001b[0m       0.5000        \u001b[35m0.7672\u001b[0m  0.0392\n",
      "      7        \u001b[36m0.7424\u001b[0m       0.5000        \u001b[35m0.7534\u001b[0m  0.0270\n",
      "      8        \u001b[36m0.7345\u001b[0m       0.5000        \u001b[35m0.7406\u001b[0m  0.0370\n",
      "      9        \u001b[36m0.7224\u001b[0m       0.5000        \u001b[35m0.7301\u001b[0m  0.0314\n",
      "     10        \u001b[36m0.7137\u001b[0m       0.5000        \u001b[35m0.7210\u001b[0m  0.0223\n",
      "     11        \u001b[36m0.7029\u001b[0m       0.5000        \u001b[35m0.7138\u001b[0m  0.0274\n",
      "     12        \u001b[36m0.7012\u001b[0m       0.5000        \u001b[35m0.7076\u001b[0m  0.0202\n",
      "     13        \u001b[36m0.6954\u001b[0m       0.5000        \u001b[35m0.7020\u001b[0m  0.0281\n",
      "     14        \u001b[36m0.6893\u001b[0m       0.5000        \u001b[35m0.6969\u001b[0m  0.0275\n",
      "     15        \u001b[36m0.6851\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6924\u001b[0m  0.0352\n",
      "     16        \u001b[36m0.6779\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6881\u001b[0m  0.0254\n",
      "     17        \u001b[36m0.6741\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6840\u001b[0m  0.0252\n",
      "     18        \u001b[36m0.6727\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6803\u001b[0m  0.0275\n",
      "     19        \u001b[36m0.6695\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6767\u001b[0m  0.0256\n",
      "     20        \u001b[36m0.6653\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6732\u001b[0m  0.0202\n",
      "     21        \u001b[36m0.6609\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6696\u001b[0m  0.0200\n",
      "     22        \u001b[36m0.6541\u001b[0m       0.6094        \u001b[35m0.6661\u001b[0m  0.0325\n",
      "     23        \u001b[36m0.6465\u001b[0m       0.6250        \u001b[35m0.6622\u001b[0m  0.0444\n",
      "     24        \u001b[36m0.6443\u001b[0m       0.6250        \u001b[35m0.6584\u001b[0m  0.0273\n",
      "     25        \u001b[36m0.6409\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6546\u001b[0m  0.0219\n",
      "     26        \u001b[36m0.6346\u001b[0m       0.6250        \u001b[35m0.6504\u001b[0m  0.0276\n",
      "     27        0.6375       0.6094        \u001b[35m0.6467\u001b[0m  0.0359\n",
      "     28        \u001b[36m0.6267\u001b[0m       0.6172        \u001b[35m0.6428\u001b[0m  0.0501\n",
      "     29        \u001b[36m0.6200\u001b[0m       0.6328        \u001b[35m0.6384\u001b[0m  0.0427\n",
      "     30        \u001b[36m0.6146\u001b[0m       0.6328        \u001b[35m0.6342\u001b[0m  0.0344\n",
      "     31        \u001b[36m0.6130\u001b[0m       0.6406        \u001b[35m0.6303\u001b[0m  0.0382\n",
      "     32        \u001b[36m0.6068\u001b[0m       0.6406        \u001b[35m0.6262\u001b[0m  0.0236\n",
      "     33        \u001b[36m0.6056\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6220\u001b[0m  0.0387\n",
      "     34        \u001b[36m0.5926\u001b[0m       0.6484        \u001b[35m0.6179\u001b[0m  0.0475\n",
      "     35        \u001b[36m0.5924\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6141\u001b[0m  0.0229\n",
      "     36        \u001b[36m0.5880\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6104\u001b[0m  0.0476\n",
      "     37        \u001b[36m0.5852\u001b[0m       0.6641        \u001b[35m0.6068\u001b[0m  0.0218\n",
      "     38        \u001b[36m0.5826\u001b[0m       0.6641        \u001b[35m0.6035\u001b[0m  0.0235\n",
      "     39        \u001b[36m0.5709\u001b[0m       0.6641        \u001b[35m0.6001\u001b[0m  0.0223\n",
      "     40        \u001b[36m0.5657\u001b[0m       0.6719        \u001b[35m0.5967\u001b[0m  0.0286\n",
      "     41        \u001b[36m0.5637\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5933\u001b[0m  0.0265\n",
      "     42        \u001b[36m0.5551\u001b[0m       0.6797        \u001b[35m0.5900\u001b[0m  0.0285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     43        \u001b[36m0.5509\u001b[0m       0.6797        \u001b[35m0.5872\u001b[0m  0.0249\n",
      "     44        0.5556       0.6719        \u001b[35m0.5844\u001b[0m  0.0390\n",
      "     45        \u001b[36m0.5485\u001b[0m       0.6719        \u001b[35m0.5817\u001b[0m  0.0279\n",
      "     46        \u001b[36m0.5437\u001b[0m       0.6719        \u001b[35m0.5792\u001b[0m  0.0265\n",
      "     47        0.5497       0.6719        \u001b[35m0.5771\u001b[0m  0.0303\n",
      "     48        \u001b[36m0.5299\u001b[0m       0.6797        \u001b[35m0.5749\u001b[0m  0.0309\n",
      "     49        \u001b[36m0.5252\u001b[0m       0.6797        \u001b[35m0.5727\u001b[0m  0.0254\n",
      "     50        \u001b[36m0.5213\u001b[0m       0.6797        \u001b[35m0.5710\u001b[0m  0.0249\n",
      "     51        \u001b[36m0.5211\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5689\u001b[0m  0.0366\n",
      "     52        \u001b[36m0.5120\u001b[0m       0.6875        \u001b[35m0.5672\u001b[0m  0.0200\n",
      "     53        0.5405       0.6875        \u001b[35m0.5658\u001b[0m  0.0323\n",
      "     54        0.5193       0.6875        \u001b[35m0.5645\u001b[0m  0.0279\n",
      "     55        0.5199       0.6875        \u001b[35m0.5633\u001b[0m  0.0252\n",
      "     56        0.5247       0.6875        \u001b[35m0.5620\u001b[0m  0.0241\n",
      "     57        0.5229       0.6875        \u001b[35m0.5610\u001b[0m  0.0375\n",
      "     58        0.5253       0.6875        \u001b[35m0.5601\u001b[0m  0.0290\n",
      "     59        0.5190       0.6875        \u001b[35m0.5594\u001b[0m  0.0246\n",
      "     60        0.5220       0.6875        \u001b[35m0.5584\u001b[0m  0.0250\n",
      "     61        \u001b[36m0.5002\u001b[0m       0.6875        \u001b[35m0.5574\u001b[0m  0.0246\n",
      "     62        0.5144       0.6797        \u001b[35m0.5567\u001b[0m  0.0214\n",
      "     63        0.5169       0.6797        \u001b[35m0.5562\u001b[0m  0.0403\n",
      "     64        0.5141       0.6797        \u001b[35m0.5556\u001b[0m  0.0340\n",
      "     65        0.5100       0.6797        \u001b[35m0.5551\u001b[0m  0.0246\n",
      "     66        0.5131       0.6797        \u001b[35m0.5542\u001b[0m  0.0241\n",
      "     67        0.5145       0.6797        \u001b[35m0.5532\u001b[0m  0.0283\n",
      "     68        0.5039       0.6797        \u001b[35m0.5525\u001b[0m  0.0204\n",
      "     69        0.5076       0.6797        \u001b[35m0.5519\u001b[0m  0.0283\n",
      "     70        0.5178       0.6797        \u001b[35m0.5511\u001b[0m  0.0401\n",
      "     71        \u001b[36m0.4776\u001b[0m       0.6797        \u001b[35m0.5505\u001b[0m  0.0200\n",
      "     72        0.5042       0.6719        \u001b[35m0.5498\u001b[0m  0.0287\n",
      "     73        0.4981       0.6719        \u001b[35m0.5493\u001b[0m  0.0261\n",
      "     74        0.4944       0.6719        \u001b[35m0.5487\u001b[0m  0.0205\n",
      "     75        0.4807       0.6797        \u001b[35m0.5482\u001b[0m  0.0256\n",
      "     76        0.4927       0.6797        \u001b[35m0.5475\u001b[0m  0.0327\n",
      "     77        0.4972       0.6797        \u001b[35m0.5466\u001b[0m  0.0229\n",
      "     78        0.4890       0.6797        \u001b[35m0.5461\u001b[0m  0.0252\n",
      "     79        0.4818       0.6797        \u001b[35m0.5456\u001b[0m  0.0231\n",
      "     80        0.4903       0.6797        \u001b[35m0.5451\u001b[0m  0.0260\n",
      "     81        0.5116       0.6797        \u001b[35m0.5442\u001b[0m  0.0222\n",
      "     82        0.5035       0.6797        \u001b[35m0.5436\u001b[0m  0.0225\n",
      "     83        0.4900       0.6797        \u001b[35m0.5430\u001b[0m  0.0195\n",
      "     84        0.4953       0.6797        \u001b[35m0.5424\u001b[0m  0.0265\n",
      "     85        0.4946       0.6797        \u001b[35m0.5419\u001b[0m  0.0263\n",
      "     86        0.5019       0.6797        \u001b[35m0.5412\u001b[0m  0.0260\n",
      "     87        0.5155       0.6797        \u001b[35m0.5404\u001b[0m  0.0197\n",
      "     88        0.5159       0.6797        \u001b[35m0.5399\u001b[0m  0.0302\n",
      "     89        0.4949       0.6797        \u001b[35m0.5395\u001b[0m  0.0193\n",
      "     90        0.4790       0.6797        \u001b[35m0.5393\u001b[0m  0.0242\n",
      "     91        0.4983       0.6797        \u001b[35m0.5391\u001b[0m  0.0213\n",
      "     92        0.5272       0.6797        \u001b[35m0.5384\u001b[0m  0.0219\n",
      "     93        0.5021       0.6875        \u001b[35m0.5377\u001b[0m  0.0276\n",
      "     94        0.4811       0.6875        \u001b[35m0.5374\u001b[0m  0.0234\n",
      "     95        0.4924       0.6875        \u001b[35m0.5369\u001b[0m  0.0211\n",
      "     96        0.4839       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5362\u001b[0m  0.0263\n",
      "     97        0.4871       0.6953        \u001b[35m0.5360\u001b[0m  0.0310\n",
      "     98        0.4832       0.6875        \u001b[35m0.5358\u001b[0m  0.0348\n",
      "     99        0.4882       0.6875        \u001b[35m0.5356\u001b[0m  0.0233\n",
      "    100        0.4813       0.6953        \u001b[35m0.5354\u001b[0m  0.0222\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6646\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6463\u001b[0m  0.0449\n",
      "      2        \u001b[36m0.6613\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6276\u001b[0m  0.0353\n",
      "      3        \u001b[36m0.6516\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6097\u001b[0m  0.0635\n",
      "      4        \u001b[36m0.6369\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5941\u001b[0m  0.0465\n",
      "      5        \u001b[36m0.6333\u001b[0m       0.7500        \u001b[35m0.5842\u001b[0m  0.0385\n",
      "      6        0.6372       0.7500        \u001b[35m0.5740\u001b[0m  0.0500\n",
      "      7        \u001b[36m0.6297\u001b[0m       0.7578        \u001b[35m0.5671\u001b[0m  0.0475\n",
      "      8        \u001b[36m0.6004\u001b[0m       0.7500        \u001b[35m0.5560\u001b[0m  0.0500\n",
      "      9        \u001b[36m0.5921\u001b[0m       0.7500        \u001b[35m0.5493\u001b[0m  0.0352\n",
      "     10        0.6037       0.7422        \u001b[35m0.5418\u001b[0m  0.0338\n",
      "     11        0.6032       0.7422        \u001b[35m0.5369\u001b[0m  0.0520\n",
      "     12        0.6088       0.7422        \u001b[35m0.5326\u001b[0m  0.0437\n",
      "     13        0.6107       0.7422        \u001b[35m0.5304\u001b[0m  0.0519\n",
      "     14        0.6003       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5239\u001b[0m  0.0371\n",
      "     15        0.6022       0.7656        \u001b[35m0.5212\u001b[0m  0.0588\n",
      "     16        \u001b[36m0.5844\u001b[0m       0.7656        \u001b[35m0.5155\u001b[0m  0.0417\n",
      "     17        0.5970       0.7656        \u001b[35m0.5130\u001b[0m  0.0332\n",
      "     18        0.6112       0.7656        0.5132  0.0581\n",
      "     19        0.5959       0.7656        \u001b[35m0.5108\u001b[0m  0.0348\n",
      "     20        0.5912       0.7656        \u001b[35m0.5081\u001b[0m  0.0334\n",
      "     21        0.5948       0.7656        \u001b[35m0.5062\u001b[0m  0.0423\n",
      "     22        \u001b[36m0.5835\u001b[0m       0.7656        \u001b[35m0.5038\u001b[0m  0.0331\n",
      "     23        0.6053       0.7656        0.5045  0.0383\n",
      "     24        0.6060       0.7656        \u001b[35m0.5029\u001b[0m  0.0348\n",
      "     25        0.5939       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5017\u001b[0m  0.0319\n",
      "     26        0.5974       0.7734        0.5022  0.0346\n",
      "     27        \u001b[36m0.5805\u001b[0m       0.7734        \u001b[35m0.4997\u001b[0m  0.0311\n",
      "     28        0.6066       0.7656        \u001b[35m0.4997\u001b[0m  0.0365\n",
      "     29        0.6120       0.7656        \u001b[35m0.4990\u001b[0m  0.0329\n",
      "     30        0.5985       0.7656        \u001b[35m0.4983\u001b[0m  0.0364\n",
      "     31        0.5917       0.7734        \u001b[35m0.4964\u001b[0m  0.0339\n",
      "     32        0.6030       \u001b[32m0.7812\u001b[0m        0.4966  0.0336\n",
      "     33        0.6024       0.7734        0.4979  0.0348\n",
      "     34        0.6030       0.7734        \u001b[35m0.4959\u001b[0m  0.0330\n",
      "     35        0.5946       0.7734        0.4960  0.0412\n",
      "     36        \u001b[36m0.5766\u001b[0m       0.7734        \u001b[35m0.4915\u001b[0m  0.0349\n",
      "     37        0.6017       0.7734        \u001b[35m0.4911\u001b[0m  0.0355\n",
      "     38        0.5820       0.7734        \u001b[35m0.4890\u001b[0m  0.0493\n",
      "     39        \u001b[36m0.5712\u001b[0m       0.7734        \u001b[35m0.4848\u001b[0m  0.0323\n",
      "     40        0.5839       0.7812        \u001b[35m0.4845\u001b[0m  0.0461\n",
      "     41        0.6005       0.7734        0.4874  0.0571\n",
      "     42        0.5824       0.7812        0.4860  0.0620\n",
      "     43        0.5751       0.7734        \u001b[35m0.4835\u001b[0m  0.0331\n",
      "     44        0.5839       0.7812        \u001b[35m0.4817\u001b[0m  0.0581\n",
      "     45        0.5769       0.7812        \u001b[35m0.4799\u001b[0m  0.0331\n",
      "     46        0.5786       \u001b[32m0.7891\u001b[0m        0.4800  0.0455\n",
      "     47        0.5777       0.7812        \u001b[35m0.4799\u001b[0m  0.0356\n",
      "     48        0.5872       0.7891        \u001b[35m0.4797\u001b[0m  0.0334\n",
      "     49        \u001b[36m0.5642\u001b[0m       0.7812        \u001b[35m0.4782\u001b[0m  0.0336\n",
      "     50        0.5866       0.7812        0.4785  0.0350\n",
      "     51        0.5949       0.7812        \u001b[35m0.4782\u001b[0m  0.0376\n",
      "     52        0.5975       \u001b[32m0.8047\u001b[0m        0.4804  0.0312\n",
      "     53        0.5917       0.7891        0.4809  0.0333\n",
      "     54        0.5722       0.7812        0.4801  0.0323\n",
      "     55        0.5704       0.7812        \u001b[35m0.4779\u001b[0m  0.0387\n",
      "     56        0.5736       0.7812        \u001b[35m0.4759\u001b[0m  0.0321\n",
      "     57        0.5810       0.7891        0.4762  0.0344\n",
      "     58        0.5915       0.7969        0.4773  0.0328\n",
      "     59        0.5874       0.7891        0.4775  0.0482\n",
      "     60        0.5781       0.7891        0.4773  0.0397\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7113\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.7025\u001b[0m  0.0288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.6974\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6912\u001b[0m  0.0484\n",
      "      3        \u001b[36m0.6839\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6837\u001b[0m  0.0365\n",
      "      4        \u001b[36m0.6802\u001b[0m       0.5625        \u001b[35m0.6773\u001b[0m  0.0332\n",
      "      5        \u001b[36m0.6747\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6715\u001b[0m  0.0372\n",
      "      6        \u001b[36m0.6581\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6652\u001b[0m  0.0341\n",
      "      7        \u001b[36m0.6579\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6601\u001b[0m  0.0319\n",
      "      8        \u001b[36m0.6540\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6548\u001b[0m  0.0320\n",
      "      9        0.6572       0.6484        \u001b[35m0.6508\u001b[0m  0.0332\n",
      "     10        \u001b[36m0.6399\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6451\u001b[0m  0.0352\n",
      "     11        0.6560       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6412\u001b[0m  0.0319\n",
      "     12        \u001b[36m0.6382\u001b[0m       0.7031        \u001b[35m0.6356\u001b[0m  0.0310\n",
      "     13        \u001b[36m0.6349\u001b[0m       0.7031        \u001b[35m0.6310\u001b[0m  0.0384\n",
      "     14        0.6479       0.6953        \u001b[35m0.6272\u001b[0m  0.0468\n",
      "     15        0.6349       0.6953        \u001b[35m0.6224\u001b[0m  0.0329\n",
      "     16        0.6414       0.6953        \u001b[35m0.6181\u001b[0m  0.0624\n",
      "     17        \u001b[36m0.6231\u001b[0m       0.7031        \u001b[35m0.6127\u001b[0m  0.0339\n",
      "     18        \u001b[36m0.6196\u001b[0m       0.7031        \u001b[35m0.6083\u001b[0m  0.0360\n",
      "     19        \u001b[36m0.6143\u001b[0m       0.6953        \u001b[35m0.6036\u001b[0m  0.0310\n",
      "     20        \u001b[36m0.5973\u001b[0m       0.7031        \u001b[35m0.5981\u001b[0m  0.0540\n",
      "     21        0.5984       0.7031        \u001b[35m0.5931\u001b[0m  0.0343\n",
      "     22        0.6020       0.6953        \u001b[35m0.5893\u001b[0m  0.0345\n",
      "     23        0.5993       0.6953        \u001b[35m0.5848\u001b[0m  0.0466\n",
      "     24        \u001b[36m0.5963\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5812\u001b[0m  0.0314\n",
      "     25        0.6246       0.7031        \u001b[35m0.5794\u001b[0m  0.0342\n",
      "     26        \u001b[36m0.5928\u001b[0m       0.7109        \u001b[35m0.5761\u001b[0m  0.0345\n",
      "     27        0.6051       0.7109        \u001b[35m0.5747\u001b[0m  0.0338\n",
      "     28        \u001b[36m0.5873\u001b[0m       0.7109        \u001b[35m0.5717\u001b[0m  0.0311\n",
      "     29        \u001b[36m0.5797\u001b[0m       0.7109        \u001b[35m0.5684\u001b[0m  0.0351\n",
      "     30        0.5804       0.7109        \u001b[35m0.5658\u001b[0m  0.0344\n",
      "     31        0.5824       0.7109        \u001b[35m0.5636\u001b[0m  0.0403\n",
      "     32        \u001b[36m0.5795\u001b[0m       0.7031        \u001b[35m0.5613\u001b[0m  0.0314\n",
      "     33        0.6020       0.7031        \u001b[35m0.5608\u001b[0m  0.0329\n",
      "     34        0.5854       0.7031        \u001b[35m0.5590\u001b[0m  0.0472\n",
      "     35        0.5921       0.7031        \u001b[35m0.5575\u001b[0m  0.0351\n",
      "     36        \u001b[36m0.5784\u001b[0m       0.7031        \u001b[35m0.5556\u001b[0m  0.0366\n",
      "     37        0.6096       0.7031        \u001b[35m0.5552\u001b[0m  0.0371\n",
      "     38        \u001b[36m0.5620\u001b[0m       0.7031        \u001b[35m0.5532\u001b[0m  0.0353\n",
      "     39        0.5820       0.7109        \u001b[35m0.5521\u001b[0m  0.0360\n",
      "     40        0.5685       0.7109        \u001b[35m0.5502\u001b[0m  0.0343\n",
      "     41        \u001b[36m0.5567\u001b[0m       0.7109        \u001b[35m0.5481\u001b[0m  0.0321\n",
      "     42        0.5603       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5472\u001b[0m  0.0327\n",
      "     43        0.5782       0.7188        \u001b[35m0.5466\u001b[0m  0.0439\n",
      "     44        0.5848       0.7188        \u001b[35m0.5460\u001b[0m  0.0347\n",
      "     45        0.5675       0.7188        \u001b[35m0.5449\u001b[0m  0.0360\n",
      "     46        0.5727       0.7188        \u001b[35m0.5436\u001b[0m  0.0364\n",
      "     47        0.5696       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5429\u001b[0m  0.0362\n",
      "     48        0.5660       0.7266        \u001b[35m0.5422\u001b[0m  0.0383\n",
      "     49        0.5618       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5411\u001b[0m  0.0320\n",
      "     50        0.5656       0.7344        \u001b[35m0.5403\u001b[0m  0.0349\n",
      "     51        0.5611       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5387\u001b[0m  0.0323\n",
      "     52        0.5729       0.7422        \u001b[35m0.5381\u001b[0m  0.0345\n",
      "     53        0.5621       0.7422        \u001b[35m0.5373\u001b[0m  0.0349\n",
      "     54        0.5649       0.7422        \u001b[35m0.5367\u001b[0m  0.0361\n",
      "     55        0.5689       0.7422        \u001b[35m0.5366\u001b[0m  0.0346\n",
      "     56        0.5611       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5364\u001b[0m  0.0354\n",
      "     57        0.5711       0.7500        \u001b[35m0.5362\u001b[0m  0.0333\n",
      "     58        0.5574       0.7500        \u001b[35m0.5359\u001b[0m  0.0327\n",
      "     59        0.5794       0.7500        \u001b[35m0.5357\u001b[0m  0.0350\n",
      "     60        0.5649       0.7500        \u001b[35m0.5352\u001b[0m  0.0348\n",
      "     61        \u001b[36m0.5508\u001b[0m       0.7500        \u001b[35m0.5349\u001b[0m  0.0356\n",
      "     62        \u001b[36m0.5408\u001b[0m       0.7500        \u001b[35m0.5340\u001b[0m  0.0339\n",
      "     63        0.5508       0.7500        \u001b[35m0.5337\u001b[0m  0.0319\n",
      "     64        0.5506       0.7500        0.5340  0.0329\n",
      "     65        0.5519       0.7500        \u001b[35m0.5335\u001b[0m  0.0354\n",
      "     66        0.5496       0.7500        \u001b[35m0.5326\u001b[0m  0.0389\n",
      "     67        0.5711       0.7500        \u001b[35m0.5316\u001b[0m  0.0346\n",
      "     68        0.5786       0.7422        \u001b[35m0.5312\u001b[0m  0.0359\n",
      "     69        0.5476       0.7500        \u001b[35m0.5304\u001b[0m  0.0346\n",
      "     70        0.5689       0.7422        0.5306  0.0370\n",
      "     71        0.5472       0.7500        \u001b[35m0.5301\u001b[0m  0.0338\n",
      "     72        0.5676       0.7422        0.5303  0.0344\n",
      "     73        0.5619       0.7500        \u001b[35m0.5295\u001b[0m  0.0377\n",
      "     74        0.5474       0.7500        \u001b[35m0.5292\u001b[0m  0.0385\n",
      "     75        0.5532       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5288\u001b[0m  0.0549\n",
      "     76        0.5490       0.7422        \u001b[35m0.5286\u001b[0m  0.0451\n",
      "     77        0.5493       0.7578        \u001b[35m0.5276\u001b[0m  0.0529\n",
      "     78        0.5494       0.7578        \u001b[35m0.5268\u001b[0m  0.0443\n",
      "     79        0.5586       0.7500        \u001b[35m0.5266\u001b[0m  0.0364\n",
      "     80        0.5506       0.7422        \u001b[35m0.5262\u001b[0m  0.0369\n",
      "     81        0.5635       0.7500        0.5267  0.0384\n",
      "     82        0.5522       0.7500        \u001b[35m0.5260\u001b[0m  0.0373\n",
      "     83        0.5493       0.7500        \u001b[35m0.5249\u001b[0m  0.0346\n",
      "     84        0.5501       0.7500        \u001b[35m0.5241\u001b[0m  0.0373\n",
      "     85        \u001b[36m0.5399\u001b[0m       0.7422        \u001b[35m0.5233\u001b[0m  0.0356\n",
      "     86        0.5630       0.7422        0.5234  0.0353\n",
      "     87        0.5434       0.7578        0.5235  0.0348\n",
      "     88        \u001b[36m0.5399\u001b[0m       0.7422        \u001b[35m0.5229\u001b[0m  0.0325\n",
      "     89        0.5570       0.7422        \u001b[35m0.5228\u001b[0m  0.0343\n",
      "     90        0.5452       0.7422        \u001b[35m0.5224\u001b[0m  0.0365\n",
      "     91        0.5506       0.7422        \u001b[35m0.5221\u001b[0m  0.0377\n",
      "     92        0.5436       0.7422        \u001b[35m0.5213\u001b[0m  0.0422\n",
      "     93        0.5467       0.7500        \u001b[35m0.5211\u001b[0m  0.0331\n",
      "     94        0.5509       0.7500        \u001b[35m0.5203\u001b[0m  0.0333\n",
      "     95        0.5454       0.7578        \u001b[35m0.5200\u001b[0m  0.0334\n",
      "     96        \u001b[36m0.5339\u001b[0m       0.7578        \u001b[35m0.5199\u001b[0m  0.0359\n",
      "     97        \u001b[36m0.5304\u001b[0m       0.7500        \u001b[35m0.5192\u001b[0m  0.0355\n",
      "     98        0.5394       0.7500        \u001b[35m0.5182\u001b[0m  0.0326\n",
      "     99        0.5444       0.7578        \u001b[35m0.5181\u001b[0m  0.0359\n",
      "    100        0.5442       0.7500        \u001b[35m0.5173\u001b[0m  0.0317\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7602\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7244\u001b[0m  0.0301\n",
      "      2        \u001b[36m0.7202\u001b[0m       0.5000        \u001b[35m0.7106\u001b[0m  0.0371\n",
      "      3        \u001b[36m0.7099\u001b[0m       0.4922        \u001b[35m0.7006\u001b[0m  0.0323\n",
      "      4        \u001b[36m0.6959\u001b[0m       0.4922        \u001b[35m0.6954\u001b[0m  0.0348\n",
      "      5        \u001b[36m0.6878\u001b[0m       0.5000        \u001b[35m0.6901\u001b[0m  0.0335\n",
      "      6        0.6904       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6865\u001b[0m  0.0369\n",
      "      7        \u001b[36m0.6808\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6827\u001b[0m  0.0318\n",
      "      8        \u001b[36m0.6719\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6789\u001b[0m  0.0355\n",
      "      9        \u001b[36m0.6677\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6748\u001b[0m  0.0339\n",
      "     10        \u001b[36m0.6658\u001b[0m       0.6172        \u001b[35m0.6702\u001b[0m  0.0347\n",
      "     11        \u001b[36m0.6652\u001b[0m       0.6094        \u001b[35m0.6661\u001b[0m  0.0376\n",
      "     12        \u001b[36m0.6505\u001b[0m       0.6094        \u001b[35m0.6601\u001b[0m  0.0424\n",
      "     13        \u001b[36m0.6445\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6537\u001b[0m  0.0378\n",
      "     14        0.6456       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6478\u001b[0m  0.0569\n",
      "     15        \u001b[36m0.6365\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6417\u001b[0m  0.0439\n",
      "     16        0.6458       0.6641        \u001b[35m0.6366\u001b[0m  0.0391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17        \u001b[36m0.6247\u001b[0m       0.6562        \u001b[35m0.6287\u001b[0m  0.0399\n",
      "     18        0.6266       0.6641        \u001b[35m0.6229\u001b[0m  0.0420\n",
      "     19        \u001b[36m0.6165\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6183\u001b[0m  0.0430\n",
      "     20        0.6313       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6134\u001b[0m  0.0366\n",
      "     21        0.6199       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6083\u001b[0m  0.0506\n",
      "     22        0.6215       0.7031        \u001b[35m0.6039\u001b[0m  0.0462\n",
      "     23        \u001b[36m0.6094\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5991\u001b[0m  0.0479\n",
      "     24        \u001b[36m0.5988\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5944\u001b[0m  0.0389\n",
      "     25        \u001b[36m0.5974\u001b[0m       0.7031        \u001b[35m0.5897\u001b[0m  0.0384\n",
      "     26        \u001b[36m0.5900\u001b[0m       0.7109        \u001b[35m0.5836\u001b[0m  0.0367\n",
      "     27        \u001b[36m0.5854\u001b[0m       0.7031        \u001b[35m0.5799\u001b[0m  0.0349\n",
      "     28        0.5858       0.7109        \u001b[35m0.5768\u001b[0m  0.0376\n",
      "     29        \u001b[36m0.5813\u001b[0m       0.7109        \u001b[35m0.5721\u001b[0m  0.0373\n",
      "     30        0.5854       0.7109        \u001b[35m0.5683\u001b[0m  0.0371\n",
      "     31        0.5898       0.7188        \u001b[35m0.5646\u001b[0m  0.1639\n",
      "     32        0.6022       0.7109        \u001b[35m0.5625\u001b[0m  0.0860\n",
      "     33        0.5857       0.7188        \u001b[35m0.5605\u001b[0m  0.0381\n",
      "     34        0.5961       0.7188        \u001b[35m0.5574\u001b[0m  0.0877\n",
      "     35        \u001b[36m0.5518\u001b[0m       0.7266        \u001b[35m0.5530\u001b[0m  0.0929\n",
      "     36        0.5930       0.7266        \u001b[35m0.5514\u001b[0m  0.0842\n",
      "     37        0.5527       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5493\u001b[0m  0.0666\n",
      "     38        0.5848       0.7344        \u001b[35m0.5485\u001b[0m  0.0535\n",
      "     39        0.5605       0.7344        \u001b[35m0.5465\u001b[0m  0.0491\n",
      "     40        0.5696       0.7266        \u001b[35m0.5453\u001b[0m  0.0431\n",
      "     41        0.5574       0.7266        \u001b[35m0.5434\u001b[0m  0.0682\n",
      "     42        0.5706       0.7266        \u001b[35m0.5427\u001b[0m  0.0528\n",
      "     43        \u001b[36m0.5398\u001b[0m       0.7266        \u001b[35m0.5411\u001b[0m  0.0582\n",
      "     44        0.5798       0.7266        0.5415  0.0466\n",
      "     45        0.5694       0.7266        \u001b[35m0.5404\u001b[0m  0.0474\n",
      "     46        0.5670       0.7266        \u001b[35m0.5400\u001b[0m  0.0666\n",
      "     47        0.5706       0.7266        \u001b[35m0.5394\u001b[0m  0.1631\n",
      "     48        0.5656       0.7266        \u001b[35m0.5386\u001b[0m  0.0547\n",
      "     49        0.5668       0.7266        0.5389  0.0550\n",
      "     50        0.5533       0.7266        \u001b[35m0.5376\u001b[0m  0.0410\n",
      "     51        0.5500       0.7188        \u001b[35m0.5361\u001b[0m  0.0351\n",
      "     52        0.5815       0.7266        \u001b[35m0.5359\u001b[0m  0.0473\n",
      "     53        0.5684       0.7188        \u001b[35m0.5357\u001b[0m  0.0696\n",
      "     54        0.5733       0.7266        0.5357  0.0631\n",
      "     55        0.5777       0.7188        0.5358  0.0580\n",
      "     56        0.5525       0.7188        0.5357  0.0634\n",
      "     57        0.5579       0.7188        \u001b[35m0.5350\u001b[0m  0.0716\n",
      "     58        0.5682       0.7188        \u001b[35m0.5348\u001b[0m  0.0781\n",
      "     59        0.5576       0.7188        \u001b[35m0.5346\u001b[0m  0.0533\n",
      "     60        0.5704       0.7188        0.5347  0.0578\n",
      "     61        0.5707       0.7188        0.5353  0.0626\n",
      "     62        0.5535       0.7266        0.5351  0.0926\n",
      "     63        0.5689       0.7266        \u001b[35m0.5341\u001b[0m  0.0767\n",
      "     64        0.5722       0.7266        0.5344  0.0695\n",
      "     65        0.5501       0.7266        \u001b[35m0.5341\u001b[0m  0.0694\n",
      "     66        0.5475       0.7266        \u001b[35m0.5331\u001b[0m  0.0755\n",
      "     67        0.5577       0.7266        \u001b[35m0.5328\u001b[0m  0.1130\n",
      "     68        \u001b[36m0.5342\u001b[0m       0.7344        \u001b[35m0.5314\u001b[0m  0.0666\n",
      "     69        0.5522       0.7266        0.5315  0.0685\n",
      "     70        0.5584       0.7344        0.5321  0.0621\n",
      "     71        0.5392       0.7344        0.5319  0.0567\n",
      "     72        0.5639       0.7344        0.5320  0.0513\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6897\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6498\u001b[0m  0.1401\n",
      "      2        0.6913       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6376\u001b[0m  0.0983\n",
      "      3        \u001b[36m0.6626\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6289\u001b[0m  0.0963\n",
      "      4        \u001b[36m0.6233\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6195\u001b[0m  0.1000\n",
      "      5        0.6422       0.6719        \u001b[35m0.6157\u001b[0m  0.0838\n",
      "      6        0.6568       0.6562        \u001b[35m0.6148\u001b[0m  0.0932\n",
      "      7        0.6636       0.6562        \u001b[35m0.6138\u001b[0m  0.0688\n",
      "      8        0.6344       0.6719        \u001b[35m0.6107\u001b[0m  0.0785\n",
      "      9        0.6353       0.6719        \u001b[35m0.6083\u001b[0m  0.0667\n",
      "     10        0.6348       0.6719        \u001b[35m0.6077\u001b[0m  0.1033\n",
      "     11        \u001b[36m0.6072\u001b[0m       0.6797        \u001b[35m0.6037\u001b[0m  0.0573\n",
      "     12        0.6144       0.6797        \u001b[35m0.6020\u001b[0m  0.1235\n",
      "     13        0.6163       0.6797        \u001b[35m0.5992\u001b[0m  0.0858\n",
      "     14        \u001b[36m0.5984\u001b[0m       0.6875        \u001b[35m0.5968\u001b[0m  0.1272\n",
      "     15        0.6102       0.6875        \u001b[35m0.5941\u001b[0m  0.0912\n",
      "     16        0.6044       0.6875        \u001b[35m0.5920\u001b[0m  0.1042\n",
      "     17        0.6027       0.6875        \u001b[35m0.5895\u001b[0m  0.0576\n",
      "     18        \u001b[36m0.5859\u001b[0m       0.6953        \u001b[35m0.5874\u001b[0m  0.0528\n",
      "     19        0.6041       0.6875        \u001b[35m0.5850\u001b[0m  0.1350\n",
      "     20        \u001b[36m0.5839\u001b[0m       0.6953        \u001b[35m0.5832\u001b[0m  0.0940\n",
      "     21        0.6189       0.6953        \u001b[35m0.5826\u001b[0m  0.0844\n",
      "     22        \u001b[36m0.5695\u001b[0m       0.6875        \u001b[35m0.5796\u001b[0m  0.0551\n",
      "     23        0.5813       0.6875        \u001b[35m0.5769\u001b[0m  0.0768\n",
      "     24        0.6002       0.7031        \u001b[35m0.5766\u001b[0m  0.1023\n",
      "     25        0.5827       0.7031        \u001b[35m0.5735\u001b[0m  0.0822\n",
      "     26        0.6024       0.7031        \u001b[35m0.5726\u001b[0m  0.1522\n",
      "     27        \u001b[36m0.5675\u001b[0m       0.7031        \u001b[35m0.5701\u001b[0m  0.1092\n",
      "     28        0.5815       0.6875        \u001b[35m0.5692\u001b[0m  0.1043\n",
      "     29        0.5815       0.7031        \u001b[35m0.5682\u001b[0m  0.0913\n",
      "     30        \u001b[36m0.5654\u001b[0m       0.6875        \u001b[35m0.5665\u001b[0m  0.0619\n",
      "     31        0.5705       0.6875        \u001b[35m0.5649\u001b[0m  0.1124\n",
      "     32        0.5812       0.6953        \u001b[35m0.5647\u001b[0m  0.1050\n",
      "     33        0.5722       0.6797        \u001b[35m0.5645\u001b[0m  0.0702\n",
      "     34        0.5802       0.6797        \u001b[35m0.5641\u001b[0m  0.0795\n",
      "     35        0.5773       0.6797        \u001b[35m0.5633\u001b[0m  0.0579\n",
      "     36        \u001b[36m0.5651\u001b[0m       0.6797        0.5634  0.0549\n",
      "     37        0.5825       0.6797        \u001b[35m0.5626\u001b[0m  0.0991\n",
      "     38        \u001b[36m0.5640\u001b[0m       0.6797        \u001b[35m0.5613\u001b[0m  0.0594\n",
      "     39        0.5739       0.6875        \u001b[35m0.5609\u001b[0m  0.0814\n",
      "     40        0.5913       0.6797        \u001b[35m0.5603\u001b[0m  0.0842\n",
      "     41        0.5852       0.6797        0.5605  0.0964\n",
      "     42        0.5810       0.6797        0.5605  0.0842\n",
      "     43        \u001b[36m0.5492\u001b[0m       0.6875        \u001b[35m0.5601\u001b[0m  0.1757\n",
      "     44        0.5574       0.6797        \u001b[35m0.5601\u001b[0m  0.0950\n",
      "     45        \u001b[36m0.5474\u001b[0m       0.6875        \u001b[35m0.5587\u001b[0m  0.0560\n",
      "     46        0.5814       0.6797        \u001b[35m0.5578\u001b[0m  0.0723\n",
      "     47        \u001b[36m0.5335\u001b[0m       0.6797        \u001b[35m0.5577\u001b[0m  0.0353\n",
      "     48        0.5677       0.6875        \u001b[35m0.5566\u001b[0m  0.0465\n",
      "     49        0.5561       0.6719        \u001b[35m0.5564\u001b[0m  0.0604\n",
      "     50        0.5701       0.6641        \u001b[35m0.5552\u001b[0m  0.0518\n",
      "     51        0.5619       0.6719        \u001b[35m0.5540\u001b[0m  0.0541\n",
      "     52        0.5743       0.6719        \u001b[35m0.5538\u001b[0m  0.0405\n",
      "     53        0.5483       0.6719        \u001b[35m0.5531\u001b[0m  0.0450\n",
      "     54        0.5631       0.6719        \u001b[35m0.5515\u001b[0m  0.0409\n",
      "     55        0.5753       0.6719        0.5517  0.0429\n",
      "     56        0.5419       0.6797        \u001b[35m0.5503\u001b[0m  0.0493\n",
      "     57        0.5675       0.6797        \u001b[35m0.5495\u001b[0m  0.0493\n",
      "     58        0.5639       0.6797        \u001b[35m0.5493\u001b[0m  0.0467\n",
      "     59        0.5618       0.6797        \u001b[35m0.5490\u001b[0m  0.0343\n",
      "     60        0.5567       0.6797        \u001b[35m0.5486\u001b[0m  0.0354\n",
      "     61        0.5576       0.6719        \u001b[35m0.5479\u001b[0m  0.0416\n",
      "     62        0.5661       0.6719        \u001b[35m0.5476\u001b[0m  0.0472\n",
      "     63        0.5499       0.6719        0.5476  0.0512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     64        \u001b[36m0.5213\u001b[0m       0.6797        \u001b[35m0.5469\u001b[0m  0.0384\n",
      "     65        0.5481       0.6719        0.5472  0.0468\n",
      "     66        0.5393       0.6797        \u001b[35m0.5464\u001b[0m  0.0368\n",
      "     67        0.5560       0.6797        \u001b[35m0.5463\u001b[0m  0.0341\n",
      "     68        0.5325       0.6797        \u001b[35m0.5460\u001b[0m  0.0392\n",
      "     69        0.5516       0.6797        \u001b[35m0.5442\u001b[0m  0.0395\n",
      "     70        0.5731       0.6797        0.5443  0.0373\n",
      "     71        0.5532       0.6797        \u001b[35m0.5441\u001b[0m  0.0498\n",
      "     72        0.5493       0.6797        \u001b[35m0.5433\u001b[0m  0.0510\n",
      "     73        0.5575       0.6797        0.5434  0.0580\n",
      "     74        0.5804       0.6797        0.5442  0.0491\n",
      "     75        0.5679       0.6797        0.5440  0.0416\n",
      "     76        0.5602       0.6797        0.5442  0.0343\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7319\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6833\u001b[0m  0.0322\n",
      "      2        \u001b[36m0.6923\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6659\u001b[0m  0.0478\n",
      "      3        \u001b[36m0.6838\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6560\u001b[0m  0.0988\n",
      "      4        \u001b[36m0.6578\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6462\u001b[0m  0.0798\n",
      "      5        0.6611       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6386\u001b[0m  0.0792\n",
      "      6        \u001b[36m0.6554\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6319\u001b[0m  0.0340\n",
      "      7        \u001b[36m0.6462\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6245\u001b[0m  0.0342\n",
      "      8        \u001b[36m0.6414\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6180\u001b[0m  0.0340\n",
      "      9        \u001b[36m0.6265\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6109\u001b[0m  0.0349\n",
      "     10        0.6294       0.7344        \u001b[35m0.6055\u001b[0m  0.0395\n",
      "     11        \u001b[36m0.6181\u001b[0m       0.7344        \u001b[35m0.6000\u001b[0m  0.1451\n",
      "     12        \u001b[36m0.6088\u001b[0m       0.7344        \u001b[35m0.5940\u001b[0m  0.0836\n",
      "     13        \u001b[36m0.5956\u001b[0m       0.7344        \u001b[35m0.5878\u001b[0m  0.1130\n",
      "     14        0.6003       0.7344        \u001b[35m0.5829\u001b[0m  0.0881\n",
      "     15        0.5958       0.7344        \u001b[35m0.5787\u001b[0m  0.0466\n",
      "     16        \u001b[36m0.5809\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5738\u001b[0m  0.0365\n",
      "     17        0.5905       0.7344        \u001b[35m0.5701\u001b[0m  0.0450\n",
      "     18        0.5842       0.7344        \u001b[35m0.5668\u001b[0m  0.0342\n",
      "     19        \u001b[36m0.5785\u001b[0m       0.7266        \u001b[35m0.5638\u001b[0m  0.0376\n",
      "     20        0.5938       0.7266        \u001b[35m0.5617\u001b[0m  0.0448\n",
      "     21        \u001b[36m0.5744\u001b[0m       0.7266        \u001b[35m0.5588\u001b[0m  0.1542\n",
      "     22        \u001b[36m0.5724\u001b[0m       0.7266        \u001b[35m0.5560\u001b[0m  0.1191\n",
      "     23        0.5803       0.7422        \u001b[35m0.5541\u001b[0m  0.1173\n",
      "     24        \u001b[36m0.5698\u001b[0m       0.7422        \u001b[35m0.5516\u001b[0m  0.1287\n",
      "     25        \u001b[36m0.5642\u001b[0m       0.7422        \u001b[35m0.5495\u001b[0m  0.0831\n",
      "     26        0.5745       0.7422        \u001b[35m0.5481\u001b[0m  0.0681\n",
      "     27        0.5740       0.7422        \u001b[35m0.5462\u001b[0m  0.0823\n",
      "     28        \u001b[36m0.5590\u001b[0m       0.7422        \u001b[35m0.5442\u001b[0m  0.1270\n",
      "     29        \u001b[36m0.5552\u001b[0m       0.7422        \u001b[35m0.5423\u001b[0m  0.1200\n",
      "     30        0.5667       0.7422        \u001b[35m0.5409\u001b[0m  0.1150\n",
      "     31        0.5691       0.7422        \u001b[35m0.5395\u001b[0m  0.1090\n",
      "     32        0.5643       0.7422        \u001b[35m0.5382\u001b[0m  0.1297\n",
      "     33        \u001b[36m0.5462\u001b[0m       0.7422        \u001b[35m0.5364\u001b[0m  0.0654\n",
      "     34        0.5586       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5349\u001b[0m  0.0756\n",
      "     35        0.5577       0.7422        \u001b[35m0.5343\u001b[0m  0.0855\n",
      "     36        \u001b[36m0.5236\u001b[0m       0.7344        \u001b[35m0.5325\u001b[0m  0.0940\n",
      "     37        0.5498       0.7344        \u001b[35m0.5316\u001b[0m  0.0564\n",
      "     38        0.5330       0.7344        \u001b[35m0.5305\u001b[0m  0.0549\n",
      "     39        0.5344       0.7344        \u001b[35m0.5291\u001b[0m  0.0632\n",
      "     40        0.5439       0.7344        \u001b[35m0.5288\u001b[0m  0.0978\n",
      "     41        0.5502       0.7344        \u001b[35m0.5280\u001b[0m  0.0921\n",
      "     42        0.5515       0.7344        \u001b[35m0.5279\u001b[0m  0.0961\n",
      "     43        0.5538       0.7344        \u001b[35m0.5273\u001b[0m  0.1454\n",
      "     44        0.5714       0.7344        \u001b[35m0.5265\u001b[0m  0.0473\n",
      "     45        0.5440       0.7344        \u001b[35m0.5259\u001b[0m  0.0419\n",
      "     46        0.5320       0.7344        \u001b[35m0.5253\u001b[0m  0.1106\n",
      "     47        0.5583       0.7344        \u001b[35m0.5250\u001b[0m  0.1048\n",
      "     48        0.5618       0.7344        \u001b[35m0.5241\u001b[0m  0.0719\n",
      "     49        0.5401       0.7344        \u001b[35m0.5237\u001b[0m  0.0786\n",
      "     50        0.5503       0.7266        \u001b[35m0.5231\u001b[0m  0.0505\n",
      "     51        0.5745       0.7266        0.5232  0.0344\n",
      "     52        0.5314       0.7344        \u001b[35m0.5224\u001b[0m  0.0349\n",
      "     53        0.5394       0.7188        0.5226  0.0347\n",
      "     54        \u001b[36m0.5234\u001b[0m       0.7266        \u001b[35m0.5219\u001b[0m  0.0387\n",
      "     55        0.5490       0.7266        \u001b[35m0.5213\u001b[0m  0.0376\n",
      "     56        0.5362       0.7266        0.5216  0.0349\n",
      "     57        0.5423       0.7266        \u001b[35m0.5209\u001b[0m  0.0351\n",
      "     58        \u001b[36m0.5185\u001b[0m       0.7188        \u001b[35m0.5209\u001b[0m  0.0344\n",
      "     59        0.5408       0.7188        \u001b[35m0.5204\u001b[0m  0.0348\n",
      "     60        0.5518       0.7188        \u001b[35m0.5200\u001b[0m  0.0341\n",
      "     61        0.5427       0.7188        0.5202  0.0333\n",
      "     62        0.5458       0.7188        \u001b[35m0.5199\u001b[0m  0.0338\n",
      "     63        0.5442       0.7266        0.5203  0.0339\n",
      "     64        0.5413       0.7188        0.5200  0.0732\n",
      "     65        0.5512       0.7188        \u001b[35m0.5197\u001b[0m  0.0371\n",
      "     66        0.5343       0.7266        \u001b[35m0.5190\u001b[0m  0.0473\n",
      "     67        0.5293       0.7266        \u001b[35m0.5180\u001b[0m  0.0374\n",
      "     68        \u001b[36m0.5112\u001b[0m       0.7266        \u001b[35m0.5169\u001b[0m  0.0336\n",
      "     69        0.5466       0.7266        0.5171  0.0350\n",
      "     70        0.5456       0.7266        \u001b[35m0.5169\u001b[0m  0.0377\n",
      "     71        0.5423       0.7266        \u001b[35m0.5164\u001b[0m  0.0379\n",
      "     72        0.5352       0.7266        \u001b[35m0.5158\u001b[0m  0.0477\n",
      "     73        0.5357       0.7266        \u001b[35m0.5156\u001b[0m  0.0333\n",
      "     74        0.5427       0.7344        \u001b[35m0.5154\u001b[0m  0.0338\n",
      "     75        0.5211       0.7422        \u001b[35m0.5153\u001b[0m  0.0356\n",
      "     76        0.5252       0.7422        \u001b[35m0.5145\u001b[0m  0.0442\n",
      "     77        0.5359       0.7422        0.5151  0.0483\n",
      "     78        0.5135       0.7422        0.5149  0.0574\n",
      "     79        0.5302       0.7422        0.5145  0.0546\n",
      "     80        0.5149       0.7422        \u001b[35m0.5140\u001b[0m  0.0427\n",
      "     81        0.5289       0.7344        \u001b[35m0.5139\u001b[0m  0.0412\n",
      "     82        0.5338       0.7344        \u001b[35m0.5138\u001b[0m  0.0368\n",
      "     83        0.5426       0.7344        \u001b[35m0.5135\u001b[0m  0.0329\n",
      "     84        0.5435       0.7344        0.5144  0.1605\n",
      "     85        0.5167       0.7344        0.5148  0.0394\n",
      "     86        0.5384       0.7344        0.5150  0.0341\n",
      "     87        0.5392       0.7344        0.5153  0.0507\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6282\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4182\u001b[0m  0.0818\n",
      "      2        \u001b[36m0.5757\u001b[0m       \u001b[32m0.7812\u001b[0m        0.4616  0.0694\n",
      "      3        \u001b[36m0.5275\u001b[0m       \u001b[32m0.8047\u001b[0m        0.4326  0.0494\n",
      "      4        \u001b[36m0.5232\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4109\u001b[0m  0.0389\n",
      "      5        \u001b[36m0.5119\u001b[0m       0.8047        0.4145  0.0514\n",
      "      6        0.5121       \u001b[32m0.8281\u001b[0m        \u001b[35m0.3676\u001b[0m  0.0355\n",
      "      7        \u001b[36m0.5053\u001b[0m       0.8281        0.4343  0.0555\n",
      "      8        \u001b[36m0.4845\u001b[0m       0.7969        0.4023  0.0543\n",
      "      9        \u001b[36m0.4791\u001b[0m       0.8047        0.3833  0.0342\n",
      "     10        0.4824       0.8047        0.3897  0.0369\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5478\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5240\u001b[0m  0.0696\n",
      "      2        \u001b[36m0.5061\u001b[0m       0.6953        0.5872  0.0632\n",
      "      3        \u001b[36m0.5012\u001b[0m       0.7031        0.5304  0.0651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        0.5090       0.6797        0.6122  0.0635\n",
      "      5        \u001b[36m0.4895\u001b[0m       0.6953        0.5499  0.0323\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5675\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5842\u001b[0m  0.0291\n",
      "      2        \u001b[36m0.5368\u001b[0m       0.6875        \u001b[35m0.5480\u001b[0m  0.0325\n",
      "      3        0.5394       0.6797        0.5746  0.0375\n",
      "      4        0.5404       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5269\u001b[0m  0.0444\n",
      "      5        \u001b[36m0.5136\u001b[0m       0.6797        0.6014  0.0336\n",
      "      6        \u001b[36m0.5078\u001b[0m       0.7266        0.5642  0.0453\n",
      "      7        \u001b[36m0.5077\u001b[0m       0.7266        0.5366  0.0581\n",
      "      8        \u001b[36m0.4931\u001b[0m       0.7422        0.5543  0.0601\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5452\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6084\u001b[0m  0.0460\n",
      "      2        \u001b[36m0.5050\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5142\u001b[0m  0.0397\n",
      "      3        \u001b[36m0.4945\u001b[0m       0.6719        0.5992  0.0390\n",
      "      4        \u001b[36m0.4783\u001b[0m       0.6719        0.5964  0.0356\n",
      "      5        \u001b[36m0.4770\u001b[0m       \u001b[32m0.7344\u001b[0m        0.5453  0.0455\n",
      "      6        \u001b[36m0.4740\u001b[0m       0.6562        0.7768  0.0394\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5623\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5429\u001b[0m  0.0330\n",
      "      2        \u001b[36m0.4716\u001b[0m       \u001b[32m0.7188\u001b[0m        0.5523  0.0388\n",
      "      3        \u001b[36m0.4618\u001b[0m       \u001b[32m0.7344\u001b[0m        0.5840  0.0350\n",
      "      4        \u001b[36m0.4611\u001b[0m       0.7344        \u001b[35m0.5237\u001b[0m  0.0351\n",
      "      5        \u001b[36m0.4293\u001b[0m       0.6797        0.6723  0.0423\n",
      "      6        0.4341       0.6875        0.5425  0.0364\n",
      "      7        0.4404       \u001b[32m0.7578\u001b[0m        0.5316  0.0403\n",
      "      8        0.4469       0.6797        0.5885  0.0350\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8830\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8590\u001b[0m  0.0173\n",
      "      2        \u001b[36m0.8240\u001b[0m       0.5000        \u001b[35m0.8053\u001b[0m  0.0199\n",
      "      3        \u001b[36m0.7811\u001b[0m       0.5000        \u001b[35m0.7662\u001b[0m  0.0245\n",
      "      4        \u001b[36m0.7496\u001b[0m       0.5000        \u001b[35m0.7366\u001b[0m  0.0260\n",
      "      5        \u001b[36m0.7260\u001b[0m       0.5000        \u001b[35m0.7141\u001b[0m  0.0279\n",
      "      6        \u001b[36m0.7076\u001b[0m       0.5000        \u001b[35m0.6964\u001b[0m  0.0269\n",
      "      7        \u001b[36m0.6931\u001b[0m       0.5000        \u001b[35m0.6819\u001b[0m  0.0280\n",
      "      8        \u001b[36m0.6814\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6700\u001b[0m  0.0244\n",
      "      9        \u001b[36m0.6718\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6597\u001b[0m  0.0266\n",
      "     10        \u001b[36m0.6633\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6506\u001b[0m  0.0273\n",
      "     11        \u001b[36m0.6557\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6424\u001b[0m  0.0247\n",
      "     12        \u001b[36m0.6489\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6347\u001b[0m  0.0267\n",
      "     13        \u001b[36m0.6426\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.6275\u001b[0m  0.0277\n",
      "     14        \u001b[36m0.6367\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.6206\u001b[0m  0.0229\n",
      "     15        \u001b[36m0.6310\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.6139\u001b[0m  0.0231\n",
      "     16        \u001b[36m0.6255\u001b[0m       0.8047        \u001b[35m0.6075\u001b[0m  0.0291\n",
      "     17        \u001b[36m0.6203\u001b[0m       0.8047        \u001b[35m0.6012\u001b[0m  0.0294\n",
      "     18        \u001b[36m0.6151\u001b[0m       0.7969        \u001b[35m0.5950\u001b[0m  0.0289\n",
      "     19        \u001b[36m0.6102\u001b[0m       0.7891        \u001b[35m0.5890\u001b[0m  0.0318\n",
      "     20        \u001b[36m0.6052\u001b[0m       0.7891        \u001b[35m0.5830\u001b[0m  0.0300\n",
      "     21        \u001b[36m0.6004\u001b[0m       0.7812        \u001b[35m0.5771\u001b[0m  0.0271\n",
      "     22        \u001b[36m0.5956\u001b[0m       0.7656        \u001b[35m0.5712\u001b[0m  0.0272\n",
      "     23        \u001b[36m0.5911\u001b[0m       0.7656        \u001b[35m0.5656\u001b[0m  0.0315\n",
      "     24        \u001b[36m0.5866\u001b[0m       0.7656        \u001b[35m0.5600\u001b[0m  0.0267\n",
      "     25        \u001b[36m0.5823\u001b[0m       0.7656        \u001b[35m0.5545\u001b[0m  0.0277\n",
      "     26        \u001b[36m0.5781\u001b[0m       0.7734        \u001b[35m0.5491\u001b[0m  0.0272\n",
      "     27        \u001b[36m0.5741\u001b[0m       0.7734        \u001b[35m0.5439\u001b[0m  0.0243\n",
      "     28        \u001b[36m0.5701\u001b[0m       0.7812        \u001b[35m0.5388\u001b[0m  0.0256\n",
      "     29        \u001b[36m0.5663\u001b[0m       0.7891        \u001b[35m0.5338\u001b[0m  0.0273\n",
      "     30        \u001b[36m0.5628\u001b[0m       0.7812        \u001b[35m0.5291\u001b[0m  0.0271\n",
      "     31        \u001b[36m0.5594\u001b[0m       0.7734        \u001b[35m0.5245\u001b[0m  0.0272\n",
      "     32        \u001b[36m0.5561\u001b[0m       0.7734        \u001b[35m0.5200\u001b[0m  0.0276\n",
      "     33        \u001b[36m0.5530\u001b[0m       0.7734        \u001b[35m0.5157\u001b[0m  0.0277\n",
      "     34        \u001b[36m0.5501\u001b[0m       0.7734        \u001b[35m0.5116\u001b[0m  0.0278\n",
      "     35        \u001b[36m0.5473\u001b[0m       0.7734        \u001b[35m0.5076\u001b[0m  0.0419\n",
      "     36        \u001b[36m0.5446\u001b[0m       0.7734        \u001b[35m0.5038\u001b[0m  0.0195\n",
      "     37        \u001b[36m0.5421\u001b[0m       0.7656        \u001b[35m0.5001\u001b[0m  0.0260\n",
      "     38        \u001b[36m0.5397\u001b[0m       0.7656        \u001b[35m0.4967\u001b[0m  0.0237\n",
      "     39        \u001b[36m0.5375\u001b[0m       0.7656        \u001b[35m0.4933\u001b[0m  0.0241\n",
      "     40        \u001b[36m0.5353\u001b[0m       0.7656        \u001b[35m0.4901\u001b[0m  0.0276\n",
      "     41        \u001b[36m0.5333\u001b[0m       0.7656        \u001b[35m0.4870\u001b[0m  0.0254\n",
      "     42        \u001b[36m0.5315\u001b[0m       0.7656        \u001b[35m0.4840\u001b[0m  0.0241\n",
      "     43        \u001b[36m0.5297\u001b[0m       0.7578        \u001b[35m0.4812\u001b[0m  0.0246\n",
      "     44        \u001b[36m0.5280\u001b[0m       0.7578        \u001b[35m0.4785\u001b[0m  0.0327\n",
      "     45        \u001b[36m0.5264\u001b[0m       0.7578        \u001b[35m0.4760\u001b[0m  0.0233\n",
      "     46        \u001b[36m0.5249\u001b[0m       0.7578        \u001b[35m0.4735\u001b[0m  0.0255\n",
      "     47        \u001b[36m0.5235\u001b[0m       0.7578        \u001b[35m0.4711\u001b[0m  0.0249\n",
      "     48        \u001b[36m0.5222\u001b[0m       0.7578        \u001b[35m0.4689\u001b[0m  0.0218\n",
      "     49        \u001b[36m0.5209\u001b[0m       0.7578        \u001b[35m0.4667\u001b[0m  0.0246\n",
      "     50        \u001b[36m0.5198\u001b[0m       0.7578        \u001b[35m0.4646\u001b[0m  0.0257\n",
      "     51        \u001b[36m0.5186\u001b[0m       0.7578        \u001b[35m0.4625\u001b[0m  0.0230\n",
      "     52        \u001b[36m0.5175\u001b[0m       0.7578        \u001b[35m0.4606\u001b[0m  0.0232\n",
      "     53        \u001b[36m0.5165\u001b[0m       0.7578        \u001b[35m0.4587\u001b[0m  0.0292\n",
      "     54        \u001b[36m0.5156\u001b[0m       0.7578        \u001b[35m0.4569\u001b[0m  0.0261\n",
      "     55        \u001b[36m0.5143\u001b[0m       0.7578        \u001b[35m0.4552\u001b[0m  0.0265\n",
      "     56        \u001b[36m0.5135\u001b[0m       0.7578        \u001b[35m0.4535\u001b[0m  0.0313\n",
      "     57        \u001b[36m0.5127\u001b[0m       0.7578        \u001b[35m0.4519\u001b[0m  0.0498\n",
      "     58        \u001b[36m0.5118\u001b[0m       0.7578        \u001b[35m0.4504\u001b[0m  0.0535\n",
      "     59        \u001b[36m0.5110\u001b[0m       0.7578        \u001b[35m0.4490\u001b[0m  0.0481\n",
      "     60        \u001b[36m0.5102\u001b[0m       0.7578        \u001b[35m0.4476\u001b[0m  0.0385\n",
      "     61        \u001b[36m0.5096\u001b[0m       0.7578        \u001b[35m0.4462\u001b[0m  0.0371\n",
      "     62        \u001b[36m0.5091\u001b[0m       0.7578        \u001b[35m0.4448\u001b[0m  0.0411\n",
      "     63        \u001b[36m0.5082\u001b[0m       0.7578        \u001b[35m0.4435\u001b[0m  0.0274\n",
      "     64        \u001b[36m0.5076\u001b[0m       0.7656        \u001b[35m0.4422\u001b[0m  0.0250\n",
      "     65        \u001b[36m0.5070\u001b[0m       0.7656        \u001b[35m0.4410\u001b[0m  0.0237\n",
      "     66        \u001b[36m0.5063\u001b[0m       0.7656        \u001b[35m0.4398\u001b[0m  0.0357\n",
      "     67        \u001b[36m0.5057\u001b[0m       0.7656        \u001b[35m0.4387\u001b[0m  0.0446\n",
      "     68        \u001b[36m0.5052\u001b[0m       0.7656        \u001b[35m0.4377\u001b[0m  0.0436\n",
      "     69        \u001b[36m0.5046\u001b[0m       0.7734        \u001b[35m0.4366\u001b[0m  0.0468\n",
      "     70        \u001b[36m0.5041\u001b[0m       0.7734        \u001b[35m0.4356\u001b[0m  0.0323\n",
      "     71        \u001b[36m0.5036\u001b[0m       0.7656        \u001b[35m0.4346\u001b[0m  0.0336\n",
      "     72        \u001b[36m0.5031\u001b[0m       0.7656        \u001b[35m0.4337\u001b[0m  0.0276\n",
      "     73        \u001b[36m0.5026\u001b[0m       0.7656        \u001b[35m0.4327\u001b[0m  0.0222\n",
      "     74        \u001b[36m0.5021\u001b[0m       0.7656        \u001b[35m0.4319\u001b[0m  0.0278\n",
      "     75        \u001b[36m0.5018\u001b[0m       0.7656        \u001b[35m0.4309\u001b[0m  0.0337\n",
      "     76        \u001b[36m0.5012\u001b[0m       0.7656        \u001b[35m0.4302\u001b[0m  0.0506\n",
      "     77        \u001b[36m0.5007\u001b[0m       0.7656        \u001b[35m0.4294\u001b[0m  0.0493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     78        \u001b[36m0.5003\u001b[0m       0.7656        \u001b[35m0.4286\u001b[0m  0.0474\n",
      "     79        \u001b[36m0.4999\u001b[0m       0.7734        \u001b[35m0.4279\u001b[0m  0.0300\n",
      "     80        \u001b[36m0.4995\u001b[0m       0.7734        \u001b[35m0.4272\u001b[0m  0.0263\n",
      "     81        \u001b[36m0.4990\u001b[0m       0.7734        \u001b[35m0.4266\u001b[0m  0.0262\n",
      "     82        \u001b[36m0.4988\u001b[0m       0.7734        \u001b[35m0.4259\u001b[0m  0.0220\n",
      "     83        \u001b[36m0.4983\u001b[0m       0.7734        \u001b[35m0.4253\u001b[0m  0.0210\n",
      "     84        \u001b[36m0.4980\u001b[0m       0.7812        \u001b[35m0.4247\u001b[0m  0.0420\n",
      "     85        \u001b[36m0.4976\u001b[0m       0.7812        \u001b[35m0.4242\u001b[0m  0.0398\n",
      "     86        \u001b[36m0.4972\u001b[0m       0.7891        \u001b[35m0.4235\u001b[0m  0.0403\n",
      "     87        \u001b[36m0.4968\u001b[0m       0.7891        \u001b[35m0.4230\u001b[0m  0.0286\n",
      "     88        \u001b[36m0.4967\u001b[0m       0.7891        \u001b[35m0.4224\u001b[0m  0.0197\n",
      "     89        \u001b[36m0.4964\u001b[0m       0.7891        \u001b[35m0.4219\u001b[0m  0.0259\n",
      "     90        \u001b[36m0.4960\u001b[0m       0.7891        \u001b[35m0.4214\u001b[0m  0.0372\n",
      "     91        \u001b[36m0.4957\u001b[0m       0.7891        \u001b[35m0.4210\u001b[0m  0.0370\n",
      "     92        \u001b[36m0.4955\u001b[0m       0.7891        \u001b[35m0.4205\u001b[0m  0.0299\n",
      "     93        \u001b[36m0.4954\u001b[0m       0.7891        \u001b[35m0.4200\u001b[0m  0.0286\n",
      "     94        \u001b[36m0.4948\u001b[0m       0.7891        \u001b[35m0.4196\u001b[0m  0.0199\n",
      "     95        \u001b[36m0.4947\u001b[0m       0.7891        \u001b[35m0.4192\u001b[0m  0.0343\n",
      "     96        \u001b[36m0.4943\u001b[0m       0.7891        \u001b[35m0.4188\u001b[0m  0.0257\n",
      "     97        \u001b[36m0.4942\u001b[0m       0.7891        \u001b[35m0.4184\u001b[0m  0.0256\n",
      "     98        \u001b[36m0.4940\u001b[0m       0.7891        \u001b[35m0.4180\u001b[0m  0.0238\n",
      "     99        \u001b[36m0.4937\u001b[0m       0.7891        \u001b[35m0.4176\u001b[0m  0.0276\n",
      "    100        \u001b[36m0.4934\u001b[0m       0.7891        \u001b[35m0.4172\u001b[0m  0.0224\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7037\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m0.7089\u001b[0m  0.0227\n",
      "      2        \u001b[36m0.6905\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6957\u001b[0m  0.0239\n",
      "      3        \u001b[36m0.6790\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6842\u001b[0m  0.0277\n",
      "      4        \u001b[36m0.6687\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6741\u001b[0m  0.0448\n",
      "      5        \u001b[36m0.6593\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6648\u001b[0m  0.0218\n",
      "      6        \u001b[36m0.6505\u001b[0m       0.6016        \u001b[35m0.6562\u001b[0m  0.0281\n",
      "      7        \u001b[36m0.6424\u001b[0m       0.6250        \u001b[35m0.6483\u001b[0m  0.0298\n",
      "      8        \u001b[36m0.6348\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6411\u001b[0m  0.0312\n",
      "      9        \u001b[36m0.6278\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6343\u001b[0m  0.0324\n",
      "     10        \u001b[36m0.6210\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6278\u001b[0m  0.0296\n",
      "     11        \u001b[36m0.6147\u001b[0m       0.6797        \u001b[35m0.6218\u001b[0m  0.0285\n",
      "     12        \u001b[36m0.6089\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6161\u001b[0m  0.0318\n",
      "     13        \u001b[36m0.6033\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6109\u001b[0m  0.0290\n",
      "     14        \u001b[36m0.5981\u001b[0m       0.7031        \u001b[35m0.6059\u001b[0m  0.0287\n",
      "     15        \u001b[36m0.5931\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6012\u001b[0m  0.0293\n",
      "     16        \u001b[36m0.5883\u001b[0m       0.7109        \u001b[35m0.5968\u001b[0m  0.0365\n",
      "     17        \u001b[36m0.5838\u001b[0m       0.7109        \u001b[35m0.5927\u001b[0m  0.0281\n",
      "     18        \u001b[36m0.5795\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5887\u001b[0m  0.0252\n",
      "     19        \u001b[36m0.5754\u001b[0m       0.7344        \u001b[35m0.5850\u001b[0m  0.0238\n",
      "     20        \u001b[36m0.5714\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5816\u001b[0m  0.0398\n",
      "     21        \u001b[36m0.5675\u001b[0m       0.7422        \u001b[35m0.5783\u001b[0m  0.0443\n",
      "     22        \u001b[36m0.5639\u001b[0m       0.7344        \u001b[35m0.5752\u001b[0m  0.0223\n",
      "     23        \u001b[36m0.5604\u001b[0m       0.7266        \u001b[35m0.5723\u001b[0m  0.0265\n",
      "     24        \u001b[36m0.5572\u001b[0m       0.7266        \u001b[35m0.5695\u001b[0m  0.0318\n",
      "     25        \u001b[36m0.5539\u001b[0m       0.7344        \u001b[35m0.5670\u001b[0m  0.0271\n",
      "     26        \u001b[36m0.5508\u001b[0m       0.7344        \u001b[35m0.5646\u001b[0m  0.0261\n",
      "     27        \u001b[36m0.5480\u001b[0m       0.7344        \u001b[35m0.5623\u001b[0m  0.0221\n",
      "     28        \u001b[36m0.5453\u001b[0m       0.7344        \u001b[35m0.5601\u001b[0m  0.0279\n",
      "     29        \u001b[36m0.5426\u001b[0m       0.7344        \u001b[35m0.5581\u001b[0m  0.0263\n",
      "     30        \u001b[36m0.5400\u001b[0m       0.7422        \u001b[35m0.5561\u001b[0m  0.0265\n",
      "     31        \u001b[36m0.5376\u001b[0m       0.7422        \u001b[35m0.5543\u001b[0m  0.0278\n",
      "     32        \u001b[36m0.5353\u001b[0m       0.7422        \u001b[35m0.5526\u001b[0m  0.0245\n",
      "     33        \u001b[36m0.5330\u001b[0m       0.7422        \u001b[35m0.5510\u001b[0m  0.0218\n",
      "     34        \u001b[36m0.5309\u001b[0m       0.7422        \u001b[35m0.5495\u001b[0m  0.0294\n",
      "     35        \u001b[36m0.5287\u001b[0m       0.7422        \u001b[35m0.5480\u001b[0m  0.0249\n",
      "     36        \u001b[36m0.5267\u001b[0m       0.7422        \u001b[35m0.5466\u001b[0m  0.0263\n",
      "     37        \u001b[36m0.5248\u001b[0m       0.7422        \u001b[35m0.5454\u001b[0m  0.0237\n",
      "     38        \u001b[36m0.5229\u001b[0m       0.7422        \u001b[35m0.5442\u001b[0m  0.0231\n",
      "     39        \u001b[36m0.5212\u001b[0m       0.7422        \u001b[35m0.5431\u001b[0m  0.0252\n",
      "     40        \u001b[36m0.5194\u001b[0m       0.7422        \u001b[35m0.5420\u001b[0m  0.0261\n",
      "     41        \u001b[36m0.5178\u001b[0m       0.7344        \u001b[35m0.5411\u001b[0m  0.0244\n",
      "     42        \u001b[36m0.5161\u001b[0m       0.7344        \u001b[35m0.5401\u001b[0m  0.0236\n",
      "     43        \u001b[36m0.5148\u001b[0m       0.7344        \u001b[35m0.5392\u001b[0m  0.0255\n",
      "     44        \u001b[36m0.5133\u001b[0m       0.7344        \u001b[35m0.5384\u001b[0m  0.0250\n",
      "     45        \u001b[36m0.5119\u001b[0m       0.7344        \u001b[35m0.5376\u001b[0m  0.0273\n",
      "     46        \u001b[36m0.5106\u001b[0m       0.7344        \u001b[35m0.5368\u001b[0m  0.0467\n",
      "     47        \u001b[36m0.5094\u001b[0m       0.7344        \u001b[35m0.5361\u001b[0m  0.0548\n",
      "     48        \u001b[36m0.5081\u001b[0m       0.7344        \u001b[35m0.5355\u001b[0m  0.0423\n",
      "     49        \u001b[36m0.5070\u001b[0m       0.7344        \u001b[35m0.5348\u001b[0m  0.0482\n",
      "     50        \u001b[36m0.5058\u001b[0m       0.7344        \u001b[35m0.5343\u001b[0m  0.0478\n",
      "     51        \u001b[36m0.5049\u001b[0m       0.7344        \u001b[35m0.5338\u001b[0m  0.0230\n",
      "     52        \u001b[36m0.5038\u001b[0m       0.7266        \u001b[35m0.5333\u001b[0m  0.0306\n",
      "     53        \u001b[36m0.5027\u001b[0m       0.7344        \u001b[35m0.5328\u001b[0m  0.0283\n",
      "     54        \u001b[36m0.5017\u001b[0m       0.7344        \u001b[35m0.5324\u001b[0m  0.0212\n",
      "     55        \u001b[36m0.5009\u001b[0m       0.7344        \u001b[35m0.5319\u001b[0m  0.0344\n",
      "     56        \u001b[36m0.5000\u001b[0m       0.7344        \u001b[35m0.5315\u001b[0m  0.0602\n",
      "     57        \u001b[36m0.4990\u001b[0m       0.7344        \u001b[35m0.5312\u001b[0m  0.0485\n",
      "     58        \u001b[36m0.4982\u001b[0m       0.7344        \u001b[35m0.5308\u001b[0m  0.0562\n",
      "     59        \u001b[36m0.4975\u001b[0m       0.7344        \u001b[35m0.5305\u001b[0m  0.0405\n",
      "     60        \u001b[36m0.4967\u001b[0m       0.7344        \u001b[35m0.5301\u001b[0m  0.0548\n",
      "     61        \u001b[36m0.4960\u001b[0m       0.7344        \u001b[35m0.5299\u001b[0m  0.0372\n",
      "     62        \u001b[36m0.4953\u001b[0m       0.7344        \u001b[35m0.5296\u001b[0m  0.0273\n",
      "     63        \u001b[36m0.4946\u001b[0m       0.7266        \u001b[35m0.5294\u001b[0m  0.0293\n",
      "     64        \u001b[36m0.4939\u001b[0m       0.7266        \u001b[35m0.5291\u001b[0m  0.0247\n",
      "     65        \u001b[36m0.4933\u001b[0m       0.7266        \u001b[35m0.5289\u001b[0m  0.0289\n",
      "     66        \u001b[36m0.4927\u001b[0m       0.7266        \u001b[35m0.5287\u001b[0m  0.0230\n",
      "     67        \u001b[36m0.4921\u001b[0m       0.7266        \u001b[35m0.5285\u001b[0m  0.0353\n",
      "     68        \u001b[36m0.4914\u001b[0m       0.7266        \u001b[35m0.5283\u001b[0m  0.0499\n",
      "     69        \u001b[36m0.4908\u001b[0m       0.7188        \u001b[35m0.5281\u001b[0m  0.0227\n",
      "     70        \u001b[36m0.4904\u001b[0m       0.7188        \u001b[35m0.5279\u001b[0m  0.0257\n",
      "     71        \u001b[36m0.4897\u001b[0m       0.7188        \u001b[35m0.5278\u001b[0m  0.0275\n",
      "     72        \u001b[36m0.4892\u001b[0m       0.7188        \u001b[35m0.5277\u001b[0m  0.0269\n",
      "     73        \u001b[36m0.4889\u001b[0m       0.7188        \u001b[35m0.5275\u001b[0m  0.0227\n",
      "     74        \u001b[36m0.4882\u001b[0m       0.7188        \u001b[35m0.5274\u001b[0m  0.0230\n",
      "     75        \u001b[36m0.4878\u001b[0m       0.7188        \u001b[35m0.5273\u001b[0m  0.0212\n",
      "     76        \u001b[36m0.4873\u001b[0m       0.7188        \u001b[35m0.5273\u001b[0m  0.0260\n",
      "     77        \u001b[36m0.4868\u001b[0m       0.7188        \u001b[35m0.5272\u001b[0m  0.0264\n",
      "     78        \u001b[36m0.4864\u001b[0m       0.7188        \u001b[35m0.5271\u001b[0m  0.0245\n",
      "     79        \u001b[36m0.4859\u001b[0m       0.7188        \u001b[35m0.5270\u001b[0m  0.0265\n",
      "     80        \u001b[36m0.4855\u001b[0m       0.7188        \u001b[35m0.5270\u001b[0m  0.0276\n",
      "     81        \u001b[36m0.4851\u001b[0m       0.7188        \u001b[35m0.5270\u001b[0m  0.0238\n",
      "     82        \u001b[36m0.4847\u001b[0m       0.7188        \u001b[35m0.5269\u001b[0m  0.0418\n",
      "     83        \u001b[36m0.4843\u001b[0m       0.7188        0.5270  0.0212\n",
      "     84        \u001b[36m0.4839\u001b[0m       0.7188        \u001b[35m0.5269\u001b[0m  0.0289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     85        \u001b[36m0.4835\u001b[0m       0.7266        \u001b[35m0.5269\u001b[0m  0.0305\n",
      "     86        \u001b[36m0.4831\u001b[0m       0.7344        0.5269  0.0208\n",
      "     87        \u001b[36m0.4826\u001b[0m       0.7344        0.5269  0.0258\n",
      "     88        \u001b[36m0.4823\u001b[0m       0.7344        0.5270  0.0291\n",
      "     89        \u001b[36m0.4819\u001b[0m       0.7344        0.5270  0.0249\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6499\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6532\u001b[0m  0.0229\n",
      "      2        \u001b[36m0.6445\u001b[0m       0.6328        \u001b[35m0.6489\u001b[0m  0.0405\n",
      "      3        \u001b[36m0.6392\u001b[0m       0.6328        \u001b[35m0.6446\u001b[0m  0.0279\n",
      "      4        \u001b[36m0.6339\u001b[0m       0.6250        \u001b[35m0.6403\u001b[0m  0.0244\n",
      "      5        \u001b[36m0.6282\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6358\u001b[0m  0.0290\n",
      "      6        \u001b[36m0.6225\u001b[0m       0.6328        \u001b[35m0.6313\u001b[0m  0.0265\n",
      "      7        \u001b[36m0.6168\u001b[0m       0.6328        \u001b[35m0.6268\u001b[0m  0.0504\n",
      "      8        \u001b[36m0.6110\u001b[0m       0.6328        \u001b[35m0.6222\u001b[0m  0.0462\n",
      "      9        \u001b[36m0.6053\u001b[0m       0.6406        \u001b[35m0.6175\u001b[0m  0.0456\n",
      "     10        \u001b[36m0.5996\u001b[0m       0.6406        \u001b[35m0.6130\u001b[0m  0.0324\n",
      "     11        \u001b[36m0.5940\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6085\u001b[0m  0.0401\n",
      "     12        \u001b[36m0.5884\u001b[0m       0.6406        \u001b[35m0.6043\u001b[0m  0.0484\n",
      "     13        \u001b[36m0.5832\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6003\u001b[0m  0.0384\n",
      "     14        \u001b[36m0.5779\u001b[0m       0.6562        \u001b[35m0.5966\u001b[0m  0.0241\n",
      "     15        \u001b[36m0.5729\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.5930\u001b[0m  0.0268\n",
      "     16        \u001b[36m0.5681\u001b[0m       0.6641        \u001b[35m0.5896\u001b[0m  0.0241\n",
      "     17        \u001b[36m0.5635\u001b[0m       0.6641        \u001b[35m0.5863\u001b[0m  0.0309\n",
      "     18        \u001b[36m0.5590\u001b[0m       0.6641        \u001b[35m0.5832\u001b[0m  0.0264\n",
      "     19        \u001b[36m0.5549\u001b[0m       0.6641        \u001b[35m0.5800\u001b[0m  0.0287\n",
      "     20        \u001b[36m0.5509\u001b[0m       0.6641        \u001b[35m0.5769\u001b[0m  0.0328\n",
      "     21        \u001b[36m0.5470\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5739\u001b[0m  0.0281\n",
      "     22        \u001b[36m0.5433\u001b[0m       0.6797        \u001b[35m0.5711\u001b[0m  0.0288\n",
      "     23        \u001b[36m0.5397\u001b[0m       0.6797        \u001b[35m0.5684\u001b[0m  0.0249\n",
      "     24        \u001b[36m0.5363\u001b[0m       0.6797        \u001b[35m0.5657\u001b[0m  0.0272\n",
      "     25        \u001b[36m0.5330\u001b[0m       0.6797        \u001b[35m0.5631\u001b[0m  0.0415\n",
      "     26        \u001b[36m0.5299\u001b[0m       0.6797        \u001b[35m0.5605\u001b[0m  0.0504\n",
      "     27        \u001b[36m0.5269\u001b[0m       0.6797        \u001b[35m0.5581\u001b[0m  0.0414\n",
      "     28        \u001b[36m0.5241\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5558\u001b[0m  0.0435\n",
      "     29        \u001b[36m0.5214\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5537\u001b[0m  0.0345\n",
      "     30        \u001b[36m0.5188\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5517\u001b[0m  0.0421\n",
      "     31        \u001b[36m0.5164\u001b[0m       0.6953        \u001b[35m0.5499\u001b[0m  0.0509\n",
      "     32        \u001b[36m0.5141\u001b[0m       0.6953        \u001b[35m0.5482\u001b[0m  0.0295\n",
      "     33        \u001b[36m0.5120\u001b[0m       0.6953        \u001b[35m0.5467\u001b[0m  0.0218\n",
      "     34        \u001b[36m0.5099\u001b[0m       0.6953        \u001b[35m0.5452\u001b[0m  0.0258\n",
      "     35        \u001b[36m0.5078\u001b[0m       0.6953        \u001b[35m0.5438\u001b[0m  0.0267\n",
      "     36        \u001b[36m0.5059\u001b[0m       0.6797        \u001b[35m0.5426\u001b[0m  0.0316\n",
      "     37        \u001b[36m0.5040\u001b[0m       0.6797        \u001b[35m0.5414\u001b[0m  0.0267\n",
      "     38        \u001b[36m0.5022\u001b[0m       0.6797        \u001b[35m0.5403\u001b[0m  0.0368\n",
      "     39        \u001b[36m0.5004\u001b[0m       0.6797        \u001b[35m0.5392\u001b[0m  0.0432\n",
      "     40        \u001b[36m0.4988\u001b[0m       0.6797        \u001b[35m0.5384\u001b[0m  0.0447\n",
      "     41        \u001b[36m0.4972\u001b[0m       0.6797        \u001b[35m0.5375\u001b[0m  0.0428\n",
      "     42        \u001b[36m0.4956\u001b[0m       0.6797        \u001b[35m0.5368\u001b[0m  0.0276\n",
      "     43        \u001b[36m0.4943\u001b[0m       0.6797        \u001b[35m0.5361\u001b[0m  0.0221\n",
      "     44        \u001b[36m0.4929\u001b[0m       0.6797        \u001b[35m0.5355\u001b[0m  0.0258\n",
      "     45        \u001b[36m0.4916\u001b[0m       0.6797        \u001b[35m0.5350\u001b[0m  0.0346\n",
      "     46        \u001b[36m0.4904\u001b[0m       0.6797        \u001b[35m0.5346\u001b[0m  0.0399\n",
      "     47        \u001b[36m0.4892\u001b[0m       0.6719        \u001b[35m0.5343\u001b[0m  0.0247\n",
      "     48        \u001b[36m0.4880\u001b[0m       0.6719        \u001b[35m0.5340\u001b[0m  0.0272\n",
      "     49        \u001b[36m0.4868\u001b[0m       0.6719        \u001b[35m0.5337\u001b[0m  0.0294\n",
      "     50        \u001b[36m0.4857\u001b[0m       0.6719        \u001b[35m0.5335\u001b[0m  0.0272\n",
      "     51        \u001b[36m0.4847\u001b[0m       0.6797        \u001b[35m0.5333\u001b[0m  0.0256\n",
      "     52        \u001b[36m0.4836\u001b[0m       0.6797        \u001b[35m0.5332\u001b[0m  0.0248\n",
      "     53        \u001b[36m0.4826\u001b[0m       0.6797        \u001b[35m0.5332\u001b[0m  0.0372\n",
      "     54        \u001b[36m0.4818\u001b[0m       0.6797        0.5333  0.0195\n",
      "     55        \u001b[36m0.4807\u001b[0m       0.6797        0.5333  0.0251\n",
      "     56        \u001b[36m0.4799\u001b[0m       0.6797        0.5334  0.0280\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6585\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6620\u001b[0m  0.0191\n",
      "      2        \u001b[36m0.6494\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6544\u001b[0m  0.0232\n",
      "      3        \u001b[36m0.6412\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6476\u001b[0m  0.0278\n",
      "      4        \u001b[36m0.6334\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6412\u001b[0m  0.0350\n",
      "      5        \u001b[36m0.6260\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6352\u001b[0m  0.0320\n",
      "      6        \u001b[36m0.6189\u001b[0m       0.6953        \u001b[35m0.6291\u001b[0m  0.0285\n",
      "      7        \u001b[36m0.6118\u001b[0m       0.6953        \u001b[35m0.6233\u001b[0m  0.0236\n",
      "      8        \u001b[36m0.6048\u001b[0m       0.6953        \u001b[35m0.6178\u001b[0m  0.0320\n",
      "      9        \u001b[36m0.5981\u001b[0m       0.7031        \u001b[35m0.6127\u001b[0m  0.0241\n",
      "     10        \u001b[36m0.5916\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6080\u001b[0m  0.0312\n",
      "     11        \u001b[36m0.5856\u001b[0m       0.7109        \u001b[35m0.6035\u001b[0m  0.0274\n",
      "     12        \u001b[36m0.5799\u001b[0m       0.7109        \u001b[35m0.5992\u001b[0m  0.0294\n",
      "     13        \u001b[36m0.5744\u001b[0m       0.7109        \u001b[35m0.5951\u001b[0m  0.0279\n",
      "     14        \u001b[36m0.5694\u001b[0m       0.7109        \u001b[35m0.5913\u001b[0m  0.0249\n",
      "     15        \u001b[36m0.5644\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5878\u001b[0m  0.0251\n",
      "     16        \u001b[36m0.5597\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5845\u001b[0m  0.0233\n",
      "     17        \u001b[36m0.5552\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5815\u001b[0m  0.0254\n",
      "     18        \u001b[36m0.5511\u001b[0m       0.7266        \u001b[35m0.5786\u001b[0m  0.0255\n",
      "     19        \u001b[36m0.5470\u001b[0m       0.7188        \u001b[35m0.5760\u001b[0m  0.0518\n",
      "     20        \u001b[36m0.5433\u001b[0m       0.7188        \u001b[35m0.5736\u001b[0m  0.0255\n",
      "     21        \u001b[36m0.5398\u001b[0m       0.7188        \u001b[35m0.5714\u001b[0m  0.0217\n",
      "     22        \u001b[36m0.5364\u001b[0m       0.7188        \u001b[35m0.5694\u001b[0m  0.0336\n",
      "     23        \u001b[36m0.5332\u001b[0m       0.7188        \u001b[35m0.5676\u001b[0m  0.0280\n",
      "     24        \u001b[36m0.5303\u001b[0m       0.7188        \u001b[35m0.5660\u001b[0m  0.0248\n",
      "     25        \u001b[36m0.5275\u001b[0m       0.7188        \u001b[35m0.5646\u001b[0m  0.0256\n",
      "     26        \u001b[36m0.5248\u001b[0m       0.7109        \u001b[35m0.5633\u001b[0m  0.0217\n",
      "     27        \u001b[36m0.5224\u001b[0m       0.7109        \u001b[35m0.5621\u001b[0m  0.0231\n",
      "     28        \u001b[36m0.5202\u001b[0m       0.7109        \u001b[35m0.5611\u001b[0m  0.0205\n",
      "     29        \u001b[36m0.5180\u001b[0m       0.7109        \u001b[35m0.5602\u001b[0m  0.0244\n",
      "     30        \u001b[36m0.5159\u001b[0m       0.7109        \u001b[35m0.5595\u001b[0m  0.0361\n",
      "     31        \u001b[36m0.5140\u001b[0m       0.7188        \u001b[35m0.5588\u001b[0m  0.0248\n",
      "     32        \u001b[36m0.5121\u001b[0m       0.7109        \u001b[35m0.5582\u001b[0m  0.0258\n",
      "     33        \u001b[36m0.5104\u001b[0m       0.7109        \u001b[35m0.5577\u001b[0m  0.0203\n",
      "     34        \u001b[36m0.5088\u001b[0m       0.7109        \u001b[35m0.5573\u001b[0m  0.0187\n",
      "     35        \u001b[36m0.5072\u001b[0m       0.7031        \u001b[35m0.5570\u001b[0m  0.0334\n",
      "     36        \u001b[36m0.5058\u001b[0m       0.7031        \u001b[35m0.5567\u001b[0m  0.0447\n",
      "     37        \u001b[36m0.5045\u001b[0m       0.7031        \u001b[35m0.5566\u001b[0m  0.0231\n",
      "     38        \u001b[36m0.5032\u001b[0m       0.7031        \u001b[35m0.5565\u001b[0m  0.0272\n",
      "     39        \u001b[36m0.5021\u001b[0m       0.7031        \u001b[35m0.5564\u001b[0m  0.0354\n",
      "     40        \u001b[36m0.5007\u001b[0m       0.7031        \u001b[35m0.5564\u001b[0m  0.0285\n",
      "     41        \u001b[36m0.4998\u001b[0m       0.7031        0.5564  0.0224\n",
      "     42        \u001b[36m0.4989\u001b[0m       0.7031        0.5565  0.0213\n",
      "     43        \u001b[36m0.4980\u001b[0m       0.6953        0.5566  0.0283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7424\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7522\u001b[0m  0.0176\n",
      "      2        \u001b[36m0.7309\u001b[0m       0.5000        \u001b[35m0.7413\u001b[0m  0.0225\n",
      "      3        \u001b[36m0.7207\u001b[0m       0.4922        \u001b[35m0.7317\u001b[0m  0.0239\n",
      "      4        \u001b[36m0.7118\u001b[0m       0.4922        \u001b[35m0.7234\u001b[0m  0.0235\n",
      "      5        \u001b[36m0.7039\u001b[0m       0.5000        \u001b[35m0.7159\u001b[0m  0.0231\n",
      "      6        \u001b[36m0.6964\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.7090\u001b[0m  0.0228\n",
      "      7        \u001b[36m0.6896\u001b[0m       0.5156        \u001b[35m0.7025\u001b[0m  0.0221\n",
      "      8        \u001b[36m0.6830\u001b[0m       0.5156        \u001b[35m0.6963\u001b[0m  0.0231\n",
      "      9        \u001b[36m0.6766\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6905\u001b[0m  0.0222\n",
      "     10        \u001b[36m0.6703\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6848\u001b[0m  0.0250\n",
      "     11        \u001b[36m0.6642\u001b[0m       0.5469        \u001b[35m0.6793\u001b[0m  0.0275\n",
      "     12        \u001b[36m0.6582\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6738\u001b[0m  0.0229\n",
      "     13        \u001b[36m0.6521\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6682\u001b[0m  0.0251\n",
      "     14        \u001b[36m0.6459\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6626\u001b[0m  0.0244\n",
      "     15        \u001b[36m0.6396\u001b[0m       0.6250        \u001b[35m0.6570\u001b[0m  0.0230\n",
      "     16        \u001b[36m0.6332\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6512\u001b[0m  0.0240\n",
      "     17        \u001b[36m0.6269\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6454\u001b[0m  0.0216\n",
      "     18        \u001b[36m0.6204\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6397\u001b[0m  0.0229\n",
      "     19        \u001b[36m0.6140\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6341\u001b[0m  0.0241\n",
      "     20        \u001b[36m0.6078\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6284\u001b[0m  0.0207\n",
      "     21        \u001b[36m0.6013\u001b[0m       0.7031        \u001b[35m0.6228\u001b[0m  0.0250\n",
      "     22        \u001b[36m0.5950\u001b[0m       0.7031        \u001b[35m0.6173\u001b[0m  0.0243\n",
      "     23        \u001b[36m0.5887\u001b[0m       0.6953        \u001b[35m0.6119\u001b[0m  0.0221\n",
      "     24        \u001b[36m0.5824\u001b[0m       0.7031        \u001b[35m0.6064\u001b[0m  0.0277\n",
      "     25        \u001b[36m0.5761\u001b[0m       0.7031        \u001b[35m0.6010\u001b[0m  0.0246\n",
      "     26        \u001b[36m0.5701\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5958\u001b[0m  0.0308\n",
      "     27        \u001b[36m0.5641\u001b[0m       0.7109        \u001b[35m0.5908\u001b[0m  0.0273\n",
      "     28        \u001b[36m0.5581\u001b[0m       0.7109        \u001b[35m0.5858\u001b[0m  0.0211\n",
      "     29        \u001b[36m0.5523\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5812\u001b[0m  0.0238\n",
      "     30        \u001b[36m0.5466\u001b[0m       0.7344        \u001b[35m0.5766\u001b[0m  0.0215\n",
      "     31        \u001b[36m0.5412\u001b[0m       0.7344        \u001b[35m0.5724\u001b[0m  0.0277\n",
      "     32        \u001b[36m0.5359\u001b[0m       0.7266        \u001b[35m0.5684\u001b[0m  0.0206\n",
      "     33        \u001b[36m0.5309\u001b[0m       0.7266        \u001b[35m0.5646\u001b[0m  0.0239\n",
      "     34        \u001b[36m0.5259\u001b[0m       0.7266        \u001b[35m0.5611\u001b[0m  0.0260\n",
      "     35        \u001b[36m0.5213\u001b[0m       0.7266        \u001b[35m0.5578\u001b[0m  0.0207\n",
      "     36        \u001b[36m0.5168\u001b[0m       0.7266        \u001b[35m0.5548\u001b[0m  0.0273\n",
      "     37        \u001b[36m0.5125\u001b[0m       0.7266        \u001b[35m0.5520\u001b[0m  0.0220\n",
      "     38        \u001b[36m0.5083\u001b[0m       0.7188        \u001b[35m0.5494\u001b[0m  0.0256\n",
      "     39        \u001b[36m0.5045\u001b[0m       0.7188        \u001b[35m0.5471\u001b[0m  0.0243\n",
      "     40        \u001b[36m0.5008\u001b[0m       0.7188        \u001b[35m0.5450\u001b[0m  0.0244\n",
      "     41        \u001b[36m0.4974\u001b[0m       0.7188        \u001b[35m0.5431\u001b[0m  0.0275\n",
      "     42        \u001b[36m0.4941\u001b[0m       0.7188        \u001b[35m0.5413\u001b[0m  0.0216\n",
      "     43        \u001b[36m0.4910\u001b[0m       0.7188        \u001b[35m0.5397\u001b[0m  0.0233\n",
      "     44        \u001b[36m0.4880\u001b[0m       0.7188        \u001b[35m0.5383\u001b[0m  0.0219\n",
      "     45        \u001b[36m0.4854\u001b[0m       0.7188        \u001b[35m0.5370\u001b[0m  0.0226\n",
      "     46        \u001b[36m0.4826\u001b[0m       0.7109        \u001b[35m0.5358\u001b[0m  0.0223\n",
      "     47        \u001b[36m0.4801\u001b[0m       0.7109        \u001b[35m0.5347\u001b[0m  0.0232\n",
      "     48        \u001b[36m0.4777\u001b[0m       0.7109        \u001b[35m0.5338\u001b[0m  0.0224\n",
      "     49        \u001b[36m0.4754\u001b[0m       0.7109        \u001b[35m0.5329\u001b[0m  0.0252\n",
      "     50        \u001b[36m0.4733\u001b[0m       0.7109        \u001b[35m0.5322\u001b[0m  0.0228\n",
      "     51        \u001b[36m0.4712\u001b[0m       0.7109        \u001b[35m0.5316\u001b[0m  0.0212\n",
      "     52        \u001b[36m0.4694\u001b[0m       0.7109        \u001b[35m0.5309\u001b[0m  0.0218\n",
      "     53        \u001b[36m0.4675\u001b[0m       0.7109        \u001b[35m0.5304\u001b[0m  0.0222\n",
      "     54        \u001b[36m0.4658\u001b[0m       0.7109        \u001b[35m0.5299\u001b[0m  0.0276\n",
      "     55        \u001b[36m0.4641\u001b[0m       0.7188        \u001b[35m0.5295\u001b[0m  0.0251\n",
      "     56        \u001b[36m0.4625\u001b[0m       0.7188        \u001b[35m0.5291\u001b[0m  0.0223\n",
      "     57        \u001b[36m0.4610\u001b[0m       0.7188        \u001b[35m0.5288\u001b[0m  0.0210\n",
      "     58        \u001b[36m0.4596\u001b[0m       0.7188        \u001b[35m0.5284\u001b[0m  0.0396\n",
      "     59        \u001b[36m0.4581\u001b[0m       0.7188        \u001b[35m0.5282\u001b[0m  0.0329\n",
      "     60        \u001b[36m0.4569\u001b[0m       0.7188        \u001b[35m0.5280\u001b[0m  0.0324\n",
      "     61        \u001b[36m0.4556\u001b[0m       0.7188        \u001b[35m0.5278\u001b[0m  0.0196\n",
      "     62        \u001b[36m0.4544\u001b[0m       0.7188        \u001b[35m0.5276\u001b[0m  0.0231\n",
      "     63        \u001b[36m0.4532\u001b[0m       0.7188        \u001b[35m0.5274\u001b[0m  0.0312\n",
      "     64        \u001b[36m0.4521\u001b[0m       0.7109        \u001b[35m0.5273\u001b[0m  0.0222\n",
      "     65        \u001b[36m0.4510\u001b[0m       0.7031        \u001b[35m0.5272\u001b[0m  0.0225\n",
      "     66        \u001b[36m0.4500\u001b[0m       0.7031        \u001b[35m0.5271\u001b[0m  0.0216\n",
      "     67        \u001b[36m0.4490\u001b[0m       0.7031        \u001b[35m0.5270\u001b[0m  0.0247\n",
      "     68        \u001b[36m0.4482\u001b[0m       0.7031        \u001b[35m0.5269\u001b[0m  0.0217\n",
      "     69        \u001b[36m0.4473\u001b[0m       0.7031        \u001b[35m0.5269\u001b[0m  0.0232\n",
      "     70        \u001b[36m0.4464\u001b[0m       0.6953        0.5269  0.0215\n",
      "     71        \u001b[36m0.4456\u001b[0m       0.6953        0.5270  0.0219\n",
      "     72        \u001b[36m0.4448\u001b[0m       0.6875        0.5270  0.0218\n",
      "     73        \u001b[36m0.4440\u001b[0m       0.6875        0.5271  0.0216\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7059\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4790\u001b[0m  0.0234\n",
      "      2        \u001b[36m0.7049\u001b[0m       0.7266        0.5557  0.0250\n",
      "      3        0.7601       0.6250        0.7021  0.0266\n",
      "      4        0.7751       0.5938        0.6797  0.0236\n",
      "      5        \u001b[36m0.6856\u001b[0m       0.7188        0.5738  0.0243\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8209\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.9189\u001b[0m  0.0181\n",
      "      2        \u001b[36m0.6839\u001b[0m       0.6328        \u001b[35m0.6469\u001b[0m  0.0188\n",
      "      3        0.7879       0.6562        0.9994  0.0207\n",
      "      4        0.8343       0.6875        0.6492  0.0246\n",
      "      5        0.7090       0.6875        1.1301  0.0217\n",
      "      6        0.7199       0.6719        1.2238  0.0238\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7634\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.7357\u001b[0m  0.0177\n",
      "      2        0.8972       0.5078        0.9109  0.0201\n",
      "      3        \u001b[36m0.7143\u001b[0m       0.4844        1.5141  0.0199\n",
      "      4        0.7794       0.5234        1.0635  0.0226\n",
      "      5        0.8664       0.5391        1.2479  0.0223\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6748\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6530\u001b[0m  0.0184\n",
      "      2        0.7731       0.7031        0.6936  0.0193\n",
      "      3        0.7617       0.6953        0.7258  0.0206\n",
      "      4        0.7790       0.5000        0.8582  0.0264\n",
      "      5        0.8791       0.5156        2.4379  0.0236\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6362\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6047\u001b[0m  0.0238\n",
      "      2        \u001b[36m0.6104\u001b[0m       0.5000        1.0619  0.0235\n",
      "      3        0.7479       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5999\u001b[0m  0.0243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        0.6813       0.6328        0.8107  0.0330\n",
      "      5        0.6425       0.6484        0.7615  0.0238\n",
      "      6        0.6686       0.5000        1.5960  0.0208\n",
      "      7        0.7612       0.6641        1.9013  0.0212\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7815\u001b[0m       \u001b[32m0.4375\u001b[0m        \u001b[35m0.7698\u001b[0m  0.0321\n",
      "      2        \u001b[36m0.7713\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.7541\u001b[0m  0.0344\n",
      "      3        0.9248       0.5000        0.8948  0.0303\n",
      "      4        0.7779       0.7344        \u001b[35m0.6371\u001b[0m  0.0312\n",
      "      5        \u001b[36m0.6600\u001b[0m       \u001b[32m0.7422\u001b[0m        0.6963  0.0317\n",
      "      6        0.7882       \u001b[32m0.7578\u001b[0m        0.6837  0.0327\n",
      "      7        1.0419       0.5000        1.2747  0.0323\n",
      "      8        1.0217       0.5938        0.8991  0.0352\n",
      "      9        0.7148       0.6484        \u001b[35m0.5804\u001b[0m  0.0327\n",
      "     10        0.7907       0.5078        0.5910  0.0314\n",
      "     11        0.8820       0.6953        0.7650  0.0330\n",
      "     12        0.7452       0.6953        0.6667  0.0342\n",
      "     13        0.8410       0.5078        0.7921  0.0339\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7899\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6697\u001b[0m  0.0287\n",
      "      2        \u001b[36m0.7291\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5639\u001b[0m  0.0332\n",
      "      3        \u001b[36m0.5911\u001b[0m       0.6953        0.6264  0.0347\n",
      "      4        0.7007       0.7031        1.0567  0.0336\n",
      "      5        0.7647       0.6719        0.6646  0.0335\n",
      "      6        0.8158       0.5312        0.6778  0.0324\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9962\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m1.4930\u001b[0m  0.0284\n",
      "      2        1.2405       0.5000        \u001b[35m1.4384\u001b[0m  0.0337\n",
      "      3        1.2581       \u001b[32m0.7031\u001b[0m        1.9025  0.0342\n",
      "      4        \u001b[36m0.9679\u001b[0m       0.5000        \u001b[35m0.7370\u001b[0m  0.0326\n",
      "      5        \u001b[36m0.8108\u001b[0m       0.5000        1.2012  0.0319\n",
      "      6        1.1964       0.5000        1.9826  0.0318\n",
      "      7        1.7611       0.5469        1.7190  0.0318\n",
      "      8        1.9218       0.5625        1.1767  0.0304\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3703\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m1.7589\u001b[0m  0.0271\n",
      "      2        1.7019       0.5703        2.0141  0.0308\n",
      "      3        1.4069       \u001b[32m0.7188\u001b[0m        \u001b[35m1.4288\u001b[0m  0.0335\n",
      "      4        \u001b[36m1.0375\u001b[0m       0.5312        \u001b[35m0.8943\u001b[0m  0.0330\n",
      "      5        \u001b[36m0.7342\u001b[0m       0.5703        \u001b[35m0.6492\u001b[0m  0.0326\n",
      "      6        \u001b[36m0.7025\u001b[0m       0.6406        0.7067  0.0334\n",
      "      7        \u001b[36m0.6739\u001b[0m       0.5078        0.7293  0.0318\n",
      "      8        0.7782       0.5078        0.7736  0.0300\n",
      "      9        0.7173       0.5078        \u001b[35m0.6440\u001b[0m  0.0353\n",
      "     10        0.7021       0.5078        0.7119  0.0469\n",
      "     11        0.7206       0.5938        \u001b[35m0.6221\u001b[0m  0.0355\n",
      "     12        0.7021       0.5938        0.6854  0.0357\n",
      "     13        0.6970       0.5078        0.8586  0.0270\n",
      "     14        0.7610       0.7109        1.3080  0.0292\n",
      "     15        0.8121       0.5312        0.8303  0.0341\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.1677\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m2.5122\u001b[0m  0.0339\n",
      "      2        2.2169       \u001b[32m0.7422\u001b[0m        3.0999  0.0335\n",
      "      3        2.0871       0.6328        \u001b[35m1.1943\u001b[0m  0.0397\n",
      "      4        1.6485       0.5312        \u001b[35m0.9241\u001b[0m  0.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bona/Applications/miniconda2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5        1.4179       0.6797        1.9141  0.0433\n",
      "      6        1.4106       0.5469        2.3567  0.0308\n",
      "      7        2.0151       0.6406        1.4956  0.0330\n",
      "      8        1.5991       0.5781        1.2570  0.0381\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6674\u001b[0m       \u001b[32m0.7250\u001b[0m        \u001b[35m0.5278\u001b[0m  0.0219\n",
      "      2        \u001b[36m0.5173\u001b[0m       0.7188        \u001b[35m0.5116\u001b[0m  0.0281\n",
      "      3        \u001b[36m0.4824\u001b[0m       0.6875        0.5284  0.0275\n",
      "      4        \u001b[36m0.4793\u001b[0m       \u001b[32m0.7312\u001b[0m        \u001b[35m0.4959\u001b[0m  0.0239\n",
      "      5        \u001b[36m0.4761\u001b[0m       \u001b[32m0.7375\u001b[0m        0.5334  0.0268\n",
      "      6        \u001b[36m0.4752\u001b[0m       \u001b[32m0.7500\u001b[0m        0.5031  0.0284\n",
      "      7        \u001b[36m0.4595\u001b[0m       0.7125        0.5244  0.0261\n",
      "      8        \u001b[36m0.4536\u001b[0m       0.7375        0.5041  0.0245\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best parameters found:\n",
      "\n",
      "{'optimizer__momentum': 0.9, 'module__num_units': 7, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 32}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.747 (+/-0.086) for {'optimizer__momentum': 0.6, 'module__num_units': 6, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 32}\n",
      "0.766 (+/-0.059) for {'optimizer__momentum': 0.9, 'module__num_units': 7, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 32}\n",
      "0.739 (+/-0.135) for {'optimizer__momentum': 0.6, 'module__num_units': 3, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 64}\n",
      "0.754 (+/-0.084) for {'optimizer__momentum': 0.6, 'module__num_units': 9, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 64}\n",
      "0.737 (+/-0.077) for {'optimizer__momentum': 0.1, 'module__num_units': 3, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 32}\n",
      "0.727 (+/-0.044) for {'optimizer__momentum': 0.3, 'module__num_units': 4, 'module__dropout': 0.5, 'lr': 0.01, 'batch_size': 16}\n",
      "0.739 (+/-0.043) for {'optimizer__momentum': 0.1, 'module__num_units': 6, 'module__dropout': 0.0, 'lr': 1, 'batch_size': 16}\n",
      "0.739 (+/-0.075) for {'optimizer__momentum': 0.1, 'module__num_units': 7, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 32}\n",
      "0.610 (+/-0.122) for {'optimizer__momentum': 0.9, 'module__num_units': 6, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 32}\n",
      "0.456 (+/-0.459) for {'optimizer__momentum': 0.9, 'module__num_units': 6, 'module__dropout': 0.0, 'lr': 1, 'batch_size': 16}\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6935\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6048\u001b[0m  0.0213\n",
      "      2        \u001b[36m0.6264\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4807\u001b[0m  0.0207\n",
      "      3        \u001b[36m0.5873\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4619\u001b[0m  0.0203\n",
      "      4        0.5877       0.7891        \u001b[35m0.4393\u001b[0m  0.0261\n",
      "      5        \u001b[36m0.5830\u001b[0m       0.7891        0.4701  0.0237\n",
      "      6        \u001b[36m0.5513\u001b[0m       0.7812        \u001b[35m0.4329\u001b[0m  0.0203\n",
      "      7        0.5614       0.7578        0.4487  0.0204\n",
      "      8        0.5802       0.7500        0.4559  0.0271\n",
      "      9        0.5675       0.7422        0.4542  0.0242\n",
      "     10        \u001b[36m0.5490\u001b[0m       0.7578        0.4443  0.0239\n",
      "     11        0.5594       0.7734        \u001b[35m0.4064\u001b[0m  0.0212\n",
      "     12        \u001b[36m0.5477\u001b[0m       0.7812        0.4418  0.0221\n",
      "     13        \u001b[36m0.5412\u001b[0m       0.7812        0.4214  0.0240\n",
      "     14        0.5547       0.7891        0.4255  0.0214\n",
      "     15        0.5437       0.8047        0.4382  0.0207\n",
      "     16        0.5632       0.7734        \u001b[35m0.4038\u001b[0m  0.0201\n",
      "     17        0.5543       0.8047        0.4393  0.0216\n",
      "     18        0.5605       0.7734        0.4272  0.0198\n",
      "     19        \u001b[36m0.5260\u001b[0m       0.7734        0.4289  0.0248\n",
      "     20        \u001b[36m0.5238\u001b[0m       0.7656        0.4238  0.0248\n",
      "     21        0.5333       0.8125        \u001b[35m0.3765\u001b[0m  0.0217\n",
      "     22        0.5517       0.7969        0.4569  0.0223\n",
      "     23        0.5304       0.7812        0.4023  0.0250\n",
      "     24        0.5525       0.7578        0.4125  0.0256\n",
      "     25        0.5540       0.7500        0.4520  0.0232\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6511\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5736\u001b[0m  0.0230\n",
      "      2        \u001b[36m0.5915\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5383\u001b[0m  0.0216\n",
      "      3        \u001b[36m0.5632\u001b[0m       0.6875        0.5484  0.0232\n",
      "      4        \u001b[36m0.5547\u001b[0m       0.6953        0.5388  0.0210\n",
      "      5        \u001b[36m0.5543\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5175\u001b[0m  0.0256\n",
      "      6        \u001b[36m0.5432\u001b[0m       0.6953        0.5235  0.0213\n",
      "      7        0.5643       0.7422        0.5476  0.0221\n",
      "      8        0.5471       0.6719        0.5199  0.0219\n",
      "      9        0.5522       0.7188        0.5199  0.0228\n",
      "     10        0.5601       0.7031        \u001b[35m0.5147\u001b[0m  0.0212\n",
      "     11        \u001b[36m0.5372\u001b[0m       0.7422        \u001b[35m0.5120\u001b[0m  0.0273\n",
      "     12        0.5636       0.7188        \u001b[35m0.5040\u001b[0m  0.0268\n",
      "     13        \u001b[36m0.5312\u001b[0m       0.6719        0.5309  0.0214\n",
      "     14        0.5512       0.6875        0.5377  0.0206\n",
      "     15        0.5506       0.6953        0.5120  0.0239\n",
      "     16        0.5496       0.6719        0.5320  0.0218\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6911\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5716\u001b[0m  0.0242\n",
      "      2        \u001b[36m0.6296\u001b[0m       0.7266        \u001b[35m0.5691\u001b[0m  0.0230\n",
      "      3        \u001b[36m0.5668\u001b[0m       0.7344        \u001b[35m0.5215\u001b[0m  0.0272\n",
      "      4        \u001b[36m0.5407\u001b[0m       0.7188        0.5304  0.0222\n",
      "      5        0.5441       0.7266        \u001b[35m0.5209\u001b[0m  0.0240\n",
      "      6        0.5532       0.7266        0.5271  0.0248\n",
      "      7        \u001b[36m0.5406\u001b[0m       0.7188        0.5350  0.0232\n",
      "      8        0.5588       0.7188        0.5392  0.0275\n",
      "      9        \u001b[36m0.5197\u001b[0m       0.7422        0.5230  0.0292\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6558\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6053\u001b[0m  0.0326\n",
      "      2        \u001b[36m0.6102\u001b[0m       0.6562        \u001b[35m0.5679\u001b[0m  0.0342\n",
      "      3        \u001b[36m0.5756\u001b[0m       0.6953        \u001b[35m0.5453\u001b[0m  0.0219\n",
      "      4        \u001b[36m0.5480\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5302\u001b[0m  0.0331\n",
      "      5        \u001b[36m0.5459\u001b[0m       0.7031        \u001b[35m0.5221\u001b[0m  0.0283\n",
      "      6        0.5524       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5067\u001b[0m  0.0258\n",
      "      7        \u001b[36m0.5319\u001b[0m       0.6953        0.5216  0.0241\n",
      "      8        0.5502       0.6797        0.5408  0.0217\n",
      "      9        0.5525       0.7422        0.5163  0.0267\n",
      "     10        0.5347       0.6875        0.5234  0.0238\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6388\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.5864\u001b[0m  0.0258\n",
      "      2        \u001b[36m0.5587\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5765\u001b[0m  0.0222\n",
      "      3        0.5644       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5479\u001b[0m  0.0344\n",
      "      4        \u001b[36m0.5537\u001b[0m       \u001b[32m0.6953\u001b[0m        0.5528  0.0243\n",
      "      5        \u001b[36m0.5379\u001b[0m       0.6953        \u001b[35m0.5462\u001b[0m  0.0292\n",
      "      6        0.5531       \u001b[32m0.7031\u001b[0m        0.5570  0.0308\n",
      "      7        \u001b[36m0.5177\u001b[0m       0.7031        0.5586  0.0241\n",
      "      8        0.5224       0.7031        0.5522  0.0281\n",
      "      9        0.5321       0.6953        0.5512  0.0265\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6319\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6048\u001b[0m  0.0363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.6005\u001b[0m       0.7109        \u001b[35m0.5752\u001b[0m  0.0387\n",
      "      3        \u001b[36m0.5777\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5509\u001b[0m  0.0350\n",
      "      4        \u001b[36m0.5603\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5309\u001b[0m  0.0349\n",
      "      5        \u001b[36m0.5466\u001b[0m       0.7266        \u001b[35m0.5141\u001b[0m  0.0347\n",
      "      6        \u001b[36m0.5356\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5006\u001b[0m  0.0379\n",
      "      7        \u001b[36m0.5279\u001b[0m       0.7422        \u001b[35m0.4898\u001b[0m  0.0365\n",
      "      8        \u001b[36m0.5212\u001b[0m       0.7344        \u001b[35m0.4805\u001b[0m  0.0332\n",
      "      9        \u001b[36m0.5160\u001b[0m       0.7344        \u001b[35m0.4724\u001b[0m  0.0347\n",
      "     10        \u001b[36m0.5115\u001b[0m       0.7344        \u001b[35m0.4651\u001b[0m  0.0401\n",
      "     11        \u001b[36m0.5081\u001b[0m       0.7422        \u001b[35m0.4594\u001b[0m  0.0343\n",
      "     12        \u001b[36m0.5052\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.4532\u001b[0m  0.0377\n",
      "     13        \u001b[36m0.5025\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4487\u001b[0m  0.0427\n",
      "     14        \u001b[36m0.5005\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4450\u001b[0m  0.0411\n",
      "     15        \u001b[36m0.4982\u001b[0m       0.7812        \u001b[35m0.4409\u001b[0m  0.0312\n",
      "     16        \u001b[36m0.4965\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4369\u001b[0m  0.0331\n",
      "     17        \u001b[36m0.4947\u001b[0m       0.7969        \u001b[35m0.4346\u001b[0m  0.0356\n",
      "     18        \u001b[36m0.4929\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4312\u001b[0m  0.0352\n",
      "     19        \u001b[36m0.4916\u001b[0m       0.8047        \u001b[35m0.4292\u001b[0m  0.0319\n",
      "     20        \u001b[36m0.4905\u001b[0m       0.8047        \u001b[35m0.4258\u001b[0m  0.0344\n",
      "     21        \u001b[36m0.4895\u001b[0m       0.8047        \u001b[35m0.4235\u001b[0m  0.0380\n",
      "     22        \u001b[36m0.4881\u001b[0m       0.8047        \u001b[35m0.4204\u001b[0m  0.0344\n",
      "     23        \u001b[36m0.4870\u001b[0m       0.8047        \u001b[35m0.4186\u001b[0m  0.0311\n",
      "     24        \u001b[36m0.4854\u001b[0m       0.8047        \u001b[35m0.4171\u001b[0m  0.0349\n",
      "     25        \u001b[36m0.4848\u001b[0m       0.8047        \u001b[35m0.4157\u001b[0m  0.0315\n",
      "     26        \u001b[36m0.4843\u001b[0m       0.8047        \u001b[35m0.4141\u001b[0m  0.0342\n",
      "     27        \u001b[36m0.4831\u001b[0m       0.8047        \u001b[35m0.4129\u001b[0m  0.0325\n",
      "     28        \u001b[36m0.4826\u001b[0m       0.8047        \u001b[35m0.4116\u001b[0m  0.0319\n",
      "     29        \u001b[36m0.4817\u001b[0m       0.8047        \u001b[35m0.4100\u001b[0m  0.0330\n",
      "     30        \u001b[36m0.4811\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m0.4089\u001b[0m  0.0299\n",
      "     31        \u001b[36m0.4802\u001b[0m       0.8281        \u001b[35m0.4080\u001b[0m  0.0340\n",
      "     32        \u001b[36m0.4796\u001b[0m       0.8281        \u001b[35m0.4062\u001b[0m  0.0304\n",
      "     33        \u001b[36m0.4787\u001b[0m       0.8203        \u001b[35m0.4047\u001b[0m  0.0348\n",
      "     34        \u001b[36m0.4780\u001b[0m       0.8281        \u001b[35m0.4046\u001b[0m  0.0330\n",
      "     35        \u001b[36m0.4768\u001b[0m       0.8203        \u001b[35m0.4032\u001b[0m  0.0302\n",
      "     36        \u001b[36m0.4764\u001b[0m       0.8203        \u001b[35m0.4024\u001b[0m  0.0328\n",
      "     37        \u001b[36m0.4754\u001b[0m       0.8281        \u001b[35m0.4013\u001b[0m  0.0337\n",
      "     38        \u001b[36m0.4748\u001b[0m       0.8281        \u001b[35m0.4002\u001b[0m  0.0310\n",
      "     39        \u001b[36m0.4737\u001b[0m       0.8203        \u001b[35m0.3996\u001b[0m  0.0324\n",
      "     40        \u001b[36m0.4734\u001b[0m       0.8281        \u001b[35m0.3993\u001b[0m  0.0309\n",
      "     41        \u001b[36m0.4725\u001b[0m       0.8281        \u001b[35m0.3984\u001b[0m  0.0328\n",
      "     42        \u001b[36m0.4714\u001b[0m       0.8281        \u001b[35m0.3978\u001b[0m  0.0314\n",
      "     43        \u001b[36m0.4709\u001b[0m       0.8281        \u001b[35m0.3971\u001b[0m  0.0372\n",
      "     44        \u001b[36m0.4698\u001b[0m       0.8281        \u001b[35m0.3958\u001b[0m  0.0356\n",
      "     45        \u001b[36m0.4691\u001b[0m       0.8281        \u001b[35m0.3957\u001b[0m  0.0480\n",
      "     46        \u001b[36m0.4682\u001b[0m       0.8281        \u001b[35m0.3949\u001b[0m  0.0305\n",
      "     47        \u001b[36m0.4676\u001b[0m       0.8203        \u001b[35m0.3937\u001b[0m  0.0462\n",
      "     48        \u001b[36m0.4670\u001b[0m       0.8281        \u001b[35m0.3934\u001b[0m  0.0398\n",
      "     49        \u001b[36m0.4661\u001b[0m       0.8281        0.3935  0.0477\n",
      "     50        \u001b[36m0.4655\u001b[0m       0.8281        \u001b[35m0.3929\u001b[0m  0.0305\n",
      "     51        \u001b[36m0.4645\u001b[0m       0.8281        \u001b[35m0.3924\u001b[0m  0.0384\n",
      "     52        \u001b[36m0.4633\u001b[0m       0.8203        \u001b[35m0.3914\u001b[0m  0.0465\n",
      "     53        \u001b[36m0.4628\u001b[0m       0.8281        \u001b[35m0.3909\u001b[0m  0.0497\n",
      "     54        \u001b[36m0.4620\u001b[0m       0.8203        \u001b[35m0.3902\u001b[0m  0.0417\n",
      "     55        \u001b[36m0.4615\u001b[0m       \u001b[32m0.8359\u001b[0m        0.3906  0.0517\n",
      "     56        \u001b[36m0.4606\u001b[0m       0.8359        0.3902  0.0311\n",
      "     57        \u001b[36m0.4600\u001b[0m       0.8359        0.3905  0.0392\n",
      "     58        \u001b[36m0.4597\u001b[0m       0.8359        \u001b[35m0.3901\u001b[0m  0.0450\n",
      "     59        \u001b[36m0.4591\u001b[0m       0.8281        \u001b[35m0.3893\u001b[0m  0.0533\n",
      "     60        \u001b[36m0.4582\u001b[0m       0.8281        0.3900  0.0306\n",
      "     61        \u001b[36m0.4582\u001b[0m       0.8281        0.3903  0.0560\n",
      "     62        \u001b[36m0.4571\u001b[0m       0.8281        0.3905  0.0300\n",
      "     63        \u001b[36m0.4566\u001b[0m       0.8281        0.3908  0.0464\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6945\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6848\u001b[0m  0.0340\n",
      "      2        \u001b[36m0.6831\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6738\u001b[0m  0.0317\n",
      "      3        \u001b[36m0.6721\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6626\u001b[0m  0.0342\n",
      "      4        \u001b[36m0.6597\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6501\u001b[0m  0.0513\n",
      "      5        \u001b[36m0.6468\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6379\u001b[0m  0.0329\n",
      "      6        \u001b[36m0.6329\u001b[0m       0.6719        \u001b[35m0.6262\u001b[0m  0.0525\n",
      "      7        \u001b[36m0.6182\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6158\u001b[0m  0.0447\n",
      "      8        \u001b[36m0.6033\u001b[0m       0.7031        \u001b[35m0.6057\u001b[0m  0.0552\n",
      "      9        \u001b[36m0.5894\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5974\u001b[0m  0.0397\n",
      "     10        \u001b[36m0.5777\u001b[0m       0.7031        \u001b[35m0.5911\u001b[0m  0.0360\n",
      "     11        \u001b[36m0.5669\u001b[0m       0.6797        \u001b[35m0.5855\u001b[0m  0.0372\n",
      "     12        \u001b[36m0.5582\u001b[0m       0.6875        \u001b[35m0.5807\u001b[0m  0.0363\n",
      "     13        \u001b[36m0.5506\u001b[0m       0.6875        \u001b[35m0.5771\u001b[0m  0.0348\n",
      "     14        \u001b[36m0.5440\u001b[0m       0.6719        \u001b[35m0.5747\u001b[0m  0.0404\n",
      "     15        \u001b[36m0.5391\u001b[0m       0.6797        \u001b[35m0.5728\u001b[0m  0.0351\n",
      "     16        \u001b[36m0.5341\u001b[0m       0.6875        \u001b[35m0.5702\u001b[0m  0.0389\n",
      "     17        \u001b[36m0.5301\u001b[0m       0.6797        \u001b[35m0.5684\u001b[0m  0.0311\n",
      "     18        \u001b[36m0.5272\u001b[0m       0.6797        \u001b[35m0.5677\u001b[0m  0.0336\n",
      "     19        \u001b[36m0.5243\u001b[0m       0.6797        \u001b[35m0.5661\u001b[0m  0.0326\n",
      "     20        \u001b[36m0.5214\u001b[0m       0.6797        \u001b[35m0.5642\u001b[0m  0.0347\n",
      "     21        \u001b[36m0.5184\u001b[0m       0.6797        \u001b[35m0.5631\u001b[0m  0.0349\n",
      "     22        \u001b[36m0.5162\u001b[0m       0.6797        \u001b[35m0.5621\u001b[0m  0.0315\n",
      "     23        \u001b[36m0.5143\u001b[0m       0.6797        \u001b[35m0.5609\u001b[0m  0.0353\n",
      "     24        \u001b[36m0.5115\u001b[0m       0.6797        \u001b[35m0.5593\u001b[0m  0.0312\n",
      "     25        \u001b[36m0.5089\u001b[0m       0.6797        \u001b[35m0.5586\u001b[0m  0.0380\n",
      "     26        \u001b[36m0.5066\u001b[0m       0.6797        \u001b[35m0.5571\u001b[0m  0.0300\n",
      "     27        \u001b[36m0.5046\u001b[0m       0.6797        \u001b[35m0.5554\u001b[0m  0.0328\n",
      "     28        \u001b[36m0.5021\u001b[0m       0.6797        \u001b[35m0.5540\u001b[0m  0.0309\n",
      "     29        \u001b[36m0.5011\u001b[0m       0.6797        \u001b[35m0.5526\u001b[0m  0.0381\n",
      "     30        \u001b[36m0.4990\u001b[0m       0.6797        \u001b[35m0.5525\u001b[0m  0.0299\n",
      "     31        \u001b[36m0.4973\u001b[0m       0.6797        \u001b[35m0.5502\u001b[0m  0.0341\n",
      "     32        \u001b[36m0.4965\u001b[0m       0.6797        \u001b[35m0.5491\u001b[0m  0.0335\n",
      "     33        \u001b[36m0.4948\u001b[0m       0.6797        \u001b[35m0.5477\u001b[0m  0.0402\n",
      "     34        \u001b[36m0.4932\u001b[0m       0.6797        \u001b[35m0.5460\u001b[0m  0.0343\n",
      "     35        \u001b[36m0.4927\u001b[0m       0.6719        \u001b[35m0.5439\u001b[0m  0.0405\n",
      "     36        \u001b[36m0.4909\u001b[0m       0.6875        \u001b[35m0.5433\u001b[0m  0.0308\n",
      "     37        \u001b[36m0.4900\u001b[0m       0.6875        \u001b[35m0.5419\u001b[0m  0.0312\n",
      "     38        \u001b[36m0.4888\u001b[0m       0.6875        \u001b[35m0.5417\u001b[0m  0.0370\n",
      "     39        \u001b[36m0.4880\u001b[0m       0.6875        \u001b[35m0.5412\u001b[0m  0.0356\n",
      "     40        \u001b[36m0.4874\u001b[0m       0.6875        \u001b[35m0.5403\u001b[0m  0.0310\n",
      "     41        \u001b[36m0.4869\u001b[0m       0.6797        \u001b[35m0.5383\u001b[0m  0.0321\n",
      "     42        \u001b[36m0.4858\u001b[0m       0.6875        \u001b[35m0.5382\u001b[0m  0.0368\n",
      "     43        \u001b[36m0.4849\u001b[0m       0.6797        \u001b[35m0.5378\u001b[0m  0.0376\n",
      "     44        \u001b[36m0.4841\u001b[0m       0.6953        \u001b[35m0.5366\u001b[0m  0.0307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     45        0.4845       0.6953        \u001b[35m0.5364\u001b[0m  0.0311\n",
      "     46        0.4842       0.6953        \u001b[35m0.5356\u001b[0m  0.0337\n",
      "     47        \u001b[36m0.4827\u001b[0m       0.6953        \u001b[35m0.5353\u001b[0m  0.0307\n",
      "     48        0.4828       0.6953        \u001b[35m0.5345\u001b[0m  0.0334\n",
      "     49        \u001b[36m0.4818\u001b[0m       0.6875        \u001b[35m0.5335\u001b[0m  0.0312\n",
      "     50        \u001b[36m0.4810\u001b[0m       0.6953        \u001b[35m0.5331\u001b[0m  0.0302\n",
      "     51        0.4816       0.6875        \u001b[35m0.5329\u001b[0m  0.0323\n",
      "     52        \u001b[36m0.4805\u001b[0m       0.6953        \u001b[35m0.5322\u001b[0m  0.0301\n",
      "     53        \u001b[36m0.4799\u001b[0m       0.6953        \u001b[35m0.5318\u001b[0m  0.0303\n",
      "     54        0.4811       0.6953        0.5322  0.0316\n",
      "     55        \u001b[36m0.4795\u001b[0m       0.6875        \u001b[35m0.5310\u001b[0m  0.0323\n",
      "     56        \u001b[36m0.4789\u001b[0m       0.6875        \u001b[35m0.5302\u001b[0m  0.0308\n",
      "     57        0.4792       0.6953        \u001b[35m0.5298\u001b[0m  0.0304\n",
      "     58        \u001b[36m0.4788\u001b[0m       0.6875        \u001b[35m0.5297\u001b[0m  0.0310\n",
      "     59        \u001b[36m0.4785\u001b[0m       0.6875        0.5302  0.0322\n",
      "     60        \u001b[36m0.4781\u001b[0m       0.6953        0.5300  0.0308\n",
      "     61        \u001b[36m0.4779\u001b[0m       0.6953        \u001b[35m0.5292\u001b[0m  0.0297\n",
      "     62        \u001b[36m0.4775\u001b[0m       0.6953        0.5297  0.0294\n",
      "     63        \u001b[36m0.4768\u001b[0m       0.6953        0.5294  0.0316\n",
      "     64        \u001b[36m0.4768\u001b[0m       0.7031        \u001b[35m0.5286\u001b[0m  0.0302\n",
      "     65        \u001b[36m0.4764\u001b[0m       0.7031        0.5290  0.0296\n",
      "     66        0.4771       0.7031        \u001b[35m0.5285\u001b[0m  0.0304\n",
      "     67        0.4767       0.7031        0.5287  0.0293\n",
      "     68        0.4769       0.7031        \u001b[35m0.5279\u001b[0m  0.0299\n",
      "     69        0.4765       0.7031        0.5283  0.0315\n",
      "     70        \u001b[36m0.4761\u001b[0m       0.7031        0.5284  0.0342\n",
      "     71        \u001b[36m0.4757\u001b[0m       0.7031        0.5286  0.0337\n",
      "     72        \u001b[36m0.4753\u001b[0m       0.7031        \u001b[35m0.5278\u001b[0m  0.0299\n",
      "     73        \u001b[36m0.4750\u001b[0m       0.7031        \u001b[35m0.5264\u001b[0m  0.0302\n",
      "     74        \u001b[36m0.4744\u001b[0m       0.7031        0.5269  0.0295\n",
      "     75        0.4750       0.7031        0.5273  0.0307\n",
      "     76        \u001b[36m0.4743\u001b[0m       0.6953        0.5270  0.0322\n",
      "     77        \u001b[36m0.4739\u001b[0m       0.7031        0.5271  0.0301\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7373\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7041\u001b[0m  0.0287\n",
      "      2        \u001b[36m0.6899\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6685\u001b[0m  0.0314\n",
      "      3        \u001b[36m0.6574\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6403\u001b[0m  0.0313\n",
      "      4        \u001b[36m0.6285\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6156\u001b[0m  0.0321\n",
      "      5        \u001b[36m0.6013\u001b[0m       0.6875        \u001b[35m0.5959\u001b[0m  0.0322\n",
      "      6        \u001b[36m0.5764\u001b[0m       0.6875        \u001b[35m0.5787\u001b[0m  0.0297\n",
      "      7        \u001b[36m0.5551\u001b[0m       0.6797        \u001b[35m0.5662\u001b[0m  0.0335\n",
      "      8        \u001b[36m0.5376\u001b[0m       0.6797        \u001b[35m0.5574\u001b[0m  0.0292\n",
      "      9        \u001b[36m0.5235\u001b[0m       0.6797        \u001b[35m0.5511\u001b[0m  0.0325\n",
      "     10        \u001b[36m0.5131\u001b[0m       0.6953        \u001b[35m0.5469\u001b[0m  0.0364\n",
      "     11        \u001b[36m0.5050\u001b[0m       0.6953        \u001b[35m0.5443\u001b[0m  0.0328\n",
      "     12        \u001b[36m0.4986\u001b[0m       0.6953        \u001b[35m0.5421\u001b[0m  0.0304\n",
      "     13        \u001b[36m0.4933\u001b[0m       0.6953        \u001b[35m0.5400\u001b[0m  0.0364\n",
      "     14        \u001b[36m0.4893\u001b[0m       0.6953        \u001b[35m0.5375\u001b[0m  0.0297\n",
      "     15        \u001b[36m0.4852\u001b[0m       0.7031        \u001b[35m0.5361\u001b[0m  0.0338\n",
      "     16        \u001b[36m0.4827\u001b[0m       0.7031        \u001b[35m0.5342\u001b[0m  0.0306\n",
      "     17        \u001b[36m0.4798\u001b[0m       0.7031        \u001b[35m0.5325\u001b[0m  0.0293\n",
      "     18        \u001b[36m0.4772\u001b[0m       0.6953        \u001b[35m0.5294\u001b[0m  0.0335\n",
      "     19        \u001b[36m0.4746\u001b[0m       0.6953        \u001b[35m0.5271\u001b[0m  0.0323\n",
      "     20        \u001b[36m0.4727\u001b[0m       0.6953        \u001b[35m0.5255\u001b[0m  0.0314\n",
      "     21        \u001b[36m0.4712\u001b[0m       0.7031        \u001b[35m0.5239\u001b[0m  0.0301\n",
      "     22        \u001b[36m0.4691\u001b[0m       0.7031        \u001b[35m0.5226\u001b[0m  0.0354\n",
      "     23        \u001b[36m0.4675\u001b[0m       0.6953        \u001b[35m0.5208\u001b[0m  0.0325\n",
      "     24        \u001b[36m0.4663\u001b[0m       0.7031        \u001b[35m0.5198\u001b[0m  0.0319\n",
      "     25        \u001b[36m0.4648\u001b[0m       0.7188        \u001b[35m0.5190\u001b[0m  0.0332\n",
      "     26        \u001b[36m0.4638\u001b[0m       0.7188        \u001b[35m0.5180\u001b[0m  0.0304\n",
      "     27        \u001b[36m0.4623\u001b[0m       0.7188        \u001b[35m0.5166\u001b[0m  0.0344\n",
      "     28        \u001b[36m0.4612\u001b[0m       0.7188        \u001b[35m0.5157\u001b[0m  0.0322\n",
      "     29        \u001b[36m0.4599\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5148\u001b[0m  0.0315\n",
      "     30        \u001b[36m0.4591\u001b[0m       0.7188        0.5154  0.0327\n",
      "     31        \u001b[36m0.4585\u001b[0m       0.7266        \u001b[35m0.5138\u001b[0m  0.0304\n",
      "     32        \u001b[36m0.4567\u001b[0m       0.7266        \u001b[35m0.5133\u001b[0m  0.0326\n",
      "     33        \u001b[36m0.4563\u001b[0m       0.7188        \u001b[35m0.5123\u001b[0m  0.0315\n",
      "     34        \u001b[36m0.4553\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5111\u001b[0m  0.0331\n",
      "     35        \u001b[36m0.4550\u001b[0m       0.7266        \u001b[35m0.5110\u001b[0m  0.0316\n",
      "     36        \u001b[36m0.4531\u001b[0m       0.7344        \u001b[35m0.5101\u001b[0m  0.0292\n",
      "     37        \u001b[36m0.4528\u001b[0m       0.7344        \u001b[35m0.5087\u001b[0m  0.0342\n",
      "     38        \u001b[36m0.4516\u001b[0m       0.7188        \u001b[35m0.5085\u001b[0m  0.0295\n",
      "     39        \u001b[36m0.4513\u001b[0m       0.7188        \u001b[35m0.5078\u001b[0m  0.0323\n",
      "     40        \u001b[36m0.4510\u001b[0m       0.7188        0.5080  0.0292\n",
      "     41        \u001b[36m0.4494\u001b[0m       0.7266        \u001b[35m0.5069\u001b[0m  0.0318\n",
      "     42        \u001b[36m0.4483\u001b[0m       0.7266        \u001b[35m0.5063\u001b[0m  0.0329\n",
      "     43        \u001b[36m0.4476\u001b[0m       0.7344        \u001b[35m0.5060\u001b[0m  0.0336\n",
      "     44        \u001b[36m0.4472\u001b[0m       0.7266        \u001b[35m0.5055\u001b[0m  0.0293\n",
      "     45        \u001b[36m0.4464\u001b[0m       0.7266        \u001b[35m0.5055\u001b[0m  0.0296\n",
      "     46        \u001b[36m0.4455\u001b[0m       0.7266        \u001b[35m0.5042\u001b[0m  0.0291\n",
      "     47        0.4457       0.7266        \u001b[35m0.5036\u001b[0m  0.0332\n",
      "     48        \u001b[36m0.4444\u001b[0m       0.7266        \u001b[35m0.5028\u001b[0m  0.0350\n",
      "     49        0.4455       \u001b[32m0.7422\u001b[0m        0.5033  0.0334\n",
      "     50        \u001b[36m0.4432\u001b[0m       0.7266        0.5043  0.0296\n",
      "     51        \u001b[36m0.4432\u001b[0m       0.7266        0.5037  0.0295\n",
      "     52        \u001b[36m0.4419\u001b[0m       0.7344        \u001b[35m0.5026\u001b[0m  0.0328\n",
      "     53        0.4426       0.7422        \u001b[35m0.5020\u001b[0m  0.0366\n",
      "     54        \u001b[36m0.4405\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5007\u001b[0m  0.0301\n",
      "     55        \u001b[36m0.4401\u001b[0m       0.7500        0.5008  0.0284\n",
      "     56        \u001b[36m0.4395\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5004\u001b[0m  0.0322\n",
      "     57        0.4401       0.7500        \u001b[35m0.4999\u001b[0m  0.0343\n",
      "     58        \u001b[36m0.4387\u001b[0m       0.7422        0.5010  0.0333\n",
      "     59        \u001b[36m0.4379\u001b[0m       0.7422        0.5009  0.0331\n",
      "     60        \u001b[36m0.4375\u001b[0m       0.7422        0.5001  0.0330\n",
      "     61        \u001b[36m0.4363\u001b[0m       0.7500        0.5003  0.0286\n",
      "     62        0.4366       0.7578        \u001b[35m0.4994\u001b[0m  0.0286\n",
      "     63        \u001b[36m0.4358\u001b[0m       0.7578        0.5005  0.0333\n",
      "     64        0.4360       0.7578        0.5006  0.0326\n",
      "     65        \u001b[36m0.4346\u001b[0m       0.7578        0.4995  0.0289\n",
      "     66        \u001b[36m0.4333\u001b[0m       0.7578        \u001b[35m0.4991\u001b[0m  0.0284\n",
      "     67        0.4336       0.7578        0.4993  0.0295\n",
      "     68        0.4334       0.7578        \u001b[35m0.4988\u001b[0m  0.0319\n",
      "     69        \u001b[36m0.4326\u001b[0m       0.7422        0.4998  0.0322\n",
      "     70        \u001b[36m0.4320\u001b[0m       0.7500        0.4990  0.0327\n",
      "     71        \u001b[36m0.4314\u001b[0m       0.7578        \u001b[35m0.4975\u001b[0m  0.0345\n",
      "     72        \u001b[36m0.4306\u001b[0m       0.7578        0.4981  0.0331\n",
      "     73        0.4320       0.7578        0.4985  0.0338\n",
      "     74        \u001b[36m0.4296\u001b[0m       0.7422        0.4987  0.0296\n",
      "     75        0.4300       0.7500        0.4989  0.0312\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6958\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6879\u001b[0m  0.0289\n",
      "      2        \u001b[36m0.6442\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6484\u001b[0m  0.0324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        \u001b[36m0.6104\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6202\u001b[0m  0.0323\n",
      "      4        \u001b[36m0.5826\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5983\u001b[0m  0.0317\n",
      "      5        \u001b[36m0.5582\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5805\u001b[0m  0.0348\n",
      "      6        \u001b[36m0.5378\u001b[0m       0.7109        \u001b[35m0.5680\u001b[0m  0.0333\n",
      "      7        \u001b[36m0.5224\u001b[0m       0.7031        \u001b[35m0.5594\u001b[0m  0.0322\n",
      "      8        \u001b[36m0.5111\u001b[0m       0.6875        \u001b[35m0.5545\u001b[0m  0.0333\n",
      "      9        \u001b[36m0.5028\u001b[0m       0.6953        \u001b[35m0.5517\u001b[0m  0.0319\n",
      "     10        \u001b[36m0.4961\u001b[0m       0.6953        \u001b[35m0.5496\u001b[0m  0.0303\n",
      "     11        \u001b[36m0.4902\u001b[0m       0.6953        \u001b[35m0.5486\u001b[0m  0.0318\n",
      "     12        \u001b[36m0.4849\u001b[0m       0.6953        \u001b[35m0.5475\u001b[0m  0.0331\n",
      "     13        \u001b[36m0.4806\u001b[0m       0.6953        \u001b[35m0.5465\u001b[0m  0.0323\n",
      "     14        \u001b[36m0.4770\u001b[0m       0.7031        \u001b[35m0.5461\u001b[0m  0.0304\n",
      "     15        \u001b[36m0.4737\u001b[0m       0.7031        \u001b[35m0.5460\u001b[0m  0.0298\n",
      "     16        \u001b[36m0.4706\u001b[0m       0.6953        \u001b[35m0.5451\u001b[0m  0.0312\n",
      "     17        \u001b[36m0.4679\u001b[0m       0.6953        0.5452  0.0323\n",
      "     18        \u001b[36m0.4663\u001b[0m       0.7031        0.5454  0.0334\n",
      "     19        \u001b[36m0.4640\u001b[0m       0.7109        0.5454  0.0301\n",
      "     20        \u001b[36m0.4624\u001b[0m       0.7031        0.5453  0.0317\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6640\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6640\u001b[0m  0.0289\n",
      "      2        \u001b[36m0.6283\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6333\u001b[0m  0.0325\n",
      "      3        \u001b[36m0.5946\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6062\u001b[0m  0.0344\n",
      "      4        \u001b[36m0.5628\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5839\u001b[0m  0.0343\n",
      "      5        \u001b[36m0.5361\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5674\u001b[0m  0.0325\n",
      "      6        \u001b[36m0.5158\u001b[0m       0.7109        \u001b[35m0.5552\u001b[0m  0.0309\n",
      "      7        \u001b[36m0.4999\u001b[0m       0.7109        \u001b[35m0.5478\u001b[0m  0.0310\n",
      "      8        \u001b[36m0.4875\u001b[0m       0.7109        \u001b[35m0.5443\u001b[0m  0.0314\n",
      "      9        \u001b[36m0.4784\u001b[0m       0.7109        \u001b[35m0.5428\u001b[0m  0.0299\n",
      "     10        \u001b[36m0.4719\u001b[0m       0.7031        \u001b[35m0.5423\u001b[0m  0.0314\n",
      "     11        \u001b[36m0.4665\u001b[0m       0.6953        0.5441  0.0298\n",
      "     12        \u001b[36m0.4625\u001b[0m       0.6953        0.5465  0.0320\n",
      "     13        \u001b[36m0.4589\u001b[0m       0.7031        0.5485  0.0337\n",
      "     14        \u001b[36m0.4562\u001b[0m       0.7031        0.5502  0.0327\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.2796\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m1.3083\u001b[0m  0.0295\n",
      "      2        2.1767       0.6172        2.9404  0.0355\n",
      "      3        1.9843       \u001b[32m0.6562\u001b[0m        3.2219  0.0348\n",
      "      4        2.2192       \u001b[32m0.6641\u001b[0m        2.7284  0.0375\n",
      "      5        1.7624       \u001b[32m0.7500\u001b[0m        2.6465  0.0334\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7062\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m2.5928\u001b[0m  0.0307\n",
      "      2        2.0145       \u001b[32m0.7344\u001b[0m        3.0285  0.0349\n",
      "      3        2.5464       0.5312        4.2147  0.0308\n",
      "      4        2.7142       0.6016        3.7246  0.0378\n",
      "      5        2.4842       0.6719        4.4618  0.0305\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.9580\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m4.9249\u001b[0m  0.0292\n",
      "      2        3.3644       \u001b[32m0.5312\u001b[0m        6.1914  0.0368\n",
      "      3        4.4397       0.5312        5.6763  0.0350\n",
      "      4        4.6606       0.5000        6.9222  0.0336\n",
      "      5        4.3344       0.4844        6.4340  0.0336\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.5102\u001b[0m       \u001b[32m0.4141\u001b[0m        \u001b[35m4.3994\u001b[0m  0.0292\n",
      "      2        \u001b[36m1.4986\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m2.1086\u001b[0m  0.0353\n",
      "      3        1.8108       0.5938        4.8924  0.0361\n",
      "      4        2.5800       0.6172        4.5163  0.0324\n",
      "      5        2.0527       0.5391        3.0145  0.0336\n",
      "      6        1.6448       0.5156        2.9434  0.0306\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.5183\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m3.2086\u001b[0m  0.0292\n",
      "      2        2.6701       0.6484        3.2290  0.0371\n",
      "      3        3.2916       0.5469        5.2571  0.0330\n",
      "      4        4.4254       0.5000        6.8868  0.0355\n",
      "      5        4.4055       0.5000        6.8816  0.0344\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6408\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5247\u001b[0m  0.0105\n",
      "      2        \u001b[36m0.5467\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.4386\u001b[0m  0.0122\n",
      "      3        \u001b[36m0.5181\u001b[0m       \u001b[32m0.7734\u001b[0m        0.4592  0.0126\n",
      "      4        \u001b[36m0.5173\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4328\u001b[0m  0.0128\n",
      "      5        0.5205       0.7734        \u001b[35m0.4040\u001b[0m  0.0133\n",
      "      6        0.5227       0.7891        0.4068  0.0177\n",
      "      7        0.5201       \u001b[32m0.8125\u001b[0m        0.4250  0.0199\n",
      "      8        \u001b[36m0.5142\u001b[0m       0.8047        0.4361  0.0123\n",
      "      9        \u001b[36m0.5073\u001b[0m       0.8047        0.4197  0.0150\n",
      "     10        0.5122       0.7969        \u001b[35m0.4009\u001b[0m  0.0137\n",
      "     11        0.5183       0.7969        0.4290  0.0217\n",
      "     12        0.5141       0.8125        \u001b[35m0.3999\u001b[0m  0.0127\n",
      "     13        \u001b[36m0.5035\u001b[0m       0.7969        0.4478  0.0142\n",
      "     14        0.5053       0.8047        0.4139  0.0143\n",
      "     15        0.5086       0.8047        0.4119  0.0187\n",
      "     16        \u001b[36m0.5033\u001b[0m       0.7969        0.4120  0.0164\n",
      "     17        0.5197       \u001b[32m0.8359\u001b[0m        \u001b[35m0.3976\u001b[0m  0.0157\n",
      "     18        \u001b[36m0.5004\u001b[0m       0.8125        0.4112  0.0158\n",
      "     19        0.5124       0.7188        0.4926  0.0138\n",
      "     20        0.5084       0.8125        0.4630  0.0179\n",
      "     21        0.5066       0.8281        0.4070  0.0141\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6500\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5356\u001b[0m  0.0139\n",
      "      2        \u001b[36m0.5260\u001b[0m       0.7266        \u001b[35m0.5237\u001b[0m  0.0158\n",
      "      3        \u001b[36m0.5091\u001b[0m       0.7266        0.5478  0.0131\n",
      "      4        \u001b[36m0.4949\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5176\u001b[0m  0.0149\n",
      "      5        \u001b[36m0.4949\u001b[0m       0.7188        0.5273  0.0190\n",
      "      6        0.4989       0.7188        0.5422  0.0163\n",
      "      7        \u001b[36m0.4887\u001b[0m       0.7031        0.5461  0.0136\n",
      "      8        \u001b[36m0.4825\u001b[0m       0.7031        0.5243  0.0159\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5760\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5582\u001b[0m  0.0141\n",
      "      2        \u001b[36m0.4990\u001b[0m       0.6797        \u001b[35m0.5458\u001b[0m  0.0151\n",
      "      3        \u001b[36m0.4909\u001b[0m       \u001b[32m0.7109\u001b[0m        0.5484  0.0133\n",
      "      4        \u001b[36m0.4881\u001b[0m       0.6719        0.5461  0.0218\n",
      "      5        \u001b[36m0.4726\u001b[0m       0.6797        0.5461  0.0129\n",
      "      6        \u001b[36m0.4690\u001b[0m       0.6562        0.5667  0.0235\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6090\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5253\u001b[0m  0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.4959\u001b[0m       0.7188        \u001b[35m0.5200\u001b[0m  0.0166\n",
      "      3        \u001b[36m0.4862\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5127\u001b[0m  0.0130\n",
      "      4        \u001b[36m0.4774\u001b[0m       0.7109        0.5239  0.0170\n",
      "      5        \u001b[36m0.4723\u001b[0m       0.6797        0.5215  0.0148\n",
      "      6        0.4817       0.6953        0.5455  0.0215\n",
      "      7        0.4748       0.7266        0.5321  0.0184\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5855\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5290\u001b[0m  0.0111\n",
      "      2        \u001b[36m0.4780\u001b[0m       0.7188        0.5400  0.0163\n",
      "      3        \u001b[36m0.4563\u001b[0m       0.7031        0.5634  0.0142\n",
      "      4        0.4629       0.7109        0.5403  0.0135\n",
      "      5        \u001b[36m0.4556\u001b[0m       0.6953        0.5531  0.0198\n",
      "      6        0.4599       0.7266        \u001b[35m0.5266\u001b[0m  0.0237\n",
      "      7        0.4559       0.7344        0.5463  0.0131\n",
      "      8        0.4713       0.7422        0.5370  0.0134\n",
      "      9        \u001b[36m0.4528\u001b[0m       0.7266        0.5374  0.0146\n",
      "     10        \u001b[36m0.4481\u001b[0m       0.6797        0.5315  0.0182\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7425\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m0.7201\u001b[0m  0.0151\n",
      "      2        \u001b[36m0.7360\u001b[0m       \u001b[32m0.4766\u001b[0m        \u001b[35m0.7153\u001b[0m  0.0140\n",
      "      3        \u001b[36m0.7223\u001b[0m       0.4688        \u001b[35m0.7115\u001b[0m  0.0152\n",
      "      4        \u001b[36m0.7184\u001b[0m       0.4688        \u001b[35m0.7074\u001b[0m  0.0200\n",
      "      5        \u001b[36m0.7070\u001b[0m       \u001b[32m0.4844\u001b[0m        \u001b[35m0.7044\u001b[0m  0.0148\n",
      "      6        \u001b[36m0.7002\u001b[0m       0.4844        \u001b[35m0.7008\u001b[0m  0.0172\n",
      "      7        0.7111       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6971\u001b[0m  0.0187\n",
      "      8        0.7053       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6937\u001b[0m  0.0214\n",
      "      9        0.7013       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6909\u001b[0m  0.0216\n",
      "     10        \u001b[36m0.6913\u001b[0m       0.5156        \u001b[35m0.6880\u001b[0m  0.0192\n",
      "     11        \u001b[36m0.6857\u001b[0m       0.5234        \u001b[35m0.6852\u001b[0m  0.0147\n",
      "     12        0.6888       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6822\u001b[0m  0.0174\n",
      "     13        \u001b[36m0.6759\u001b[0m       0.5547        \u001b[35m0.6793\u001b[0m  0.0200\n",
      "     14        0.6771       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6762\u001b[0m  0.0162\n",
      "     15        0.6915       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6730\u001b[0m  0.0237\n",
      "     16        \u001b[36m0.6754\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6702\u001b[0m  0.0208\n",
      "     17        \u001b[36m0.6729\u001b[0m       0.6016        \u001b[35m0.6670\u001b[0m  0.0149\n",
      "     18        0.6837       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6640\u001b[0m  0.0185\n",
      "     19        \u001b[36m0.6699\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6609\u001b[0m  0.0149\n",
      "     20        \u001b[36m0.6670\u001b[0m       0.6328        \u001b[35m0.6571\u001b[0m  0.0180\n",
      "     21        0.6699       0.6328        \u001b[35m0.6538\u001b[0m  0.0187\n",
      "     22        \u001b[36m0.6644\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6507\u001b[0m  0.0146\n",
      "     23        \u001b[36m0.6521\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6470\u001b[0m  0.0192\n",
      "     24        \u001b[36m0.6455\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6437\u001b[0m  0.0179\n",
      "     25        0.6597       0.6641        \u001b[35m0.6402\u001b[0m  0.0141\n",
      "     26        0.6589       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6372\u001b[0m  0.0167\n",
      "     27        0.6615       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6345\u001b[0m  0.0257\n",
      "     28        0.6499       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6316\u001b[0m  0.0147\n",
      "     29        \u001b[36m0.6435\u001b[0m       0.6953        \u001b[35m0.6286\u001b[0m  0.0209\n",
      "     30        \u001b[36m0.6394\u001b[0m       0.6953        \u001b[35m0.6256\u001b[0m  0.0184\n",
      "     31        0.6558       0.6953        \u001b[35m0.6232\u001b[0m  0.0150\n",
      "     32        \u001b[36m0.6387\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6202\u001b[0m  0.0154\n",
      "     33        \u001b[36m0.6320\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6169\u001b[0m  0.0145\n",
      "     34        0.6410       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6141\u001b[0m  0.0228\n",
      "     35        0.6452       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6110\u001b[0m  0.0198\n",
      "     36        0.6329       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6079\u001b[0m  0.0146\n",
      "     37        0.6426       \u001b[32m0.7734\u001b[0m        \u001b[35m0.6054\u001b[0m  0.0180\n",
      "     38        \u001b[36m0.6195\u001b[0m       0.7734        \u001b[35m0.6016\u001b[0m  0.0144\n",
      "     39        0.6404       0.7734        \u001b[35m0.5994\u001b[0m  0.0182\n",
      "     40        0.6270       0.7656        \u001b[35m0.5967\u001b[0m  0.0147\n",
      "     41        0.6363       0.7656        \u001b[35m0.5941\u001b[0m  0.0207\n",
      "     42        0.6211       0.7656        \u001b[35m0.5911\u001b[0m  0.0182\n",
      "     43        \u001b[36m0.6138\u001b[0m       0.7656        \u001b[35m0.5880\u001b[0m  0.0148\n",
      "     44        0.6291       0.7656        \u001b[35m0.5857\u001b[0m  0.0175\n",
      "     45        0.6220       0.7578        \u001b[35m0.5830\u001b[0m  0.0147\n",
      "     46        0.6241       0.7578        \u001b[35m0.5807\u001b[0m  0.0158\n",
      "     47        0.6224       0.7656        \u001b[35m0.5783\u001b[0m  0.0148\n",
      "     48        0.6156       0.7656        \u001b[35m0.5758\u001b[0m  0.0166\n",
      "     49        0.6224       0.7656        \u001b[35m0.5738\u001b[0m  0.0143\n",
      "     50        0.6310       0.7578        \u001b[35m0.5719\u001b[0m  0.0161\n",
      "     51        \u001b[36m0.6098\u001b[0m       0.7578        \u001b[35m0.5692\u001b[0m  0.0155\n",
      "     52        \u001b[36m0.6092\u001b[0m       0.7578        \u001b[35m0.5666\u001b[0m  0.0167\n",
      "     53        0.6102       0.7578        \u001b[35m0.5644\u001b[0m  0.0144\n",
      "     54        \u001b[36m0.6087\u001b[0m       0.7578        \u001b[35m0.5622\u001b[0m  0.0173\n",
      "     55        0.6121       0.7578        \u001b[35m0.5603\u001b[0m  0.0151\n",
      "     56        0.6124       0.7578        \u001b[35m0.5584\u001b[0m  0.0219\n",
      "     57        0.6158       0.7578        \u001b[35m0.5569\u001b[0m  0.0139\n",
      "     58        \u001b[36m0.6000\u001b[0m       0.7578        \u001b[35m0.5547\u001b[0m  0.0146\n",
      "     59        0.6084       0.7578        \u001b[35m0.5530\u001b[0m  0.0185\n",
      "     60        0.6114       0.7578        \u001b[35m0.5516\u001b[0m  0.0159\n",
      "     61        \u001b[36m0.5997\u001b[0m       0.7578        \u001b[35m0.5494\u001b[0m  0.0210\n",
      "     62        \u001b[36m0.5975\u001b[0m       0.7578        \u001b[35m0.5478\u001b[0m  0.0149\n",
      "     63        0.6127       0.7578        \u001b[35m0.5462\u001b[0m  0.0197\n",
      "     64        0.6020       0.7578        \u001b[35m0.5445\u001b[0m  0.0212\n",
      "     65        0.6082       0.7656        \u001b[35m0.5432\u001b[0m  0.0154\n",
      "     66        0.6116       0.7656        \u001b[35m0.5421\u001b[0m  0.0196\n",
      "     67        0.6113       0.7656        \u001b[35m0.5410\u001b[0m  0.0160\n",
      "     68        \u001b[36m0.5950\u001b[0m       0.7656        \u001b[35m0.5394\u001b[0m  0.0169\n",
      "     69        0.5963       0.7656        \u001b[35m0.5377\u001b[0m  0.0201\n",
      "     70        0.5967       0.7656        \u001b[35m0.5363\u001b[0m  0.0162\n",
      "     71        0.6113       0.7656        \u001b[35m0.5360\u001b[0m  0.0222\n",
      "     72        0.6034       0.7656        \u001b[35m0.5353\u001b[0m  0.0157\n",
      "     73        0.6128       0.7656        \u001b[35m0.5347\u001b[0m  0.0169\n",
      "     74        \u001b[36m0.5943\u001b[0m       0.7656        \u001b[35m0.5335\u001b[0m  0.0196\n",
      "     75        0.6082       0.7656        \u001b[35m0.5328\u001b[0m  0.0154\n",
      "     76        0.5987       0.7578        \u001b[35m0.5318\u001b[0m  0.0203\n",
      "     77        0.5997       0.7578        \u001b[35m0.5306\u001b[0m  0.0149\n",
      "     78        0.5976       0.7578        \u001b[35m0.5295\u001b[0m  0.0177\n",
      "     79        0.6129       0.7578        \u001b[35m0.5290\u001b[0m  0.0184\n",
      "     80        0.6072       0.7578        \u001b[35m0.5287\u001b[0m  0.0135\n",
      "     81        \u001b[36m0.5851\u001b[0m       0.7578        \u001b[35m0.5273\u001b[0m  0.0147\n",
      "     82        0.6083       0.7578        \u001b[35m0.5265\u001b[0m  0.0154\n",
      "     83        0.6063       0.7578        \u001b[35m0.5257\u001b[0m  0.0190\n",
      "     84        0.6125       0.7578        \u001b[35m0.5252\u001b[0m  0.0184\n",
      "     85        0.5935       0.7578        \u001b[35m0.5242\u001b[0m  0.0174\n",
      "     86        0.5899       0.7578        \u001b[35m0.5235\u001b[0m  0.0177\n",
      "     87        0.6028       0.7578        \u001b[35m0.5229\u001b[0m  0.0176\n",
      "     88        0.6016       0.7578        \u001b[35m0.5224\u001b[0m  0.0143\n",
      "     89        0.6095       0.7578        \u001b[35m0.5218\u001b[0m  0.0174\n",
      "     90        0.5893       0.7578        \u001b[35m0.5211\u001b[0m  0.0155\n",
      "     91        \u001b[36m0.5769\u001b[0m       0.7578        \u001b[35m0.5197\u001b[0m  0.0133\n",
      "     92        0.5869       0.7578        \u001b[35m0.5183\u001b[0m  0.0172\n",
      "     93        0.5981       0.7578        \u001b[35m0.5176\u001b[0m  0.0148\n",
      "     94        0.6011       0.7656        \u001b[35m0.5173\u001b[0m  0.0134\n",
      "     95        0.6070       0.7656        \u001b[35m0.5170\u001b[0m  0.0184\n",
      "     96        0.5840       0.7656        \u001b[35m0.5160\u001b[0m  0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     97        0.5893       0.7656        \u001b[35m0.5153\u001b[0m  0.0142\n",
      "     98        0.6045       0.7656        \u001b[35m0.5149\u001b[0m  0.0209\n",
      "     99        0.5956       0.7656        \u001b[35m0.5142\u001b[0m  0.0149\n",
      "    100        \u001b[36m0.5764\u001b[0m       0.7656        \u001b[35m0.5133\u001b[0m  0.0164\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7020\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m0.7011\u001b[0m  0.0147\n",
      "      2        \u001b[36m0.6985\u001b[0m       0.4688        \u001b[35m0.7004\u001b[0m  0.0132\n",
      "      3        0.7005       0.4688        \u001b[35m0.6998\u001b[0m  0.0251\n",
      "      4        \u001b[36m0.6965\u001b[0m       0.4688        \u001b[35m0.6992\u001b[0m  0.0170\n",
      "      5        0.6969       0.4609        \u001b[35m0.6986\u001b[0m  0.0146\n",
      "      6        0.6983       0.4609        \u001b[35m0.6982\u001b[0m  0.0149\n",
      "      7        0.6994       0.4688        \u001b[35m0.6976\u001b[0m  0.0147\n",
      "      8        0.6982       0.4609        \u001b[35m0.6971\u001b[0m  0.0189\n",
      "      9        \u001b[36m0.6950\u001b[0m       0.4609        \u001b[35m0.6967\u001b[0m  0.0288\n",
      "     10        0.6956       \u001b[32m0.4844\u001b[0m        \u001b[35m0.6962\u001b[0m  0.0223\n",
      "     11        \u001b[36m0.6945\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6959\u001b[0m  0.0171\n",
      "     12        0.6976       0.5000        \u001b[35m0.6955\u001b[0m  0.0149\n",
      "     13        \u001b[36m0.6932\u001b[0m       0.5000        \u001b[35m0.6951\u001b[0m  0.0234\n",
      "     14        \u001b[36m0.6927\u001b[0m       0.5000        \u001b[35m0.6948\u001b[0m  0.0191\n",
      "     15        0.6949       0.5000        \u001b[35m0.6945\u001b[0m  0.0142\n",
      "     16        0.6950       0.4844        \u001b[35m0.6942\u001b[0m  0.0212\n",
      "     17        0.6942       0.4766        \u001b[35m0.6940\u001b[0m  0.0166\n",
      "     18        0.6947       0.4766        \u001b[35m0.6937\u001b[0m  0.0150\n",
      "     19        0.6946       0.4766        \u001b[35m0.6934\u001b[0m  0.0181\n",
      "     20        0.6949       0.4766        \u001b[35m0.6931\u001b[0m  0.0144\n",
      "     21        \u001b[36m0.6927\u001b[0m       0.4844        \u001b[35m0.6929\u001b[0m  0.0191\n",
      "     22        0.6953       0.4922        \u001b[35m0.6926\u001b[0m  0.0176\n",
      "     23        0.6937       0.4922        \u001b[35m0.6923\u001b[0m  0.0147\n",
      "     24        0.6930       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6920\u001b[0m  0.0194\n",
      "     25        0.6935       0.5312        \u001b[35m0.6918\u001b[0m  0.0171\n",
      "     26        0.6945       0.5234        \u001b[35m0.6916\u001b[0m  0.0144\n",
      "     27        \u001b[36m0.6920\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6914\u001b[0m  0.0155\n",
      "     28        0.6928       0.5391        \u001b[35m0.6912\u001b[0m  0.0149\n",
      "     29        0.6936       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6911\u001b[0m  0.0180\n",
      "     30        \u001b[36m0.6916\u001b[0m       0.5469        \u001b[35m0.6908\u001b[0m  0.0195\n",
      "     31        0.6924       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6906\u001b[0m  0.0171\n",
      "     32        0.6930       0.5469        \u001b[35m0.6904\u001b[0m  0.0193\n",
      "     33        0.6921       0.5391        \u001b[35m0.6902\u001b[0m  0.0147\n",
      "     34        \u001b[36m0.6912\u001b[0m       0.5547        \u001b[35m0.6899\u001b[0m  0.0186\n",
      "     35        \u001b[36m0.6907\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6897\u001b[0m  0.0190\n",
      "     36        \u001b[36m0.6896\u001b[0m       0.5625        \u001b[35m0.6895\u001b[0m  0.0158\n",
      "     37        0.6901       0.5625        \u001b[35m0.6893\u001b[0m  0.0190\n",
      "     38        0.6927       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6891\u001b[0m  0.0161\n",
      "     39        0.6902       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6889\u001b[0m  0.0202\n",
      "     40        \u001b[36m0.6887\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6886\u001b[0m  0.0158\n",
      "     41        \u001b[36m0.6877\u001b[0m       0.5938        \u001b[35m0.6883\u001b[0m  0.0207\n",
      "     42        0.6918       0.5938        \u001b[35m0.6881\u001b[0m  0.0199\n",
      "     43        0.6896       0.5938        \u001b[35m0.6879\u001b[0m  0.0143\n",
      "     44        0.6890       0.5938        \u001b[35m0.6877\u001b[0m  0.0189\n",
      "     45        0.6914       0.5938        \u001b[35m0.6875\u001b[0m  0.0141\n",
      "     46        0.6903       0.5938        \u001b[35m0.6874\u001b[0m  0.0189\n",
      "     47        0.6918       0.6016        \u001b[35m0.6872\u001b[0m  0.0148\n",
      "     48        \u001b[36m0.6876\u001b[0m       0.5938        \u001b[35m0.6870\u001b[0m  0.0198\n",
      "     49        0.6885       0.5938        \u001b[35m0.6867\u001b[0m  0.0157\n",
      "     50        0.6882       0.6016        \u001b[35m0.6864\u001b[0m  0.0190\n",
      "     51        0.6896       0.6016        \u001b[35m0.6862\u001b[0m  0.0160\n",
      "     52        \u001b[36m0.6856\u001b[0m       0.6016        \u001b[35m0.6858\u001b[0m  0.0184\n",
      "     53        0.6862       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6855\u001b[0m  0.0188\n",
      "     54        0.6894       0.6094        \u001b[35m0.6853\u001b[0m  0.0150\n",
      "     55        0.6862       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6849\u001b[0m  0.0199\n",
      "     56        0.6877       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6847\u001b[0m  0.0149\n",
      "     57        \u001b[36m0.6835\u001b[0m       0.6094        \u001b[35m0.6843\u001b[0m  0.0238\n",
      "     58        0.6867       0.6172        \u001b[35m0.6840\u001b[0m  0.0147\n",
      "     59        0.6850       0.6172        \u001b[35m0.6836\u001b[0m  0.0191\n",
      "     60        0.6874       0.6172        \u001b[35m0.6833\u001b[0m  0.0150\n",
      "     61        \u001b[36m0.6821\u001b[0m       0.6250        \u001b[35m0.6829\u001b[0m  0.0250\n",
      "     62        0.6886       0.6250        \u001b[35m0.6826\u001b[0m  0.0162\n",
      "     63        0.6868       0.6250        \u001b[35m0.6823\u001b[0m  0.0186\n",
      "     64        0.6863       0.6250        \u001b[35m0.6820\u001b[0m  0.0147\n",
      "     65        0.6863       0.6250        \u001b[35m0.6817\u001b[0m  0.0214\n",
      "     66        0.6858       0.6250        \u001b[35m0.6813\u001b[0m  0.0201\n",
      "     67        0.6854       0.6250        \u001b[35m0.6810\u001b[0m  0.0199\n",
      "     68        0.6841       0.6250        \u001b[35m0.6806\u001b[0m  0.0276\n",
      "     69        \u001b[36m0.6807\u001b[0m       0.6250        \u001b[35m0.6801\u001b[0m  0.0179\n",
      "     70        0.6838       0.6250        \u001b[35m0.6797\u001b[0m  0.0242\n",
      "     71        0.6819       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6793\u001b[0m  0.0291\n",
      "     72        \u001b[36m0.6797\u001b[0m       0.6328        \u001b[35m0.6788\u001b[0m  0.0192\n",
      "     73        0.6812       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6784\u001b[0m  0.0303\n",
      "     74        0.6836       0.6484        \u001b[35m0.6780\u001b[0m  0.0203\n",
      "     75        0.6863       0.6484        \u001b[35m0.6777\u001b[0m  0.0197\n",
      "     76        0.6823       0.6484        \u001b[35m0.6772\u001b[0m  0.0197\n",
      "     77        0.6829       0.6484        \u001b[35m0.6767\u001b[0m  0.0245\n",
      "     78        0.6835       0.6484        \u001b[35m0.6763\u001b[0m  0.0162\n",
      "     79        \u001b[36m0.6777\u001b[0m       0.6484        \u001b[35m0.6758\u001b[0m  0.0172\n",
      "     80        0.6794       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6753\u001b[0m  0.0151\n",
      "     81        0.6778       0.6562        \u001b[35m0.6747\u001b[0m  0.0141\n",
      "     82        \u001b[36m0.6750\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6741\u001b[0m  0.0165\n",
      "     83        0.6796       0.6641        \u001b[35m0.6736\u001b[0m  0.0139\n",
      "     84        0.6807       0.6641        \u001b[35m0.6731\u001b[0m  0.0192\n",
      "     85        0.6781       0.6641        \u001b[35m0.6725\u001b[0m  0.0158\n",
      "     86        0.6795       0.6641        \u001b[35m0.6720\u001b[0m  0.0145\n",
      "     87        0.6765       0.6641        \u001b[35m0.6715\u001b[0m  0.0165\n",
      "     88        0.6756       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6708\u001b[0m  0.0159\n",
      "     89        0.6769       0.6719        \u001b[35m0.6703\u001b[0m  0.0137\n",
      "     90        \u001b[36m0.6706\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6696\u001b[0m  0.0164\n",
      "     91        \u001b[36m0.6705\u001b[0m       0.6797        \u001b[35m0.6688\u001b[0m  0.0146\n",
      "     92        0.6750       0.6797        \u001b[35m0.6681\u001b[0m  0.0133\n",
      "     93        0.6760       0.6797        \u001b[35m0.6675\u001b[0m  0.0166\n",
      "     94        0.6733       0.6797        \u001b[35m0.6668\u001b[0m  0.0157\n",
      "     95        0.6735       0.6797        \u001b[35m0.6662\u001b[0m  0.0140\n",
      "     96        0.6717       0.6797        \u001b[35m0.6655\u001b[0m  0.0175\n",
      "     97        \u001b[36m0.6704\u001b[0m       0.6797        \u001b[35m0.6649\u001b[0m  0.0155\n",
      "     98        \u001b[36m0.6691\u001b[0m       0.6797        \u001b[35m0.6641\u001b[0m  0.0129\n",
      "     99        \u001b[36m0.6680\u001b[0m       0.6797        \u001b[35m0.6633\u001b[0m  0.0188\n",
      "    100        \u001b[36m0.6658\u001b[0m       0.6719        \u001b[35m0.6624\u001b[0m  0.0164\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7289\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7158\u001b[0m  0.0184\n",
      "      2        \u001b[36m0.7182\u001b[0m       0.5000        \u001b[35m0.7102\u001b[0m  0.0132\n",
      "      3        \u001b[36m0.7081\u001b[0m       0.5000        \u001b[35m0.7050\u001b[0m  0.0246\n",
      "      4        \u001b[36m0.7046\u001b[0m       0.5000        \u001b[35m0.7002\u001b[0m  0.0157\n",
      "      5        \u001b[36m0.7016\u001b[0m       0.5000        \u001b[35m0.6958\u001b[0m  0.0174\n",
      "      6        \u001b[36m0.7009\u001b[0m       0.5000        \u001b[35m0.6917\u001b[0m  0.0146\n",
      "      7        \u001b[36m0.6918\u001b[0m       0.5000        \u001b[35m0.6880\u001b[0m  0.0227\n",
      "      8        \u001b[36m0.6839\u001b[0m       0.5000        \u001b[35m0.6846\u001b[0m  0.0144\n",
      "      9        0.6867       0.5000        \u001b[35m0.6815\u001b[0m  0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        0.6859       0.5000        \u001b[35m0.6786\u001b[0m  0.0153\n",
      "     11        \u001b[36m0.6786\u001b[0m       0.5000        \u001b[35m0.6758\u001b[0m  0.0193\n",
      "     12        0.6801       0.5000        \u001b[35m0.6732\u001b[0m  0.0136\n",
      "     13        \u001b[36m0.6766\u001b[0m       0.5000        \u001b[35m0.6707\u001b[0m  0.0202\n",
      "     14        \u001b[36m0.6587\u001b[0m       0.5000        \u001b[35m0.6678\u001b[0m  0.0187\n",
      "     15        0.6671       0.5000        \u001b[35m0.6652\u001b[0m  0.0148\n",
      "     16        0.6613       0.5000        \u001b[35m0.6627\u001b[0m  0.0173\n",
      "     17        0.6612       0.5000        \u001b[35m0.6602\u001b[0m  0.0175\n",
      "     18        0.6658       0.5000        \u001b[35m0.6579\u001b[0m  0.0148\n",
      "     19        \u001b[36m0.6567\u001b[0m       0.5000        \u001b[35m0.6556\u001b[0m  0.0191\n",
      "     20        \u001b[36m0.6553\u001b[0m       0.5000        \u001b[35m0.6531\u001b[0m  0.0156\n",
      "     21        0.6590       0.5000        \u001b[35m0.6510\u001b[0m  0.0152\n",
      "     22        0.6603       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6491\u001b[0m  0.0193\n",
      "     23        \u001b[36m0.6497\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6469\u001b[0m  0.0159\n",
      "     24        \u001b[36m0.6454\u001b[0m       0.6094        \u001b[35m0.6446\u001b[0m  0.0147\n",
      "     25        0.6512       0.6094        \u001b[35m0.6426\u001b[0m  0.0193\n",
      "     26        0.6503       0.6094        \u001b[35m0.6408\u001b[0m  0.0180\n",
      "     27        0.6487       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6389\u001b[0m  0.0149\n",
      "     28        \u001b[36m0.6339\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6366\u001b[0m  0.0188\n",
      "     29        0.6417       0.6328        \u001b[35m0.6346\u001b[0m  0.0162\n",
      "     30        0.6398       0.6328        \u001b[35m0.6327\u001b[0m  0.0148\n",
      "     31        0.6420       0.6328        \u001b[35m0.6308\u001b[0m  0.0201\n",
      "     32        0.6409       0.6328        \u001b[35m0.6290\u001b[0m  0.0193\n",
      "     33        0.6390       0.6406        \u001b[35m0.6273\u001b[0m  0.0131\n",
      "     34        0.6379       0.6328        \u001b[35m0.6255\u001b[0m  0.0254\n",
      "     35        \u001b[36m0.6315\u001b[0m       0.6328        \u001b[35m0.6236\u001b[0m  0.0155\n",
      "     36        \u001b[36m0.6204\u001b[0m       0.6484        \u001b[35m0.6216\u001b[0m  0.0156\n",
      "     37        0.6328       0.6484        \u001b[35m0.6199\u001b[0m  0.0187\n",
      "     38        0.6232       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6180\u001b[0m  0.0210\n",
      "     39        0.6255       0.6562        \u001b[35m0.6162\u001b[0m  0.0148\n",
      "     40        0.6295       0.6562        \u001b[35m0.6144\u001b[0m  0.0200\n",
      "     41        0.6334       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6130\u001b[0m  0.0158\n",
      "     42        0.6300       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6116\u001b[0m  0.0190\n",
      "     43        0.6219       0.6719        \u001b[35m0.6099\u001b[0m  0.0198\n",
      "     44        0.6279       0.6641        \u001b[35m0.6084\u001b[0m  0.0150\n",
      "     45        0.6303       0.6719        \u001b[35m0.6068\u001b[0m  0.0184\n",
      "     46        0.6229       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6052\u001b[0m  0.0136\n",
      "     47        0.6268       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6039\u001b[0m  0.0180\n",
      "     48        \u001b[36m0.6194\u001b[0m       0.6875        \u001b[35m0.6023\u001b[0m  0.0177\n",
      "     49        \u001b[36m0.6172\u001b[0m       0.6875        \u001b[35m0.6007\u001b[0m  0.0166\n",
      "     50        \u001b[36m0.6161\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5991\u001b[0m  0.0146\n",
      "     51        \u001b[36m0.6156\u001b[0m       0.6953        \u001b[35m0.5976\u001b[0m  0.0204\n",
      "     52        \u001b[36m0.6135\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5965\u001b[0m  0.0148\n",
      "     53        0.6153       0.7031        \u001b[35m0.5951\u001b[0m  0.0188\n",
      "     54        0.6254       0.7031        \u001b[35m0.5939\u001b[0m  0.0146\n",
      "     55        \u001b[36m0.6064\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5924\u001b[0m  0.0180\n",
      "     56        0.6111       0.7188        \u001b[35m0.5911\u001b[0m  0.0154\n",
      "     57        \u001b[36m0.6060\u001b[0m       0.7188        \u001b[35m0.5896\u001b[0m  0.0196\n",
      "     58        0.6061       0.7188        \u001b[35m0.5883\u001b[0m  0.0144\n",
      "     59        0.6103       0.7188        \u001b[35m0.5872\u001b[0m  0.0196\n",
      "     60        0.6190       0.7188        \u001b[35m0.5860\u001b[0m  0.0138\n",
      "     61        \u001b[36m0.6027\u001b[0m       0.7188        \u001b[35m0.5846\u001b[0m  0.0179\n",
      "     62        \u001b[36m0.5993\u001b[0m       0.7188        \u001b[35m0.5831\u001b[0m  0.0159\n",
      "     63        \u001b[36m0.5906\u001b[0m       0.7188        \u001b[35m0.5818\u001b[0m  0.0240\n",
      "     64        0.6219       0.7188        \u001b[35m0.5810\u001b[0m  0.0157\n",
      "     65        0.5986       0.7188        \u001b[35m0.5796\u001b[0m  0.0184\n",
      "     66        \u001b[36m0.5854\u001b[0m       0.7188        \u001b[35m0.5782\u001b[0m  0.0137\n",
      "     67        0.5941       0.7188        \u001b[35m0.5769\u001b[0m  0.0144\n",
      "     68        0.6003       0.7188        \u001b[35m0.5759\u001b[0m  0.0176\n",
      "     69        0.6037       0.7188        \u001b[35m0.5748\u001b[0m  0.0148\n",
      "     70        0.5958       0.7188        \u001b[35m0.5736\u001b[0m  0.0177\n",
      "     71        0.5966       0.7188        \u001b[35m0.5726\u001b[0m  0.0151\n",
      "     72        0.5902       0.7188        \u001b[35m0.5715\u001b[0m  0.0186\n",
      "     73        0.5890       0.7188        \u001b[35m0.5704\u001b[0m  0.0167\n",
      "     74        0.5991       0.7188        \u001b[35m0.5695\u001b[0m  0.0144\n",
      "     75        0.5915       0.7188        \u001b[35m0.5686\u001b[0m  0.0168\n",
      "     76        0.5865       0.7188        \u001b[35m0.5675\u001b[0m  0.0167\n",
      "     77        0.5893       0.7188        \u001b[35m0.5666\u001b[0m  0.0149\n",
      "     78        \u001b[36m0.5835\u001b[0m       0.7188        \u001b[35m0.5655\u001b[0m  0.0172\n",
      "     79        \u001b[36m0.5717\u001b[0m       0.7188        \u001b[35m0.5642\u001b[0m  0.0204\n",
      "     80        0.5877       0.7188        \u001b[35m0.5634\u001b[0m  0.0153\n",
      "     81        0.5875       0.7188        \u001b[35m0.5624\u001b[0m  0.0148\n",
      "     82        0.6012       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5617\u001b[0m  0.0227\n",
      "     83        0.5864       0.7266        \u001b[35m0.5609\u001b[0m  0.0150\n",
      "     84        0.5971       0.7188        \u001b[35m0.5602\u001b[0m  0.0160\n",
      "     85        0.5978       0.7266        \u001b[35m0.5597\u001b[0m  0.0201\n",
      "     86        0.5842       0.7266        \u001b[35m0.5589\u001b[0m  0.0219\n",
      "     87        0.5724       0.7266        \u001b[35m0.5580\u001b[0m  0.0152\n",
      "     88        0.5838       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5575\u001b[0m  0.0144\n",
      "     89        0.5909       0.7344        \u001b[35m0.5570\u001b[0m  0.0210\n",
      "     90        0.5747       0.7344        \u001b[35m0.5562\u001b[0m  0.0171\n",
      "     91        0.5925       0.7344        \u001b[35m0.5558\u001b[0m  0.0132\n",
      "     92        0.5939       0.7344        \u001b[35m0.5553\u001b[0m  0.0176\n",
      "     93        0.5757       0.7344        \u001b[35m0.5544\u001b[0m  0.0160\n",
      "     94        0.5995       0.7344        \u001b[35m0.5540\u001b[0m  0.0151\n",
      "     95        0.5770       0.7344        \u001b[35m0.5533\u001b[0m  0.0150\n",
      "     96        0.5838       0.7344        \u001b[35m0.5528\u001b[0m  0.0228\n",
      "     97        \u001b[36m0.5709\u001b[0m       0.7344        \u001b[35m0.5522\u001b[0m  0.0176\n",
      "     98        0.5848       0.7344        \u001b[35m0.5518\u001b[0m  0.0158\n",
      "     99        0.5848       0.7344        \u001b[35m0.5513\u001b[0m  0.0179\n",
      "    100        0.5805       0.7344        \u001b[35m0.5508\u001b[0m  0.0174\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6783\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6685\u001b[0m  0.0186\n",
      "      2        0.6825       0.5000        \u001b[35m0.6661\u001b[0m  0.0152\n",
      "      3        0.6833       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6637\u001b[0m  0.0140\n",
      "      4        0.6852       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6618\u001b[0m  0.0175\n",
      "      5        \u001b[36m0.6728\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6599\u001b[0m  0.0137\n",
      "      6        \u001b[36m0.6665\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6582\u001b[0m  0.0147\n",
      "      7        0.6712       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6567\u001b[0m  0.0158\n",
      "      8        \u001b[36m0.6623\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6550\u001b[0m  0.0149\n",
      "      9        \u001b[36m0.6544\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6531\u001b[0m  0.0173\n",
      "     10        0.6580       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6515\u001b[0m  0.0152\n",
      "     11        0.6667       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6501\u001b[0m  0.0175\n",
      "     12        \u001b[36m0.6469\u001b[0m       0.6797        \u001b[35m0.6483\u001b[0m  0.0141\n",
      "     13        0.6515       0.6797        \u001b[35m0.6469\u001b[0m  0.0137\n",
      "     14        0.6649       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6458\u001b[0m  0.0139\n",
      "     15        0.6638       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6448\u001b[0m  0.0152\n",
      "     16        0.6507       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6434\u001b[0m  0.0156\n",
      "     17        0.6553       0.7109        \u001b[35m0.6423\u001b[0m  0.0134\n",
      "     18        0.6564       0.7188        \u001b[35m0.6411\u001b[0m  0.0154\n",
      "     19        0.6684       0.7031        \u001b[35m0.6402\u001b[0m  0.0168\n",
      "     20        \u001b[36m0.6425\u001b[0m       0.7031        \u001b[35m0.6390\u001b[0m  0.0132\n",
      "     21        \u001b[36m0.6353\u001b[0m       0.7031        \u001b[35m0.6377\u001b[0m  0.0148\n",
      "     22        0.6413       0.6953        \u001b[35m0.6365\u001b[0m  0.0170\n",
      "     23        0.6380       0.7031        \u001b[35m0.6355\u001b[0m  0.0134\n",
      "     24        0.6364       0.7031        \u001b[35m0.6345\u001b[0m  0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25        0.6546       0.6875        \u001b[35m0.6337\u001b[0m  0.0136\n",
      "     26        0.6376       0.6875        \u001b[35m0.6327\u001b[0m  0.0131\n",
      "     27        0.6367       0.6875        \u001b[35m0.6318\u001b[0m  0.0148\n",
      "     28        \u001b[36m0.6342\u001b[0m       0.6875        \u001b[35m0.6308\u001b[0m  0.0175\n",
      "     29        \u001b[36m0.6288\u001b[0m       0.6875        \u001b[35m0.6298\u001b[0m  0.0150\n",
      "     30        0.6468       0.6953        \u001b[35m0.6291\u001b[0m  0.0169\n",
      "     31        0.6320       0.6953        \u001b[35m0.6283\u001b[0m  0.0147\n",
      "     32        0.6468       0.6875        \u001b[35m0.6277\u001b[0m  0.0195\n",
      "     33        \u001b[36m0.6230\u001b[0m       0.6875        \u001b[35m0.6267\u001b[0m  0.0183\n",
      "     34        0.6323       0.6875        \u001b[35m0.6259\u001b[0m  0.0251\n",
      "     35        0.6429       0.6719        \u001b[35m0.6253\u001b[0m  0.0230\n",
      "     36        0.6322       0.6719        \u001b[35m0.6246\u001b[0m  0.0141\n",
      "     37        \u001b[36m0.6118\u001b[0m       0.6797        \u001b[35m0.6235\u001b[0m  0.0166\n",
      "     38        0.6355       0.6797        \u001b[35m0.6229\u001b[0m  0.0207\n",
      "     39        0.6387       0.6797        \u001b[35m0.6225\u001b[0m  0.0158\n",
      "     40        0.6335       0.6719        \u001b[35m0.6219\u001b[0m  0.0153\n",
      "     41        0.6149       0.6797        \u001b[35m0.6210\u001b[0m  0.0187\n",
      "     42        0.6189       0.6797        \u001b[35m0.6204\u001b[0m  0.0169\n",
      "     43        0.6224       0.6875        \u001b[35m0.6197\u001b[0m  0.0149\n",
      "     44        0.6129       0.6875        \u001b[35m0.6190\u001b[0m  0.0167\n",
      "     45        0.6342       0.6875        \u001b[35m0.6186\u001b[0m  0.0172\n",
      "     46        0.6199       0.6875        \u001b[35m0.6178\u001b[0m  0.0128\n",
      "     47        0.6323       0.6875        \u001b[35m0.6174\u001b[0m  0.0193\n",
      "     48        \u001b[36m0.6071\u001b[0m       0.6875        \u001b[35m0.6168\u001b[0m  0.0150\n",
      "     49        0.6302       0.6875        \u001b[35m0.6162\u001b[0m  0.0206\n",
      "     50        \u001b[36m0.6013\u001b[0m       0.6875        \u001b[35m0.6155\u001b[0m  0.0171\n",
      "     51        0.6158       0.6875        \u001b[35m0.6149\u001b[0m  0.0129\n",
      "     52        0.6168       0.6953        \u001b[35m0.6143\u001b[0m  0.0175\n",
      "     53        0.6245       0.6953        \u001b[35m0.6139\u001b[0m  0.0143\n",
      "     54        0.6109       0.6875        \u001b[35m0.6133\u001b[0m  0.0158\n",
      "     55        0.6257       0.6875        \u001b[35m0.6129\u001b[0m  0.0150\n",
      "     56        0.6174       0.6875        \u001b[35m0.6125\u001b[0m  0.0192\n",
      "     57        0.6271       0.6797        \u001b[35m0.6122\u001b[0m  0.0175\n",
      "     58        0.6072       0.6797        \u001b[35m0.6117\u001b[0m  0.0126\n",
      "     59        0.6174       0.6875        \u001b[35m0.6113\u001b[0m  0.0178\n",
      "     60        0.6199       0.6875        \u001b[35m0.6108\u001b[0m  0.0134\n",
      "     61        0.6170       0.6875        \u001b[35m0.6104\u001b[0m  0.0173\n",
      "     62        0.6043       0.6875        \u001b[35m0.6099\u001b[0m  0.0128\n",
      "     63        0.6092       0.6875        \u001b[35m0.6095\u001b[0m  0.0176\n",
      "     64        0.6048       0.6875        \u001b[35m0.6091\u001b[0m  0.0139\n",
      "     65        \u001b[36m0.5937\u001b[0m       0.6875        \u001b[35m0.6084\u001b[0m  0.0189\n",
      "     66        0.6222       0.6875        \u001b[35m0.6081\u001b[0m  0.0140\n",
      "     67        0.6084       0.6875        \u001b[35m0.6077\u001b[0m  0.0188\n",
      "     68        0.6218       0.6875        \u001b[35m0.6074\u001b[0m  0.0148\n",
      "     69        0.6024       0.6875        \u001b[35m0.6070\u001b[0m  0.0196\n",
      "     70        0.6082       0.6875        \u001b[35m0.6066\u001b[0m  0.0162\n",
      "     71        0.6129       0.6875        \u001b[35m0.6062\u001b[0m  0.0154\n",
      "     72        \u001b[36m0.5911\u001b[0m       0.6875        \u001b[35m0.6058\u001b[0m  0.0147\n",
      "     73        0.6184       0.6875        \u001b[35m0.6055\u001b[0m  0.0185\n",
      "     74        0.6022       0.6875        \u001b[35m0.6052\u001b[0m  0.0168\n",
      "     75        0.5992       0.6875        \u001b[35m0.6049\u001b[0m  0.0187\n",
      "     76        \u001b[36m0.5904\u001b[0m       0.6875        \u001b[35m0.6044\u001b[0m  0.0180\n",
      "     77        0.6090       0.6875        \u001b[35m0.6041\u001b[0m  0.0150\n",
      "     78        0.5972       0.6875        \u001b[35m0.6037\u001b[0m  0.0250\n",
      "     79        0.6091       0.6875        \u001b[35m0.6036\u001b[0m  0.0137\n",
      "     80        0.6046       0.6875        \u001b[35m0.6032\u001b[0m  0.0157\n",
      "     81        \u001b[36m0.5873\u001b[0m       0.6875        \u001b[35m0.6029\u001b[0m  0.0211\n",
      "     82        0.6169       0.6875        0.6029  0.0194\n",
      "     83        0.6045       0.6875        \u001b[35m0.6026\u001b[0m  0.0166\n",
      "     84        0.6172       0.6875        \u001b[35m0.6023\u001b[0m  0.0133\n",
      "     85        0.6083       0.6875        \u001b[35m0.6021\u001b[0m  0.0201\n",
      "     86        0.6149       0.6875        \u001b[35m0.6020\u001b[0m  0.0141\n",
      "     87        0.6231       0.6875        \u001b[35m0.6018\u001b[0m  0.0146\n",
      "     88        0.5996       0.6875        \u001b[35m0.6016\u001b[0m  0.0159\n",
      "     89        0.5941       0.6875        \u001b[35m0.6013\u001b[0m  0.0150\n",
      "     90        0.6102       0.6875        \u001b[35m0.6011\u001b[0m  0.0162\n",
      "     91        0.6031       0.6875        \u001b[35m0.6007\u001b[0m  0.0135\n",
      "     92        \u001b[36m0.5833\u001b[0m       0.6875        \u001b[35m0.6005\u001b[0m  0.0167\n",
      "     93        0.6075       0.6875        \u001b[35m0.6004\u001b[0m  0.0139\n",
      "     94        0.6096       0.6875        \u001b[35m0.6003\u001b[0m  0.0165\n",
      "     95        0.6124       0.6875        \u001b[35m0.5999\u001b[0m  0.0138\n",
      "     96        0.5952       0.6875        \u001b[35m0.5998\u001b[0m  0.0171\n",
      "     97        0.5955       0.6875        \u001b[35m0.5996\u001b[0m  0.0151\n",
      "     98        0.5929       0.6875        \u001b[35m0.5993\u001b[0m  0.0136\n",
      "     99        0.6184       0.6875        \u001b[35m0.5993\u001b[0m  0.0155\n",
      "    100        0.6168       0.6875        \u001b[35m0.5992\u001b[0m  0.0141\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7029\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m0.6973\u001b[0m  0.0150\n",
      "      2        \u001b[36m0.6994\u001b[0m       0.4375        \u001b[35m0.6950\u001b[0m  0.0148\n",
      "      3        0.7004       0.4375        \u001b[35m0.6934\u001b[0m  0.0164\n",
      "      4        \u001b[36m0.6990\u001b[0m       0.4375        \u001b[35m0.6916\u001b[0m  0.0163\n",
      "      5        \u001b[36m0.6912\u001b[0m       0.4062        \u001b[35m0.6906\u001b[0m  0.0345\n",
      "      6        0.6946       \u001b[32m0.4922\u001b[0m        \u001b[35m0.6890\u001b[0m  0.0273\n",
      "      7        \u001b[36m0.6903\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6877\u001b[0m  0.0170\n",
      "      8        \u001b[36m0.6880\u001b[0m       0.5859        \u001b[35m0.6867\u001b[0m  0.0171\n",
      "      9        \u001b[36m0.6850\u001b[0m       0.5781        \u001b[35m0.6855\u001b[0m  0.0171\n",
      "     10        0.6903       0.5781        \u001b[35m0.6847\u001b[0m  0.0143\n",
      "     11        0.6876       0.5625        \u001b[35m0.6835\u001b[0m  0.0280\n",
      "     12        0.6856       0.5625        \u001b[35m0.6826\u001b[0m  0.0164\n",
      "     13        \u001b[36m0.6836\u001b[0m       0.5703        \u001b[35m0.6817\u001b[0m  0.0192\n",
      "     14        \u001b[36m0.6767\u001b[0m       0.5859        \u001b[35m0.6806\u001b[0m  0.0152\n",
      "     15        0.6802       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6797\u001b[0m  0.0132\n",
      "     16        \u001b[36m0.6737\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6786\u001b[0m  0.0212\n",
      "     17        0.6790       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6778\u001b[0m  0.0153\n",
      "     18        \u001b[36m0.6694\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6765\u001b[0m  0.0158\n",
      "     19        0.6757       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6754\u001b[0m  0.0160\n",
      "     20        0.6715       0.6641        \u001b[35m0.6744\u001b[0m  0.0146\n",
      "     21        0.6760       0.6562        \u001b[35m0.6734\u001b[0m  0.0252\n",
      "     22        \u001b[36m0.6677\u001b[0m       0.6484        \u001b[35m0.6722\u001b[0m  0.0154\n",
      "     23        0.6759       0.6484        \u001b[35m0.6713\u001b[0m  0.0151\n",
      "     24        0.6723       0.6406        \u001b[35m0.6704\u001b[0m  0.0175\n",
      "     25        \u001b[36m0.6637\u001b[0m       0.6484        \u001b[35m0.6692\u001b[0m  0.0142\n",
      "     26        0.6673       0.6406        \u001b[35m0.6682\u001b[0m  0.0176\n",
      "     27        \u001b[36m0.6583\u001b[0m       0.6406        \u001b[35m0.6668\u001b[0m  0.0160\n",
      "     28        0.6672       0.6484        \u001b[35m0.6657\u001b[0m  0.0168\n",
      "     29        \u001b[36m0.6549\u001b[0m       0.6484        \u001b[35m0.6642\u001b[0m  0.0185\n",
      "     30        0.6573       0.6484        \u001b[35m0.6630\u001b[0m  0.0155\n",
      "     31        0.6571       0.6484        \u001b[35m0.6618\u001b[0m  0.0125\n",
      "     32        0.6632       0.6484        \u001b[35m0.6607\u001b[0m  0.0159\n",
      "     33        0.6638       0.6484        \u001b[35m0.6597\u001b[0m  0.0177\n",
      "     34        \u001b[36m0.6457\u001b[0m       0.6484        \u001b[35m0.6583\u001b[0m  0.0148\n",
      "     35        0.6488       0.6484        \u001b[35m0.6567\u001b[0m  0.0136\n",
      "     36        0.6577       0.6484        \u001b[35m0.6556\u001b[0m  0.0181\n",
      "     37        0.6521       0.6406        \u001b[35m0.6543\u001b[0m  0.0136\n",
      "     38        0.6478       0.6406        \u001b[35m0.6529\u001b[0m  0.0129\n",
      "     39        \u001b[36m0.6452\u001b[0m       0.6406        \u001b[35m0.6514\u001b[0m  0.0197\n",
      "     40        0.6487       0.6484        \u001b[35m0.6502\u001b[0m  0.0134\n",
      "     41        0.6551       0.6484        \u001b[35m0.6491\u001b[0m  0.0188\n",
      "     42        \u001b[36m0.6366\u001b[0m       0.6562        \u001b[35m0.6477\u001b[0m  0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     43        \u001b[36m0.6328\u001b[0m       0.6562        \u001b[35m0.6459\u001b[0m  0.0153\n",
      "     44        0.6430       0.6562        \u001b[35m0.6446\u001b[0m  0.0152\n",
      "     45        0.6523       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6435\u001b[0m  0.0215\n",
      "     46        0.6396       0.6719        \u001b[35m0.6420\u001b[0m  0.0193\n",
      "     47        \u001b[36m0.6303\u001b[0m       0.6641        \u001b[35m0.6405\u001b[0m  0.0135\n",
      "     48        \u001b[36m0.6218\u001b[0m       0.6719        \u001b[35m0.6387\u001b[0m  0.0175\n",
      "     49        0.6481       0.6719        \u001b[35m0.6378\u001b[0m  0.0175\n",
      "     50        0.6399       0.6719        \u001b[35m0.6366\u001b[0m  0.0153\n",
      "     51        0.6330       0.6641        \u001b[35m0.6351\u001b[0m  0.0154\n",
      "     52        0.6271       0.6641        \u001b[35m0.6336\u001b[0m  0.0151\n",
      "     53        0.6318       0.6641        \u001b[35m0.6324\u001b[0m  0.0169\n",
      "     54        0.6347       0.6641        \u001b[35m0.6313\u001b[0m  0.0171\n",
      "     55        0.6387       0.6641        \u001b[35m0.6300\u001b[0m  0.0213\n",
      "     56        0.6268       0.6641        \u001b[35m0.6286\u001b[0m  0.0179\n",
      "     57        0.6337       0.6641        \u001b[35m0.6273\u001b[0m  0.0128\n",
      "     58        \u001b[36m0.6110\u001b[0m       0.6641        \u001b[35m0.6256\u001b[0m  0.0156\n",
      "     59        0.6285       0.6562        \u001b[35m0.6245\u001b[0m  0.0183\n",
      "     60        0.6305       0.6562        \u001b[35m0.6236\u001b[0m  0.0259\n",
      "     61        0.6164       0.6641        \u001b[35m0.6221\u001b[0m  0.0148\n",
      "     62        0.6187       0.6641        \u001b[35m0.6210\u001b[0m  0.0152\n",
      "     63        0.6441       0.6641        \u001b[35m0.6201\u001b[0m  0.0242\n",
      "     64        0.6209       0.6641        \u001b[35m0.6191\u001b[0m  0.0170\n",
      "     65        \u001b[36m0.6071\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6177\u001b[0m  0.0152\n",
      "     66        0.6254       0.6719        \u001b[35m0.6164\u001b[0m  0.0192\n",
      "     67        0.6216       0.6797        \u001b[35m0.6152\u001b[0m  0.0302\n",
      "     68        0.6100       0.6797        \u001b[35m0.6139\u001b[0m  0.0176\n",
      "     69        0.6232       0.6797        \u001b[35m0.6131\u001b[0m  0.0131\n",
      "     70        \u001b[36m0.6063\u001b[0m       0.6797        \u001b[35m0.6119\u001b[0m  0.0166\n",
      "     71        0.6142       0.6797        \u001b[35m0.6107\u001b[0m  0.0171\n",
      "     72        0.6088       0.6797        \u001b[35m0.6095\u001b[0m  0.0187\n",
      "     73        0.6172       0.6797        \u001b[35m0.6086\u001b[0m  0.0156\n",
      "     74        0.6333       0.6797        \u001b[35m0.6079\u001b[0m  0.0153\n",
      "     75        0.6076       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6069\u001b[0m  0.0436\n",
      "     76        \u001b[36m0.6053\u001b[0m       0.6875        \u001b[35m0.6058\u001b[0m  0.0187\n",
      "     77        0.6347       0.6875        \u001b[35m0.6054\u001b[0m  0.0150\n",
      "     78        0.6249       0.6875        \u001b[35m0.6046\u001b[0m  0.0206\n",
      "     79        0.6210       0.6875        \u001b[35m0.6039\u001b[0m  0.0158\n",
      "     80        0.6166       0.6875        \u001b[35m0.6028\u001b[0m  0.0188\n",
      "     81        0.6142       0.6875        \u001b[35m0.6020\u001b[0m  0.0167\n",
      "     82        0.6365       0.6875        \u001b[35m0.6011\u001b[0m  0.0146\n",
      "     83        0.6126       0.6875        \u001b[35m0.6005\u001b[0m  0.0204\n",
      "     84        0.6061       0.6875        \u001b[35m0.5994\u001b[0m  0.0157\n",
      "     85        0.6241       0.6875        \u001b[35m0.5989\u001b[0m  0.0134\n",
      "     86        \u001b[36m0.6021\u001b[0m       0.6875        \u001b[35m0.5979\u001b[0m  0.0268\n",
      "     87        0.6145       0.6875        \u001b[35m0.5972\u001b[0m  0.0326\n",
      "     88        0.6044       0.6875        \u001b[35m0.5963\u001b[0m  0.0514\n",
      "     89        0.6234       0.6797        \u001b[35m0.5959\u001b[0m  0.0203\n",
      "     90        \u001b[36m0.5987\u001b[0m       0.6797        \u001b[35m0.5949\u001b[0m  0.0211\n",
      "     91        0.6013       0.6797        \u001b[35m0.5941\u001b[0m  0.0174\n",
      "     92        0.6054       0.6797        \u001b[35m0.5930\u001b[0m  0.0150\n",
      "     93        \u001b[36m0.5942\u001b[0m       0.6797        \u001b[35m0.5920\u001b[0m  0.0258\n",
      "     94        \u001b[36m0.5862\u001b[0m       0.6797        \u001b[35m0.5911\u001b[0m  0.0202\n",
      "     95        0.6139       0.6797        \u001b[35m0.5906\u001b[0m  0.0145\n",
      "     96        0.6135       0.6797        \u001b[35m0.5902\u001b[0m  0.0327\n",
      "     97        0.5940       0.6797        \u001b[35m0.5893\u001b[0m  0.0161\n",
      "     98        0.5939       0.6797        \u001b[35m0.5884\u001b[0m  0.0144\n",
      "     99        0.5945       0.6797        \u001b[35m0.5878\u001b[0m  0.0163\n",
      "    100        0.6026       0.6797        \u001b[35m0.5869\u001b[0m  0.0415\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7420\u001b[0m       \u001b[32m0.4297\u001b[0m        \u001b[35m0.7264\u001b[0m  0.0415\n",
      "      2        \u001b[36m0.7066\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6840\u001b[0m  0.0351\n",
      "      3        \u001b[36m0.6720\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6520\u001b[0m  0.0411\n",
      "      4        \u001b[36m0.6427\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6229\u001b[0m  0.0381\n",
      "      5        \u001b[36m0.6363\u001b[0m       0.6641        \u001b[35m0.5995\u001b[0m  0.0586\n",
      "      6        \u001b[36m0.6165\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5770\u001b[0m  0.0348\n",
      "      7        \u001b[36m0.5848\u001b[0m       0.7031        \u001b[35m0.5535\u001b[0m  0.0366\n",
      "      8        0.5891       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5339\u001b[0m  0.0461\n",
      "      9        \u001b[36m0.5725\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5168\u001b[0m  0.0363\n",
      "     10        \u001b[36m0.5591\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5026\u001b[0m  0.0363\n",
      "     11        \u001b[36m0.5490\u001b[0m       0.7578        \u001b[35m0.4891\u001b[0m  0.0517\n",
      "     12        \u001b[36m0.5488\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4782\u001b[0m  0.0374\n",
      "     13        \u001b[36m0.5366\u001b[0m       0.7734        \u001b[35m0.4685\u001b[0m  0.0373\n",
      "     14        \u001b[36m0.5305\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4599\u001b[0m  0.0367\n",
      "     15        0.5317       0.7812        \u001b[35m0.4529\u001b[0m  0.0635\n",
      "     16        \u001b[36m0.5207\u001b[0m       0.7734        \u001b[35m0.4454\u001b[0m  0.0355\n",
      "     17        0.5216       0.7812        \u001b[35m0.4411\u001b[0m  0.0411\n",
      "     18        \u001b[36m0.5173\u001b[0m       0.7812        \u001b[35m0.4373\u001b[0m  0.0384\n",
      "     19        \u001b[36m0.5044\u001b[0m       0.7812        \u001b[35m0.4317\u001b[0m  0.0432\n",
      "     20        0.5271       0.7812        \u001b[35m0.4298\u001b[0m  0.0367\n",
      "     21        \u001b[36m0.4995\u001b[0m       0.7812        \u001b[35m0.4256\u001b[0m  0.0393\n",
      "     22        0.5099       0.7812        \u001b[35m0.4231\u001b[0m  0.0384\n",
      "     23        0.5120       0.7812        \u001b[35m0.4222\u001b[0m  0.0460\n",
      "     24        0.5014       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4199\u001b[0m  0.0384\n",
      "     25        \u001b[36m0.4918\u001b[0m       0.7812        \u001b[35m0.4164\u001b[0m  0.0343\n",
      "     26        \u001b[36m0.4890\u001b[0m       0.7812        \u001b[35m0.4135\u001b[0m  0.0526\n",
      "     27        \u001b[36m0.4846\u001b[0m       0.7812        \u001b[35m0.4097\u001b[0m  0.0349\n",
      "     28        0.5045       0.7891        \u001b[35m0.4082\u001b[0m  0.0368\n",
      "     29        0.5006       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4066\u001b[0m  0.0482\n",
      "     30        0.5022       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4047\u001b[0m  0.0447\n",
      "     31        0.4884       0.7812        \u001b[35m0.4043\u001b[0m  0.0710\n",
      "     32        0.4912       0.7812        \u001b[35m0.4032\u001b[0m  0.0481\n",
      "     33        0.4922       0.8047        \u001b[35m0.4020\u001b[0m  0.0419\n",
      "     34        0.4961       0.7969        \u001b[35m0.4020\u001b[0m  0.0380\n",
      "     35        0.4902       0.8047        \u001b[35m0.4003\u001b[0m  0.0368\n",
      "     36        0.4919       0.8047        \u001b[35m0.3977\u001b[0m  0.0428\n",
      "     37        \u001b[36m0.4724\u001b[0m       0.8047        \u001b[35m0.3955\u001b[0m  0.0392\n",
      "     38        0.5066       \u001b[32m0.8125\u001b[0m        \u001b[35m0.3954\u001b[0m  0.0417\n",
      "     39        0.4817       0.8125        \u001b[35m0.3941\u001b[0m  0.0390\n",
      "     40        0.4847       \u001b[32m0.8203\u001b[0m        \u001b[35m0.3932\u001b[0m  0.0440\n",
      "     41        0.4954       0.8203        \u001b[35m0.3928\u001b[0m  0.0418\n",
      "     42        0.4891       0.8203        0.3930  0.0372\n",
      "     43        0.4820       0.8203        \u001b[35m0.3905\u001b[0m  0.0368\n",
      "     44        \u001b[36m0.4700\u001b[0m       0.8203        \u001b[35m0.3883\u001b[0m  0.0342\n",
      "     45        0.4762       0.8203        \u001b[35m0.3882\u001b[0m  0.0348\n",
      "     46        0.4936       0.8203        0.3892  0.0347\n",
      "     47        0.4866       0.8203        0.3890  0.0495\n",
      "     48        0.4781       0.8203        \u001b[35m0.3881\u001b[0m  0.0734\n",
      "     49        0.4759       0.8203        \u001b[35m0.3873\u001b[0m  0.0801\n",
      "     50        0.4828       0.8203        \u001b[35m0.3859\u001b[0m  0.0759\n",
      "     51        0.4786       0.8203        \u001b[35m0.3854\u001b[0m  0.0673\n",
      "     52        0.4786       0.8203        0.3860  0.0419\n",
      "     53        0.4802       0.8203        0.3857  0.0368\n",
      "     54        0.4813       0.8203        0.3854  0.0392\n",
      "     55        0.4716       0.8203        \u001b[35m0.3848\u001b[0m  0.0354\n",
      "     56        0.4756       0.8203        0.3855  0.0711\n",
      "     57        0.4859       0.8203        0.3848  0.0695\n",
      "     58        0.4761       0.8203        0.3854  0.0741\n",
      "     59        0.4816       0.8203        0.3858  0.0703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     60        \u001b[36m0.4618\u001b[0m       0.8203        \u001b[35m0.3840\u001b[0m  0.0573\n",
      "     61        \u001b[36m0.4578\u001b[0m       0.8203        \u001b[35m0.3829\u001b[0m  0.0535\n",
      "     62        0.4697       0.8203        \u001b[35m0.3828\u001b[0m  0.0565\n",
      "     63        0.4843       0.8203        \u001b[35m0.3828\u001b[0m  0.0652\n",
      "     64        0.4806       0.8125        \u001b[35m0.3820\u001b[0m  0.0374\n",
      "     65        0.4715       0.8125        \u001b[35m0.3811\u001b[0m  0.0557\n",
      "     66        0.4800       0.8125        \u001b[35m0.3808\u001b[0m  0.0664\n",
      "     67        0.4962       0.8125        0.3817  0.0596\n",
      "     68        0.4817       0.8125        0.3817  0.0604\n",
      "     69        0.4771       0.8125        0.3814  0.0837\n",
      "     70        \u001b[36m0.4574\u001b[0m       0.8125        \u001b[35m0.3807\u001b[0m  0.0509\n",
      "     71        0.4703       0.8125        \u001b[35m0.3807\u001b[0m  0.0573\n",
      "     72        0.4753       0.8125        \u001b[35m0.3802\u001b[0m  0.0593\n",
      "     73        0.4793       0.8125        \u001b[35m0.3800\u001b[0m  0.0439\n",
      "     74        0.4701       0.8125        \u001b[35m0.3788\u001b[0m  0.0368\n",
      "     75        0.4703       0.8203        0.3794  0.0354\n",
      "     76        0.4617       0.8125        0.3793  0.0427\n",
      "     77        0.4618       0.8125        \u001b[35m0.3781\u001b[0m  0.0359\n",
      "     78        0.4764       0.8125        \u001b[35m0.3763\u001b[0m  0.0695\n",
      "     79        0.4624       0.8125        0.3766  0.0604\n",
      "     80        0.4742       0.8125        0.3786  0.0582\n",
      "     81        0.4723       0.8125        0.3774  0.0575\n",
      "     82        0.4691       0.8125        0.3776  0.0371\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6775\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6290\u001b[0m  0.0322\n",
      "      2        \u001b[36m0.6402\u001b[0m       0.7031        \u001b[35m0.6027\u001b[0m  0.0419\n",
      "      3        \u001b[36m0.6190\u001b[0m       0.6953        \u001b[35m0.5826\u001b[0m  0.0472\n",
      "      4        \u001b[36m0.5936\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5669\u001b[0m  0.0386\n",
      "      5        \u001b[36m0.5767\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5564\u001b[0m  0.0378\n",
      "      6        \u001b[36m0.5563\u001b[0m       0.7188        \u001b[35m0.5473\u001b[0m  0.0413\n",
      "      7        \u001b[36m0.5558\u001b[0m       0.7109        \u001b[35m0.5421\u001b[0m  0.0371\n",
      "      8        0.5563       0.7109        \u001b[35m0.5386\u001b[0m  0.0387\n",
      "      9        \u001b[36m0.5400\u001b[0m       0.7109        \u001b[35m0.5362\u001b[0m  0.0417\n",
      "     10        0.5413       0.7188        \u001b[35m0.5341\u001b[0m  0.0365\n",
      "     11        \u001b[36m0.5228\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5327\u001b[0m  0.0620\n",
      "     12        0.5314       0.7266        \u001b[35m0.5317\u001b[0m  0.0644\n",
      "     13        \u001b[36m0.5208\u001b[0m       0.7266        \u001b[35m0.5311\u001b[0m  0.0576\n",
      "     14        \u001b[36m0.5198\u001b[0m       0.7188        \u001b[35m0.5300\u001b[0m  0.0584\n",
      "     15        0.5240       0.7266        \u001b[35m0.5293\u001b[0m  0.0553\n",
      "     16        0.5301       0.7188        \u001b[35m0.5289\u001b[0m  0.0564\n",
      "     17        0.5263       0.7266        0.5292  0.0559\n",
      "     18        0.5202       0.7266        0.5297  0.0468\n",
      "     19        0.5232       0.7188        0.5292  0.0582\n",
      "     20        \u001b[36m0.5093\u001b[0m       0.7109        0.5292  0.0701\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7089\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6633\u001b[0m  0.0391\n",
      "      2        \u001b[36m0.6484\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6183\u001b[0m  0.0494\n",
      "      3        \u001b[36m0.6047\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5902\u001b[0m  0.0526\n",
      "      4        \u001b[36m0.5857\u001b[0m       0.7031        \u001b[35m0.5685\u001b[0m  0.0517\n",
      "      5        \u001b[36m0.5612\u001b[0m       0.7109        \u001b[35m0.5544\u001b[0m  0.0365\n",
      "      6        \u001b[36m0.5571\u001b[0m       0.7266        \u001b[35m0.5449\u001b[0m  0.0486\n",
      "      7        \u001b[36m0.5493\u001b[0m       0.7266        \u001b[35m0.5393\u001b[0m  0.0621\n",
      "      8        \u001b[36m0.5252\u001b[0m       0.7266        \u001b[35m0.5349\u001b[0m  0.0574\n",
      "      9        \u001b[36m0.5173\u001b[0m       0.7266        \u001b[35m0.5325\u001b[0m  0.0400\n",
      "     10        \u001b[36m0.5137\u001b[0m       0.7109        \u001b[35m0.5300\u001b[0m  0.0371\n",
      "     11        \u001b[36m0.5015\u001b[0m       0.7109        \u001b[35m0.5289\u001b[0m  0.0435\n",
      "     12        0.5195       0.7109        \u001b[35m0.5280\u001b[0m  0.0351\n",
      "     13        0.5103       0.7109        0.5281  0.0441\n",
      "     14        0.5077       0.7109        0.5282  0.0454\n",
      "     15        \u001b[36m0.4953\u001b[0m       0.7109        \u001b[35m0.5278\u001b[0m  0.0397\n",
      "     16        \u001b[36m0.4816\u001b[0m       0.7109        \u001b[35m0.5273\u001b[0m  0.0361\n",
      "     17        0.4831       0.7188        0.5282  0.0365\n",
      "     18        0.4973       0.7109        0.5298  0.0379\n",
      "     19        0.4873       0.7266        0.5293  0.0419\n",
      "     20        0.4837       0.7188        0.5303  0.0474\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6461\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6266\u001b[0m  0.0347\n",
      "      2        \u001b[36m0.6250\u001b[0m       0.7109        \u001b[35m0.6036\u001b[0m  0.0411\n",
      "      3        \u001b[36m0.5893\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5808\u001b[0m  0.0347\n",
      "      4        \u001b[36m0.5693\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5638\u001b[0m  0.0411\n",
      "      5        \u001b[36m0.5496\u001b[0m       0.7266        \u001b[35m0.5519\u001b[0m  0.0372\n",
      "      6        0.5517       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5441\u001b[0m  0.0672\n",
      "      7        \u001b[36m0.5336\u001b[0m       0.7344        \u001b[35m0.5383\u001b[0m  0.0551\n",
      "      8        \u001b[36m0.5250\u001b[0m       0.7344        \u001b[35m0.5337\u001b[0m  0.0400\n",
      "      9        0.5296       0.7344        \u001b[35m0.5311\u001b[0m  0.0581\n",
      "     10        \u001b[36m0.5147\u001b[0m       0.7344        \u001b[35m0.5285\u001b[0m  0.0366\n",
      "     11        0.5156       0.7344        \u001b[35m0.5260\u001b[0m  0.0345\n",
      "     12        \u001b[36m0.5064\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5242\u001b[0m  0.0417\n",
      "     13        0.5112       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5223\u001b[0m  0.0347\n",
      "     14        0.5166       0.7500        \u001b[35m0.5210\u001b[0m  0.0450\n",
      "     15        \u001b[36m0.4892\u001b[0m       0.7500        \u001b[35m0.5202\u001b[0m  0.0566\n",
      "     16        0.5029       0.7344        \u001b[35m0.5196\u001b[0m  0.0379\n",
      "     17        0.5005       0.7344        \u001b[35m0.5191\u001b[0m  0.0359\n",
      "     18        0.5067       0.7344        \u001b[35m0.5184\u001b[0m  0.0389\n",
      "     19        \u001b[36m0.4804\u001b[0m       0.7344        \u001b[35m0.5178\u001b[0m  0.0360\n",
      "     20        0.4885       0.7266        \u001b[35m0.5175\u001b[0m  0.0383\n",
      "     21        0.5002       0.7266        \u001b[35m0.5175\u001b[0m  0.0437\n",
      "     22        0.4894       0.7266        \u001b[35m0.5174\u001b[0m  0.0377\n",
      "     23        0.4861       0.7344        \u001b[35m0.5172\u001b[0m  0.0358\n",
      "     24        0.4841       0.7344        0.5177  0.0357\n",
      "     25        0.4828       0.7266        0.5193  0.0378\n",
      "     26        0.4969       0.7266        0.5193  0.0374\n",
      "     27        \u001b[36m0.4792\u001b[0m       0.7266        0.5200  0.0357\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7691\u001b[0m       \u001b[32m0.4453\u001b[0m        \u001b[35m0.7161\u001b[0m  0.0696\n",
      "      2        \u001b[36m0.6977\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6746\u001b[0m  0.0674\n",
      "      3        \u001b[36m0.6623\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6418\u001b[0m  0.0653\n",
      "      4        \u001b[36m0.6294\u001b[0m       0.7031        \u001b[35m0.6147\u001b[0m  0.0596\n",
      "      5        \u001b[36m0.5970\u001b[0m       0.7031        \u001b[35m0.5925\u001b[0m  0.0463\n",
      "      6        \u001b[36m0.5789\u001b[0m       0.7031        \u001b[35m0.5766\u001b[0m  0.0486\n",
      "      7        \u001b[36m0.5446\u001b[0m       0.7031        \u001b[35m0.5641\u001b[0m  0.0423\n",
      "      8        \u001b[36m0.5337\u001b[0m       0.7031        \u001b[35m0.5574\u001b[0m  0.0377\n",
      "      9        \u001b[36m0.5245\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5533\u001b[0m  0.0387\n",
      "     10        \u001b[36m0.5125\u001b[0m       0.7109        \u001b[35m0.5505\u001b[0m  0.0484\n",
      "     11        \u001b[36m0.5111\u001b[0m       0.7109        0.5506  0.0439\n",
      "     12        0.5116       0.7031        0.5507  0.0467\n",
      "     13        \u001b[36m0.4919\u001b[0m       0.7031        0.5512  0.0387\n",
      "     14        0.5049       0.7031        0.5514  0.0347\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6668\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5866\u001b[0m  0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.6249\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5281\u001b[0m  0.0139\n",
      "      3        \u001b[36m0.5889\u001b[0m       0.7578        \u001b[35m0.4926\u001b[0m  0.0138\n",
      "      4        \u001b[36m0.5699\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4786\u001b[0m  0.0143\n",
      "      5        0.5711       0.7734        0.5264  0.0144\n",
      "      6        0.5863       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4728\u001b[0m  0.0193\n",
      "      7        \u001b[36m0.5669\u001b[0m       0.7812        \u001b[35m0.4516\u001b[0m  0.0285\n",
      "      8        0.5733       0.7969        0.4700  0.0165\n",
      "      9        \u001b[36m0.5535\u001b[0m       0.7578        0.4582  0.0299\n",
      "     10        0.5675       0.7891        0.4668  0.0205\n",
      "     11        0.5584       0.7734        \u001b[35m0.4376\u001b[0m  0.0216\n",
      "     12        0.5537       0.7969        0.4492  0.0226\n",
      "     13        \u001b[36m0.5488\u001b[0m       0.7891        \u001b[35m0.4342\u001b[0m  0.0146\n",
      "     14        0.5771       0.7812        0.4409  0.0159\n",
      "     15        \u001b[36m0.5448\u001b[0m       0.7891        \u001b[35m0.4294\u001b[0m  0.0242\n",
      "     16        \u001b[36m0.5356\u001b[0m       0.7891        \u001b[35m0.4210\u001b[0m  0.0260\n",
      "     17        0.5586       0.7812        0.4611  0.0255\n",
      "     18        0.5430       0.7891        0.4456  0.0178\n",
      "     19        0.5687       0.7734        0.4487  0.0163\n",
      "     20        0.5540       0.7734        0.4246  0.0209\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6614\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5525\u001b[0m  0.0153\n",
      "      2        \u001b[36m0.5908\u001b[0m       0.7266        \u001b[35m0.5429\u001b[0m  0.0158\n",
      "      3        0.5943       0.7031        0.5457  0.0203\n",
      "      4        \u001b[36m0.5723\u001b[0m       0.7031        \u001b[35m0.5319\u001b[0m  0.0207\n",
      "      5        0.5734       0.7109        \u001b[35m0.5259\u001b[0m  0.0157\n",
      "      6        \u001b[36m0.5721\u001b[0m       0.7266        0.5315  0.0283\n",
      "      7        \u001b[36m0.5685\u001b[0m       0.7031        0.5278  0.0239\n",
      "      8        \u001b[36m0.5655\u001b[0m       0.7188        \u001b[35m0.5153\u001b[0m  0.0170\n",
      "      9        \u001b[36m0.5403\u001b[0m       0.7266        0.5196  0.0175\n",
      "     10        0.5766       0.7266        0.5371  0.0226\n",
      "     11        0.5603       0.6797        0.5348  0.0216\n",
      "     12        0.5491       \u001b[32m0.7422\u001b[0m        0.5267  0.0161\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6440\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5383\u001b[0m  0.0201\n",
      "      2        \u001b[36m0.5641\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5312\u001b[0m  0.0263\n",
      "      3        \u001b[36m0.5386\u001b[0m       0.7344        \u001b[35m0.5077\u001b[0m  0.0462\n",
      "      4        0.5783       0.7500        0.5356  0.0296\n",
      "      5        0.5572       0.7344        0.5177  0.0237\n",
      "      6        0.5543       0.7188        0.5268  0.0158\n",
      "      7        0.5504       0.7422        0.5192  0.0269\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5991\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5312\u001b[0m  0.0151\n",
      "      2        \u001b[36m0.5573\u001b[0m       \u001b[32m0.7656\u001b[0m        0.5469  0.0172\n",
      "      3        \u001b[36m0.5412\u001b[0m       0.7344        \u001b[35m0.5283\u001b[0m  0.0176\n",
      "      4        0.5497       0.7344        0.5319  0.0224\n",
      "      5        0.5567       0.6875        0.5636  0.0190\n",
      "      6        \u001b[36m0.5358\u001b[0m       0.7266        0.5468  0.0201\n",
      "      7        0.5473       0.7344        \u001b[35m0.5275\u001b[0m  0.0182\n",
      "      8        0.5395       0.7422        \u001b[35m0.5274\u001b[0m  0.0164\n",
      "      9        0.5467       0.7344        0.5358  0.0240\n",
      "     10        \u001b[36m0.5348\u001b[0m       0.7344        0.5358  0.0167\n",
      "     11        0.5412       0.7422        0.5330  0.0139\n",
      "     12        0.5511       0.7344        \u001b[35m0.5262\u001b[0m  0.0178\n",
      "     13        0.5733       0.7031        0.5534  0.0143\n",
      "     14        \u001b[36m0.5239\u001b[0m       0.7344        0.5341  0.0166\n",
      "     15        0.5428       0.7188        0.5310  0.0195\n",
      "     16        \u001b[36m0.5186\u001b[0m       0.7188        0.5546  0.0226\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5986\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5871\u001b[0m  0.0394\n",
      "      2        \u001b[36m0.5746\u001b[0m       0.6797        \u001b[35m0.5551\u001b[0m  0.0235\n",
      "      3        \u001b[36m0.5552\u001b[0m       0.6875        \u001b[35m0.5497\u001b[0m  0.0167\n",
      "      4        \u001b[36m0.5407\u001b[0m       0.6875        0.5511  0.0191\n",
      "      5        \u001b[36m0.5163\u001b[0m       0.7109        \u001b[35m0.5327\u001b[0m  0.0156\n",
      "      6        0.5358       \u001b[32m0.7500\u001b[0m        0.5368  0.0232\n",
      "      7        \u001b[36m0.5163\u001b[0m       0.7031        0.5407  0.0159\n",
      "      8        0.5516       0.7031        \u001b[35m0.5263\u001b[0m  0.0184\n",
      "      9        0.5343       0.6875        \u001b[35m0.5241\u001b[0m  0.0155\n",
      "     10        0.5405       0.6719        \u001b[35m0.5213\u001b[0m  0.0223\n",
      "     11        0.5203       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5172\u001b[0m  0.0174\n",
      "     12        \u001b[36m0.5082\u001b[0m       0.7344        0.5231  0.0310\n",
      "     13        0.5244       0.7422        \u001b[35m0.5136\u001b[0m  0.0177\n",
      "     14        0.5309       0.7344        0.5232  0.0175\n",
      "     15        0.5184       0.6953        0.5301  0.0232\n",
      "     16        0.5291       0.7344        0.5321  0.0174\n",
      "     17        0.5097       0.7344        0.5394  0.0239\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6305\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6490\u001b[0m  0.0427\n",
      "      2        \u001b[36m0.6001\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4201\u001b[0m  0.0412\n",
      "      3        \u001b[36m0.5956\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.3992\u001b[0m  0.0494\n",
      "      4        \u001b[36m0.5745\u001b[0m       0.7734        0.4327  0.0341\n",
      "      5        \u001b[36m0.5742\u001b[0m       0.7500        0.5497  0.0403\n",
      "      6        0.5854       0.7656        0.4707  0.0351\n",
      "      7        0.5766       0.7734        0.5140  0.0410\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6742\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.5589\u001b[0m  0.0316\n",
      "      2        \u001b[36m0.5726\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5522\u001b[0m  0.0360\n",
      "      3        \u001b[36m0.5560\u001b[0m       \u001b[32m0.7422\u001b[0m        0.6194  0.0426\n",
      "      4        0.5864       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5245\u001b[0m  0.0346\n",
      "      5        0.5613       0.7500        0.5263  0.0376\n",
      "      6        0.5657       0.7578        \u001b[35m0.5161\u001b[0m  0.0375\n",
      "      7        \u001b[36m0.5140\u001b[0m       0.7734        \u001b[35m0.4977\u001b[0m  0.0352\n",
      "      8        0.5167       0.7344        0.5359  0.0447\n",
      "      9        0.5245       0.7500        0.5357  0.0716\n",
      "     10        0.5478       0.6953        0.5827  0.0647\n",
      "     11        0.5534       0.7109        0.5344  0.0478\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6864\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5500\u001b[0m  0.0313\n",
      "      2        \u001b[36m0.6205\u001b[0m       \u001b[32m0.7422\u001b[0m        0.6201  0.0338\n",
      "      3        0.6461       0.6875        0.5610  0.0387\n",
      "      4        \u001b[36m0.5797\u001b[0m       0.6562        0.5727  0.0411\n",
      "      5        0.5967       0.7031        \u001b[35m0.5485\u001b[0m  0.0387\n",
      "      6        \u001b[36m0.5530\u001b[0m       0.7422        0.6142  0.0411\n",
      "      7        \u001b[36m0.5521\u001b[0m       0.7344        \u001b[35m0.5303\u001b[0m  0.0395\n",
      "      8        \u001b[36m0.5490\u001b[0m       0.6797        0.8174  0.0419\n",
      "      9        \u001b[36m0.5408\u001b[0m       \u001b[32m0.7656\u001b[0m        0.5696  0.0430\n",
      "     10        \u001b[36m0.5351\u001b[0m       0.7031        0.5511  0.0423\n",
      "     11        0.5589       0.7578        0.5414  0.0354\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6031\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5576\u001b[0m  0.0341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.6024\u001b[0m       0.6797        0.6064  0.0464\n",
      "      3        \u001b[36m0.5328\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5456\u001b[0m  0.0398\n",
      "      4        0.5424       0.7266        0.5837  0.0344\n",
      "      5        \u001b[36m0.5123\u001b[0m       0.7266        0.5939  0.0391\n",
      "      6        0.5547       0.5000        0.8505  0.0388\n",
      "      7        0.5209       0.6875        0.7339  0.0340\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5978\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6633\u001b[0m  0.0337\n",
      "      2        \u001b[36m0.5359\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5490\u001b[0m  0.0398\n",
      "      3        \u001b[36m0.5307\u001b[0m       0.5703        0.7007  0.0463\n",
      "      4        \u001b[36m0.5247\u001b[0m       0.6953        0.5538  0.0437\n",
      "      5        0.5472       0.6406        0.6471  0.0372\n",
      "      6        0.5260       0.7422        0.5632  0.0421\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.2089\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m2.9952\u001b[0m  0.0322\n",
      "      2        2.3026       0.6094        4.7155  0.0505\n",
      "      3        3.6232       0.5547        5.0969  0.0415\n",
      "      4        3.5929       0.5469        5.2090  0.0393\n",
      "      5        3.6919       0.6406        3.6285  0.0408\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8375\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m1.5877\u001b[0m  0.0331\n",
      "      2        1.0188       \u001b[32m0.6562\u001b[0m        \u001b[35m1.2591\u001b[0m  0.0435\n",
      "      3        1.0303       \u001b[32m0.6797\u001b[0m        1.3696  0.0367\n",
      "      4        \u001b[36m0.7324\u001b[0m       0.6094        \u001b[35m0.7594\u001b[0m  0.0398\n",
      "      5        0.9268       0.5156        1.5960  0.0367\n",
      "      6        1.0197       0.6562        1.5272  0.0351\n",
      "      7        0.7485       \u001b[32m0.7109\u001b[0m        \u001b[35m0.7416\u001b[0m  0.0398\n",
      "      8        0.8036       0.5000        \u001b[35m0.6549\u001b[0m  0.0335\n",
      "      9        0.8560       0.5547        \u001b[35m0.6538\u001b[0m  0.0519\n",
      "     10        0.7805       0.5547        0.7214  0.0354\n",
      "     11        0.7958       0.5000        0.7146  0.0365\n",
      "     12        0.8133       0.5547        0.7486  0.0397\n",
      "     13        0.8491       0.5000        0.7167  0.0332\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0760\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m2.2017\u001b[0m  0.0309\n",
      "      2        1.5848       \u001b[32m0.7266\u001b[0m        \u001b[35m1.3542\u001b[0m  0.0421\n",
      "      3        1.2639       \u001b[32m0.7500\u001b[0m        \u001b[35m1.1394\u001b[0m  0.0352\n",
      "      4        1.1392       0.7500        \u001b[35m1.0446\u001b[0m  0.0379\n",
      "      5        1.2760       0.7500        \u001b[35m1.0402\u001b[0m  0.0450\n",
      "      6        1.3864       0.5000        1.4057  0.0385\n",
      "      7        1.2705       0.5000        1.3563  0.0412\n",
      "      8        1.2682       0.7500        \u001b[35m1.0243\u001b[0m  0.0444\n",
      "      9        1.2791       0.7500        1.0444  0.0376\n",
      "     10        1.3154       0.7500        1.0581  0.0463\n",
      "     11        1.3344       0.5000        1.1913  0.0346\n",
      "     12        1.3645       0.5000        1.5186  0.0401\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.2478\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m2.5772\u001b[0m  0.0315\n",
      "      2        1.8174       \u001b[32m0.6094\u001b[0m        \u001b[35m1.5393\u001b[0m  0.0476\n",
      "      3        1.2794       0.6094        \u001b[35m1.2458\u001b[0m  0.0380\n",
      "      4        \u001b[36m1.0425\u001b[0m       0.5781        \u001b[35m0.9195\u001b[0m  0.0392\n",
      "      5        \u001b[36m0.7958\u001b[0m       0.6094        \u001b[35m0.7892\u001b[0m  0.0385\n",
      "      6        0.8227       0.6094        0.8618  0.0345\n",
      "      7        0.8332       0.6094        0.8544  0.0327\n",
      "      8        0.8259       0.6016        0.7918  0.0344\n",
      "      9        0.8546       \u001b[32m0.6172\u001b[0m        0.9259  0.0359\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3022\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m1.8482\u001b[0m  0.0305\n",
      "      2        1.3600       0.5703        2.0223  0.0361\n",
      "      3        1.6403       0.5000        3.2510  0.0348\n",
      "      4        1.8530       0.5000        1.9629  0.0341\n",
      "      5        \u001b[36m1.2751\u001b[0m       0.5625        1.9261  0.0319\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6720\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.5463\u001b[0m  0.0118\n",
      "      2        \u001b[36m0.6016\u001b[0m       0.7812        \u001b[35m0.4538\u001b[0m  0.0127\n",
      "      3        \u001b[36m0.5708\u001b[0m       0.7734        \u001b[35m0.4455\u001b[0m  0.0128\n",
      "      4        \u001b[36m0.5688\u001b[0m       0.7969        \u001b[35m0.4389\u001b[0m  0.0187\n",
      "      5        \u001b[36m0.5646\u001b[0m       \u001b[32m0.8203\u001b[0m        0.4398  0.0155\n",
      "      6        \u001b[36m0.5639\u001b[0m       0.8203        0.4494  0.0228\n",
      "      7        \u001b[36m0.5355\u001b[0m       0.8125        \u001b[35m0.4153\u001b[0m  0.0135\n",
      "      8        0.5552       0.8125        0.4196  0.0175\n",
      "      9        0.5357       0.8203        \u001b[35m0.4000\u001b[0m  0.0193\n",
      "     10        \u001b[36m0.5064\u001b[0m       0.8047        \u001b[35m0.3942\u001b[0m  0.0142\n",
      "     11        0.5363       0.7891        0.4148  0.0194\n",
      "     12        \u001b[36m0.5001\u001b[0m       0.8047        0.4038  0.0151\n",
      "     13        0.5002       \u001b[32m0.8281\u001b[0m        0.4049  0.0224\n",
      "     14        0.5210       0.8125        0.4019  0.0158\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6438\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5567\u001b[0m  0.0327\n",
      "      2        \u001b[36m0.5590\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5563\u001b[0m  0.0323\n",
      "      3        \u001b[36m0.5575\u001b[0m       0.7344        \u001b[35m0.5292\u001b[0m  0.0343\n",
      "      4        0.5599       0.7422        0.5300  0.0241\n",
      "      5        \u001b[36m0.5378\u001b[0m       0.7422        \u001b[35m0.5212\u001b[0m  0.0180\n",
      "      6        \u001b[36m0.5266\u001b[0m       0.7422        0.5236  0.0287\n",
      "      7        0.5315       \u001b[32m0.7734\u001b[0m        0.5250  0.0380\n",
      "      8        \u001b[36m0.5095\u001b[0m       0.7500        \u001b[35m0.5200\u001b[0m  0.0234\n",
      "      9        0.5178       0.7188        0.5218  0.0558\n",
      "     10        0.5255       0.7344        0.5246  0.0255\n",
      "     11        0.5199       0.7188        0.5317  0.0162\n",
      "     12        \u001b[36m0.5035\u001b[0m       0.7500        \u001b[35m0.5082\u001b[0m  0.0159\n",
      "     13        0.5175       0.7266        0.5145  0.0214\n",
      "     14        0.5074       0.7422        0.5143  0.0164\n",
      "     15        0.5099       0.7344        0.5131  0.0210\n",
      "     16        0.5099       0.7344        0.5149  0.0161\n",
      "     17        0.5037       0.7422        \u001b[35m0.4961\u001b[0m  0.0146\n",
      "     18        \u001b[36m0.4980\u001b[0m       0.7266        0.5071  0.0178\n",
      "     19        \u001b[36m0.4967\u001b[0m       0.7344        0.5046  0.0172\n",
      "     20        \u001b[36m0.4858\u001b[0m       0.7422        0.5293  0.0214\n",
      "     21        0.5010       0.7266        0.5168  0.0144\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6309\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5416\u001b[0m  0.0123\n",
      "      2        \u001b[36m0.5702\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5346\u001b[0m  0.0173\n",
      "      3        \u001b[36m0.5409\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5214\u001b[0m  0.0141\n",
      "      4        \u001b[36m0.5392\u001b[0m       \u001b[32m0.7422\u001b[0m        0.5224  0.0173\n",
      "      5        \u001b[36m0.5088\u001b[0m       0.7109        \u001b[35m0.5205\u001b[0m  0.0187\n",
      "      6        0.5329       0.7031        0.5281  0.0203\n",
      "      7        0.5273       0.7266        0.5360  0.0254\n",
      "      8        0.5202       \u001b[32m0.7500\u001b[0m        0.5251  0.0263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9        0.5204       0.7266        0.5293  0.0172\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6315\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5469\u001b[0m  0.0147\n",
      "      2        \u001b[36m0.5607\u001b[0m       0.7266        \u001b[35m0.5336\u001b[0m  0.0196\n",
      "      3        \u001b[36m0.5322\u001b[0m       0.7266        \u001b[35m0.5274\u001b[0m  0.0195\n",
      "      4        \u001b[36m0.5218\u001b[0m       0.6797        0.5471  0.0180\n",
      "      5        \u001b[36m0.5182\u001b[0m       0.7188        \u001b[35m0.5145\u001b[0m  0.0141\n",
      "      6        0.5236       0.7031        0.5196  0.0170\n",
      "      7        \u001b[36m0.5179\u001b[0m       0.7031        0.5295  0.0174\n",
      "      8        \u001b[36m0.5020\u001b[0m       0.6875        0.5175  0.0248\n",
      "      9        0.5235       0.7266        0.5229  0.0172\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6518\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5441\u001b[0m  0.0128\n",
      "      2        \u001b[36m0.5298\u001b[0m       0.7109        \u001b[35m0.5306\u001b[0m  0.0173\n",
      "      3        \u001b[36m0.4983\u001b[0m       0.7031        0.5341  0.0150\n",
      "      4        0.5284       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5240\u001b[0m  0.0161\n",
      "      5        \u001b[36m0.4897\u001b[0m       0.7188        0.5329  0.0246\n",
      "      6        0.5007       0.7188        0.5246  0.0195\n",
      "      7        0.5117       0.7188        0.5317  0.0170\n",
      "      8        0.5069       0.7188        \u001b[35m0.5228\u001b[0m  0.0160\n",
      "      9        \u001b[36m0.4666\u001b[0m       0.6953        0.5455  0.0165\n",
      "     10        0.5008       0.7109        \u001b[35m0.5160\u001b[0m  0.0175\n",
      "     11        0.4672       0.7031        0.5426  0.0243\n",
      "     12        0.5041       0.7109        0.5269  0.0160\n",
      "     13        \u001b[36m0.4443\u001b[0m       0.7109        0.5439  0.0181\n",
      "     14        0.4877       0.6953        0.5323  0.0174\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6099\u001b[0m       \u001b[32m0.7125\u001b[0m        \u001b[35m0.5164\u001b[0m  0.0189\n",
      "      2        \u001b[36m0.5636\u001b[0m       0.7063        0.5264  0.0170\n",
      "      3        0.5847       \u001b[32m0.7250\u001b[0m        0.5295  0.0200\n",
      "      4        0.5641       0.7188        0.5246  0.0180\n",
      "      5        \u001b[36m0.5380\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.4966\u001b[0m  0.0253\n",
      "      6        0.5607       0.7375        0.5262  0.0158\n",
      "      7        \u001b[36m0.5362\u001b[0m       0.7063        0.5106  0.0194\n",
      "      8        0.5511       0.7000        0.5044  0.0173\n",
      "      9        0.5540       0.6937        0.5100  0.0295\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best parameters found:\n",
      "\n",
      "{'optimizer__momentum': 0.3, 'module__num_units': 4, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 64}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.732 (+/-0.102) for {'optimizer__momentum': 0.9, 'module__num_units': 5, 'module__dropout': 0.5, 'lr': 0.1, 'batch_size': 32}\n",
      "0.778 (+/-0.116) for {'optimizer__momentum': 0.6, 'module__num_units': 6, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 16}\n",
      "0.438 (+/-0.668) for {'optimizer__momentum': 0.9, 'module__num_units': 8, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 16}\n",
      "0.698 (+/-0.136) for {'optimizer__momentum': 0.1, 'module__num_units': 4, 'module__dropout': 0.0, 'lr': 1, 'batch_size': 64}\n",
      "0.715 (+/-0.144) for {'optimizer__momentum': 0.3, 'module__num_units': 3, 'module__dropout': 0.5, 'lr': 0.01, 'batch_size': 64}\n",
      "0.762 (+/-0.082) for {'optimizer__momentum': 0.6, 'module__num_units': 8, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 16}\n",
      "0.865 (+/-0.068) for {'optimizer__momentum': 0.3, 'module__num_units': 4, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 64}\n",
      "0.840 (+/-0.167) for {'optimizer__momentum': 0.6, 'module__num_units': 6, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 16}\n",
      "0.730 (+/-0.774) for {'optimizer__momentum': 0.9, 'module__num_units': 6, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 16}\n",
      "0.832 (+/-0.064) for {'optimizer__momentum': 0.1, 'module__num_units': 8, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 64}\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5851\u001b[0m       \u001b[32m0.8594\u001b[0m        \u001b[35m0.4294\u001b[0m  0.0263\n",
      "      2        \u001b[36m0.5258\u001b[0m       0.8203        \u001b[35m0.3999\u001b[0m  0.0342\n",
      "      3        0.5328       0.8047        0.4715  0.0441\n",
      "      4        0.5260       0.8125        0.4313  0.0230\n",
      "      5        0.5346       0.7969        0.4215  0.0293\n",
      "      6        \u001b[36m0.5067\u001b[0m       0.7891        0.4055  0.0393\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6145\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5558\u001b[0m  0.0175\n",
      "      2        \u001b[36m0.5480\u001b[0m       0.7031        \u001b[35m0.5532\u001b[0m  0.0206\n",
      "      3        \u001b[36m0.5360\u001b[0m       0.6875        \u001b[35m0.5242\u001b[0m  0.0270\n",
      "      4        \u001b[36m0.5202\u001b[0m       0.7188        \u001b[35m0.5176\u001b[0m  0.0224\n",
      "      5        \u001b[36m0.4798\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5035\u001b[0m  0.0275\n",
      "      6        0.4887       0.7344        0.5094  0.0324\n",
      "      7        0.4887       0.7266        0.5279  0.0347\n",
      "      8        0.5054       \u001b[32m0.7578\u001b[0m        0.5172  0.0239\n",
      "      9        0.4966       0.7500        0.5096  0.0351\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6012\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5822\u001b[0m  0.0216\n",
      "      2        \u001b[36m0.5319\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5467\u001b[0m  0.0201\n",
      "      3        0.5476       0.6953        \u001b[35m0.5231\u001b[0m  0.0467\n",
      "      4        0.5399       0.6641        0.5701  0.0243\n",
      "      5        0.5329       \u001b[32m0.7188\u001b[0m        0.5605  0.0203\n",
      "      6        \u001b[36m0.5184\u001b[0m       0.6953        0.5716  0.0227\n",
      "      7        0.5306       0.7109        0.5631  0.0318\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6488\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6022\u001b[0m  0.0178\n",
      "      2        \u001b[36m0.5647\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5513\u001b[0m  0.0419\n",
      "      3        \u001b[36m0.5389\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5174\u001b[0m  0.0241\n",
      "      4        \u001b[36m0.5037\u001b[0m       0.7188        0.5329  0.0245\n",
      "      5        0.5059       0.6875        0.5493  0.0240\n",
      "      6        0.5174       0.7344        0.5424  0.0290\n",
      "      7        \u001b[36m0.5028\u001b[0m       0.7344        \u001b[35m0.5162\u001b[0m  0.0243\n",
      "      8        0.5097       0.6797        0.5343  0.0238\n",
      "      9        \u001b[36m0.5006\u001b[0m       0.6562        0.5682  0.0365\n",
      "     10        0.5050       0.6719        0.5554  0.0344\n",
      "     11        \u001b[36m0.4858\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5074\u001b[0m  0.0430\n",
      "     12        \u001b[36m0.4694\u001b[0m       0.6875        0.5330  0.0352\n",
      "     13        0.5078       0.7266        0.5276  0.0349\n",
      "     14        0.4832       0.7109        0.5269  0.0296\n",
      "     15        0.4999       0.7031        0.5282  0.0274\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6183\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5625\u001b[0m  0.0320\n",
      "      2        \u001b[36m0.5333\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5252\u001b[0m  0.0262\n",
      "      3        \u001b[36m0.5026\u001b[0m       0.7500        \u001b[35m0.5221\u001b[0m  0.0235\n",
      "      4        \u001b[36m0.4899\u001b[0m       0.7344        \u001b[35m0.5148\u001b[0m  0.0327\n",
      "      5        \u001b[36m0.4732\u001b[0m       0.7500        0.5494  0.0406\n",
      "      6        0.4891       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5111\u001b[0m  0.0393\n",
      "      7        0.4832       0.7266        0.5415  0.0265\n",
      "      8        \u001b[36m0.4642\u001b[0m       0.7500        0.5215  0.0382\n",
      "      9        0.4732       0.7266        0.5179  0.0291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        0.4664       0.7578        0.5684  0.0369\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6272\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4472\u001b[0m  0.0245\n",
      "      2        \u001b[36m0.5330\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4338\u001b[0m  0.0237\n",
      "      3        \u001b[36m0.5217\u001b[0m       0.7734        0.4425  0.0285\n",
      "      4        \u001b[36m0.4967\u001b[0m       0.8047        \u001b[35m0.4029\u001b[0m  0.0261\n",
      "      5        \u001b[36m0.4835\u001b[0m       \u001b[32m0.8203\u001b[0m        0.4123  0.0238\n",
      "      6        0.5064       \u001b[32m0.8281\u001b[0m        \u001b[35m0.3988\u001b[0m  0.0213\n",
      "      7        0.4865       \u001b[32m0.8359\u001b[0m        0.4135  0.0328\n",
      "      8        0.4946       0.8047        0.4088  0.0390\n",
      "      9        0.4928       0.8203        0.4018  0.0287\n",
      "     10        0.4899       0.8125        \u001b[35m0.3951\u001b[0m  0.0245\n",
      "     11        0.4875       0.8281        \u001b[35m0.3948\u001b[0m  0.0240\n",
      "     12        0.5177       0.8203        0.4017  0.0416\n",
      "     13        0.4866       0.8125        0.3963  0.0247\n",
      "     14        0.4885       0.7969        0.3997  0.0329\n",
      "     15        0.4907       0.8203        \u001b[35m0.3947\u001b[0m  0.0339\n",
      "     16        0.4940       \u001b[32m0.8438\u001b[0m        \u001b[35m0.3935\u001b[0m  0.0383\n",
      "     17        \u001b[36m0.4728\u001b[0m       0.8125        \u001b[35m0.3916\u001b[0m  0.0248\n",
      "     18        0.4780       \u001b[32m0.8516\u001b[0m        \u001b[35m0.3899\u001b[0m  0.0239\n",
      "     19        0.4825       0.8359        \u001b[35m0.3818\u001b[0m  0.0241\n",
      "     20        0.4929       0.8438        0.3926  0.0224\n",
      "     21        \u001b[36m0.4646\u001b[0m       0.8281        0.3974  0.0287\n",
      "     22        0.4938       0.8281        0.3951  0.0214\n",
      "     23        0.4916       0.8438        0.3896  0.0354\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6186\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5742\u001b[0m  0.0197\n",
      "      2        \u001b[36m0.5657\u001b[0m       0.6797        \u001b[35m0.5501\u001b[0m  0.0311\n",
      "      3        \u001b[36m0.5222\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5454\u001b[0m  0.0334\n",
      "      4        \u001b[36m0.5121\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5130\u001b[0m  0.0294\n",
      "      5        \u001b[36m0.4973\u001b[0m       0.6953        0.5234  0.0267\n",
      "      6        \u001b[36m0.4794\u001b[0m       0.7031        0.5288  0.0241\n",
      "      7        0.4995       0.7031        0.5805  0.0260\n",
      "      8        0.4912       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5113\u001b[0m  0.0221\n",
      "      9        \u001b[36m0.4647\u001b[0m       0.7266        0.5186  0.0239\n",
      "     10        \u001b[36m0.4637\u001b[0m       0.7422        0.5121  0.0313\n",
      "     11        \u001b[36m0.4605\u001b[0m       0.7500        \u001b[35m0.4975\u001b[0m  0.0446\n",
      "     12        0.4693       0.7188        \u001b[35m0.4895\u001b[0m  0.0377\n",
      "     13        \u001b[36m0.4377\u001b[0m       0.7344        0.5131  0.0332\n",
      "     14        0.4640       0.7031        0.5021  0.0313\n",
      "     15        0.4403       0.7422        0.5002  0.0261\n",
      "     16        0.4501       0.7344        0.5183  0.0350\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6748\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5767\u001b[0m  0.0209\n",
      "      2        \u001b[36m0.5404\u001b[0m       0.7031        \u001b[35m0.5388\u001b[0m  0.0223\n",
      "      3        \u001b[36m0.5278\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5363\u001b[0m  0.0374\n",
      "      4        \u001b[36m0.5053\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5209\u001b[0m  0.0367\n",
      "      5        0.5054       \u001b[32m0.7422\u001b[0m        0.5288  0.0448\n",
      "      6        \u001b[36m0.4622\u001b[0m       0.7188        0.5539  0.0468\n",
      "      7        0.4834       0.7031        \u001b[35m0.5197\u001b[0m  0.0213\n",
      "      8        0.4741       0.7031        0.5412  0.0360\n",
      "      9        0.4828       0.6953        0.5206  0.0280\n",
      "     10        0.4696       0.7109        0.5228  0.0222\n",
      "     11        0.4684       0.7188        0.5355  0.0285\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5976\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5494\u001b[0m  0.0195\n",
      "      2        \u001b[36m0.5277\u001b[0m       0.6875        0.5543  0.0223\n",
      "      3        \u001b[36m0.4776\u001b[0m       0.7109        0.5511  0.0263\n",
      "      4        \u001b[36m0.4543\u001b[0m       0.6953        0.5839  0.0358\n",
      "      5        0.4694       0.6953        0.5883  0.0290\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6675\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5974\u001b[0m  0.0411\n",
      "      2        \u001b[36m0.5476\u001b[0m       0.6953        \u001b[35m0.5953\u001b[0m  0.0196\n",
      "      3        \u001b[36m0.5107\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5929\u001b[0m  0.0310\n",
      "      4        \u001b[36m0.5096\u001b[0m       0.6875        \u001b[35m0.5586\u001b[0m  0.0256\n",
      "      5        \u001b[36m0.4735\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5446\u001b[0m  0.0222\n",
      "      6        0.4752       0.6953        0.5729  0.0257\n",
      "      7        0.4759       0.7109        0.5588  0.0270\n",
      "      8        0.4769       0.7188        0.5488  0.0261\n",
      "      9        \u001b[36m0.4569\u001b[0m       0.6875        0.5619  0.0239\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6433\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.5366\u001b[0m  0.0347\n",
      "      2        \u001b[36m0.5960\u001b[0m       0.8047        \u001b[35m0.4869\u001b[0m  0.0478\n",
      "      3        0.5981       0.8125        0.4936  0.0417\n",
      "      4        \u001b[36m0.5660\u001b[0m       0.8125        \u001b[35m0.4698\u001b[0m  0.0473\n",
      "      5        0.5816       0.8125        0.4759  0.0513\n",
      "      6        0.5691       0.8047        0.4789  0.0462\n",
      "      7        \u001b[36m0.5608\u001b[0m       0.8125        \u001b[35m0.4547\u001b[0m  0.0502\n",
      "      8        0.5798       0.8203        0.4556  0.0479\n",
      "      9        \u001b[36m0.5571\u001b[0m       0.8125        \u001b[35m0.4479\u001b[0m  0.0611\n",
      "     10        0.5656       \u001b[32m0.8438\u001b[0m        \u001b[35m0.4470\u001b[0m  0.0477\n",
      "     11        0.5671       0.8125        0.4519  0.0395\n",
      "     12        0.5668       0.7969        0.4602  0.0363\n",
      "     13        0.5836       0.7891        0.4769  0.0408\n",
      "     14        0.5882       0.7656        0.4751  0.0360\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6851\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5974\u001b[0m  0.0323\n",
      "      2        \u001b[36m0.5995\u001b[0m       0.7109        \u001b[35m0.5677\u001b[0m  0.0368\n",
      "      3        \u001b[36m0.5823\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5365\u001b[0m  0.0405\n",
      "      4        0.5967       \u001b[32m0.7422\u001b[0m        0.5385  0.0373\n",
      "      5        \u001b[36m0.5637\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5240\u001b[0m  0.0342\n",
      "      6        \u001b[36m0.5536\u001b[0m       0.7500        0.5336  0.0434\n",
      "      7        0.5569       0.7344        0.5250  0.0370\n",
      "      8        0.5773       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5221\u001b[0m  0.0442\n",
      "      9        0.5901       0.7578        0.5246  0.0366\n",
      "     10        0.5540       0.7656        \u001b[35m0.5197\u001b[0m  0.0352\n",
      "     11        0.5623       0.7578        0.5280  0.0457\n",
      "     12        0.5652       0.7578        0.5229  0.0339\n",
      "     13        0.5620       0.7500        0.5246  0.0404\n",
      "     14        \u001b[36m0.5256\u001b[0m       0.7422        0.5213  0.0381\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6526\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5792\u001b[0m  0.0349\n",
      "      2        \u001b[36m0.6185\u001b[0m       0.7266        \u001b[35m0.5518\u001b[0m  0.0437\n",
      "      3        \u001b[36m0.5953\u001b[0m       0.6953        \u001b[35m0.5400\u001b[0m  0.0401\n",
      "      4        0.5991       0.6875        0.5424  0.0392\n",
      "      5        \u001b[36m0.5844\u001b[0m       0.7188        \u001b[35m0.5289\u001b[0m  0.0358\n",
      "      6        0.6015       0.7266        0.5487  0.0401\n",
      "      7        0.5877       0.7344        0.5368  0.0348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        \u001b[36m0.5840\u001b[0m       0.7422        0.5435  0.0436\n",
      "      9        \u001b[36m0.5828\u001b[0m       0.6641        0.5602  0.0363\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6701\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6304\u001b[0m  0.0311\n",
      "      2        \u001b[36m0.6297\u001b[0m       0.6797        \u001b[35m0.5865\u001b[0m  0.0349\n",
      "      3        \u001b[36m0.6147\u001b[0m       0.6797        \u001b[35m0.5613\u001b[0m  0.0362\n",
      "      4        \u001b[36m0.6093\u001b[0m       0.6953        \u001b[35m0.5560\u001b[0m  0.0328\n",
      "      5        0.6099       0.6719        \u001b[35m0.5542\u001b[0m  0.0426\n",
      "      6        \u001b[36m0.5908\u001b[0m       \u001b[32m0.7422\u001b[0m        0.5548  0.0385\n",
      "      7        0.5947       0.7344        \u001b[35m0.5488\u001b[0m  0.0377\n",
      "      8        \u001b[36m0.5877\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5437\u001b[0m  0.0365\n",
      "      9        \u001b[36m0.5842\u001b[0m       0.7344        \u001b[35m0.5334\u001b[0m  0.0414\n",
      "     10        0.5881       0.7500        0.5411  0.0351\n",
      "     11        0.5856       0.7344        0.5426  0.0398\n",
      "     12        0.5974       0.7188        0.5461  0.0334\n",
      "     13        \u001b[36m0.5720\u001b[0m       0.7500        \u001b[35m0.5305\u001b[0m  0.0397\n",
      "     14        \u001b[36m0.5702\u001b[0m       0.7422        \u001b[35m0.5156\u001b[0m  0.0335\n",
      "     15        0.5994       0.7422        0.5465  0.0410\n",
      "     16        0.5830       0.7344        0.5263  0.0348\n",
      "     17        0.5719       0.6953        0.5266  0.0417\n",
      "     18        0.5844       0.7344        0.5266  0.0333\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6884\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5831\u001b[0m  0.0310\n",
      "      2        \u001b[36m0.5679\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5573\u001b[0m  0.0352\n",
      "      3        \u001b[36m0.5649\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5526\u001b[0m  0.0343\n",
      "      4        \u001b[36m0.5367\u001b[0m       0.6953        \u001b[35m0.5431\u001b[0m  0.0404\n",
      "      5        0.5579       0.6875        \u001b[35m0.5382\u001b[0m  0.0403\n",
      "      6        0.5516       0.7031        0.5488  0.0360\n",
      "      7        0.5390       0.6875        0.5394  0.0412\n",
      "      8        0.5603       0.6953        \u001b[35m0.5347\u001b[0m  0.0353\n",
      "      9        0.5513       0.7031        0.5373  0.0381\n",
      "     10        0.5567       0.7031        0.5387  0.0339\n",
      "     11        0.5551       0.6875        0.5469  0.0421\n",
      "     12        0.5662       0.7031        0.5374  0.0344\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8362\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.0228\u001b[0m  0.0300\n",
      "      2        \u001b[36m0.8024\u001b[0m       0.5000        \u001b[35m0.6814\u001b[0m  0.0387\n",
      "      3        0.8324       \u001b[32m0.5312\u001b[0m        0.7469  0.0418\n",
      "      4        1.2058       \u001b[32m0.6875\u001b[0m        1.8166  0.0405\n",
      "      5        1.9840       0.6875        1.9403  0.0329\n",
      "      6        1.9491       0.6875        2.0122  0.0549\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0001\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m1.5270\u001b[0m  0.0331\n",
      "      2        1.2351       0.5312        \u001b[35m0.7628\u001b[0m  0.0372\n",
      "      3        \u001b[36m0.7663\u001b[0m       0.5391        1.3258  0.0355\n",
      "      4        0.9012       0.5547        1.2720  0.0425\n",
      "      5        0.8127       0.5312        \u001b[35m0.6905\u001b[0m  0.0341\n",
      "      6        \u001b[36m0.6883\u001b[0m       0.5234        \u001b[35m0.6873\u001b[0m  0.0384\n",
      "      7        \u001b[36m0.6715\u001b[0m       0.6719        \u001b[35m0.6337\u001b[0m  0.0392\n",
      "      8        0.6974       0.5469        0.6781  0.0329\n",
      "      9        0.8387       0.5078        0.9040  0.0393\n",
      "     10        0.8199       0.5234        0.7317  0.0347\n",
      "     11        0.6927       0.5234        0.6967  0.0378\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.6006\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m2.8187\u001b[0m  0.0341\n",
      "      2        \u001b[36m1.0076\u001b[0m       0.5234        \u001b[35m0.9535\u001b[0m  0.0454\n",
      "      3        1.1251       0.5234        1.1358  0.0373\n",
      "      4        \u001b[36m0.9739\u001b[0m       0.4766        1.3331  0.0398\n",
      "      5        \u001b[36m0.9521\u001b[0m       0.4766        1.1650  0.0351\n",
      "      6        \u001b[36m0.9292\u001b[0m       0.4766        1.1972  0.0328\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0030\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m1.4530\u001b[0m  0.0337\n",
      "      2        1.1077       0.5078        \u001b[35m1.3886\u001b[0m  0.0359\n",
      "      3        1.0868       0.5078        2.0153  0.0397\n",
      "      4        2.1088       \u001b[32m0.6797\u001b[0m        2.6675  0.0322\n",
      "      5        1.6157       0.6797        2.2495  0.0404\n",
      "      6        2.2529       0.6641        2.2690  0.0393\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7319\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m1.1434\u001b[0m  0.0319\n",
      "      2        1.2625       0.4922        \u001b[35m1.0098\u001b[0m  0.0327\n",
      "      3        1.2881       0.4922        1.9738  0.0508\n",
      "      4        1.1078       0.5469        \u001b[35m0.7750\u001b[0m  0.0508\n",
      "      5        0.8614       0.5000        0.9527  0.0566\n",
      "      6        0.7579       0.5156        \u001b[35m0.7171\u001b[0m  0.0367\n",
      "      7        0.8304       0.5156        \u001b[35m0.6943\u001b[0m  0.0364\n",
      "      8        0.8034       0.5000        \u001b[35m0.6818\u001b[0m  0.0346\n",
      "      9        \u001b[36m0.6772\u001b[0m       0.5312        0.7120  0.0376\n",
      "     10        0.8006       0.5000        0.9019  0.0461\n",
      "     11        0.7776       0.5312        \u001b[35m0.6713\u001b[0m  0.0486\n",
      "     12        0.7013       0.5312        \u001b[35m0.6710\u001b[0m  0.0423\n",
      "     13        0.7196       0.5000        0.8584  0.0361\n",
      "     14        0.7225       0.5312        1.0126  0.0366\n",
      "     15        0.7916       0.5312        0.9905  0.0336\n",
      "     16        0.7157       0.5000        0.6936  0.0417\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7585\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m0.7659\u001b[0m  0.0178\n",
      "      2        \u001b[36m0.7546\u001b[0m       0.4531        \u001b[35m0.7447\u001b[0m  0.0220\n",
      "      3        \u001b[36m0.7336\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m0.7264\u001b[0m  0.0265\n",
      "      4        \u001b[36m0.7171\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m0.7120\u001b[0m  0.0258\n",
      "      5        \u001b[36m0.7083\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6995\u001b[0m  0.0312\n",
      "      6        \u001b[36m0.6910\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6885\u001b[0m  0.0307\n",
      "      7        \u001b[36m0.6905\u001b[0m       0.5312        \u001b[35m0.6795\u001b[0m  0.0300\n",
      "      8        \u001b[36m0.6756\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6711\u001b[0m  0.0389\n",
      "      9        0.6805       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6630\u001b[0m  0.0227\n",
      "     10        \u001b[36m0.6727\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6554\u001b[0m  0.0222\n",
      "     11        \u001b[36m0.6582\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6487\u001b[0m  0.0293\n",
      "     12        0.6639       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6423\u001b[0m  0.0296\n",
      "     13        \u001b[36m0.6530\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6360\u001b[0m  0.0312\n",
      "     14        \u001b[36m0.6522\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6299\u001b[0m  0.0278\n",
      "     15        \u001b[36m0.6399\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6235\u001b[0m  0.0302\n",
      "     16        0.6403       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6175\u001b[0m  0.0253\n",
      "     17        0.6496       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6120\u001b[0m  0.0262\n",
      "     18        0.6433       0.7188        \u001b[35m0.6062\u001b[0m  0.0264\n",
      "     19        \u001b[36m0.6371\u001b[0m       0.7266        \u001b[35m0.6011\u001b[0m  0.0317\n",
      "     20        \u001b[36m0.6240\u001b[0m       0.7188        \u001b[35m0.5957\u001b[0m  0.0299\n",
      "     21        0.6286       0.7188        \u001b[35m0.5904\u001b[0m  0.0268\n",
      "     22        \u001b[36m0.6119\u001b[0m       0.7188        \u001b[35m0.5849\u001b[0m  0.0293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     23        0.6265       0.7266        \u001b[35m0.5801\u001b[0m  0.0291\n",
      "     24        \u001b[36m0.6115\u001b[0m       0.7266        \u001b[35m0.5755\u001b[0m  0.0242\n",
      "     25        0.6145       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5713\u001b[0m  0.0295\n",
      "     26        \u001b[36m0.6005\u001b[0m       0.7344        \u001b[35m0.5670\u001b[0m  0.0209\n",
      "     27        \u001b[36m0.5996\u001b[0m       0.7344        \u001b[35m0.5631\u001b[0m  0.0232\n",
      "     28        0.6066       0.7344        \u001b[35m0.5592\u001b[0m  0.0358\n",
      "     29        \u001b[36m0.5972\u001b[0m       0.7344        \u001b[35m0.5554\u001b[0m  0.0339\n",
      "     30        \u001b[36m0.5942\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5517\u001b[0m  0.0201\n",
      "     31        0.5992       0.7422        \u001b[35m0.5481\u001b[0m  0.0229\n",
      "     32        \u001b[36m0.5884\u001b[0m       0.7422        \u001b[35m0.5448\u001b[0m  0.0418\n",
      "     33        0.6045       0.7422        \u001b[35m0.5419\u001b[0m  0.0242\n",
      "     34        0.5892       0.7422        \u001b[35m0.5387\u001b[0m  0.0534\n",
      "     35        0.5898       0.7422        \u001b[35m0.5358\u001b[0m  0.0276\n",
      "     36        0.5986       0.7344        \u001b[35m0.5331\u001b[0m  0.0272\n",
      "     37        \u001b[36m0.5765\u001b[0m       0.7422        \u001b[35m0.5302\u001b[0m  0.0284\n",
      "     38        \u001b[36m0.5672\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5272\u001b[0m  0.0323\n",
      "     39        0.5777       0.7500        \u001b[35m0.5245\u001b[0m  0.0246\n",
      "     40        0.5712       0.7500        \u001b[35m0.5219\u001b[0m  0.0283\n",
      "     41        0.5772       0.7500        \u001b[35m0.5194\u001b[0m  0.0403\n",
      "     42        0.5780       0.7500        \u001b[35m0.5171\u001b[0m  0.0202\n",
      "     43        0.5845       0.7500        \u001b[35m0.5153\u001b[0m  0.0305\n",
      "     44        0.5867       0.7500        \u001b[35m0.5136\u001b[0m  0.0295\n",
      "     45        \u001b[36m0.5621\u001b[0m       0.7500        \u001b[35m0.5113\u001b[0m  0.0281\n",
      "     46        0.5633       0.7500        \u001b[35m0.5093\u001b[0m  0.0262\n",
      "     47        0.5709       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5075\u001b[0m  0.0232\n",
      "     48        0.5705       0.7578        \u001b[35m0.5056\u001b[0m  0.0215\n",
      "     49        0.5694       0.7578        \u001b[35m0.5038\u001b[0m  0.0285\n",
      "     50        \u001b[36m0.5552\u001b[0m       0.7578        \u001b[35m0.5021\u001b[0m  0.0228\n",
      "     51        0.5622       0.7578        \u001b[35m0.5004\u001b[0m  0.0231\n",
      "     52        0.5620       0.7578        \u001b[35m0.4986\u001b[0m  0.0270\n",
      "     53        0.5592       0.7578        \u001b[35m0.4970\u001b[0m  0.0288\n",
      "     54        0.5660       0.7578        \u001b[35m0.4956\u001b[0m  0.0243\n",
      "     55        \u001b[36m0.5547\u001b[0m       0.7578        \u001b[35m0.4941\u001b[0m  0.0253\n",
      "     56        0.5566       0.7578        \u001b[35m0.4927\u001b[0m  0.0293\n",
      "     57        0.5550       0.7578        \u001b[35m0.4912\u001b[0m  0.0286\n",
      "     58        0.5696       0.7578        \u001b[35m0.4903\u001b[0m  0.0241\n",
      "     59        \u001b[36m0.5539\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4891\u001b[0m  0.0266\n",
      "     60        0.5544       0.7656        \u001b[35m0.4879\u001b[0m  0.0283\n",
      "     61        0.5550       0.7656        \u001b[35m0.4867\u001b[0m  0.0205\n",
      "     62        0.5578       0.7656        \u001b[35m0.4858\u001b[0m  0.0303\n",
      "     63        0.5644       0.7656        \u001b[35m0.4850\u001b[0m  0.0227\n",
      "     64        \u001b[36m0.5519\u001b[0m       0.7656        \u001b[35m0.4841\u001b[0m  0.0331\n",
      "     65        \u001b[36m0.5418\u001b[0m       0.7656        \u001b[35m0.4829\u001b[0m  0.0273\n",
      "     66        0.5582       0.7656        \u001b[35m0.4821\u001b[0m  0.0319\n",
      "     67        0.5506       0.7656        \u001b[35m0.4812\u001b[0m  0.0252\n",
      "     68        0.5516       0.7656        \u001b[35m0.4804\u001b[0m  0.0234\n",
      "     69        0.5451       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4796\u001b[0m  0.0325\n",
      "     70        \u001b[36m0.5373\u001b[0m       0.7734        \u001b[35m0.4785\u001b[0m  0.0313\n",
      "     71        0.5456       0.7734        \u001b[35m0.4775\u001b[0m  0.0227\n",
      "     72        0.5491       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4767\u001b[0m  0.0283\n",
      "     73        0.5498       0.7812        \u001b[35m0.4760\u001b[0m  0.0270\n",
      "     74        \u001b[36m0.5171\u001b[0m       0.7812        \u001b[35m0.4748\u001b[0m  0.0242\n",
      "     75        0.5476       0.7812        \u001b[35m0.4741\u001b[0m  0.0224\n",
      "     76        0.5455       0.7812        \u001b[35m0.4734\u001b[0m  0.0332\n",
      "     77        0.5433       0.7812        \u001b[35m0.4726\u001b[0m  0.0248\n",
      "     78        0.5498       0.7812        \u001b[35m0.4719\u001b[0m  0.0307\n",
      "     79        0.5420       0.7812        \u001b[35m0.4712\u001b[0m  0.0307\n",
      "     80        0.5408       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4705\u001b[0m  0.0203\n",
      "     81        0.5316       0.7812        \u001b[35m0.4697\u001b[0m  0.0304\n",
      "     82        0.5416       0.7891        \u001b[35m0.4691\u001b[0m  0.0225\n",
      "     83        0.5459       0.7891        \u001b[35m0.4687\u001b[0m  0.0240\n",
      "     84        0.5525       0.7891        \u001b[35m0.4684\u001b[0m  0.0325\n",
      "     85        0.5444       0.7812        \u001b[35m0.4678\u001b[0m  0.0212\n",
      "     86        0.5399       0.7891        \u001b[35m0.4673\u001b[0m  0.0264\n",
      "     87        0.5480       0.7891        \u001b[35m0.4667\u001b[0m  0.0302\n",
      "     88        0.5221       0.7891        \u001b[35m0.4660\u001b[0m  0.0216\n",
      "     89        0.5410       0.7891        \u001b[35m0.4655\u001b[0m  0.0303\n",
      "     90        0.5309       0.7891        \u001b[35m0.4648\u001b[0m  0.0243\n",
      "     91        0.5508       0.7891        \u001b[35m0.4643\u001b[0m  0.0230\n",
      "     92        0.5593       0.7891        \u001b[35m0.4641\u001b[0m  0.0324\n",
      "     93        0.5261       0.7891        \u001b[35m0.4635\u001b[0m  0.0208\n",
      "     94        0.5456       0.7891        \u001b[35m0.4632\u001b[0m  0.0346\n",
      "     95        0.5438       0.7891        \u001b[35m0.4628\u001b[0m  0.0288\n",
      "     96        0.5351       0.7891        \u001b[35m0.4623\u001b[0m  0.0366\n",
      "     97        0.5350       0.7891        \u001b[35m0.4617\u001b[0m  0.0236\n",
      "     98        0.5358       0.7891        \u001b[35m0.4609\u001b[0m  0.0407\n",
      "     99        0.5316       0.7891        \u001b[35m0.4604\u001b[0m  0.0241\n",
      "    100        0.5458       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4604\u001b[0m  0.0305\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6707\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6523\u001b[0m  0.0375\n",
      "      2        \u001b[36m0.6660\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6475\u001b[0m  0.0410\n",
      "      3        \u001b[36m0.6583\u001b[0m       0.6953        \u001b[35m0.6429\u001b[0m  0.0405\n",
      "      4        \u001b[36m0.6580\u001b[0m       0.6719        \u001b[35m0.6389\u001b[0m  0.0329\n",
      "      5        \u001b[36m0.6445\u001b[0m       0.6719        \u001b[35m0.6344\u001b[0m  0.0323\n",
      "      6        \u001b[36m0.6422\u001b[0m       0.6719        \u001b[35m0.6301\u001b[0m  0.0337\n",
      "      7        0.6437       0.6719        \u001b[35m0.6262\u001b[0m  0.0251\n",
      "      8        \u001b[36m0.6349\u001b[0m       0.6719        \u001b[35m0.6219\u001b[0m  0.0348\n",
      "      9        0.6350       0.6719        \u001b[35m0.6180\u001b[0m  0.0302\n",
      "     10        \u001b[36m0.6322\u001b[0m       0.6719        \u001b[35m0.6141\u001b[0m  0.0297\n",
      "     11        \u001b[36m0.6209\u001b[0m       0.6797        \u001b[35m0.6100\u001b[0m  0.0271\n",
      "     12        \u001b[36m0.6193\u001b[0m       0.6797        \u001b[35m0.6062\u001b[0m  0.0309\n",
      "     13        0.6200       0.6953        \u001b[35m0.6025\u001b[0m  0.0312\n",
      "     14        \u001b[36m0.6084\u001b[0m       0.6953        \u001b[35m0.5988\u001b[0m  0.0319\n",
      "     15        0.6094       0.6953        \u001b[35m0.5952\u001b[0m  0.0296\n",
      "     16        \u001b[36m0.6074\u001b[0m       0.7031        \u001b[35m0.5918\u001b[0m  0.0286\n",
      "     17        \u001b[36m0.5947\u001b[0m       0.7109        \u001b[35m0.5882\u001b[0m  0.0256\n",
      "     18        0.5991       0.7109        \u001b[35m0.5850\u001b[0m  0.0269\n",
      "     19        \u001b[36m0.5921\u001b[0m       0.7109        \u001b[35m0.5818\u001b[0m  0.0294\n",
      "     20        \u001b[36m0.5900\u001b[0m       0.7109        \u001b[35m0.5786\u001b[0m  0.0278\n",
      "     21        0.6006       0.7109        \u001b[35m0.5761\u001b[0m  0.0364\n",
      "     22        0.5907       0.7109        \u001b[35m0.5734\u001b[0m  0.0388\n",
      "     23        0.5905       0.7109        \u001b[35m0.5709\u001b[0m  0.0242\n",
      "     24        \u001b[36m0.5890\u001b[0m       0.7109        \u001b[35m0.5686\u001b[0m  0.0241\n",
      "     25        \u001b[36m0.5864\u001b[0m       0.7109        \u001b[35m0.5662\u001b[0m  0.0232\n",
      "     26        0.5940       0.7109        \u001b[35m0.5643\u001b[0m  0.0226\n",
      "     27        \u001b[36m0.5784\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5622\u001b[0m  0.0318\n",
      "     28        \u001b[36m0.5757\u001b[0m       0.7188        \u001b[35m0.5603\u001b[0m  0.0403\n",
      "     29        0.5778       0.7188        \u001b[35m0.5586\u001b[0m  0.0243\n",
      "     30        \u001b[36m0.5501\u001b[0m       0.7188        \u001b[35m0.5564\u001b[0m  0.0235\n",
      "     31        0.5860       0.7188        \u001b[35m0.5553\u001b[0m  0.0276\n",
      "     32        0.5776       0.7188        \u001b[35m0.5541\u001b[0m  0.0332\n",
      "     33        0.5682       0.7188        \u001b[35m0.5527\u001b[0m  0.0292\n",
      "     34        0.5691       0.7109        \u001b[35m0.5514\u001b[0m  0.0308\n",
      "     35        0.5591       0.7109        \u001b[35m0.5502\u001b[0m  0.0305\n",
      "     36        0.5645       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5489\u001b[0m  0.0301\n",
      "     37        0.5729       0.7266        \u001b[35m0.5480\u001b[0m  0.0312\n",
      "     38        0.5502       0.7266        \u001b[35m0.5468\u001b[0m  0.0315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     39        0.5703       0.7266        \u001b[35m0.5460\u001b[0m  0.0282\n",
      "     40        0.5691       0.7266        \u001b[35m0.5454\u001b[0m  0.0247\n",
      "     41        \u001b[36m0.5483\u001b[0m       0.7266        \u001b[35m0.5444\u001b[0m  0.0262\n",
      "     42        0.5646       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5438\u001b[0m  0.0270\n",
      "     43        0.5541       0.7344        \u001b[35m0.5432\u001b[0m  0.0273\n",
      "     44        0.5592       0.7344        \u001b[35m0.5427\u001b[0m  0.0270\n",
      "     45        0.5658       0.7344        \u001b[35m0.5421\u001b[0m  0.0277\n",
      "     46        0.5568       0.7344        \u001b[35m0.5415\u001b[0m  0.0272\n",
      "     47        0.5556       0.7344        \u001b[35m0.5411\u001b[0m  0.0287\n",
      "     48        0.5489       0.7344        \u001b[35m0.5407\u001b[0m  0.0236\n",
      "     49        0.5616       0.7344        \u001b[35m0.5403\u001b[0m  0.0298\n",
      "     50        \u001b[36m0.5331\u001b[0m       0.7344        \u001b[35m0.5396\u001b[0m  0.0314\n",
      "     51        0.5451       0.7344        \u001b[35m0.5391\u001b[0m  0.0276\n",
      "     52        0.5401       0.7266        \u001b[35m0.5387\u001b[0m  0.0247\n",
      "     53        0.5380       0.7266        \u001b[35m0.5382\u001b[0m  0.0277\n",
      "     54        0.5514       0.7266        \u001b[35m0.5379\u001b[0m  0.0219\n",
      "     55        0.5500       0.7266        \u001b[35m0.5376\u001b[0m  0.0234\n",
      "     56        0.5589       0.7266        \u001b[35m0.5375\u001b[0m  0.0300\n",
      "     57        0.5395       0.7266        \u001b[35m0.5369\u001b[0m  0.0264\n",
      "     58        0.5428       0.7266        \u001b[35m0.5368\u001b[0m  0.0311\n",
      "     59        0.5531       0.7266        \u001b[35m0.5365\u001b[0m  0.0278\n",
      "     60        0.5485       0.7266        \u001b[35m0.5362\u001b[0m  0.0207\n",
      "     61        0.5512       0.7344        \u001b[35m0.5358\u001b[0m  0.0240\n",
      "     62        0.5379       0.7266        \u001b[35m0.5353\u001b[0m  0.0611\n",
      "     63        0.5463       0.7266        \u001b[35m0.5350\u001b[0m  0.0205\n",
      "     64        0.5576       0.7266        \u001b[35m0.5348\u001b[0m  0.0280\n",
      "     65        0.5340       0.7266        \u001b[35m0.5345\u001b[0m  0.0359\n",
      "     66        0.5507       0.7266        \u001b[35m0.5343\u001b[0m  0.0205\n",
      "     67        0.5431       0.7266        \u001b[35m0.5340\u001b[0m  0.0320\n",
      "     68        0.5366       0.7266        \u001b[35m0.5337\u001b[0m  0.0277\n",
      "     69        0.5350       0.7266        \u001b[35m0.5335\u001b[0m  0.0276\n",
      "     70        0.5370       0.7266        \u001b[35m0.5333\u001b[0m  0.0324\n",
      "     71        0.5429       0.7188        \u001b[35m0.5331\u001b[0m  0.0216\n",
      "     72        0.5419       0.7188        \u001b[35m0.5330\u001b[0m  0.0281\n",
      "     73        0.5420       0.7109        \u001b[35m0.5329\u001b[0m  0.0264\n",
      "     74        0.5415       0.7109        \u001b[35m0.5326\u001b[0m  0.0253\n",
      "     75        \u001b[36m0.5327\u001b[0m       0.7109        \u001b[35m0.5324\u001b[0m  0.0316\n",
      "     76        \u001b[36m0.5327\u001b[0m       0.7109        \u001b[35m0.5323\u001b[0m  0.0217\n",
      "     77        0.5409       0.7109        0.5324  0.0262\n",
      "     78        0.5442       0.7109        \u001b[35m0.5322\u001b[0m  0.0461\n",
      "     79        0.5501       0.7109        0.5322  0.0226\n",
      "     80        \u001b[36m0.5246\u001b[0m       0.7109        \u001b[35m0.5319\u001b[0m  0.0314\n",
      "     81        \u001b[36m0.5237\u001b[0m       0.7031        \u001b[35m0.5318\u001b[0m  0.0250\n",
      "     82        0.5398       0.7031        \u001b[35m0.5316\u001b[0m  0.0310\n",
      "     83        0.5405       0.7031        \u001b[35m0.5314\u001b[0m  0.0253\n",
      "     84        0.5503       0.7031        \u001b[35m0.5312\u001b[0m  0.0211\n",
      "     85        0.5322       0.7031        \u001b[35m0.5309\u001b[0m  0.0391\n",
      "     86        0.5271       0.7031        \u001b[35m0.5307\u001b[0m  0.0265\n",
      "     87        \u001b[36m0.5228\u001b[0m       0.7031        \u001b[35m0.5306\u001b[0m  0.0221\n",
      "     88        0.5399       0.7031        \u001b[35m0.5304\u001b[0m  0.0297\n",
      "     89        0.5477       0.7031        \u001b[35m0.5302\u001b[0m  0.0249\n",
      "     90        0.5392       0.7031        \u001b[35m0.5301\u001b[0m  0.0243\n",
      "     91        0.5303       0.6953        0.5302  0.0291\n",
      "     92        0.5320       0.6953        0.5302  0.0222\n",
      "     93        0.5408       0.6953        0.5302  0.0266\n",
      "     94        \u001b[36m0.5201\u001b[0m       0.6953        0.5302  0.0287\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7243\u001b[0m       \u001b[32m0.4141\u001b[0m        \u001b[35m0.7297\u001b[0m  0.0285\n",
      "      2        \u001b[36m0.7127\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m0.7209\u001b[0m  0.0279\n",
      "      3        0.7136       \u001b[32m0.4766\u001b[0m        \u001b[35m0.7129\u001b[0m  0.0346\n",
      "      4        \u001b[36m0.7041\u001b[0m       0.4766        \u001b[35m0.7055\u001b[0m  0.0421\n",
      "      5        \u001b[36m0.6947\u001b[0m       \u001b[32m0.4844\u001b[0m        \u001b[35m0.6992\u001b[0m  0.0357\n",
      "      6        \u001b[36m0.6880\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6931\u001b[0m  0.0264\n",
      "      7        \u001b[36m0.6847\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6877\u001b[0m  0.0298\n",
      "      8        \u001b[36m0.6788\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6824\u001b[0m  0.0262\n",
      "      9        \u001b[36m0.6757\u001b[0m       0.5547        \u001b[35m0.6770\u001b[0m  0.0278\n",
      "     10        0.6767       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6720\u001b[0m  0.0234\n",
      "     11        \u001b[36m0.6668\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6672\u001b[0m  0.0231\n",
      "     12        \u001b[36m0.6640\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6623\u001b[0m  0.0257\n",
      "     13        \u001b[36m0.6536\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6571\u001b[0m  0.0229\n",
      "     14        \u001b[36m0.6522\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6523\u001b[0m  0.0233\n",
      "     15        0.6604       0.6719        \u001b[35m0.6483\u001b[0m  0.0236\n",
      "     16        \u001b[36m0.6407\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6439\u001b[0m  0.0256\n",
      "     17        0.6468       0.6797        \u001b[35m0.6402\u001b[0m  0.0263\n",
      "     18        \u001b[36m0.6322\u001b[0m       0.6797        \u001b[35m0.6360\u001b[0m  0.0330\n",
      "     19        0.6379       0.6797        \u001b[35m0.6319\u001b[0m  0.0285\n",
      "     20        \u001b[36m0.6309\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6278\u001b[0m  0.0324\n",
      "     21        \u001b[36m0.6275\u001b[0m       0.6875        \u001b[35m0.6236\u001b[0m  0.0263\n",
      "     22        \u001b[36m0.6155\u001b[0m       0.6875        \u001b[35m0.6194\u001b[0m  0.0282\n",
      "     23        0.6169       0.6953        \u001b[35m0.6152\u001b[0m  0.0235\n",
      "     24        \u001b[36m0.6119\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6108\u001b[0m  0.0274\n",
      "     25        \u001b[36m0.6078\u001b[0m       0.6953        \u001b[35m0.6069\u001b[0m  0.0241\n",
      "     26        \u001b[36m0.6007\u001b[0m       0.6797        \u001b[35m0.6029\u001b[0m  0.0252\n",
      "     27        0.6009       0.6875        \u001b[35m0.5990\u001b[0m  0.0274\n",
      "     28        \u001b[36m0.6006\u001b[0m       0.6875        \u001b[35m0.5951\u001b[0m  0.0283\n",
      "     29        \u001b[36m0.5916\u001b[0m       0.6953        \u001b[35m0.5912\u001b[0m  0.0290\n",
      "     30        \u001b[36m0.5907\u001b[0m       0.6875        \u001b[35m0.5876\u001b[0m  0.0294\n",
      "     31        \u001b[36m0.5888\u001b[0m       0.6875        \u001b[35m0.5842\u001b[0m  0.0231\n",
      "     32        0.5899       0.6953        \u001b[35m0.5811\u001b[0m  0.0233\n",
      "     33        \u001b[36m0.5785\u001b[0m       0.6953        \u001b[35m0.5779\u001b[0m  0.0296\n",
      "     34        0.6000       0.6875        \u001b[35m0.5753\u001b[0m  0.0272\n",
      "     35        0.5844       0.6953        \u001b[35m0.5725\u001b[0m  0.0304\n",
      "     36        \u001b[36m0.5690\u001b[0m       0.6953        \u001b[35m0.5695\u001b[0m  0.0282\n",
      "     37        \u001b[36m0.5604\u001b[0m       0.6953        \u001b[35m0.5667\u001b[0m  0.0319\n",
      "     38        0.5666       0.7031        \u001b[35m0.5642\u001b[0m  0.0285\n",
      "     39        0.5665       0.7031        \u001b[35m0.5620\u001b[0m  0.0271\n",
      "     40        0.5636       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5600\u001b[0m  0.0299\n",
      "     41        \u001b[36m0.5506\u001b[0m       0.7109        \u001b[35m0.5577\u001b[0m  0.0284\n",
      "     42        0.5587       0.7031        \u001b[35m0.5556\u001b[0m  0.0295\n",
      "     43        0.5762       0.6953        \u001b[35m0.5539\u001b[0m  0.0296\n",
      "     44        0.5775       0.6953        \u001b[35m0.5527\u001b[0m  0.0255\n",
      "     45        0.5582       0.6875        \u001b[35m0.5512\u001b[0m  0.0283\n",
      "     46        \u001b[36m0.5490\u001b[0m       0.6875        \u001b[35m0.5493\u001b[0m  0.0215\n",
      "     47        \u001b[36m0.5415\u001b[0m       0.6875        \u001b[35m0.5480\u001b[0m  0.0307\n",
      "     48        \u001b[36m0.5398\u001b[0m       0.6797        \u001b[35m0.5466\u001b[0m  0.0286\n",
      "     49        0.5406       0.6797        \u001b[35m0.5455\u001b[0m  0.0282\n",
      "     50        0.5511       0.6797        \u001b[35m0.5444\u001b[0m  0.0260\n",
      "     51        0.5452       0.6797        \u001b[35m0.5434\u001b[0m  0.0264\n",
      "     52        0.5446       0.6875        \u001b[35m0.5422\u001b[0m  0.0288\n",
      "     53        \u001b[36m0.5337\u001b[0m       0.6875        \u001b[35m0.5414\u001b[0m  0.0310\n",
      "     54        0.5368       0.6875        \u001b[35m0.5403\u001b[0m  0.0232\n",
      "     55        0.5467       0.6875        \u001b[35m0.5395\u001b[0m  0.0326\n",
      "     56        0.5490       0.6953        \u001b[35m0.5389\u001b[0m  0.0266\n",
      "     57        0.5581       0.6953        \u001b[35m0.5383\u001b[0m  0.0301\n",
      "     58        0.5421       0.6953        \u001b[35m0.5378\u001b[0m  0.0246\n",
      "     59        0.5622       0.7031        \u001b[35m0.5373\u001b[0m  0.0305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     60        \u001b[36m0.5297\u001b[0m       0.7031        \u001b[35m0.5367\u001b[0m  0.0248\n",
      "     61        0.5351       0.7031        \u001b[35m0.5362\u001b[0m  0.0240\n",
      "     62        0.5313       0.7109        \u001b[35m0.5357\u001b[0m  0.0254\n",
      "     63        \u001b[36m0.5184\u001b[0m       0.7109        \u001b[35m0.5351\u001b[0m  0.0228\n",
      "     64        0.5309       0.7109        \u001b[35m0.5346\u001b[0m  0.0233\n",
      "     65        0.5246       0.7109        \u001b[35m0.5340\u001b[0m  0.0248\n",
      "     66        0.5371       0.7031        \u001b[35m0.5338\u001b[0m  0.0260\n",
      "     67        0.5285       0.7031        \u001b[35m0.5335\u001b[0m  0.0250\n",
      "     68        0.5406       0.7031        \u001b[35m0.5331\u001b[0m  0.0252\n",
      "     69        0.5412       0.6953        \u001b[35m0.5327\u001b[0m  0.0278\n",
      "     70        0.5289       0.6953        \u001b[35m0.5323\u001b[0m  0.0288\n",
      "     71        0.5356       0.6953        \u001b[35m0.5320\u001b[0m  0.0232\n",
      "     72        0.5342       0.6953        \u001b[35m0.5317\u001b[0m  0.0232\n",
      "     73        \u001b[36m0.5168\u001b[0m       0.6953        \u001b[35m0.5315\u001b[0m  0.0287\n",
      "     74        0.5411       0.6953        \u001b[35m0.5313\u001b[0m  0.0312\n",
      "     75        0.5270       0.6953        \u001b[35m0.5310\u001b[0m  0.0224\n",
      "     76        0.5188       0.6953        \u001b[35m0.5309\u001b[0m  0.0289\n",
      "     77        0.5332       0.6953        \u001b[35m0.5305\u001b[0m  0.0286\n",
      "     78        0.5346       0.6953        \u001b[35m0.5302\u001b[0m  0.0215\n",
      "     79        \u001b[36m0.5166\u001b[0m       0.6953        \u001b[35m0.5298\u001b[0m  0.0263\n",
      "     80        0.5311       0.6953        \u001b[35m0.5297\u001b[0m  0.0257\n",
      "     81        0.5276       0.6953        \u001b[35m0.5294\u001b[0m  0.0253\n",
      "     82        0.5341       0.6953        \u001b[35m0.5288\u001b[0m  0.0244\n",
      "     83        0.5232       0.6953        \u001b[35m0.5288\u001b[0m  0.0201\n",
      "     84        0.5369       0.6875        \u001b[35m0.5286\u001b[0m  0.0237\n",
      "     85        0.5329       0.6875        \u001b[35m0.5285\u001b[0m  0.0279\n",
      "     86        0.5336       0.6875        \u001b[35m0.5280\u001b[0m  0.0289\n",
      "     87        \u001b[36m0.5033\u001b[0m       0.6875        \u001b[35m0.5278\u001b[0m  0.0255\n",
      "     88        0.5331       0.6875        \u001b[35m0.5276\u001b[0m  0.0247\n",
      "     89        0.5291       0.6875        \u001b[35m0.5273\u001b[0m  0.0240\n",
      "     90        0.5111       0.6875        0.5273  0.0193\n",
      "     91        0.5284       0.6875        \u001b[35m0.5271\u001b[0m  0.0199\n",
      "     92        0.5307       0.6875        \u001b[35m0.5271\u001b[0m  0.0194\n",
      "     93        0.5427       0.6875        \u001b[35m0.5268\u001b[0m  0.0197\n",
      "     94        0.5073       0.6875        \u001b[35m0.5267\u001b[0m  0.0234\n",
      "     95        0.5248       0.6875        \u001b[35m0.5263\u001b[0m  0.0185\n",
      "     96        0.5180       0.6875        \u001b[35m0.5262\u001b[0m  0.0216\n",
      "     97        0.5163       0.6953        \u001b[35m0.5261\u001b[0m  0.0240\n",
      "     98        0.5125       0.6953        \u001b[35m0.5258\u001b[0m  0.0202\n",
      "     99        0.5220       0.6953        \u001b[35m0.5255\u001b[0m  0.0324\n",
      "    100        0.5428       0.6953        \u001b[35m0.5254\u001b[0m  0.0347\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7007\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6997\u001b[0m  0.0207\n",
      "      2        \u001b[36m0.6950\u001b[0m       0.5000        \u001b[35m0.6938\u001b[0m  0.0429\n",
      "      3        \u001b[36m0.6885\u001b[0m       0.5000        \u001b[35m0.6887\u001b[0m  0.0281\n",
      "      4        \u001b[36m0.6838\u001b[0m       0.5000        \u001b[35m0.6841\u001b[0m  0.0197\n",
      "      5        \u001b[36m0.6726\u001b[0m       0.5000        \u001b[35m0.6802\u001b[0m  0.0426\n",
      "      6        \u001b[36m0.6711\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6764\u001b[0m  0.0372\n",
      "      7        0.6718       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6730\u001b[0m  0.0486\n",
      "      8        \u001b[36m0.6592\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6694\u001b[0m  0.0327\n",
      "      9        0.6620       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6663\u001b[0m  0.0512\n",
      "     10        \u001b[36m0.6516\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6628\u001b[0m  0.0262\n",
      "     11        \u001b[36m0.6495\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6595\u001b[0m  0.0397\n",
      "     12        \u001b[36m0.6393\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6559\u001b[0m  0.0311\n",
      "     13        0.6413       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6523\u001b[0m  0.0541\n",
      "     14        0.6404       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6491\u001b[0m  0.0252\n",
      "     15        \u001b[36m0.6338\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6455\u001b[0m  0.0359\n",
      "     16        \u001b[36m0.6259\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.6417\u001b[0m  0.0343\n",
      "     17        \u001b[36m0.6237\u001b[0m       0.7500        \u001b[35m0.6379\u001b[0m  0.0241\n",
      "     18        \u001b[36m0.6195\u001b[0m       0.7500        \u001b[35m0.6342\u001b[0m  0.0329\n",
      "     19        \u001b[36m0.6190\u001b[0m       0.7500        \u001b[35m0.6304\u001b[0m  0.0266\n",
      "     20        \u001b[36m0.6119\u001b[0m       0.7500        \u001b[35m0.6266\u001b[0m  0.0226\n",
      "     21        0.6125       0.7578        \u001b[35m0.6231\u001b[0m  0.0242\n",
      "     22        \u001b[36m0.6013\u001b[0m       0.7500        \u001b[35m0.6192\u001b[0m  0.0284\n",
      "     23        \u001b[36m0.5962\u001b[0m       0.7500        \u001b[35m0.6153\u001b[0m  0.0235\n",
      "     24        \u001b[36m0.5882\u001b[0m       0.7500        \u001b[35m0.6113\u001b[0m  0.0271\n",
      "     25        0.5908       0.7578        \u001b[35m0.6078\u001b[0m  0.0285\n",
      "     26        \u001b[36m0.5873\u001b[0m       0.7578        \u001b[35m0.6044\u001b[0m  0.0423\n",
      "     27        \u001b[36m0.5827\u001b[0m       0.7578        \u001b[35m0.6010\u001b[0m  0.0247\n",
      "     28        0.5831       0.7422        \u001b[35m0.5980\u001b[0m  0.0204\n",
      "     29        0.5828       0.7422        \u001b[35m0.5952\u001b[0m  0.0397\n",
      "     30        \u001b[36m0.5762\u001b[0m       0.7500        \u001b[35m0.5921\u001b[0m  0.0209\n",
      "     31        \u001b[36m0.5760\u001b[0m       0.7500        \u001b[35m0.5894\u001b[0m  0.0246\n",
      "     32        \u001b[36m0.5575\u001b[0m       0.7500        \u001b[35m0.5864\u001b[0m  0.0435\n",
      "     33        \u001b[36m0.5571\u001b[0m       0.7422        \u001b[35m0.5836\u001b[0m  0.0340\n",
      "     34        0.5761       0.7422        \u001b[35m0.5814\u001b[0m  0.0466\n",
      "     35        0.5575       0.7422        \u001b[35m0.5791\u001b[0m  0.0255\n",
      "     36        \u001b[36m0.5488\u001b[0m       0.7422        \u001b[35m0.5768\u001b[0m  0.0208\n",
      "     37        0.5609       0.7422        \u001b[35m0.5748\u001b[0m  0.0411\n",
      "     38        \u001b[36m0.5439\u001b[0m       0.7422        \u001b[35m0.5727\u001b[0m  0.0240\n",
      "     39        0.5500       0.7422        \u001b[35m0.5709\u001b[0m  0.0208\n",
      "     40        0.5479       0.7422        \u001b[35m0.5692\u001b[0m  0.0265\n",
      "     41        0.5502       0.7422        \u001b[35m0.5678\u001b[0m  0.0472\n",
      "     42        0.5451       0.7344        \u001b[35m0.5663\u001b[0m  0.0262\n",
      "     43        0.5480       0.7344        \u001b[35m0.5651\u001b[0m  0.0219\n",
      "     44        \u001b[36m0.5381\u001b[0m       0.7344        \u001b[35m0.5638\u001b[0m  0.0215\n",
      "     45        \u001b[36m0.5319\u001b[0m       0.7344        \u001b[35m0.5626\u001b[0m  0.0225\n",
      "     46        0.5463       0.7344        \u001b[35m0.5616\u001b[0m  0.0427\n",
      "     47        0.5390       0.7344        \u001b[35m0.5606\u001b[0m  0.0561\n",
      "     48        \u001b[36m0.5234\u001b[0m       0.7344        \u001b[35m0.5595\u001b[0m  0.0256\n",
      "     49        0.5384       0.7344        \u001b[35m0.5585\u001b[0m  0.0341\n",
      "     50        \u001b[36m0.5224\u001b[0m       0.7344        \u001b[35m0.5576\u001b[0m  0.0271\n",
      "     51        0.5323       0.7344        \u001b[35m0.5568\u001b[0m  0.0227\n",
      "     52        0.5364       0.7344        \u001b[35m0.5564\u001b[0m  0.0259\n",
      "     53        0.5288       0.7344        \u001b[35m0.5557\u001b[0m  0.0311\n",
      "     54        0.5241       0.7344        \u001b[35m0.5551\u001b[0m  0.0271\n",
      "     55        \u001b[36m0.5220\u001b[0m       0.7344        \u001b[35m0.5544\u001b[0m  0.0239\n",
      "     56        0.5350       0.7344        \u001b[35m0.5539\u001b[0m  0.0299\n",
      "     57        \u001b[36m0.5182\u001b[0m       0.7344        \u001b[35m0.5533\u001b[0m  0.0259\n",
      "     58        \u001b[36m0.5146\u001b[0m       0.7344        \u001b[35m0.5527\u001b[0m  0.0248\n",
      "     59        0.5291       0.7344        \u001b[35m0.5520\u001b[0m  0.0252\n",
      "     60        0.5240       0.7422        \u001b[35m0.5514\u001b[0m  0.0234\n",
      "     61        0.5314       0.7344        \u001b[35m0.5511\u001b[0m  0.0226\n",
      "     62        0.5178       0.7344        \u001b[35m0.5507\u001b[0m  0.0254\n",
      "     63        0.5211       0.7344        \u001b[35m0.5501\u001b[0m  0.0233\n",
      "     64        0.5177       0.7344        \u001b[35m0.5497\u001b[0m  0.0267\n",
      "     65        \u001b[36m0.4982\u001b[0m       0.7344        \u001b[35m0.5491\u001b[0m  0.0272\n",
      "     66        0.5179       0.7344        \u001b[35m0.5488\u001b[0m  0.0247\n",
      "     67        0.5385       0.7266        \u001b[35m0.5484\u001b[0m  0.0324\n",
      "     68        0.5218       0.7266        \u001b[35m0.5479\u001b[0m  0.0333\n",
      "     69        0.5271       0.7266        \u001b[35m0.5478\u001b[0m  0.0237\n",
      "     70        0.5159       0.7266        \u001b[35m0.5474\u001b[0m  0.0255\n",
      "     71        0.5155       0.7266        \u001b[35m0.5469\u001b[0m  0.0317\n",
      "     72        0.5256       0.7188        \u001b[35m0.5468\u001b[0m  0.0225\n",
      "     73        0.5096       0.7188        \u001b[35m0.5466\u001b[0m  0.0412\n",
      "     74        0.5197       0.7188        \u001b[35m0.5463\u001b[0m  0.0206\n",
      "     75        0.5021       0.7188        \u001b[35m0.5458\u001b[0m  0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     76        0.5268       0.7188        0.5459  0.0444\n",
      "     77        0.5185       0.7188        \u001b[35m0.5457\u001b[0m  0.0274\n",
      "     78        0.5134       0.7188        \u001b[35m0.5456\u001b[0m  0.0235\n",
      "     79        0.5237       0.7188        0.5456  0.0258\n",
      "     80        0.4996       0.7188        \u001b[35m0.5450\u001b[0m  0.0354\n",
      "     81        0.5181       0.7188        0.5451  0.0198\n",
      "     82        0.4994       0.7188        \u001b[35m0.5449\u001b[0m  0.0425\n",
      "     83        0.5206       0.7188        \u001b[35m0.5446\u001b[0m  0.0219\n",
      "     84        0.5043       0.7188        \u001b[35m0.5442\u001b[0m  0.0247\n",
      "     85        0.5198       0.7188        \u001b[35m0.5440\u001b[0m  0.0426\n",
      "     86        0.5159       0.7188        \u001b[35m0.5439\u001b[0m  0.0190\n",
      "     87        0.5010       0.7188        \u001b[35m0.5438\u001b[0m  0.0215\n",
      "     88        0.5033       0.7188        \u001b[35m0.5435\u001b[0m  0.0291\n",
      "     89        0.5090       0.7188        \u001b[35m0.5434\u001b[0m  0.0246\n",
      "     90        0.5023       0.7188        \u001b[35m0.5432\u001b[0m  0.0216\n",
      "     91        0.5066       0.7188        \u001b[35m0.5430\u001b[0m  0.0211\n",
      "     92        \u001b[36m0.4944\u001b[0m       0.7188        \u001b[35m0.5429\u001b[0m  0.0226\n",
      "     93        0.5003       0.7188        \u001b[35m0.5428\u001b[0m  0.0239\n",
      "     94        \u001b[36m0.4819\u001b[0m       0.7188        \u001b[35m0.5424\u001b[0m  0.0254\n",
      "     95        0.5048       0.7188        \u001b[35m0.5424\u001b[0m  0.0213\n",
      "     96        0.4912       0.7188        \u001b[35m0.5421\u001b[0m  0.0213\n",
      "     97        0.5040       0.7188        0.5422  0.0233\n",
      "     98        0.5068       0.7188        \u001b[35m0.5421\u001b[0m  0.0341\n",
      "     99        0.5159       0.7109        \u001b[35m0.5419\u001b[0m  0.0234\n",
      "    100        0.4872       0.7188        \u001b[35m0.5418\u001b[0m  0.0243\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7433\u001b[0m       \u001b[32m0.4297\u001b[0m        \u001b[35m0.7211\u001b[0m  0.0200\n",
      "      2        \u001b[36m0.7363\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m0.7129\u001b[0m  0.0324\n",
      "      3        \u001b[36m0.7287\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.7054\u001b[0m  0.0379\n",
      "      4        \u001b[36m0.7152\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6993\u001b[0m  0.0209\n",
      "      5        \u001b[36m0.7065\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6934\u001b[0m  0.0250\n",
      "      6        \u001b[36m0.6995\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6866\u001b[0m  0.0267\n",
      "      7        \u001b[36m0.6947\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6805\u001b[0m  0.0336\n",
      "      8        \u001b[36m0.6931\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6745\u001b[0m  0.0287\n",
      "      9        \u001b[36m0.6814\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6685\u001b[0m  0.0246\n",
      "     10        \u001b[36m0.6699\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6624\u001b[0m  0.0258\n",
      "     11        \u001b[36m0.6668\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6564\u001b[0m  0.0238\n",
      "     12        \u001b[36m0.6594\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6512\u001b[0m  0.0248\n",
      "     13        \u001b[36m0.6521\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6464\u001b[0m  0.0419\n",
      "     14        \u001b[36m0.6455\u001b[0m       0.7031        \u001b[35m0.6411\u001b[0m  0.0381\n",
      "     15        \u001b[36m0.6439\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6359\u001b[0m  0.0254\n",
      "     16        \u001b[36m0.6366\u001b[0m       0.7109        \u001b[35m0.6307\u001b[0m  0.0235\n",
      "     17        \u001b[36m0.6307\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6256\u001b[0m  0.0335\n",
      "     18        \u001b[36m0.6212\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6203\u001b[0m  0.0411\n",
      "     19        0.6252       0.7266        \u001b[35m0.6160\u001b[0m  0.0215\n",
      "     20        \u001b[36m0.6123\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6114\u001b[0m  0.0226\n",
      "     21        \u001b[36m0.6082\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6073\u001b[0m  0.0253\n",
      "     22        \u001b[36m0.6029\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6037\u001b[0m  0.0227\n",
      "     23        \u001b[36m0.5983\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5998\u001b[0m  0.0235\n",
      "     24        \u001b[36m0.5978\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5963\u001b[0m  0.0377\n",
      "     25        \u001b[36m0.5879\u001b[0m       0.7578        \u001b[35m0.5927\u001b[0m  0.0285\n",
      "     26        \u001b[36m0.5852\u001b[0m       0.7422        \u001b[35m0.5891\u001b[0m  0.0301\n",
      "     27        \u001b[36m0.5757\u001b[0m       0.7422        \u001b[35m0.5856\u001b[0m  0.0306\n",
      "     28        0.5766       0.7422        \u001b[35m0.5824\u001b[0m  0.0454\n",
      "     29        0.5813       0.7344        \u001b[35m0.5795\u001b[0m  0.0288\n",
      "     30        \u001b[36m0.5714\u001b[0m       0.7266        \u001b[35m0.5766\u001b[0m  0.0264\n",
      "     31        0.5716       0.7344        \u001b[35m0.5740\u001b[0m  0.0282\n",
      "     32        \u001b[36m0.5599\u001b[0m       0.7344        \u001b[35m0.5714\u001b[0m  0.0229\n",
      "     33        0.5674       0.7344        \u001b[35m0.5690\u001b[0m  0.0246\n",
      "     34        0.5647       0.7344        \u001b[35m0.5666\u001b[0m  0.0292\n",
      "     35        \u001b[36m0.5556\u001b[0m       0.7344        \u001b[35m0.5643\u001b[0m  0.0331\n",
      "     36        0.5612       0.7344        \u001b[35m0.5623\u001b[0m  0.0228\n",
      "     37        \u001b[36m0.5505\u001b[0m       0.7344        \u001b[35m0.5605\u001b[0m  0.0216\n",
      "     38        \u001b[36m0.5335\u001b[0m       0.7344        \u001b[35m0.5583\u001b[0m  0.0219\n",
      "     39        0.5476       0.7344        \u001b[35m0.5565\u001b[0m  0.0256\n",
      "     40        0.5432       0.7344        \u001b[35m0.5548\u001b[0m  0.0260\n",
      "     41        0.5430       0.7344        \u001b[35m0.5531\u001b[0m  0.0277\n",
      "     42        0.5345       0.7500        \u001b[35m0.5516\u001b[0m  0.0259\n",
      "     43        0.5343       0.7500        \u001b[35m0.5501\u001b[0m  0.0444\n",
      "     44        \u001b[36m0.5262\u001b[0m       0.7578        \u001b[35m0.5487\u001b[0m  0.0297\n",
      "     45        \u001b[36m0.5261\u001b[0m       0.7656        \u001b[35m0.5474\u001b[0m  0.0252\n",
      "     46        0.5386       0.7578        \u001b[35m0.5462\u001b[0m  0.0444\n",
      "     47        0.5487       0.7578        \u001b[35m0.5451\u001b[0m  0.0252\n",
      "     48        \u001b[36m0.5256\u001b[0m       0.7500        \u001b[35m0.5439\u001b[0m  0.0250\n",
      "     49        0.5354       0.7500        \u001b[35m0.5429\u001b[0m  0.0274\n",
      "     50        0.5270       0.7500        \u001b[35m0.5419\u001b[0m  0.0388\n",
      "     51        \u001b[36m0.5246\u001b[0m       0.7500        \u001b[35m0.5410\u001b[0m  0.0242\n",
      "     52        0.5288       0.7500        \u001b[35m0.5401\u001b[0m  0.0254\n",
      "     53        \u001b[36m0.5198\u001b[0m       0.7500        \u001b[35m0.5394\u001b[0m  0.0275\n",
      "     54        \u001b[36m0.5166\u001b[0m       0.7500        \u001b[35m0.5386\u001b[0m  0.0288\n",
      "     55        \u001b[36m0.5143\u001b[0m       0.7500        \u001b[35m0.5379\u001b[0m  0.0264\n",
      "     56        0.5206       0.7500        \u001b[35m0.5374\u001b[0m  0.0257\n",
      "     57        \u001b[36m0.5132\u001b[0m       0.7500        \u001b[35m0.5367\u001b[0m  0.0266\n",
      "     58        0.5153       0.7500        \u001b[35m0.5360\u001b[0m  0.0286\n",
      "     59        \u001b[36m0.5126\u001b[0m       0.7500        \u001b[35m0.5353\u001b[0m  0.0261\n",
      "     60        0.5173       0.7500        \u001b[35m0.5349\u001b[0m  0.0339\n",
      "     61        \u001b[36m0.5048\u001b[0m       0.7500        \u001b[35m0.5346\u001b[0m  0.0232\n",
      "     62        0.5059       0.7500        \u001b[35m0.5341\u001b[0m  0.0331\n",
      "     63        0.5072       0.7500        \u001b[35m0.5339\u001b[0m  0.0248\n",
      "     64        \u001b[36m0.5044\u001b[0m       0.7500        \u001b[35m0.5335\u001b[0m  0.0263\n",
      "     65        0.5146       0.7422        \u001b[35m0.5330\u001b[0m  0.0257\n",
      "     66        0.5147       0.7422        \u001b[35m0.5325\u001b[0m  0.0267\n",
      "     67        \u001b[36m0.5023\u001b[0m       0.7422        \u001b[35m0.5321\u001b[0m  0.0318\n",
      "     68        0.5049       0.7422        0.5321  0.0291\n",
      "     69        \u001b[36m0.4924\u001b[0m       0.7422        \u001b[35m0.5320\u001b[0m  0.0216\n",
      "     70        0.5154       0.7422        \u001b[35m0.5316\u001b[0m  0.0254\n",
      "     71        0.5051       0.7422        \u001b[35m0.5314\u001b[0m  0.0264\n",
      "     72        0.5017       0.7422        \u001b[35m0.5308\u001b[0m  0.0291\n",
      "     73        0.5034       0.7422        \u001b[35m0.5303\u001b[0m  0.0241\n",
      "     74        0.5172       0.7422        \u001b[35m0.5301\u001b[0m  0.0247\n",
      "     75        0.5115       0.7422        \u001b[35m0.5300\u001b[0m  0.0246\n",
      "     76        \u001b[36m0.4918\u001b[0m       0.7422        \u001b[35m0.5300\u001b[0m  0.0237\n",
      "     77        \u001b[36m0.4904\u001b[0m       0.7422        \u001b[35m0.5298\u001b[0m  0.0266\n",
      "     78        0.5073       0.7422        \u001b[35m0.5293\u001b[0m  0.0317\n",
      "     79        0.5111       0.7422        \u001b[35m0.5291\u001b[0m  0.0274\n",
      "     80        0.4916       0.7422        \u001b[35m0.5291\u001b[0m  0.0266\n",
      "     81        0.5056       0.7344        0.5292  0.0267\n",
      "     82        0.5034       0.7344        \u001b[35m0.5289\u001b[0m  0.0220\n",
      "     83        0.4906       0.7344        \u001b[35m0.5288\u001b[0m  0.0228\n",
      "     84        0.4990       0.7344        \u001b[35m0.5282\u001b[0m  0.0599\n",
      "     85        0.5075       0.7344        \u001b[35m0.5279\u001b[0m  0.0243\n",
      "     86        0.5026       0.7344        \u001b[35m0.5273\u001b[0m  0.0241\n",
      "     87        \u001b[36m0.4883\u001b[0m       0.7344        \u001b[35m0.5272\u001b[0m  0.0251\n",
      "     88        0.4911       0.7266        \u001b[35m0.5271\u001b[0m  0.0231\n",
      "     89        0.5016       0.7266        0.5272  0.0256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     90        0.4916       0.7266        0.5272  0.0435\n",
      "     91        0.5004       0.7266        \u001b[35m0.5271\u001b[0m  0.0232\n",
      "     92        0.4971       0.7266        \u001b[35m0.5269\u001b[0m  0.0312\n",
      "     93        \u001b[36m0.4850\u001b[0m       0.7266        \u001b[35m0.5267\u001b[0m  0.0248\n",
      "     94        0.4885       0.7266        \u001b[35m0.5264\u001b[0m  0.0293\n",
      "     95        \u001b[36m0.4819\u001b[0m       0.7266        \u001b[35m0.5263\u001b[0m  0.0281\n",
      "     96        0.4832       0.7266        0.5265  0.0292\n",
      "     97        0.4978       0.7266        \u001b[35m0.5262\u001b[0m  0.0252\n",
      "     98        0.4975       0.7266        \u001b[35m0.5261\u001b[0m  0.0325\n",
      "     99        0.5160       0.7266        \u001b[35m0.5260\u001b[0m  0.0240\n",
      "    100        \u001b[36m0.4786\u001b[0m       0.7188        0.5265  0.0272\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6134\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5332\u001b[0m  0.0352\n",
      "      2        \u001b[36m0.5663\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4873\u001b[0m  0.0356\n",
      "      3        \u001b[36m0.5632\u001b[0m       0.7812        \u001b[35m0.4629\u001b[0m  0.0425\n",
      "      4        \u001b[36m0.5503\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4463\u001b[0m  0.0356\n",
      "      5        \u001b[36m0.5432\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4420\u001b[0m  0.0413\n",
      "      6        \u001b[36m0.5294\u001b[0m       0.7969        \u001b[35m0.4218\u001b[0m  0.0342\n",
      "      7        \u001b[36m0.5264\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4155\u001b[0m  0.0480\n",
      "      8        0.5308       0.8125        0.4223  0.0343\n",
      "      9        \u001b[36m0.5111\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m0.4113\u001b[0m  0.0373\n",
      "     10        0.5388       0.8203        0.4198  0.0430\n",
      "     11        0.5215       0.8125        0.4174  0.0424\n",
      "     12        0.5238       0.8281        0.4187  0.0410\n",
      "     13        0.5295       0.8203        0.4163  0.0426\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6551\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5781\u001b[0m  0.0328\n",
      "      2        \u001b[36m0.5926\u001b[0m       0.7109        \u001b[35m0.5481\u001b[0m  0.0426\n",
      "      3        \u001b[36m0.5355\u001b[0m       0.7031        \u001b[35m0.5351\u001b[0m  0.0363\n",
      "      4        \u001b[36m0.5338\u001b[0m       0.6953        0.5352  0.0399\n",
      "      5        \u001b[36m0.5227\u001b[0m       0.6875        \u001b[35m0.5351\u001b[0m  0.0384\n",
      "      6        \u001b[36m0.5162\u001b[0m       0.7188        \u001b[35m0.5280\u001b[0m  0.0441\n",
      "      7        \u001b[36m0.5152\u001b[0m       0.7109        \u001b[35m0.5240\u001b[0m  0.0367\n",
      "      8        \u001b[36m0.5021\u001b[0m       0.7031        0.5257  0.0391\n",
      "      9        0.5296       0.6953        0.5282  0.0424\n",
      "     10        0.5039       0.7109        \u001b[35m0.5227\u001b[0m  0.0364\n",
      "     11        0.5097       0.6953        0.5298  0.0402\n",
      "     12        0.5073       0.7031        0.5264  0.0354\n",
      "     13        0.5033       0.6875        0.5391  0.0416\n",
      "     14        0.5102       0.7031        0.5293  0.0356\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6650\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5887\u001b[0m  0.0339\n",
      "      2        \u001b[36m0.5813\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5544\u001b[0m  0.0453\n",
      "      3        \u001b[36m0.5386\u001b[0m       0.7344        \u001b[35m0.5466\u001b[0m  0.0403\n",
      "      4        \u001b[36m0.5332\u001b[0m       0.7422        \u001b[35m0.5375\u001b[0m  0.0504\n",
      "      5        \u001b[36m0.5156\u001b[0m       0.7422        \u001b[35m0.5354\u001b[0m  0.0430\n",
      "      6        \u001b[36m0.4998\u001b[0m       0.7266        \u001b[35m0.5322\u001b[0m  0.0462\n",
      "      7        0.5253       0.7031        \u001b[35m0.5320\u001b[0m  0.0512\n",
      "      8        0.5072       0.7188        \u001b[35m0.5305\u001b[0m  0.0406\n",
      "      9        \u001b[36m0.4988\u001b[0m       0.7266        \u001b[35m0.5298\u001b[0m  0.0359\n",
      "     10        0.5018       0.7188        \u001b[35m0.5264\u001b[0m  0.0387\n",
      "     11        \u001b[36m0.4980\u001b[0m       0.7031        \u001b[35m0.5259\u001b[0m  0.0325\n",
      "     12        \u001b[36m0.4904\u001b[0m       0.7031        \u001b[35m0.5254\u001b[0m  0.0392\n",
      "     13        \u001b[36m0.4805\u001b[0m       0.7031        0.5369  0.0332\n",
      "     14        0.4980       0.7109        0.5287  0.0406\n",
      "     15        0.5014       0.7109        0.5340  0.0367\n",
      "     16        \u001b[36m0.4763\u001b[0m       0.7188        0.5312  0.0391\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6044\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5752\u001b[0m  0.0297\n",
      "      2        \u001b[36m0.5368\u001b[0m       0.6797        \u001b[35m0.5583\u001b[0m  0.0395\n",
      "      3        \u001b[36m0.5039\u001b[0m       0.6797        0.5594  0.0362\n",
      "      4        \u001b[36m0.4961\u001b[0m       \u001b[32m0.6953\u001b[0m        0.5663  0.0331\n",
      "      5        \u001b[36m0.4939\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5567\u001b[0m  0.0490\n",
      "      6        \u001b[36m0.4696\u001b[0m       0.6953        \u001b[35m0.5523\u001b[0m  0.0382\n",
      "      7        0.5039       0.6875        \u001b[35m0.5519\u001b[0m  0.0372\n",
      "      8        0.4970       0.6875        0.5537  0.0381\n",
      "      9        0.4814       0.6641        0.5587  0.0364\n",
      "     10        0.4851       0.6797        0.5600  0.0365\n",
      "     11        \u001b[36m0.4684\u001b[0m       0.6797        0.5596  0.0340\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6960\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6291\u001b[0m  0.0329\n",
      "      2        \u001b[36m0.5673\u001b[0m       0.7031        \u001b[35m0.5377\u001b[0m  0.0593\n",
      "      3        \u001b[36m0.5126\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5223\u001b[0m  0.0359\n",
      "      4        \u001b[36m0.4644\u001b[0m       0.7344        0.5254  0.0346\n",
      "      5        0.4836       0.7422        \u001b[35m0.5222\u001b[0m  0.0408\n",
      "      6        0.4879       0.7344        0.5266  0.0304\n",
      "      7        0.4847       0.7344        \u001b[35m0.5128\u001b[0m  0.0344\n",
      "      8        0.4875       0.7344        \u001b[35m0.5122\u001b[0m  0.0351\n",
      "      9        0.4767       0.7422        \u001b[35m0.5118\u001b[0m  0.0331\n",
      "     10        0.4650       0.7188        0.5248  0.0323\n",
      "     11        \u001b[36m0.4576\u001b[0m       0.7188        0.5274  0.0343\n",
      "     12        0.4659       0.7109        0.5335  0.0377\n",
      "     13        \u001b[36m0.4514\u001b[0m       0.7344        0.5317  0.0464\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7522\u001b[0m       \u001b[32m0.3984\u001b[0m        \u001b[35m0.7296\u001b[0m  0.0108\n",
      "      2        \u001b[36m0.7194\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6910\u001b[0m  0.0123\n",
      "      3        \u001b[36m0.6866\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6606\u001b[0m  0.0176\n",
      "      4        \u001b[36m0.6554\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6360\u001b[0m  0.0234\n",
      "      5        0.6611       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6169\u001b[0m  0.0192\n",
      "      6        \u001b[36m0.6353\u001b[0m       0.7344        \u001b[35m0.5995\u001b[0m  0.0162\n",
      "      7        \u001b[36m0.6328\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5836\u001b[0m  0.0222\n",
      "      8        \u001b[36m0.6209\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5697\u001b[0m  0.0260\n",
      "      9        \u001b[36m0.6019\u001b[0m       0.7500        \u001b[35m0.5538\u001b[0m  0.0217\n",
      "     10        0.6110       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5431\u001b[0m  0.0181\n",
      "     11        \u001b[36m0.5935\u001b[0m       0.7578        \u001b[35m0.5314\u001b[0m  0.0141\n",
      "     12        0.6096       0.7578        \u001b[35m0.5227\u001b[0m  0.0188\n",
      "     13        \u001b[36m0.5932\u001b[0m       0.7578        \u001b[35m0.5165\u001b[0m  0.0156\n",
      "     14        \u001b[36m0.5906\u001b[0m       0.7578        \u001b[35m0.5105\u001b[0m  0.0248\n",
      "     15        \u001b[36m0.5791\u001b[0m       0.7578        \u001b[35m0.5048\u001b[0m  0.0134\n",
      "     16        0.5981       0.7578        \u001b[35m0.5007\u001b[0m  0.0181\n",
      "     17        0.5876       0.7578        \u001b[35m0.4977\u001b[0m  0.0188\n",
      "     18        0.5910       0.7578        \u001b[35m0.4973\u001b[0m  0.0260\n",
      "     19        0.5885       0.7422        \u001b[35m0.4951\u001b[0m  0.0147\n",
      "     20        0.5898       0.7500        \u001b[35m0.4950\u001b[0m  0.0184\n",
      "     21        \u001b[36m0.5738\u001b[0m       0.7500        \u001b[35m0.4924\u001b[0m  0.0146\n",
      "     22        0.5959       0.7578        \u001b[35m0.4917\u001b[0m  0.0226\n",
      "     23        0.5954       0.7422        \u001b[35m0.4916\u001b[0m  0.0163\n",
      "     24        \u001b[36m0.5716\u001b[0m       0.7656        \u001b[35m0.4894\u001b[0m  0.0151\n",
      "     25        \u001b[36m0.5634\u001b[0m       0.7656        \u001b[35m0.4852\u001b[0m  0.0209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     26        0.5644       0.7656        \u001b[35m0.4798\u001b[0m  0.0150\n",
      "     27        0.5636       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4750\u001b[0m  0.0218\n",
      "     28        0.5753       0.7812        \u001b[35m0.4721\u001b[0m  0.0149\n",
      "     29        0.5728       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4684\u001b[0m  0.0184\n",
      "     30        0.5720       0.7734        \u001b[35m0.4660\u001b[0m  0.0201\n",
      "     31        \u001b[36m0.5634\u001b[0m       0.7812        \u001b[35m0.4650\u001b[0m  0.0181\n",
      "     32        \u001b[36m0.5569\u001b[0m       0.7891        \u001b[35m0.4635\u001b[0m  0.0334\n",
      "     33        0.5683       0.7812        \u001b[35m0.4620\u001b[0m  0.0227\n",
      "     34        0.5643       0.7891        \u001b[35m0.4608\u001b[0m  0.0264\n",
      "     35        0.5639       0.7891        \u001b[35m0.4593\u001b[0m  0.0203\n",
      "     36        0.5721       0.7812        \u001b[35m0.4583\u001b[0m  0.0188\n",
      "     37        0.5647       0.7734        \u001b[35m0.4577\u001b[0m  0.0333\n",
      "     38        \u001b[36m0.5461\u001b[0m       0.7734        \u001b[35m0.4559\u001b[0m  0.0214\n",
      "     39        \u001b[36m0.5453\u001b[0m       0.7734        \u001b[35m0.4527\u001b[0m  0.0190\n",
      "     40        \u001b[36m0.5451\u001b[0m       0.7734        \u001b[35m0.4498\u001b[0m  0.0171\n",
      "     41        0.5458       0.7734        \u001b[35m0.4468\u001b[0m  0.0420\n",
      "     42        \u001b[36m0.5451\u001b[0m       0.7734        \u001b[35m0.4458\u001b[0m  0.0223\n",
      "     43        0.5618       0.7734        \u001b[35m0.4454\u001b[0m  0.0145\n",
      "     44        0.5665       0.7734        \u001b[35m0.4446\u001b[0m  0.0240\n",
      "     45        0.5669       0.7812        0.4461  0.0258\n",
      "     46        0.5716       0.7812        0.4460  0.0541\n",
      "     47        0.5460       0.7812        0.4471  0.0219\n",
      "     48        0.5547       0.7812        0.4456  0.0151\n",
      "     49        0.5459       0.7891        \u001b[35m0.4419\u001b[0m  0.0156\n",
      "     50        \u001b[36m0.5390\u001b[0m       0.7891        \u001b[35m0.4402\u001b[0m  0.0371\n",
      "     51        0.5546       0.7891        \u001b[35m0.4384\u001b[0m  0.0187\n",
      "     52        \u001b[36m0.5219\u001b[0m       0.7891        \u001b[35m0.4360\u001b[0m  0.0212\n",
      "     53        \u001b[36m0.5191\u001b[0m       0.7812        \u001b[35m0.4303\u001b[0m  0.0143\n",
      "     54        0.5408       0.7812        \u001b[35m0.4263\u001b[0m  0.0263\n",
      "     55        0.5508       0.7812        \u001b[35m0.4248\u001b[0m  0.0329\n",
      "     56        0.5632       0.7812        \u001b[35m0.4244\u001b[0m  0.0274\n",
      "     57        0.5406       \u001b[32m0.7969\u001b[0m        0.4267  0.0200\n",
      "     58        0.5474       0.7812        0.4272  0.0216\n",
      "     59        0.5424       0.7969        0.4269  0.0165\n",
      "     60        0.5344       0.7969        0.4264  0.0192\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7257\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7058\u001b[0m  0.0169\n",
      "      2        \u001b[36m0.6816\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6606\u001b[0m  0.0169\n",
      "      3        \u001b[36m0.6503\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6322\u001b[0m  0.0245\n",
      "      4        \u001b[36m0.6385\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6157\u001b[0m  0.0235\n",
      "      5        0.6387       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6036\u001b[0m  0.0165\n",
      "      6        \u001b[36m0.6246\u001b[0m       0.7578        \u001b[35m0.5924\u001b[0m  0.0206\n",
      "      7        \u001b[36m0.6220\u001b[0m       0.7500        \u001b[35m0.5850\u001b[0m  0.0203\n",
      "      8        0.6286       0.7422        \u001b[35m0.5796\u001b[0m  0.0188\n",
      "      9        \u001b[36m0.6077\u001b[0m       0.7344        \u001b[35m0.5750\u001b[0m  0.0411\n",
      "     10        \u001b[36m0.6047\u001b[0m       0.7266        \u001b[35m0.5717\u001b[0m  0.0391\n",
      "     11        0.6170       0.7266        \u001b[35m0.5680\u001b[0m  0.0196\n",
      "     12        0.6136       0.7344        \u001b[35m0.5655\u001b[0m  0.0187\n",
      "     13        \u001b[36m0.5977\u001b[0m       0.7344        \u001b[35m0.5638\u001b[0m  0.0152\n",
      "     14        \u001b[36m0.5949\u001b[0m       0.7344        \u001b[35m0.5614\u001b[0m  0.0196\n",
      "     15        \u001b[36m0.5772\u001b[0m       0.7422        \u001b[35m0.5589\u001b[0m  0.0160\n",
      "     16        0.5928       0.7500        \u001b[35m0.5555\u001b[0m  0.0236\n",
      "     17        0.5989       0.7422        \u001b[35m0.5532\u001b[0m  0.0158\n",
      "     18        \u001b[36m0.5603\u001b[0m       0.7500        \u001b[35m0.5511\u001b[0m  0.0230\n",
      "     19        \u001b[36m0.5588\u001b[0m       0.7500        \u001b[35m0.5489\u001b[0m  0.0160\n",
      "     20        0.5727       0.7500        \u001b[35m0.5470\u001b[0m  0.0255\n",
      "     21        0.5819       0.7422        \u001b[35m0.5468\u001b[0m  0.0238\n",
      "     22        0.5928       0.7500        \u001b[35m0.5462\u001b[0m  0.0161\n",
      "     23        0.5673       0.7422        \u001b[35m0.5459\u001b[0m  0.0255\n",
      "     24        \u001b[36m0.5518\u001b[0m       0.7266        \u001b[35m0.5454\u001b[0m  0.0233\n",
      "     25        0.5573       0.7266        \u001b[35m0.5446\u001b[0m  0.0148\n",
      "     26        0.5763       0.7188        \u001b[35m0.5437\u001b[0m  0.0246\n",
      "     27        0.5640       0.7188        \u001b[35m0.5422\u001b[0m  0.0161\n",
      "     28        0.5581       0.7188        \u001b[35m0.5417\u001b[0m  0.0246\n",
      "     29        0.5704       0.7188        \u001b[35m0.5407\u001b[0m  0.0237\n",
      "     30        0.5618       0.7188        \u001b[35m0.5396\u001b[0m  0.1077\n",
      "     31        \u001b[36m0.5479\u001b[0m       0.7188        \u001b[35m0.5391\u001b[0m  0.0294\n",
      "     32        0.5586       0.7188        \u001b[35m0.5377\u001b[0m  0.0239\n",
      "     33        \u001b[36m0.5466\u001b[0m       0.7188        \u001b[35m0.5364\u001b[0m  0.0213\n",
      "     34        0.5654       0.7188        \u001b[35m0.5358\u001b[0m  0.0232\n",
      "     35        0.5483       0.7109        \u001b[35m0.5354\u001b[0m  0.0199\n",
      "     36        \u001b[36m0.5430\u001b[0m       0.7109        \u001b[35m0.5350\u001b[0m  0.0145\n",
      "     37        0.5495       0.7109        \u001b[35m0.5346\u001b[0m  0.0154\n",
      "     38        \u001b[36m0.5331\u001b[0m       0.7109        \u001b[35m0.5342\u001b[0m  0.0145\n",
      "     39        0.5674       0.7109        \u001b[35m0.5337\u001b[0m  0.0135\n",
      "     40        0.5382       0.7109        \u001b[35m0.5332\u001b[0m  0.0179\n",
      "     41        0.5382       0.7109        \u001b[35m0.5330\u001b[0m  0.0141\n",
      "     42        0.5409       0.7109        0.5330  0.0147\n",
      "     43        0.5411       0.7109        0.5330  0.0152\n",
      "     44        \u001b[36m0.5266\u001b[0m       0.7109        \u001b[35m0.5329\u001b[0m  0.0145\n",
      "     45        0.5403       0.7109        \u001b[35m0.5324\u001b[0m  0.0188\n",
      "     46        0.5390       0.7109        \u001b[35m0.5322\u001b[0m  0.0725\n",
      "     47        0.5330       0.7109        0.5323  0.1159\n",
      "     48        0.5343       0.7109        0.5328  0.0215\n",
      "     49        0.5603       0.7109        0.5327  0.0270\n",
      "     50        0.5360       0.7109        0.5331  0.0568\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6912\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6849\u001b[0m  0.0331\n",
      "      2        \u001b[36m0.6669\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6636\u001b[0m  0.0245\n",
      "      3        \u001b[36m0.6478\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6454\u001b[0m  0.0385\n",
      "      4        \u001b[36m0.6313\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6290\u001b[0m  0.0173\n",
      "      5        \u001b[36m0.6224\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6150\u001b[0m  0.0437\n",
      "      6        \u001b[36m0.6047\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6025\u001b[0m  0.0196\n",
      "      7        0.6212       0.6953        \u001b[35m0.5912\u001b[0m  0.0158\n",
      "      8        \u001b[36m0.5856\u001b[0m       0.6953        \u001b[35m0.5828\u001b[0m  0.0185\n",
      "      9        0.5958       0.6875        \u001b[35m0.5757\u001b[0m  0.0214\n",
      "     10        \u001b[36m0.5699\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5698\u001b[0m  0.1027\n",
      "     11        0.5889       0.6953        \u001b[35m0.5655\u001b[0m  0.0405\n",
      "     12        0.5728       0.6953        \u001b[35m0.5619\u001b[0m  0.0185\n",
      "     13        0.5714       0.6953        \u001b[35m0.5581\u001b[0m  0.0259\n",
      "     14        0.5728       0.7031        \u001b[35m0.5557\u001b[0m  0.0234\n",
      "     15        \u001b[36m0.5503\u001b[0m       0.7031        \u001b[35m0.5538\u001b[0m  0.0477\n",
      "     16        0.5662       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5528\u001b[0m  0.0242\n",
      "     17        \u001b[36m0.5444\u001b[0m       0.7109        \u001b[35m0.5511\u001b[0m  0.0327\n",
      "     18        \u001b[36m0.5417\u001b[0m       0.7109        \u001b[35m0.5494\u001b[0m  0.0173\n",
      "     19        0.5485       0.7031        \u001b[35m0.5478\u001b[0m  0.0250\n",
      "     20        0.5576       0.6953        \u001b[35m0.5474\u001b[0m  0.0366\n",
      "     21        0.5642       0.6953        \u001b[35m0.5459\u001b[0m  0.0163\n",
      "     22        0.5456       0.7031        \u001b[35m0.5446\u001b[0m  0.0222\n",
      "     23        0.5539       0.7109        \u001b[35m0.5435\u001b[0m  0.0283\n",
      "     24        \u001b[36m0.5415\u001b[0m       0.7031        \u001b[35m0.5431\u001b[0m  0.0338\n",
      "     25        0.5423       0.7031        0.5436  0.0191\n",
      "     26        \u001b[36m0.5337\u001b[0m       0.7031        \u001b[35m0.5426\u001b[0m  0.0195\n",
      "     27        0.5343       0.7031        \u001b[35m0.5421\u001b[0m  0.0300\n",
      "     28        0.5377       0.7031        \u001b[35m0.5404\u001b[0m  0.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     29        \u001b[36m0.5300\u001b[0m       0.6953        \u001b[35m0.5388\u001b[0m  0.0279\n",
      "     30        0.5507       0.7031        \u001b[35m0.5379\u001b[0m  0.0152\n",
      "     31        \u001b[36m0.5195\u001b[0m       0.6953        \u001b[35m0.5377\u001b[0m  0.0211\n",
      "     32        0.5450       0.7109        \u001b[35m0.5372\u001b[0m  0.0180\n",
      "     33        \u001b[36m0.5195\u001b[0m       0.7109        \u001b[35m0.5366\u001b[0m  0.0258\n",
      "     34        0.5323       0.7031        \u001b[35m0.5362\u001b[0m  0.0155\n",
      "     35        0.5236       0.7031        \u001b[35m0.5355\u001b[0m  0.0156\n",
      "     36        0.5232       0.7031        0.5357  0.0278\n",
      "     37        \u001b[36m0.5095\u001b[0m       0.7031        \u001b[35m0.5351\u001b[0m  0.0217\n",
      "     38        0.5404       0.7031        \u001b[35m0.5344\u001b[0m  0.0325\n",
      "     39        0.5220       0.7031        0.5349  0.0319\n",
      "     40        \u001b[36m0.5062\u001b[0m       0.7031        0.5347  0.0280\n",
      "     41        0.5326       0.7109        0.5346  0.0238\n",
      "     42        0.5273       0.7109        0.5344  0.0154\n",
      "     43        0.5404       0.7109        \u001b[35m0.5332\u001b[0m  0.0229\n",
      "     44        0.5250       0.6953        0.5337  0.0181\n",
      "     45        0.5286       0.7031        0.5345  0.0165\n",
      "     46        0.5314       0.7031        0.5357  0.0293\n",
      "     47        0.5106       0.7031        0.5361  0.0149\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6993\u001b[0m       \u001b[32m0.4453\u001b[0m        \u001b[35m0.7004\u001b[0m  0.0592\n",
      "      2        \u001b[36m0.6832\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6789\u001b[0m  0.0186\n",
      "      3        \u001b[36m0.6672\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6573\u001b[0m  0.0223\n",
      "      4        \u001b[36m0.6460\u001b[0m       0.6953        \u001b[35m0.6376\u001b[0m  0.0222\n",
      "      5        \u001b[36m0.6304\u001b[0m       0.6797        \u001b[35m0.6214\u001b[0m  0.0274\n",
      "      6        \u001b[36m0.6033\u001b[0m       0.6875        \u001b[35m0.6077\u001b[0m  0.0253\n",
      "      7        0.6070       0.7031        \u001b[35m0.5941\u001b[0m  0.0243\n",
      "      8        \u001b[36m0.5727\u001b[0m       0.7031        \u001b[35m0.5828\u001b[0m  0.0237\n",
      "      9        0.5987       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5743\u001b[0m  0.0242\n",
      "     10        \u001b[36m0.5702\u001b[0m       0.7109        \u001b[35m0.5681\u001b[0m  0.0173\n",
      "     11        \u001b[36m0.5679\u001b[0m       0.7031        \u001b[35m0.5626\u001b[0m  0.0172\n",
      "     12        0.5967       0.7109        \u001b[35m0.5585\u001b[0m  0.0216\n",
      "     13        \u001b[36m0.5582\u001b[0m       0.7109        \u001b[35m0.5561\u001b[0m  0.0153\n",
      "     14        0.5774       0.6875        \u001b[35m0.5541\u001b[0m  0.0239\n",
      "     15        0.5628       0.6953        \u001b[35m0.5514\u001b[0m  0.0223\n",
      "     16        \u001b[36m0.5476\u001b[0m       0.7109        \u001b[35m0.5485\u001b[0m  0.0152\n",
      "     17        0.5589       0.7109        \u001b[35m0.5463\u001b[0m  0.0206\n",
      "     18        0.5524       0.7031        \u001b[35m0.5449\u001b[0m  0.0199\n",
      "     19        0.5512       0.7031        \u001b[35m0.5445\u001b[0m  0.0174\n",
      "     20        \u001b[36m0.5404\u001b[0m       0.7109        \u001b[35m0.5444\u001b[0m  0.0246\n",
      "     21        0.5509       0.7109        \u001b[35m0.5436\u001b[0m  0.0241\n",
      "     22        0.5405       0.7031        \u001b[35m0.5430\u001b[0m  0.0286\n",
      "     23        0.5444       0.6953        \u001b[35m0.5421\u001b[0m  0.0147\n",
      "     24        0.5453       0.6953        \u001b[35m0.5416\u001b[0m  0.0223\n",
      "     25        \u001b[36m0.5337\u001b[0m       0.6953        \u001b[35m0.5405\u001b[0m  0.0166\n",
      "     26        0.5400       0.6953        \u001b[35m0.5404\u001b[0m  0.0248\n",
      "     27        \u001b[36m0.5164\u001b[0m       0.6953        \u001b[35m0.5401\u001b[0m  0.0309\n",
      "     28        0.5286       0.6953        0.5403  0.0370\n",
      "     29        0.5514       0.6875        0.5408  0.0245\n",
      "     30        \u001b[36m0.5127\u001b[0m       0.7031        0.5418  0.0155\n",
      "     31        0.5265       0.7031        0.5419  0.0228\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7245\u001b[0m       \u001b[32m0.4766\u001b[0m        \u001b[35m0.7002\u001b[0m  0.0204\n",
      "      2        \u001b[36m0.6998\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6710\u001b[0m  0.0184\n",
      "      3        \u001b[36m0.6685\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6479\u001b[0m  0.0185\n",
      "      4        \u001b[36m0.6518\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6303\u001b[0m  0.0161\n",
      "      5        \u001b[36m0.6422\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6171\u001b[0m  0.0158\n",
      "      6        \u001b[36m0.6290\u001b[0m       0.6953        \u001b[35m0.6057\u001b[0m  0.0320\n",
      "      7        \u001b[36m0.6159\u001b[0m       0.6953        \u001b[35m0.5956\u001b[0m  0.0258\n",
      "      8        \u001b[36m0.5852\u001b[0m       0.6953        \u001b[35m0.5856\u001b[0m  0.0235\n",
      "      9        0.5951       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5766\u001b[0m  0.0164\n",
      "     10        0.5915       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5699\u001b[0m  0.0258\n",
      "     11        0.5891       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5651\u001b[0m  0.0256\n",
      "     12        \u001b[36m0.5760\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5618\u001b[0m  0.0210\n",
      "     13        0.5898       0.7266        \u001b[35m0.5586\u001b[0m  0.0162\n",
      "     14        \u001b[36m0.5677\u001b[0m       0.7266        \u001b[35m0.5564\u001b[0m  0.0260\n",
      "     15        0.5824       0.7188        \u001b[35m0.5542\u001b[0m  0.0189\n",
      "     16        \u001b[36m0.5653\u001b[0m       0.7109        \u001b[35m0.5525\u001b[0m  0.0252\n",
      "     17        \u001b[36m0.5618\u001b[0m       0.7109        \u001b[35m0.5517\u001b[0m  0.0253\n",
      "     18        0.5668       0.7109        \u001b[35m0.5506\u001b[0m  0.0215\n",
      "     19        0.5664       0.7188        \u001b[35m0.5504\u001b[0m  0.0172\n",
      "     20        \u001b[36m0.5487\u001b[0m       0.7109        \u001b[35m0.5496\u001b[0m  0.0255\n",
      "     21        \u001b[36m0.5459\u001b[0m       0.7109        \u001b[35m0.5489\u001b[0m  0.0146\n",
      "     22        \u001b[36m0.5271\u001b[0m       0.7109        \u001b[35m0.5487\u001b[0m  0.0140\n",
      "     23        0.5385       0.7109        0.5491  0.0145\n",
      "     24        0.5440       0.7188        0.5488  0.0152\n",
      "     25        \u001b[36m0.5202\u001b[0m       0.7109        0.5492  0.0142\n",
      "     26        0.5484       0.7109        \u001b[35m0.5484\u001b[0m  0.0256\n",
      "     27        0.5226       0.7109        0.5485  0.0169\n",
      "     28        0.5311       0.7109        0.5486  0.0246\n",
      "     29        0.5527       0.7031        \u001b[35m0.5480\u001b[0m  0.0283\n",
      "     30        0.5304       0.7031        \u001b[35m0.5474\u001b[0m  0.0178\n",
      "     31        0.5232       0.6953        \u001b[35m0.5472\u001b[0m  0.0255\n",
      "     32        0.5268       0.6953        \u001b[35m0.5468\u001b[0m  0.0233\n",
      "     33        0.5445       0.6953        0.5471  0.0180\n",
      "     34        0.5302       0.6953        0.5478  0.0146\n",
      "     35        0.5208       0.6953        0.5476  0.0279\n",
      "     36        \u001b[36m0.5124\u001b[0m       0.6953        0.5472  0.0287\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6780\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6631\u001b[0m  0.0501\n",
      "      2        \u001b[36m0.6504\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6335\u001b[0m  0.0475\n",
      "      3        \u001b[36m0.6338\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6044\u001b[0m  0.0376\n",
      "      4        \u001b[36m0.6063\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5753\u001b[0m  0.0339\n",
      "      5        \u001b[36m0.5955\u001b[0m       0.7578        \u001b[35m0.5519\u001b[0m  0.0354\n",
      "      6        \u001b[36m0.5739\u001b[0m       0.7578        \u001b[35m0.5313\u001b[0m  0.0568\n",
      "      7        \u001b[36m0.5720\u001b[0m       0.7578        \u001b[35m0.5135\u001b[0m  0.0496\n",
      "      8        \u001b[36m0.5561\u001b[0m       0.7500        \u001b[35m0.4994\u001b[0m  0.0455\n",
      "      9        0.5599       0.7500        \u001b[35m0.4877\u001b[0m  0.0357\n",
      "     10        \u001b[36m0.5459\u001b[0m       0.7578        \u001b[35m0.4763\u001b[0m  0.0401\n",
      "     11        \u001b[36m0.5343\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4670\u001b[0m  0.0451\n",
      "     12        0.5388       0.7656        \u001b[35m0.4597\u001b[0m  0.0393\n",
      "     13        0.5455       0.7578        \u001b[35m0.4545\u001b[0m  0.0402\n",
      "     14        0.5383       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4494\u001b[0m  0.0423\n",
      "     15        0.5448       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4435\u001b[0m  0.0419\n",
      "     16        \u001b[36m0.5305\u001b[0m       0.7812        \u001b[35m0.4399\u001b[0m  0.0346\n",
      "     17        \u001b[36m0.5288\u001b[0m       0.7812        \u001b[35m0.4358\u001b[0m  0.0413\n",
      "     18        \u001b[36m0.5281\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4314\u001b[0m  0.0457\n",
      "     19        0.5282       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4288\u001b[0m  0.0390\n",
      "     20        \u001b[36m0.5196\u001b[0m       0.7969        \u001b[35m0.4254\u001b[0m  0.0410\n",
      "     21        0.5203       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4237\u001b[0m  0.0365\n",
      "     22        \u001b[36m0.5169\u001b[0m       0.8047        \u001b[35m0.4212\u001b[0m  0.0415\n",
      "     23        \u001b[36m0.5152\u001b[0m       0.8047        \u001b[35m0.4184\u001b[0m  0.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24        0.5213       0.8047        \u001b[35m0.4180\u001b[0m  0.0505\n",
      "     25        0.5283       0.8047        \u001b[35m0.4169\u001b[0m  0.0391\n",
      "     26        0.5159       0.8047        \u001b[35m0.4150\u001b[0m  0.0378\n",
      "     27        0.5186       0.8047        \u001b[35m0.4143\u001b[0m  0.0413\n",
      "     28        0.5185       0.8047        \u001b[35m0.4134\u001b[0m  0.0364\n",
      "     29        0.5194       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4132\u001b[0m  0.0363\n",
      "     30        0.5184       0.8047        \u001b[35m0.4110\u001b[0m  0.0368\n",
      "     31        0.5213       0.8047        0.4113  0.0460\n",
      "     32        0.5315       0.8125        0.4119  0.0358\n",
      "     33        \u001b[36m0.5014\u001b[0m       0.8047        \u001b[35m0.4092\u001b[0m  0.0376\n",
      "     34        0.5177       0.8125        0.4100  0.0373\n",
      "     35        0.5144       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4074\u001b[0m  0.0361\n",
      "     36        0.5369       0.8203        0.4091  0.0333\n",
      "     37        0.5167       0.8125        0.4096  0.0345\n",
      "     38        0.5082       0.8203        0.4084  0.0476\n",
      "     39        0.5154       0.8203        0.4080  0.0326\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7162\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.7039\u001b[0m  0.0316\n",
      "      2        \u001b[36m0.6805\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6785\u001b[0m  0.0392\n",
      "      3        \u001b[36m0.6580\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6597\u001b[0m  0.0327\n",
      "      4        \u001b[36m0.6379\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6417\u001b[0m  0.0343\n",
      "      5        \u001b[36m0.6092\u001b[0m       0.6484        \u001b[35m0.6237\u001b[0m  0.0403\n",
      "      6        \u001b[36m0.5964\u001b[0m       0.6641        \u001b[35m0.6076\u001b[0m  0.0331\n",
      "      7        \u001b[36m0.5889\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.5928\u001b[0m  0.0319\n",
      "      8        \u001b[36m0.5596\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5810\u001b[0m  0.0350\n",
      "      9        0.5620       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5730\u001b[0m  0.0350\n",
      "     10        \u001b[36m0.5530\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5656\u001b[0m  0.0349\n",
      "     11        \u001b[36m0.5361\u001b[0m       0.7031        \u001b[35m0.5606\u001b[0m  0.0344\n",
      "     12        \u001b[36m0.5231\u001b[0m       0.6953        \u001b[35m0.5568\u001b[0m  0.0544\n",
      "     13        0.5252       0.6875        \u001b[35m0.5539\u001b[0m  0.0420\n",
      "     14        \u001b[36m0.5198\u001b[0m       0.6953        \u001b[35m0.5527\u001b[0m  0.0539\n",
      "     15        0.5207       0.6953        \u001b[35m0.5499\u001b[0m  0.0516\n",
      "     16        \u001b[36m0.5084\u001b[0m       0.7031        \u001b[35m0.5485\u001b[0m  0.0317\n",
      "     17        0.5292       0.7031        \u001b[35m0.5470\u001b[0m  0.0318\n",
      "     18        \u001b[36m0.4947\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5453\u001b[0m  0.0488\n",
      "     19        0.5069       0.7031        \u001b[35m0.5442\u001b[0m  0.0344\n",
      "     20        0.4966       0.7031        \u001b[35m0.5432\u001b[0m  0.0397\n",
      "     21        0.5029       0.7109        \u001b[35m0.5418\u001b[0m  0.0349\n",
      "     22        0.4997       0.6953        \u001b[35m0.5413\u001b[0m  0.0379\n",
      "     23        \u001b[36m0.4936\u001b[0m       0.7031        \u001b[35m0.5398\u001b[0m  0.0536\n",
      "     24        \u001b[36m0.4864\u001b[0m       0.7109        \u001b[35m0.5391\u001b[0m  0.0463\n",
      "     25        0.4933       0.7109        \u001b[35m0.5386\u001b[0m  0.0510\n",
      "     26        \u001b[36m0.4857\u001b[0m       0.7109        \u001b[35m0.5380\u001b[0m  0.0436\n",
      "     27        \u001b[36m0.4774\u001b[0m       0.7109        \u001b[35m0.5366\u001b[0m  0.0358\n",
      "     28        0.4832       0.7109        \u001b[35m0.5351\u001b[0m  0.0509\n",
      "     29        0.4850       0.7109        \u001b[35m0.5335\u001b[0m  0.0323\n",
      "     30        0.4843       0.7109        \u001b[35m0.5325\u001b[0m  0.0472\n",
      "     31        0.4811       0.7109        \u001b[35m0.5319\u001b[0m  0.0317\n",
      "     32        \u001b[36m0.4728\u001b[0m       0.7109        0.5323  0.0343\n",
      "     33        0.4771       0.7109        \u001b[35m0.5312\u001b[0m  0.0347\n",
      "     34        0.4771       0.7109        \u001b[35m0.5306\u001b[0m  0.0323\n",
      "     35        0.4820       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5295\u001b[0m  0.0365\n",
      "     36        0.4783       0.7188        \u001b[35m0.5286\u001b[0m  0.0316\n",
      "     37        0.4821       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5276\u001b[0m  0.0463\n",
      "     38        \u001b[36m0.4721\u001b[0m       0.7188        0.5276  0.0372\n",
      "     39        0.4814       0.7188        \u001b[35m0.5262\u001b[0m  0.0354\n",
      "     40        \u001b[36m0.4688\u001b[0m       0.7188        \u001b[35m0.5254\u001b[0m  0.0560\n",
      "     41        0.4723       0.7188        0.5258  0.0339\n",
      "     42        0.4847       0.7188        0.5255  0.0340\n",
      "     43        0.4764       0.7188        \u001b[35m0.5252\u001b[0m  0.0325\n",
      "     44        \u001b[36m0.4651\u001b[0m       0.7109        0.5260  0.0334\n",
      "     45        0.4673       0.7188        0.5259  0.0613\n",
      "     46        \u001b[36m0.4582\u001b[0m       0.7188        \u001b[35m0.5251\u001b[0m  0.0338\n",
      "     47        0.4715       0.7188        0.5258  0.0648\n",
      "     48        0.4702       0.7109        0.5259  0.0318\n",
      "     49        0.4682       0.7109        0.5264  0.0351\n",
      "     50        0.4659       0.7109        0.5259  0.0326\n",
      "     51        0.4672       0.7109        \u001b[35m0.5248\u001b[0m  0.0354\n",
      "     52        0.4657       0.7109        0.5259  0.0320\n",
      "     53        0.4651       0.7188        \u001b[35m0.5245\u001b[0m  0.0321\n",
      "     54        0.4651       0.7188        \u001b[35m0.5237\u001b[0m  0.0339\n",
      "     55        \u001b[36m0.4526\u001b[0m       0.7109        0.5242  0.0331\n",
      "     56        0.4777       0.7109        \u001b[35m0.5227\u001b[0m  0.0337\n",
      "     57        0.4559       0.7109        0.5228  0.0386\n",
      "     58        0.4648       0.7188        \u001b[35m0.5215\u001b[0m  0.0392\n",
      "     59        0.4598       0.7188        \u001b[35m0.5202\u001b[0m  0.0358\n",
      "     60        0.4544       0.7109        0.5202  0.0329\n",
      "     61        0.4602       0.7188        \u001b[35m0.5190\u001b[0m  0.0376\n",
      "     62        \u001b[36m0.4522\u001b[0m       0.7188        0.5202  0.0352\n",
      "     63        \u001b[36m0.4427\u001b[0m       0.7109        0.5207  0.0372\n",
      "     64        \u001b[36m0.4417\u001b[0m       0.7188        0.5211  0.0404\n",
      "     65        0.4554       0.7109        0.5226  0.0365\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6735\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6393\u001b[0m  0.0325\n",
      "      2        \u001b[36m0.6309\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6091\u001b[0m  0.0378\n",
      "      3        \u001b[36m0.6053\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5885\u001b[0m  0.0439\n",
      "      4        \u001b[36m0.5745\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5712\u001b[0m  0.0432\n",
      "      5        \u001b[36m0.5537\u001b[0m       0.7422        \u001b[35m0.5606\u001b[0m  0.0391\n",
      "      6        \u001b[36m0.5495\u001b[0m       0.7344        \u001b[35m0.5543\u001b[0m  0.0420\n",
      "      7        \u001b[36m0.5356\u001b[0m       0.7344        \u001b[35m0.5502\u001b[0m  0.0475\n",
      "      8        0.5476       0.7344        \u001b[35m0.5478\u001b[0m  0.0488\n",
      "      9        \u001b[36m0.5349\u001b[0m       0.7266        \u001b[35m0.5451\u001b[0m  0.0405\n",
      "     10        \u001b[36m0.5316\u001b[0m       0.7109        \u001b[35m0.5436\u001b[0m  0.0399\n",
      "     11        \u001b[36m0.5166\u001b[0m       0.7109        \u001b[35m0.5430\u001b[0m  0.0405\n",
      "     12        \u001b[36m0.5130\u001b[0m       0.7109        \u001b[35m0.5424\u001b[0m  0.0351\n",
      "     13        0.5167       0.7188        \u001b[35m0.5418\u001b[0m  0.0419\n",
      "     14        0.5184       0.7188        \u001b[35m0.5405\u001b[0m  0.0337\n",
      "     15        \u001b[36m0.5028\u001b[0m       0.7266        \u001b[35m0.5389\u001b[0m  0.0488\n",
      "     16        0.5085       0.7188        \u001b[35m0.5383\u001b[0m  0.0379\n",
      "     17        0.5106       0.7266        0.5384  0.0354\n",
      "     18        0.5062       0.7188        0.5391  0.0614\n",
      "     19        0.5096       0.7109        \u001b[35m0.5383\u001b[0m  0.0686\n",
      "     20        0.5055       0.7109        0.5387  0.0323\n",
      "     21        0.5081       0.7031        \u001b[35m0.5380\u001b[0m  0.0388\n",
      "     22        \u001b[36m0.4898\u001b[0m       0.7031        \u001b[35m0.5380\u001b[0m  0.0559\n",
      "     23        0.5017       0.7031        \u001b[35m0.5376\u001b[0m  0.0317\n",
      "     24        0.4905       0.7031        \u001b[35m0.5375\u001b[0m  0.0489\n",
      "     25        0.5022       0.7031        0.5384  0.0333\n",
      "     26        0.5086       0.7031        \u001b[35m0.5368\u001b[0m  0.0364\n",
      "     27        \u001b[36m0.4888\u001b[0m       0.7031        0.5371  0.0368\n",
      "     28        0.4904       0.7031        \u001b[35m0.5365\u001b[0m  0.0324\n",
      "     29        0.5073       0.7031        \u001b[35m0.5362\u001b[0m  0.0488\n",
      "     30        0.4995       0.7031        0.5366  0.0327\n",
      "     31        0.5011       0.7109        \u001b[35m0.5359\u001b[0m  0.0383\n",
      "     32        0.5030       0.7109        0.5363  0.0326\n",
      "     33        0.5027       0.7109        \u001b[35m0.5358\u001b[0m  0.0351\n",
      "     34        0.4909       0.7031        0.5366  0.0344\n",
      "     35        0.4942       0.7109        0.5363  0.0328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     36        0.5010       0.7109        0.5369  0.0403\n",
      "     37        0.4929       0.7031        0.5373  0.0338\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6705\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6566\u001b[0m  0.0395\n",
      "      2        \u001b[36m0.6387\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6298\u001b[0m  0.0423\n",
      "      3        \u001b[36m0.6117\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6084\u001b[0m  0.0333\n",
      "      4        \u001b[36m0.5929\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5900\u001b[0m  0.0352\n",
      "      5        \u001b[36m0.5690\u001b[0m       0.7031        \u001b[35m0.5743\u001b[0m  0.0406\n",
      "      6        \u001b[36m0.5555\u001b[0m       0.6953        \u001b[35m0.5638\u001b[0m  0.0347\n",
      "      7        \u001b[36m0.5432\u001b[0m       0.7109        \u001b[35m0.5553\u001b[0m  0.0392\n",
      "      8        \u001b[36m0.5285\u001b[0m       0.7109        \u001b[35m0.5498\u001b[0m  0.0338\n",
      "      9        0.5288       0.7188        \u001b[35m0.5465\u001b[0m  0.0350\n",
      "     10        \u001b[36m0.5167\u001b[0m       0.7188        \u001b[35m0.5432\u001b[0m  0.0408\n",
      "     11        \u001b[36m0.4964\u001b[0m       0.7188        \u001b[35m0.5408\u001b[0m  0.0345\n",
      "     12        0.5030       0.7266        \u001b[35m0.5389\u001b[0m  0.0410\n",
      "     13        \u001b[36m0.4922\u001b[0m       0.7266        \u001b[35m0.5377\u001b[0m  0.0343\n",
      "     14        0.5052       0.7344        \u001b[35m0.5364\u001b[0m  0.0416\n",
      "     15        0.4954       0.7266        0.5374  0.0342\n",
      "     16        0.4971       0.7266        0.5373  0.0397\n",
      "     17        0.4974       0.7266        0.5366  0.0355\n",
      "     18        0.4950       0.7188        \u001b[35m0.5362\u001b[0m  0.0366\n",
      "     19        \u001b[36m0.4866\u001b[0m       0.7188        0.5364  0.0341\n",
      "     20        \u001b[36m0.4683\u001b[0m       0.7266        0.5374  0.0351\n",
      "     21        0.4891       0.7188        0.5373  0.0319\n",
      "     22        0.4761       0.7188        0.5378  0.0359\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7815\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7227\u001b[0m  0.0426\n",
      "      2        \u001b[36m0.6987\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6806\u001b[0m  0.0388\n",
      "      3        \u001b[36m0.6642\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6539\u001b[0m  0.0405\n",
      "      4        \u001b[36m0.6372\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6321\u001b[0m  0.0363\n",
      "      5        \u001b[36m0.6183\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6145\u001b[0m  0.0394\n",
      "      6        \u001b[36m0.5940\u001b[0m       0.6953        \u001b[35m0.5997\u001b[0m  0.0344\n",
      "      7        \u001b[36m0.5804\u001b[0m       0.6797        \u001b[35m0.5871\u001b[0m  0.0346\n",
      "      8        \u001b[36m0.5539\u001b[0m       0.6797        \u001b[35m0.5763\u001b[0m  0.0393\n",
      "      9        \u001b[36m0.5376\u001b[0m       0.6875        \u001b[35m0.5684\u001b[0m  0.0324\n",
      "     10        \u001b[36m0.5293\u001b[0m       0.6797        \u001b[35m0.5618\u001b[0m  0.0364\n",
      "     11        \u001b[36m0.5238\u001b[0m       0.6797        \u001b[35m0.5571\u001b[0m  0.0369\n",
      "     12        \u001b[36m0.5172\u001b[0m       0.6719        \u001b[35m0.5541\u001b[0m  0.0336\n",
      "     13        \u001b[36m0.4960\u001b[0m       0.6797        \u001b[35m0.5513\u001b[0m  0.0513\n",
      "     14        0.5142       0.6797        \u001b[35m0.5485\u001b[0m  0.0327\n",
      "     15        0.5098       0.6875        \u001b[35m0.5474\u001b[0m  0.0349\n",
      "     16        \u001b[36m0.4879\u001b[0m       0.6875        \u001b[35m0.5463\u001b[0m  0.0401\n",
      "     17        0.4885       0.6875        \u001b[35m0.5459\u001b[0m  0.0353\n",
      "     18        \u001b[36m0.4843\u001b[0m       0.6875        \u001b[35m0.5450\u001b[0m  0.0400\n",
      "     19        0.4956       0.6875        \u001b[35m0.5447\u001b[0m  0.0332\n",
      "     20        \u001b[36m0.4808\u001b[0m       0.6875        \u001b[35m0.5432\u001b[0m  0.0390\n",
      "     21        0.4901       0.6953        \u001b[35m0.5419\u001b[0m  0.0325\n",
      "     22        0.4812       0.6953        \u001b[35m0.5405\u001b[0m  0.0345\n",
      "     23        \u001b[36m0.4774\u001b[0m       0.6875        0.5406  0.0319\n",
      "     24        0.4906       0.6875        \u001b[35m0.5402\u001b[0m  0.0361\n",
      "     25        \u001b[36m0.4686\u001b[0m       0.6875        0.5406  0.0323\n",
      "     26        0.4767       0.6875        0.5405  0.0369\n",
      "     27        \u001b[36m0.4618\u001b[0m       0.7031        \u001b[35m0.5396\u001b[0m  0.0343\n",
      "     28        0.4630       0.6875        \u001b[35m0.5385\u001b[0m  0.0355\n",
      "     29        0.4723       0.7031        \u001b[35m0.5370\u001b[0m  0.0329\n",
      "     30        0.4837       0.6953        \u001b[35m0.5369\u001b[0m  0.0378\n",
      "     31        0.4753       0.6953        \u001b[35m0.5356\u001b[0m  0.0347\n",
      "     32        0.4884       0.6875        \u001b[35m0.5351\u001b[0m  0.0335\n",
      "     33        0.4699       0.7109        \u001b[35m0.5329\u001b[0m  0.0366\n",
      "     34        \u001b[36m0.4574\u001b[0m       0.6953        0.5366  0.0326\n",
      "     35        0.4617       0.7109        0.5342  0.0326\n",
      "     36        \u001b[36m0.4550\u001b[0m       0.7188        0.5344  0.0353\n",
      "     37        0.4648       0.7031        0.5338  0.0325\n",
      "     38        0.4557       0.7031        \u001b[35m0.5319\u001b[0m  0.0336\n",
      "     39        0.4661       0.7188        \u001b[35m0.5299\u001b[0m  0.0342\n",
      "     40        \u001b[36m0.4511\u001b[0m       0.7188        0.5313  0.0328\n",
      "     41        \u001b[36m0.4468\u001b[0m       0.7266        0.5301  0.0347\n",
      "     42        0.4551       0.7266        0.5301  0.0331\n",
      "     43        0.4597       0.7266        \u001b[35m0.5293\u001b[0m  0.0326\n",
      "     44        0.4622       0.7188        \u001b[35m0.5277\u001b[0m  0.0361\n",
      "     45        0.4564       0.7266        \u001b[35m0.5256\u001b[0m  0.0389\n",
      "     46        0.4685       0.7266        \u001b[35m0.5233\u001b[0m  0.0343\n",
      "     47        0.4539       0.7266        \u001b[35m0.5225\u001b[0m  0.0356\n",
      "     48        0.4648       0.7188        \u001b[35m0.5222\u001b[0m  0.0351\n",
      "     49        \u001b[36m0.4409\u001b[0m       0.7188        0.5234  0.0360\n",
      "     50        0.4575       0.7188        0.5228  0.0346\n",
      "     51        0.4449       0.7188        \u001b[35m0.5205\u001b[0m  0.0354\n",
      "     52        0.4474       0.7188        0.5207  0.0347\n",
      "     53        0.4426       0.7188        0.5211  0.0335\n",
      "     54        0.4497       0.7188        0.5206  0.0325\n",
      "     55        0.4412       0.7188        \u001b[35m0.5199\u001b[0m  0.0343\n",
      "     56        0.4452       0.7188        \u001b[35m0.5197\u001b[0m  0.0355\n",
      "     57        \u001b[36m0.4292\u001b[0m       0.7188        \u001b[35m0.5188\u001b[0m  0.0376\n",
      "     58        0.4384       0.7188        0.5193  0.0351\n",
      "     59        0.4350       0.7188        \u001b[35m0.5182\u001b[0m  0.0366\n",
      "     60        0.4545       0.7188        \u001b[35m0.5168\u001b[0m  0.0345\n",
      "     61        0.4459       0.7188        0.5169  0.0361\n",
      "     62        0.4366       0.7188        \u001b[35m0.5159\u001b[0m  0.0353\n",
      "     63        0.4531       0.7188        0.5168  0.0356\n",
      "     64        0.4405       0.7188        0.5167  0.0323\n",
      "     65        0.4453       0.7266        \u001b[35m0.5158\u001b[0m  0.0328\n",
      "     66        0.4555       0.7266        \u001b[35m0.5151\u001b[0m  0.0328\n",
      "     67        0.4470       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5138\u001b[0m  0.0369\n",
      "     68        0.4324       0.7344        0.5151  0.0350\n",
      "     69        \u001b[36m0.4287\u001b[0m       0.7344        0.5154  0.0402\n",
      "     70        0.4402       \u001b[32m0.7422\u001b[0m        0.5151  0.0345\n",
      "     71        0.4442       0.7422        0.5145  0.0359\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7218\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6795\u001b[0m  0.0176\n",
      "      2        \u001b[36m0.6947\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6667\u001b[0m  0.0190\n",
      "      3        \u001b[36m0.6910\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6565\u001b[0m  0.0290\n",
      "      4        \u001b[36m0.6878\u001b[0m       0.6641        \u001b[35m0.6480\u001b[0m  0.0256\n",
      "      5        \u001b[36m0.6708\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6390\u001b[0m  0.0241\n",
      "      6        \u001b[36m0.6637\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6305\u001b[0m  0.0309\n",
      "      7        \u001b[36m0.6628\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6222\u001b[0m  0.0230\n",
      "      8        0.6647       0.7188        \u001b[35m0.6159\u001b[0m  0.0294\n",
      "      9        \u001b[36m0.6570\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6098\u001b[0m  0.0250\n",
      "     10        \u001b[36m0.6380\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6007\u001b[0m  0.0311\n",
      "     11        0.6496       0.7500        \u001b[35m0.5942\u001b[0m  0.0296\n",
      "     12        \u001b[36m0.6327\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.5864\u001b[0m  0.0249\n",
      "     13        0.6368       \u001b[32m0.7969\u001b[0m        \u001b[35m0.5788\u001b[0m  0.0287\n",
      "     14        \u001b[36m0.6236\u001b[0m       0.7969        \u001b[35m0.5704\u001b[0m  0.0432\n",
      "     15        \u001b[36m0.6227\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.5625\u001b[0m  0.0302\n",
      "     16        \u001b[36m0.6116\u001b[0m       0.8047        \u001b[35m0.5555\u001b[0m  0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17        \u001b[36m0.6048\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.5466\u001b[0m  0.0316\n",
      "     18        0.6212       0.8125        \u001b[35m0.5415\u001b[0m  0.0274\n",
      "     19        0.6080       \u001b[32m0.8203\u001b[0m        \u001b[35m0.5358\u001b[0m  0.0300\n",
      "     20        \u001b[36m0.6042\u001b[0m       0.8203        \u001b[35m0.5304\u001b[0m  0.0273\n",
      "     21        \u001b[36m0.5990\u001b[0m       0.8047        \u001b[35m0.5245\u001b[0m  0.0288\n",
      "     22        0.6009       0.8047        \u001b[35m0.5208\u001b[0m  0.0266\n",
      "     23        \u001b[36m0.5974\u001b[0m       0.8047        \u001b[35m0.5161\u001b[0m  0.0279\n",
      "     24        \u001b[36m0.5883\u001b[0m       0.8047        \u001b[35m0.5103\u001b[0m  0.0306\n",
      "     25        \u001b[36m0.5874\u001b[0m       0.8125        \u001b[35m0.5060\u001b[0m  0.0285\n",
      "     26        \u001b[36m0.5633\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m0.5006\u001b[0m  0.0257\n",
      "     27        0.5703       0.8203        \u001b[35m0.4967\u001b[0m  0.0270\n",
      "     28        0.5862       0.8203        \u001b[35m0.4947\u001b[0m  0.0271\n",
      "     29        0.6018       0.8125        \u001b[35m0.4923\u001b[0m  0.0229\n",
      "     30        0.5674       0.8203        \u001b[35m0.4878\u001b[0m  0.0295\n",
      "     31        0.5825       0.8125        \u001b[35m0.4863\u001b[0m  0.0235\n",
      "     32        0.5986       0.8125        \u001b[35m0.4852\u001b[0m  0.1822\n",
      "     33        0.5969       0.8125        \u001b[35m0.4844\u001b[0m  0.0771\n",
      "     34        0.5849       0.8203        \u001b[35m0.4829\u001b[0m  0.0305\n",
      "     35        0.5634       0.8125        \u001b[35m0.4791\u001b[0m  0.0249\n",
      "     36        0.5671       0.8047        \u001b[35m0.4763\u001b[0m  0.0293\n",
      "     37        \u001b[36m0.5632\u001b[0m       0.8047        \u001b[35m0.4738\u001b[0m  0.0323\n",
      "     38        0.5755       0.7891        \u001b[35m0.4734\u001b[0m  0.0330\n",
      "     39        0.5652       0.8125        \u001b[35m0.4732\u001b[0m  0.0278\n",
      "     40        \u001b[36m0.5564\u001b[0m       0.8125        \u001b[35m0.4721\u001b[0m  0.0286\n",
      "     41        0.5600       0.8047        \u001b[35m0.4697\u001b[0m  0.0306\n",
      "     42        0.5723       0.8047        \u001b[35m0.4691\u001b[0m  0.0245\n",
      "     43        \u001b[36m0.5519\u001b[0m       0.8047        \u001b[35m0.4663\u001b[0m  0.0239\n",
      "     44        0.5590       0.7969        \u001b[35m0.4645\u001b[0m  0.0310\n",
      "     45        0.5806       0.7969        0.4645  0.0454\n",
      "     46        0.5959       0.7969        0.4665  0.0490\n",
      "     47        0.5846       0.7969        0.4671  0.0370\n",
      "     48        0.5747       0.7891        0.4665  0.0395\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7437\u001b[0m       \u001b[32m0.4375\u001b[0m        \u001b[35m0.6987\u001b[0m  0.0195\n",
      "      2        \u001b[36m0.7212\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6753\u001b[0m  0.0214\n",
      "      3        \u001b[36m0.6826\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6632\u001b[0m  0.0283\n",
      "      4        0.6826       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6562\u001b[0m  0.0307\n",
      "      5        \u001b[36m0.6722\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6478\u001b[0m  0.0307\n",
      "      6        \u001b[36m0.6714\u001b[0m       0.7109        \u001b[35m0.6434\u001b[0m  0.0307\n",
      "      7        \u001b[36m0.6548\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6380\u001b[0m  0.0343\n",
      "      8        0.6583       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6332\u001b[0m  0.0338\n",
      "      9        0.6591       0.7344        \u001b[35m0.6300\u001b[0m  0.0288\n",
      "     10        \u001b[36m0.6423\u001b[0m       0.7266        \u001b[35m0.6260\u001b[0m  0.0337\n",
      "     11        0.6467       0.7109        \u001b[35m0.6223\u001b[0m  0.0363\n",
      "     12        \u001b[36m0.6322\u001b[0m       0.7031        \u001b[35m0.6185\u001b[0m  0.0341\n",
      "     13        \u001b[36m0.6314\u001b[0m       0.6875        \u001b[35m0.6156\u001b[0m  0.0284\n",
      "     14        0.6387       0.6875        \u001b[35m0.6131\u001b[0m  0.0300\n",
      "     15        \u001b[36m0.6266\u001b[0m       0.6953        \u001b[35m0.6102\u001b[0m  0.0270\n",
      "     16        \u001b[36m0.6150\u001b[0m       0.6953        \u001b[35m0.6078\u001b[0m  0.0290\n",
      "     17        0.6445       0.6953        \u001b[35m0.6070\u001b[0m  0.0312\n",
      "     18        0.6161       0.6953        \u001b[35m0.6052\u001b[0m  0.0333\n",
      "     19        0.6164       0.6953        \u001b[35m0.6024\u001b[0m  0.0364\n",
      "     20        0.6208       0.6875        \u001b[35m0.6015\u001b[0m  0.0363\n",
      "     21        0.6172       0.6875        \u001b[35m0.6002\u001b[0m  0.0336\n",
      "     22        0.6234       0.6875        \u001b[35m0.5989\u001b[0m  0.0334\n",
      "     23        \u001b[36m0.6066\u001b[0m       0.6797        \u001b[35m0.5970\u001b[0m  0.0375\n",
      "     24        \u001b[36m0.6028\u001b[0m       0.6875        \u001b[35m0.5946\u001b[0m  0.0248\n",
      "     25        \u001b[36m0.6022\u001b[0m       0.6875        \u001b[35m0.5921\u001b[0m  0.0252\n",
      "     26        \u001b[36m0.5964\u001b[0m       0.6875        \u001b[35m0.5912\u001b[0m  0.0264\n",
      "     27        0.6069       0.6953        \u001b[35m0.5903\u001b[0m  0.0303\n",
      "     28        0.5988       0.6953        \u001b[35m0.5885\u001b[0m  0.0273\n",
      "     29        \u001b[36m0.5854\u001b[0m       0.6953        \u001b[35m0.5874\u001b[0m  0.0303\n",
      "     30        0.6100       0.6953        \u001b[35m0.5872\u001b[0m  0.0369\n",
      "     31        0.5951       0.6953        \u001b[35m0.5864\u001b[0m  0.0427\n",
      "     32        0.6116       0.6953        \u001b[35m0.5862\u001b[0m  0.0471\n",
      "     33        0.6207       0.6953        0.5862  0.0317\n",
      "     34        0.6109       0.6875        \u001b[35m0.5851\u001b[0m  0.0286\n",
      "     35        0.6113       0.6875        \u001b[35m0.5847\u001b[0m  0.0327\n",
      "     36        0.5936       0.6875        \u001b[35m0.5840\u001b[0m  0.0263\n",
      "     37        0.5947       0.6797        \u001b[35m0.5831\u001b[0m  0.0231\n",
      "     38        \u001b[36m0.5829\u001b[0m       0.6797        \u001b[35m0.5821\u001b[0m  0.0251\n",
      "     39        0.5830       0.6797        \u001b[35m0.5810\u001b[0m  0.0364\n",
      "     40        0.5917       0.6875        0.5814  0.0234\n",
      "     41        \u001b[36m0.5672\u001b[0m       0.6875        \u001b[35m0.5802\u001b[0m  0.0456\n",
      "     42        0.6047       0.6953        \u001b[35m0.5801\u001b[0m  0.0283\n",
      "     43        0.5780       0.6953        \u001b[35m0.5800\u001b[0m  0.0249\n",
      "     44        0.5873       0.6875        \u001b[35m0.5797\u001b[0m  0.0440\n",
      "     45        0.5841       0.6797        \u001b[35m0.5785\u001b[0m  0.0291\n",
      "     46        0.5824       0.6875        \u001b[35m0.5779\u001b[0m  0.0337\n",
      "     47        \u001b[36m0.5605\u001b[0m       0.6875        \u001b[35m0.5777\u001b[0m  0.0312\n",
      "     48        0.6046       0.6875        \u001b[35m0.5773\u001b[0m  0.0426\n",
      "     49        0.5800       0.6875        \u001b[35m0.5768\u001b[0m  0.0358\n",
      "     50        \u001b[36m0.5511\u001b[0m       0.6875        \u001b[35m0.5761\u001b[0m  0.0394\n",
      "     51        0.5932       0.6875        \u001b[35m0.5758\u001b[0m  0.0246\n",
      "     52        0.5881       0.6875        0.5765  0.0415\n",
      "     53        0.5678       0.6875        \u001b[35m0.5755\u001b[0m  0.0333\n",
      "     54        0.5945       0.6875        \u001b[35m0.5752\u001b[0m  0.0334\n",
      "     55        0.5917       0.6875        \u001b[35m0.5750\u001b[0m  0.0431\n",
      "     56        0.5867       0.6875        \u001b[35m0.5748\u001b[0m  0.0475\n",
      "     57        0.5704       0.6875        \u001b[35m0.5734\u001b[0m  0.0316\n",
      "     58        0.5771       0.6875        \u001b[35m0.5724\u001b[0m  0.0477\n",
      "     59        0.5791       0.6875        \u001b[35m0.5716\u001b[0m  0.0220\n",
      "     60        0.5763       0.6875        \u001b[35m0.5712\u001b[0m  0.0298\n",
      "     61        0.5735       0.6875        \u001b[35m0.5701\u001b[0m  0.0237\n",
      "     62        0.5698       0.6875        \u001b[35m0.5688\u001b[0m  0.0408\n",
      "     63        0.5826       0.6875        \u001b[35m0.5685\u001b[0m  0.0280\n",
      "     64        0.5924       0.6953        \u001b[35m0.5681\u001b[0m  0.0227\n",
      "     65        0.5870       0.6953        \u001b[35m0.5680\u001b[0m  0.0483\n",
      "     66        0.5801       0.6953        \u001b[35m0.5673\u001b[0m  0.0394\n",
      "     67        0.5688       0.6875        \u001b[35m0.5666\u001b[0m  0.0235\n",
      "     68        0.5723       0.6875        \u001b[35m0.5660\u001b[0m  0.0409\n",
      "     69        0.5644       0.6797        \u001b[35m0.5658\u001b[0m  0.0472\n",
      "     70        0.5586       0.6797        \u001b[35m0.5652\u001b[0m  0.0511\n",
      "     71        0.5774       0.6875        0.5654  0.0220\n",
      "     72        0.5838       0.6953        \u001b[35m0.5645\u001b[0m  0.0353\n",
      "     73        0.5642       0.6953        \u001b[35m0.5636\u001b[0m  0.0314\n",
      "     74        0.5667       0.6875        \u001b[35m0.5631\u001b[0m  0.0238\n",
      "     75        0.5848       0.6875        \u001b[35m0.5627\u001b[0m  0.0369\n",
      "     76        0.5620       0.6875        \u001b[35m0.5621\u001b[0m  0.0253\n",
      "     77        0.5746       0.6875        \u001b[35m0.5614\u001b[0m  0.0360\n",
      "     78        0.5645       0.6875        \u001b[35m0.5608\u001b[0m  0.0243\n",
      "     79        0.5811       0.6875        \u001b[35m0.5601\u001b[0m  0.0342\n",
      "     80        0.5772       0.6875        \u001b[35m0.5598\u001b[0m  0.0221\n",
      "     81        0.5614       0.6875        \u001b[35m0.5581\u001b[0m  0.0371\n",
      "     82        0.5663       0.6875        \u001b[35m0.5571\u001b[0m  0.0245\n",
      "     83        0.5734       0.6875        \u001b[35m0.5567\u001b[0m  0.0369\n",
      "     84        0.5670       0.6875        \u001b[35m0.5562\u001b[0m  0.0271\n",
      "     85        0.5707       0.6797        0.5564  0.0299\n",
      "     86        0.5551       0.6797        \u001b[35m0.5545\u001b[0m  0.0281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     87        0.5703       0.6875        \u001b[35m0.5538\u001b[0m  0.0357\n",
      "     88        0.5580       0.6797        \u001b[35m0.5535\u001b[0m  0.0433\n",
      "     89        0.5542       0.6797        \u001b[35m0.5518\u001b[0m  0.0465\n",
      "     90        0.5611       0.6797        \u001b[35m0.5508\u001b[0m  0.0396\n",
      "     91        0.5607       0.6797        \u001b[35m0.5487\u001b[0m  0.0418\n",
      "     92        0.5570       0.6797        \u001b[35m0.5476\u001b[0m  0.0404\n",
      "     93        0.5726       0.6797        \u001b[35m0.5471\u001b[0m  0.0283\n",
      "     94        0.5704       0.6797        \u001b[35m0.5470\u001b[0m  0.0257\n",
      "     95        0.5694       0.6797        \u001b[35m0.5459\u001b[0m  0.0233\n",
      "     96        \u001b[36m0.5506\u001b[0m       0.6797        \u001b[35m0.5456\u001b[0m  0.0297\n",
      "     97        \u001b[36m0.5496\u001b[0m       0.6797        0.5459  0.0398\n",
      "     98        0.5623       0.6875        \u001b[35m0.5444\u001b[0m  0.0449\n",
      "     99        0.5552       0.6875        \u001b[35m0.5438\u001b[0m  0.0304\n",
      "    100        \u001b[36m0.5443\u001b[0m       0.6875        \u001b[35m0.5422\u001b[0m  0.0290\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7741\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7361\u001b[0m  0.0311\n",
      "      2        \u001b[36m0.7425\u001b[0m       0.5000        \u001b[35m0.7131\u001b[0m  0.0380\n",
      "      3        \u001b[36m0.7173\u001b[0m       0.5000        \u001b[35m0.6963\u001b[0m  0.0305\n",
      "      4        \u001b[36m0.7015\u001b[0m       0.5000        \u001b[35m0.6826\u001b[0m  0.0384\n",
      "      5        \u001b[36m0.6885\u001b[0m       0.5000        \u001b[35m0.6708\u001b[0m  0.0346\n",
      "      6        \u001b[36m0.6733\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6594\u001b[0m  0.0227\n",
      "      7        \u001b[36m0.6718\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6515\u001b[0m  0.0433\n",
      "      8        \u001b[36m0.6573\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6425\u001b[0m  0.0251\n",
      "      9        \u001b[36m0.6435\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6333\u001b[0m  0.0420\n",
      "     10        0.6533       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6274\u001b[0m  0.0228\n",
      "     11        \u001b[36m0.6390\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6207\u001b[0m  0.0352\n",
      "     12        0.6459       0.7188        \u001b[35m0.6167\u001b[0m  0.0540\n",
      "     13        \u001b[36m0.6269\u001b[0m       0.7266        \u001b[35m0.6096\u001b[0m  0.0373\n",
      "     14        0.6282       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6045\u001b[0m  0.0499\n",
      "     15        \u001b[36m0.6245\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5994\u001b[0m  0.0221\n",
      "     16        \u001b[36m0.6179\u001b[0m       0.7500        \u001b[35m0.5952\u001b[0m  0.0486\n",
      "     17        \u001b[36m0.6161\u001b[0m       0.7500        \u001b[35m0.5911\u001b[0m  0.0532\n",
      "     18        \u001b[36m0.6120\u001b[0m       0.7500        \u001b[35m0.5872\u001b[0m  0.0322\n",
      "     19        \u001b[36m0.6073\u001b[0m       0.7422        \u001b[35m0.5838\u001b[0m  0.0454\n",
      "     20        0.6234       0.7422        \u001b[35m0.5815\u001b[0m  0.0232\n",
      "     21        0.6141       0.7422        \u001b[35m0.5800\u001b[0m  0.0453\n",
      "     22        0.6165       0.7422        \u001b[35m0.5778\u001b[0m  0.0236\n",
      "     23        0.6159       0.7422        \u001b[35m0.5762\u001b[0m  0.0354\n",
      "     24        0.6206       0.7422        \u001b[35m0.5749\u001b[0m  0.0298\n",
      "     25        \u001b[36m0.5813\u001b[0m       0.7422        \u001b[35m0.5708\u001b[0m  0.0241\n",
      "     26        0.6141       0.7422        \u001b[35m0.5697\u001b[0m  0.0331\n",
      "     27        0.6129       0.7422        \u001b[35m0.5684\u001b[0m  0.0334\n",
      "     28        0.6030       0.7422        \u001b[35m0.5682\u001b[0m  0.0223\n",
      "     29        0.5982       0.7422        \u001b[35m0.5666\u001b[0m  0.0412\n",
      "     30        0.5983       0.7422        \u001b[35m0.5646\u001b[0m  0.0412\n",
      "     31        0.5941       0.7422        \u001b[35m0.5628\u001b[0m  0.0407\n",
      "     32        0.6078       0.7422        \u001b[35m0.5623\u001b[0m  0.0437\n",
      "     33        0.5845       0.7422        \u001b[35m0.5607\u001b[0m  0.0269\n",
      "     34        0.5923       0.7422        \u001b[35m0.5589\u001b[0m  0.0325\n",
      "     35        0.5819       0.7344        \u001b[35m0.5576\u001b[0m  0.0269\n",
      "     36        0.5865       0.7344        \u001b[35m0.5567\u001b[0m  0.0297\n",
      "     37        0.5864       0.7344        \u001b[35m0.5555\u001b[0m  0.0240\n",
      "     38        0.5891       0.7344        \u001b[35m0.5544\u001b[0m  0.0281\n",
      "     39        \u001b[36m0.5792\u001b[0m       0.7344        \u001b[35m0.5531\u001b[0m  0.0313\n",
      "     40        0.5797       0.7344        \u001b[35m0.5519\u001b[0m  0.0323\n",
      "     41        0.5972       0.7344        \u001b[35m0.5515\u001b[0m  0.0330\n",
      "     42        0.5958       0.7344        0.5517  0.0256\n",
      "     43        0.5860       0.7344        0.5518  0.0272\n",
      "     44        0.5812       0.7422        \u001b[35m0.5515\u001b[0m  0.0236\n",
      "     45        \u001b[36m0.5552\u001b[0m       0.7344        \u001b[35m0.5500\u001b[0m  0.0348\n",
      "     46        0.5760       0.7344        \u001b[35m0.5498\u001b[0m  0.0299\n",
      "     47        0.5747       0.7344        0.5499  0.0223\n",
      "     48        0.5911       0.7266        0.5500  0.0371\n",
      "     49        0.5968       0.7266        0.5501  0.0291\n",
      "     50        0.5725       0.7188        0.5502  0.0291\n",
      "     51        0.5697       0.7266        \u001b[35m0.5494\u001b[0m  0.0280\n",
      "     52        0.5753       0.7188        \u001b[35m0.5492\u001b[0m  0.0339\n",
      "     53        0.5843       0.7109        \u001b[35m0.5491\u001b[0m  0.0232\n",
      "     54        0.5622       0.7109        \u001b[35m0.5486\u001b[0m  0.0384\n",
      "     55        0.5636       0.7109        \u001b[35m0.5475\u001b[0m  0.0411\n",
      "     56        0.5676       0.7109        0.5478  0.0345\n",
      "     57        0.5564       0.7031        \u001b[35m0.5469\u001b[0m  0.0333\n",
      "     58        0.6012       0.7031        0.5475  0.0305\n",
      "     59        0.5694       0.7109        0.5475  0.0255\n",
      "     60        0.5701       0.7109        \u001b[35m0.5466\u001b[0m  0.0360\n",
      "     61        0.5631       0.7109        \u001b[35m0.5461\u001b[0m  0.0313\n",
      "     62        0.5828       0.6953        0.5465  0.0510\n",
      "     63        0.5554       0.7031        0.5469  0.0217\n",
      "     64        0.5554       0.7031        0.5463  0.0383\n",
      "     65        \u001b[36m0.5502\u001b[0m       0.7031        0.5461  0.0484\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6899\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6901\u001b[0m  0.0222\n",
      "      2        \u001b[36m0.6868\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6861\u001b[0m  0.0351\n",
      "      3        \u001b[36m0.6860\u001b[0m       0.5391        \u001b[35m0.6832\u001b[0m  0.0446\n",
      "      4        \u001b[36m0.6832\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6800\u001b[0m  0.0394\n",
      "      5        \u001b[36m0.6801\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6775\u001b[0m  0.0240\n",
      "      6        \u001b[36m0.6747\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6742\u001b[0m  0.0408\n",
      "      7        \u001b[36m0.6671\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6703\u001b[0m  0.0220\n",
      "      8        0.6767       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6676\u001b[0m  0.0290\n",
      "      9        \u001b[36m0.6631\u001b[0m       0.6484        \u001b[35m0.6636\u001b[0m  0.0364\n",
      "     10        \u001b[36m0.6589\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6596\u001b[0m  0.0781\n",
      "     11        \u001b[36m0.6527\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6550\u001b[0m  0.0327\n",
      "     12        0.6604       0.6797        \u001b[35m0.6518\u001b[0m  0.0291\n",
      "     13        \u001b[36m0.6504\u001b[0m       0.6875        \u001b[35m0.6474\u001b[0m  0.0300\n",
      "     14        \u001b[36m0.6482\u001b[0m       0.6875        \u001b[35m0.6434\u001b[0m  0.0379\n",
      "     15        \u001b[36m0.6343\u001b[0m       0.6797        \u001b[35m0.6391\u001b[0m  0.0229\n",
      "     16        \u001b[36m0.6241\u001b[0m       0.6797        \u001b[35m0.6336\u001b[0m  0.0452\n",
      "     17        0.6285       0.6875        \u001b[35m0.6284\u001b[0m  0.0225\n",
      "     18        \u001b[36m0.6231\u001b[0m       0.6875        \u001b[35m0.6237\u001b[0m  0.0305\n",
      "     19        0.6359       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6201\u001b[0m  0.0244\n",
      "     20        0.6332       0.6953        \u001b[35m0.6174\u001b[0m  0.0219\n",
      "     21        \u001b[36m0.6190\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6141\u001b[0m  0.0442\n",
      "     22        \u001b[36m0.6176\u001b[0m       0.7031        \u001b[35m0.6107\u001b[0m  0.0222\n",
      "     23        \u001b[36m0.6101\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6069\u001b[0m  0.0284\n",
      "     24        0.6238       0.7188        \u001b[35m0.6054\u001b[0m  0.0204\n",
      "     25        0.6107       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6025\u001b[0m  0.0435\n",
      "     26        \u001b[36m0.6069\u001b[0m       0.7344        \u001b[35m0.5994\u001b[0m  0.0239\n",
      "     27        \u001b[36m0.5944\u001b[0m       0.7344        \u001b[35m0.5965\u001b[0m  0.0333\n",
      "     28        0.6055       0.7344        \u001b[35m0.5933\u001b[0m  0.0408\n",
      "     29        0.6035       0.7344        \u001b[35m0.5911\u001b[0m  0.0335\n",
      "     30        0.6017       0.7266        \u001b[35m0.5891\u001b[0m  0.0222\n",
      "     31        \u001b[36m0.5887\u001b[0m       0.7188        \u001b[35m0.5871\u001b[0m  0.0328\n",
      "     32        0.5979       0.7188        \u001b[35m0.5855\u001b[0m  0.0310\n",
      "     33        0.5935       0.7188        \u001b[35m0.5840\u001b[0m  0.0328\n",
      "     34        0.6028       0.7188        \u001b[35m0.5827\u001b[0m  0.0398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     35        \u001b[36m0.5868\u001b[0m       0.7188        \u001b[35m0.5809\u001b[0m  0.0207\n",
      "     36        0.6001       0.7266        \u001b[35m0.5798\u001b[0m  0.0306\n",
      "     37        \u001b[36m0.5735\u001b[0m       0.7188        \u001b[35m0.5776\u001b[0m  0.0236\n",
      "     38        0.5909       0.7109        \u001b[35m0.5762\u001b[0m  0.0319\n",
      "     39        \u001b[36m0.5715\u001b[0m       0.7109        \u001b[35m0.5743\u001b[0m  0.0648\n",
      "     40        0.5726       0.7109        \u001b[35m0.5722\u001b[0m  0.0416\n",
      "     41        \u001b[36m0.5642\u001b[0m       0.6953        \u001b[35m0.5708\u001b[0m  0.0427\n",
      "     42        0.5788       0.6953        \u001b[35m0.5701\u001b[0m  0.0266\n",
      "     43        0.5810       0.6953        \u001b[35m0.5683\u001b[0m  0.0316\n",
      "     44        0.5831       0.6875        \u001b[35m0.5669\u001b[0m  0.0227\n",
      "     45        0.5834       0.6797        \u001b[35m0.5656\u001b[0m  0.0249\n",
      "     46        \u001b[36m0.5630\u001b[0m       0.6797        \u001b[35m0.5639\u001b[0m  0.0262\n",
      "     47        \u001b[36m0.5586\u001b[0m       0.6797        \u001b[35m0.5629\u001b[0m  0.0267\n",
      "     48        0.5664       0.6797        \u001b[35m0.5621\u001b[0m  0.0276\n",
      "     49        0.5828       0.6797        \u001b[35m0.5609\u001b[0m  0.0296\n",
      "     50        \u001b[36m0.5583\u001b[0m       0.6797        \u001b[35m0.5599\u001b[0m  0.0335\n",
      "     51        \u001b[36m0.5557\u001b[0m       0.6719        \u001b[35m0.5582\u001b[0m  0.0217\n",
      "     52        \u001b[36m0.5527\u001b[0m       0.6719        \u001b[35m0.5568\u001b[0m  0.0461\n",
      "     53        0.5781       0.6719        \u001b[35m0.5567\u001b[0m  0.0457\n",
      "     54        \u001b[36m0.5384\u001b[0m       0.6797        \u001b[35m0.5548\u001b[0m  0.0393\n",
      "     55        0.5432       0.6719        \u001b[35m0.5533\u001b[0m  0.0298\n",
      "     56        0.5616       0.6719        \u001b[35m0.5520\u001b[0m  0.0360\n",
      "     57        0.5423       0.6719        \u001b[35m0.5507\u001b[0m  0.0403\n",
      "     58        0.5643       0.6719        \u001b[35m0.5497\u001b[0m  0.0266\n",
      "     59        0.5694       0.6719        \u001b[35m0.5483\u001b[0m  0.0240\n",
      "     60        0.5596       0.6797        \u001b[35m0.5476\u001b[0m  0.0299\n",
      "     61        0.5525       0.6797        \u001b[35m0.5468\u001b[0m  0.0323\n",
      "     62        0.5483       0.6875        \u001b[35m0.5455\u001b[0m  0.0288\n",
      "     63        0.5429       0.6875        \u001b[35m0.5447\u001b[0m  0.0324\n",
      "     64        0.5509       0.6875        \u001b[35m0.5436\u001b[0m  0.0389\n",
      "     65        0.5535       0.6953        \u001b[35m0.5426\u001b[0m  0.0493\n",
      "     66        \u001b[36m0.5381\u001b[0m       0.6953        \u001b[35m0.5415\u001b[0m  0.0254\n",
      "     67        \u001b[36m0.5377\u001b[0m       0.6953        \u001b[35m0.5402\u001b[0m  0.0377\n",
      "     68        \u001b[36m0.5371\u001b[0m       0.7031        \u001b[35m0.5395\u001b[0m  0.0333\n",
      "     69        0.5454       0.7031        \u001b[35m0.5389\u001b[0m  0.0363\n",
      "     70        0.5437       0.7109        \u001b[35m0.5377\u001b[0m  0.0308\n",
      "     71        0.5570       0.7109        \u001b[35m0.5366\u001b[0m  0.0376\n",
      "     72        0.5471       0.7109        \u001b[35m0.5361\u001b[0m  0.0394\n",
      "     73        \u001b[36m0.5218\u001b[0m       0.7109        \u001b[35m0.5356\u001b[0m  0.0298\n",
      "     74        0.5246       0.7109        \u001b[35m0.5353\u001b[0m  0.0271\n",
      "     75        0.5358       0.7109        \u001b[35m0.5352\u001b[0m  0.0218\n",
      "     76        0.5366       0.7109        0.5352  0.0328\n",
      "     77        0.5306       0.7109        \u001b[35m0.5349\u001b[0m  0.0428\n",
      "     78        0.5407       0.7109        \u001b[35m0.5346\u001b[0m  0.0397\n",
      "     79        0.5400       0.7109        \u001b[35m0.5335\u001b[0m  0.0402\n",
      "     80        0.5573       0.7109        \u001b[35m0.5333\u001b[0m  0.0379\n",
      "     81        0.5453       0.7109        \u001b[35m0.5333\u001b[0m  0.0286\n",
      "     82        0.5473       0.7109        \u001b[35m0.5322\u001b[0m  0.0327\n",
      "     83        0.5322       0.7031        \u001b[35m0.5318\u001b[0m  0.0211\n",
      "     84        0.5521       0.7031        0.5321  0.0309\n",
      "     85        0.5494       0.7031        0.5323  0.0241\n",
      "     86        0.5415       0.7031        0.5319  0.0295\n",
      "     87        0.5273       0.7109        0.5321  0.0283\n",
      "     88        \u001b[36m0.5177\u001b[0m       0.7031        \u001b[35m0.5315\u001b[0m  0.0214\n",
      "     89        0.5415       0.7031        \u001b[35m0.5314\u001b[0m  0.0304\n",
      "     90        0.5304       0.7109        0.5317  0.0231\n",
      "     91        0.5374       0.7109        \u001b[35m0.5313\u001b[0m  0.0310\n",
      "     92        0.5440       0.7031        \u001b[35m0.5306\u001b[0m  0.0239\n",
      "     93        0.5458       0.7031        \u001b[35m0.5305\u001b[0m  0.0328\n",
      "     94        0.5533       0.7031        \u001b[35m0.5301\u001b[0m  0.0237\n",
      "     95        0.5493       0.7031        \u001b[35m0.5299\u001b[0m  0.0293\n",
      "     96        0.5215       0.7031        \u001b[35m0.5291\u001b[0m  0.0283\n",
      "     97        0.5468       0.7109        \u001b[35m0.5290\u001b[0m  0.0307\n",
      "     98        0.5387       0.7109        \u001b[35m0.5290\u001b[0m  0.0220\n",
      "     99        0.5375       0.7109        \u001b[35m0.5289\u001b[0m  0.0323\n",
      "    100        0.5400       0.7109        \u001b[35m0.5283\u001b[0m  0.0280\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8190\u001b[0m       \u001b[32m0.4766\u001b[0m        \u001b[35m0.7706\u001b[0m  0.0309\n",
      "      2        \u001b[36m0.7720\u001b[0m       \u001b[32m0.4844\u001b[0m        \u001b[35m0.7398\u001b[0m  0.0357\n",
      "      3        \u001b[36m0.7402\u001b[0m       0.4844        \u001b[35m0.7088\u001b[0m  0.0419\n",
      "      4        \u001b[36m0.7031\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6802\u001b[0m  0.0318\n",
      "      5        \u001b[36m0.6752\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6602\u001b[0m  0.0453\n",
      "      6        \u001b[36m0.6514\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6426\u001b[0m  0.0390\n",
      "      7        \u001b[36m0.6468\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6297\u001b[0m  0.0235\n",
      "      8        \u001b[36m0.6243\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6182\u001b[0m  0.0390\n",
      "      9        \u001b[36m0.6197\u001b[0m       0.7344        \u001b[35m0.6100\u001b[0m  0.0211\n",
      "     10        0.6241       0.7344        \u001b[35m0.6037\u001b[0m  0.0260\n",
      "     11        0.6230       0.7344        \u001b[35m0.5981\u001b[0m  0.0349\n",
      "     12        \u001b[36m0.6161\u001b[0m       0.7344        \u001b[35m0.5934\u001b[0m  0.0206\n",
      "     13        \u001b[36m0.6047\u001b[0m       0.7344        \u001b[35m0.5888\u001b[0m  0.0268\n",
      "     14        0.6076       0.7344        \u001b[35m0.5843\u001b[0m  0.0369\n",
      "     15        \u001b[36m0.5936\u001b[0m       0.7344        \u001b[35m0.5806\u001b[0m  0.0321\n",
      "     16        0.6016       0.7344        \u001b[35m0.5773\u001b[0m  0.0337\n",
      "     17        \u001b[36m0.5852\u001b[0m       0.7422        \u001b[35m0.5745\u001b[0m  0.0305\n",
      "     18        0.5940       0.7500        \u001b[35m0.5713\u001b[0m  0.0217\n",
      "     19        \u001b[36m0.5814\u001b[0m       0.7500        \u001b[35m0.5677\u001b[0m  0.0403\n",
      "     20        0.5947       0.7500        \u001b[35m0.5652\u001b[0m  0.0234\n",
      "     21        \u001b[36m0.5722\u001b[0m       0.7500        \u001b[35m0.5622\u001b[0m  0.0363\n",
      "     22        0.5783       0.7500        \u001b[35m0.5597\u001b[0m  0.0313\n",
      "     23        0.5812       0.7500        \u001b[35m0.5577\u001b[0m  0.0352\n",
      "     24        0.5804       0.7500        \u001b[35m0.5567\u001b[0m  0.0469\n",
      "     25        0.5827       0.7500        \u001b[35m0.5549\u001b[0m  0.0339\n",
      "     26        0.5786       0.7422        \u001b[35m0.5539\u001b[0m  0.0472\n",
      "     27        \u001b[36m0.5642\u001b[0m       0.7422        \u001b[35m0.5520\u001b[0m  0.0336\n",
      "     28        0.5739       0.7422        \u001b[35m0.5498\u001b[0m  0.0411\n",
      "     29        0.5660       0.7500        \u001b[35m0.5485\u001b[0m  0.0371\n",
      "     30        0.5804       0.7422        \u001b[35m0.5474\u001b[0m  0.0660\n",
      "     31        \u001b[36m0.5566\u001b[0m       0.7500        \u001b[35m0.5458\u001b[0m  0.0289\n",
      "     32        \u001b[36m0.5471\u001b[0m       0.7500        \u001b[35m0.5442\u001b[0m  0.0345\n",
      "     33        0.5740       0.7500        \u001b[35m0.5434\u001b[0m  0.0708\n",
      "     34        0.6040       0.7500        \u001b[35m0.5433\u001b[0m  0.0340\n",
      "     35        \u001b[36m0.5423\u001b[0m       0.7422        \u001b[35m0.5417\u001b[0m  0.0309\n",
      "     36        0.5560       0.7422        \u001b[35m0.5403\u001b[0m  0.0294\n",
      "     37        0.5727       0.7422        \u001b[35m0.5401\u001b[0m  0.0312\n",
      "     38        0.5590       0.7422        \u001b[35m0.5393\u001b[0m  0.0367\n",
      "     39        0.5466       0.7422        \u001b[35m0.5387\u001b[0m  0.0235\n",
      "     40        0.5599       0.7422        \u001b[35m0.5381\u001b[0m  0.0383\n",
      "     41        0.5717       0.7422        \u001b[35m0.5373\u001b[0m  0.0224\n",
      "     42        0.5514       0.7422        \u001b[35m0.5365\u001b[0m  0.0413\n",
      "     43        0.5697       0.7422        \u001b[35m0.5361\u001b[0m  0.0344\n",
      "     44        0.5529       0.7500        0.5361  0.0224\n",
      "     45        0.5516       0.7500        \u001b[35m0.5353\u001b[0m  0.0420\n",
      "     46        \u001b[36m0.5315\u001b[0m       0.7500        \u001b[35m0.5349\u001b[0m  0.0259\n",
      "     47        0.5539       0.7500        \u001b[35m0.5345\u001b[0m  0.0235\n",
      "     48        0.5456       0.7500        \u001b[35m0.5334\u001b[0m  0.0569\n",
      "     49        0.5533       0.7500        \u001b[35m0.5328\u001b[0m  0.0351\n",
      "     50        0.5517       0.7500        \u001b[35m0.5325\u001b[0m  0.0563\n",
      "     51        0.5369       0.7344        \u001b[35m0.5319\u001b[0m  0.0940\n",
      "     52        \u001b[36m0.5281\u001b[0m       0.7422        \u001b[35m0.5316\u001b[0m  0.0388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     53        \u001b[36m0.5273\u001b[0m       0.7422        \u001b[35m0.5309\u001b[0m  0.0382\n",
      "     54        0.5457       0.7422        0.5310  0.0445\n",
      "     55        0.5275       0.7422        \u001b[35m0.5307\u001b[0m  0.0452\n",
      "     56        0.5405       0.7422        \u001b[35m0.5303\u001b[0m  0.0470\n",
      "     57        0.5431       0.7422        \u001b[35m0.5301\u001b[0m  0.0340\n",
      "     58        0.5290       0.7422        \u001b[35m0.5297\u001b[0m  0.0706\n",
      "     59        0.5314       0.7422        \u001b[35m0.5296\u001b[0m  0.0588\n",
      "     60        0.5278       0.7422        \u001b[35m0.5295\u001b[0m  0.0362\n",
      "     61        0.5353       0.7422        0.5299  0.0499\n",
      "     62        0.5329       0.7422        \u001b[35m0.5294\u001b[0m  0.0581\n",
      "     63        0.5512       0.7422        0.5295  0.0407\n",
      "     64        0.5523       0.7422        \u001b[35m0.5287\u001b[0m  0.0462\n",
      "     65        0.5578       0.7422        \u001b[35m0.5282\u001b[0m  0.0548\n",
      "     66        0.5328       0.7344        0.5291  0.0351\n",
      "     67        0.5303       0.7422        0.5285  0.0606\n",
      "     68        \u001b[36m0.5206\u001b[0m       0.7344        0.5289  0.0558\n",
      "     69        \u001b[36m0.5100\u001b[0m       0.7266        0.5288  0.0464\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6937\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6931\u001b[0m  0.0602\n",
      "      2        \u001b[36m0.6924\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6911\u001b[0m  0.0485\n",
      "      3        \u001b[36m0.6898\u001b[0m       0.5547        \u001b[35m0.6877\u001b[0m  0.0533\n",
      "      4        \u001b[36m0.6864\u001b[0m       0.5703        \u001b[35m0.6812\u001b[0m  0.0363\n",
      "      5        \u001b[36m0.6793\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6715\u001b[0m  0.0442\n",
      "      6        \u001b[36m0.6676\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6544\u001b[0m  0.0332\n",
      "      7        \u001b[36m0.6484\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6295\u001b[0m  0.0328\n",
      "      8        \u001b[36m0.6244\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6012\u001b[0m  0.0437\n",
      "      9        \u001b[36m0.5979\u001b[0m       0.7188        \u001b[35m0.5733\u001b[0m  0.0362\n",
      "     10        \u001b[36m0.5753\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5487\u001b[0m  0.0274\n",
      "     11        \u001b[36m0.5571\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5290\u001b[0m  0.0471\n",
      "     12        \u001b[36m0.5448\u001b[0m       0.7188        \u001b[35m0.5127\u001b[0m  0.0278\n",
      "     13        \u001b[36m0.5341\u001b[0m       0.7266        \u001b[35m0.4971\u001b[0m  0.0288\n",
      "     14        \u001b[36m0.5259\u001b[0m       0.7422        \u001b[35m0.4824\u001b[0m  0.0341\n",
      "     15        \u001b[36m0.5187\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.4692\u001b[0m  0.0386\n",
      "     16        \u001b[36m0.5118\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4564\u001b[0m  0.0327\n",
      "     17        \u001b[36m0.5052\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4446\u001b[0m  0.0332\n",
      "     18        \u001b[36m0.5006\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4337\u001b[0m  0.0289\n",
      "     19        \u001b[36m0.4959\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4261\u001b[0m  0.0459\n",
      "     20        \u001b[36m0.4917\u001b[0m       0.8125        \u001b[35m0.4168\u001b[0m  0.0528\n",
      "     21        \u001b[36m0.4869\u001b[0m       0.8203        \u001b[35m0.4091\u001b[0m  0.0399\n",
      "     22        \u001b[36m0.4843\u001b[0m       0.8203        \u001b[35m0.4043\u001b[0m  0.0250\n",
      "     23        \u001b[36m0.4820\u001b[0m       0.8203        \u001b[35m0.4010\u001b[0m  0.0253\n",
      "     24        \u001b[36m0.4786\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m0.3958\u001b[0m  0.0432\n",
      "     25        \u001b[36m0.4776\u001b[0m       0.8281        \u001b[35m0.3948\u001b[0m  0.0298\n",
      "     26        \u001b[36m0.4750\u001b[0m       \u001b[32m0.8359\u001b[0m        \u001b[35m0.3914\u001b[0m  0.0323\n",
      "     27        \u001b[36m0.4742\u001b[0m       0.8359        \u001b[35m0.3884\u001b[0m  0.0444\n",
      "     28        \u001b[36m0.4729\u001b[0m       0.8359        \u001b[35m0.3879\u001b[0m  0.0242\n",
      "     29        \u001b[36m0.4713\u001b[0m       0.8281        \u001b[35m0.3843\u001b[0m  0.0512\n",
      "     30        \u001b[36m0.4708\u001b[0m       0.8359        \u001b[35m0.3829\u001b[0m  0.0304\n",
      "     31        \u001b[36m0.4700\u001b[0m       \u001b[32m0.8438\u001b[0m        0.3848  0.0473\n",
      "     32        \u001b[36m0.4688\u001b[0m       0.8359        \u001b[35m0.3820\u001b[0m  0.0371\n",
      "     33        \u001b[36m0.4673\u001b[0m       0.8359        \u001b[35m0.3820\u001b[0m  0.0263\n",
      "     34        \u001b[36m0.4664\u001b[0m       0.8438        0.3820  0.0462\n",
      "     35        \u001b[36m0.4656\u001b[0m       0.8438        \u001b[35m0.3810\u001b[0m  0.0316\n",
      "     36        \u001b[36m0.4654\u001b[0m       0.8438        0.3820  0.0397\n",
      "     37        \u001b[36m0.4653\u001b[0m       \u001b[32m0.8516\u001b[0m        \u001b[35m0.3805\u001b[0m  0.0288\n",
      "     38        0.4654       0.8438        0.3811  0.0332\n",
      "     39        \u001b[36m0.4639\u001b[0m       0.8516        0.3814  0.0428\n",
      "     40        0.4645       0.8438        0.3815  0.0333\n",
      "     41        \u001b[36m0.4634\u001b[0m       0.8516        0.3813  0.0272\n",
      "     42        \u001b[36m0.4627\u001b[0m       0.8516        \u001b[35m0.3804\u001b[0m  0.0583\n",
      "     43        0.4628       0.8516        0.3809  0.0370\n",
      "     44        \u001b[36m0.4620\u001b[0m       0.8516        0.3805  0.0288\n",
      "     45        0.4633       0.8516        0.3821  0.0346\n",
      "     46        0.4621       0.8516        \u001b[35m0.3796\u001b[0m  0.0469\n",
      "     47        0.4621       0.8516        0.3810  0.0582\n",
      "     48        \u001b[36m0.4617\u001b[0m       0.8516        0.3803  0.0453\n",
      "     49        0.4623       \u001b[32m0.8594\u001b[0m        \u001b[35m0.3786\u001b[0m  0.0494\n",
      "     50        0.4620       0.8516        0.3791  0.0256\n",
      "     51        \u001b[36m0.4612\u001b[0m       0.8516        0.3811  0.0507\n",
      "     52        \u001b[36m0.4608\u001b[0m       0.8516        0.3807  0.0509\n",
      "     53        0.4621       0.8438        0.3802  0.0418\n",
      "     54        0.4610       0.8438        \u001b[35m0.3779\u001b[0m  0.0590\n",
      "     55        \u001b[36m0.4606\u001b[0m       0.8594        0.3783  0.0311\n",
      "     56        \u001b[36m0.4600\u001b[0m       0.8516        0.3779  0.0376\n",
      "     57        \u001b[36m0.4598\u001b[0m       0.8516        0.3810  0.0295\n",
      "     58        \u001b[36m0.4593\u001b[0m       0.8594        0.3800  0.0267\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6962\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6766\u001b[0m  0.0371\n",
      "      2        \u001b[36m0.6682\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6444\u001b[0m  0.0402\n",
      "      3        \u001b[36m0.6442\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6222\u001b[0m  0.0284\n",
      "      4        \u001b[36m0.6225\u001b[0m       0.7266        \u001b[35m0.6045\u001b[0m  0.0506\n",
      "      5        \u001b[36m0.6006\u001b[0m       0.7266        \u001b[35m0.5941\u001b[0m  0.0457\n",
      "      6        \u001b[36m0.5835\u001b[0m       0.7266        \u001b[35m0.5889\u001b[0m  0.0290\n",
      "      7        \u001b[36m0.5702\u001b[0m       0.7188        \u001b[35m0.5880\u001b[0m  0.0483\n",
      "      8        \u001b[36m0.5600\u001b[0m       0.7188        \u001b[35m0.5845\u001b[0m  0.0287\n",
      "      9        \u001b[36m0.5513\u001b[0m       0.7188        0.5859  0.0491\n",
      "     10        \u001b[36m0.5452\u001b[0m       0.7188        0.5852  0.0442\n",
      "     11        \u001b[36m0.5398\u001b[0m       0.7109        \u001b[35m0.5832\u001b[0m  0.0357\n",
      "     12        \u001b[36m0.5355\u001b[0m       0.7109        \u001b[35m0.5819\u001b[0m  0.0531\n",
      "     13        \u001b[36m0.5306\u001b[0m       0.7031        \u001b[35m0.5783\u001b[0m  0.0261\n",
      "     14        \u001b[36m0.5283\u001b[0m       0.7031        \u001b[35m0.5781\u001b[0m  0.0243\n",
      "     15        \u001b[36m0.5252\u001b[0m       0.6953        \u001b[35m0.5769\u001b[0m  0.0296\n",
      "     16        \u001b[36m0.5230\u001b[0m       0.6875        0.5782  0.0247\n",
      "     17        \u001b[36m0.5218\u001b[0m       0.6953        \u001b[35m0.5732\u001b[0m  0.0310\n",
      "     18        \u001b[36m0.5190\u001b[0m       0.6953        0.5744  0.0499\n",
      "     19        \u001b[36m0.5176\u001b[0m       0.6875        0.5753  0.0296\n",
      "     20        \u001b[36m0.5172\u001b[0m       0.6953        \u001b[35m0.5711\u001b[0m  0.0517\n",
      "     21        \u001b[36m0.5157\u001b[0m       0.6953        0.5719  0.0362\n",
      "     22        \u001b[36m0.5144\u001b[0m       0.6953        0.5717  0.0490\n",
      "     23        \u001b[36m0.5132\u001b[0m       0.6875        0.5735  0.0286\n",
      "     24        \u001b[36m0.5124\u001b[0m       0.6875        \u001b[35m0.5705\u001b[0m  0.0508\n",
      "     25        0.5133       0.6875        \u001b[35m0.5697\u001b[0m  0.0303\n",
      "     26        0.5127       0.6953        \u001b[35m0.5674\u001b[0m  0.0375\n",
      "     27        \u001b[36m0.5118\u001b[0m       0.6953        \u001b[35m0.5666\u001b[0m  0.0465\n",
      "     28        \u001b[36m0.5103\u001b[0m       0.6875        0.5669  0.0273\n",
      "     29        \u001b[36m0.5103\u001b[0m       0.6875        0.5674  0.0482\n",
      "     30        \u001b[36m0.5095\u001b[0m       0.6875        0.5679  0.0292\n",
      "     31        0.5098       0.6953        \u001b[35m0.5636\u001b[0m  0.0267\n",
      "     32        \u001b[36m0.5085\u001b[0m       0.6875        0.5671  0.0325\n",
      "     33        \u001b[36m0.5078\u001b[0m       0.6953        \u001b[35m0.5628\u001b[0m  0.0296\n",
      "     34        0.5081       0.6953        0.5639  0.0347\n",
      "     35        0.5078       0.6797        0.5680  0.0255\n",
      "     36        \u001b[36m0.5071\u001b[0m       0.6953        \u001b[35m0.5622\u001b[0m  0.0494\n",
      "     37        \u001b[36m0.5065\u001b[0m       0.6953        0.5626  0.0298\n",
      "     38        0.5070       0.6953        \u001b[35m0.5619\u001b[0m  0.0310\n",
      "     39        \u001b[36m0.5057\u001b[0m       0.6953        0.5632  0.0365\n",
      "     40        0.5062       0.6875        0.5641  0.0379\n",
      "     41        0.5058       0.6953        0.5636  0.0479\n",
      "     42        0.5060       0.6875        0.5635  0.0250\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6604\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6639\u001b[0m  0.0234\n",
      "      2        \u001b[36m0.6422\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6462\u001b[0m  0.0509\n",
      "      3        \u001b[36m0.6155\u001b[0m       0.7031        \u001b[35m0.6250\u001b[0m  0.0313\n",
      "      4        \u001b[36m0.5865\u001b[0m       0.6953        \u001b[35m0.6088\u001b[0m  0.0388\n",
      "      5        \u001b[36m0.5586\u001b[0m       0.6953        \u001b[35m0.5934\u001b[0m  0.0340\n",
      "      6        \u001b[36m0.5385\u001b[0m       0.6953        \u001b[35m0.5831\u001b[0m  0.0364\n",
      "      7        \u001b[36m0.5233\u001b[0m       0.7031        \u001b[35m0.5749\u001b[0m  0.0328\n",
      "      8        \u001b[36m0.5117\u001b[0m       0.7109        \u001b[35m0.5671\u001b[0m  0.0373\n",
      "      9        \u001b[36m0.5052\u001b[0m       0.7109        \u001b[35m0.5640\u001b[0m  0.0272\n",
      "     10        \u001b[36m0.5005\u001b[0m       0.7031        \u001b[35m0.5601\u001b[0m  0.0301\n",
      "     11        \u001b[36m0.4968\u001b[0m       0.7031        \u001b[35m0.5538\u001b[0m  0.0305\n",
      "     12        \u001b[36m0.4931\u001b[0m       0.7109        \u001b[35m0.5486\u001b[0m  0.0317\n",
      "     13        \u001b[36m0.4909\u001b[0m       0.7109        \u001b[35m0.5439\u001b[0m  0.0306\n",
      "     14        \u001b[36m0.4891\u001b[0m       0.6953        \u001b[35m0.5437\u001b[0m  0.0291\n",
      "     15        \u001b[36m0.4870\u001b[0m       0.7031        \u001b[35m0.5420\u001b[0m  0.0324\n",
      "     16        \u001b[36m0.4846\u001b[0m       0.7031        \u001b[35m0.5393\u001b[0m  0.0305\n",
      "     17        \u001b[36m0.4822\u001b[0m       0.7031        \u001b[35m0.5353\u001b[0m  0.0264\n",
      "     18        \u001b[36m0.4816\u001b[0m       0.7031        \u001b[35m0.5329\u001b[0m  0.0583\n",
      "     19        \u001b[36m0.4787\u001b[0m       0.7109        \u001b[35m0.5302\u001b[0m  0.0283\n",
      "     20        \u001b[36m0.4785\u001b[0m       0.7031        \u001b[35m0.5290\u001b[0m  0.0287\n",
      "     21        \u001b[36m0.4766\u001b[0m       0.6953        \u001b[35m0.5289\u001b[0m  0.0510\n",
      "     22        \u001b[36m0.4766\u001b[0m       0.7031        \u001b[35m0.5277\u001b[0m  0.0303\n",
      "     23        0.4770       0.7031        \u001b[35m0.5248\u001b[0m  0.0312\n",
      "     24        \u001b[36m0.4741\u001b[0m       0.6875        \u001b[35m0.5234\u001b[0m  0.0554\n",
      "     25        \u001b[36m0.4737\u001b[0m       0.7031        \u001b[35m0.5223\u001b[0m  0.0275\n",
      "     26        \u001b[36m0.4734\u001b[0m       0.6875        0.5247  0.0396\n",
      "     27        \u001b[36m0.4724\u001b[0m       0.6953        \u001b[35m0.5221\u001b[0m  0.0498\n",
      "     28        \u001b[36m0.4713\u001b[0m       0.7031        0.5226  0.0267\n",
      "     29        0.4729       0.6953        0.5224  0.0361\n",
      "     30        \u001b[36m0.4704\u001b[0m       0.7031        0.5222  0.0424\n",
      "     31        0.4705       0.7031        \u001b[35m0.5212\u001b[0m  0.0435\n",
      "     32        \u001b[36m0.4703\u001b[0m       0.6953        \u001b[35m0.5202\u001b[0m  0.0279\n",
      "     33        0.4711       \u001b[32m0.7188\u001b[0m        0.5210  0.0465\n",
      "     34        0.4707       0.7031        \u001b[35m0.5187\u001b[0m  0.0528\n",
      "     35        \u001b[36m0.4695\u001b[0m       0.7109        \u001b[35m0.5182\u001b[0m  0.0427\n",
      "     36        0.4696       0.6953        0.5182  0.0260\n",
      "     37        0.4701       0.7031        \u001b[35m0.5180\u001b[0m  0.0435\n",
      "     38        \u001b[36m0.4677\u001b[0m       0.7109        \u001b[35m0.5161\u001b[0m  0.0265\n",
      "     39        0.4687       0.6953        0.5169  0.0261\n",
      "     40        0.4682       0.7188        0.5190  0.0899\n",
      "     41        \u001b[36m0.4670\u001b[0m       0.7188        0.5172  0.0301\n",
      "     42        0.4681       0.7109        \u001b[35m0.5156\u001b[0m  0.0315\n",
      "     43        \u001b[36m0.4665\u001b[0m       0.7031        0.5172  0.0420\n",
      "     44        0.4681       0.7031        0.5196  0.1234\n",
      "     45        0.4668       0.7031        0.5171  0.0573\n",
      "     46        0.4670       0.7188        0.5174  0.0361\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7239\u001b[0m       \u001b[32m0.3906\u001b[0m        \u001b[35m0.7115\u001b[0m  0.0361\n",
      "      2        \u001b[36m0.6975\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.6902\u001b[0m  0.0349\n",
      "      3        \u001b[36m0.6805\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6778\u001b[0m  0.0292\n",
      "      4        \u001b[36m0.6661\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6669\u001b[0m  0.0300\n",
      "      5        \u001b[36m0.6489\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6535\u001b[0m  0.0367\n",
      "      6        \u001b[36m0.6282\u001b[0m       0.6953        \u001b[35m0.6393\u001b[0m  0.0654\n",
      "      7        \u001b[36m0.6012\u001b[0m       0.6797        \u001b[35m0.6282\u001b[0m  0.0346\n",
      "      8        \u001b[36m0.5787\u001b[0m       0.6953        \u001b[35m0.6177\u001b[0m  0.0546\n",
      "      9        \u001b[36m0.5572\u001b[0m       0.6875        \u001b[35m0.6140\u001b[0m  0.0343\n",
      "     10        \u001b[36m0.5416\u001b[0m       0.6875        \u001b[35m0.6126\u001b[0m  0.0251\n",
      "     11        \u001b[36m0.5298\u001b[0m       0.6875        \u001b[35m0.6126\u001b[0m  0.0641\n",
      "     12        \u001b[36m0.5225\u001b[0m       0.6875        \u001b[35m0.6110\u001b[0m  0.0315\n",
      "     13        \u001b[36m0.5163\u001b[0m       0.6797        0.6124  0.0678\n",
      "     14        \u001b[36m0.5095\u001b[0m       0.6797        \u001b[35m0.6102\u001b[0m  0.0531\n",
      "     15        \u001b[36m0.5044\u001b[0m       0.6875        \u001b[35m0.6082\u001b[0m  0.0550\n",
      "     16        \u001b[36m0.4992\u001b[0m       0.6797        \u001b[35m0.6053\u001b[0m  0.0312\n",
      "     17        \u001b[36m0.4960\u001b[0m       0.6797        \u001b[35m0.6007\u001b[0m  0.0288\n",
      "     18        \u001b[36m0.4933\u001b[0m       0.6797        \u001b[35m0.5973\u001b[0m  0.0521\n",
      "     19        \u001b[36m0.4899\u001b[0m       0.6953        \u001b[35m0.5964\u001b[0m  0.0474\n",
      "     20        \u001b[36m0.4878\u001b[0m       0.6719        \u001b[35m0.5929\u001b[0m  0.0294\n",
      "     21        \u001b[36m0.4850\u001b[0m       0.6797        \u001b[35m0.5862\u001b[0m  0.0256\n",
      "     22        \u001b[36m0.4820\u001b[0m       0.6719        \u001b[35m0.5841\u001b[0m  0.0462\n",
      "     23        \u001b[36m0.4805\u001b[0m       0.6719        \u001b[35m0.5814\u001b[0m  0.0480\n",
      "     24        \u001b[36m0.4793\u001b[0m       0.6719        \u001b[35m0.5771\u001b[0m  0.0301\n",
      "     25        \u001b[36m0.4764\u001b[0m       0.6797        \u001b[35m0.5717\u001b[0m  0.0351\n",
      "     26        \u001b[36m0.4752\u001b[0m       0.6641        \u001b[35m0.5678\u001b[0m  0.0526\n",
      "     27        \u001b[36m0.4723\u001b[0m       0.6797        \u001b[35m0.5647\u001b[0m  0.0340\n",
      "     28        \u001b[36m0.4716\u001b[0m       0.6875        \u001b[35m0.5615\u001b[0m  0.0389\n",
      "     29        \u001b[36m0.4700\u001b[0m       0.6719        \u001b[35m0.5592\u001b[0m  0.0414\n",
      "     30        \u001b[36m0.4692\u001b[0m       0.6875        \u001b[35m0.5581\u001b[0m  0.0606\n",
      "     31        \u001b[36m0.4674\u001b[0m       0.6641        \u001b[35m0.5557\u001b[0m  0.0458\n",
      "     32        \u001b[36m0.4671\u001b[0m       0.6719        \u001b[35m0.5541\u001b[0m  0.0465\n",
      "     33        \u001b[36m0.4667\u001b[0m       0.6719        \u001b[35m0.5514\u001b[0m  0.0427\n",
      "     34        \u001b[36m0.4666\u001b[0m       0.6875        0.5534  0.0358\n",
      "     35        \u001b[36m0.4663\u001b[0m       0.6641        \u001b[35m0.5511\u001b[0m  0.0547\n",
      "     36        \u001b[36m0.4649\u001b[0m       0.6719        \u001b[35m0.5506\u001b[0m  0.0371\n",
      "     37        \u001b[36m0.4642\u001b[0m       0.6875        \u001b[35m0.5499\u001b[0m  0.0394\n",
      "     38        0.4649       0.6875        \u001b[35m0.5483\u001b[0m  0.0413\n",
      "     39        \u001b[36m0.4639\u001b[0m       0.6875        \u001b[35m0.5473\u001b[0m  0.0541\n",
      "     40        \u001b[36m0.4628\u001b[0m       0.6797        \u001b[35m0.5470\u001b[0m  0.0396\n",
      "     41        0.4629       0.6875        0.5471  0.0510\n",
      "     42        \u001b[36m0.4627\u001b[0m       0.6875        \u001b[35m0.5466\u001b[0m  0.0335\n",
      "     43        \u001b[36m0.4622\u001b[0m       0.6797        \u001b[35m0.5443\u001b[0m  0.0513\n",
      "     44        \u001b[36m0.4614\u001b[0m       0.6875        \u001b[35m0.5436\u001b[0m  0.0432\n",
      "     45        \u001b[36m0.4610\u001b[0m       0.6875        0.5447  0.0314\n",
      "     46        \u001b[36m0.4605\u001b[0m       0.6797        \u001b[35m0.5431\u001b[0m  0.0326\n",
      "     47        0.4605       0.6875        0.5443  0.0329\n",
      "     48        \u001b[36m0.4600\u001b[0m       0.6797        0.5433  0.0532\n",
      "     49        \u001b[36m0.4597\u001b[0m       0.6797        \u001b[35m0.5427\u001b[0m  0.0285\n",
      "     50        0.4616       0.6719        \u001b[35m0.5426\u001b[0m  0.0505\n",
      "     51        0.4598       0.6797        0.5433  0.0615\n",
      "     52        \u001b[36m0.4596\u001b[0m       0.6797        \u001b[35m0.5417\u001b[0m  0.0477\n",
      "     53        0.4601       0.6719        \u001b[35m0.5402\u001b[0m  0.0301\n",
      "     54        \u001b[36m0.4584\u001b[0m       0.6719        0.5413  0.0275\n",
      "     55        0.4586       0.6797        0.5416  0.0396\n",
      "     56        \u001b[36m0.4575\u001b[0m       0.6797        \u001b[35m0.5402\u001b[0m  0.0342\n",
      "     57        \u001b[36m0.4574\u001b[0m       0.6797        \u001b[35m0.5396\u001b[0m  0.0467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     58        0.4577       0.6875        \u001b[35m0.5390\u001b[0m  0.0318\n",
      "     59        0.4575       0.6797        \u001b[35m0.5373\u001b[0m  0.0350\n",
      "     60        \u001b[36m0.4565\u001b[0m       0.6797        \u001b[35m0.5370\u001b[0m  0.0314\n",
      "     61        \u001b[36m0.4556\u001b[0m       0.6797        0.5375  0.0356\n",
      "     62        \u001b[36m0.4554\u001b[0m       0.6719        0.5372  0.0350\n",
      "     63        \u001b[36m0.4552\u001b[0m       0.6719        \u001b[35m0.5369\u001b[0m  0.0299\n",
      "     64        \u001b[36m0.4551\u001b[0m       0.6719        0.5385  0.0726\n",
      "     65        \u001b[36m0.4549\u001b[0m       0.6719        0.5372  0.0430\n",
      "     66        \u001b[36m0.4544\u001b[0m       0.6719        0.5375  0.0434\n",
      "     67        0.4550       0.6797        0.5377  0.0338\n",
      "     68        0.4549       0.6641        \u001b[35m0.5364\u001b[0m  0.0400\n",
      "     69        0.4560       0.6641        0.5393  0.0491\n",
      "     70        0.4559       0.6797        0.5380  0.0614\n",
      "     71        \u001b[36m0.4540\u001b[0m       0.6719        0.5382  0.0415\n",
      "     72        0.4544       0.6641        0.5388  0.0364\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7532\u001b[0m       \u001b[32m0.4141\u001b[0m        \u001b[35m0.7340\u001b[0m  0.0364\n",
      "      2        \u001b[36m0.6887\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6741\u001b[0m  0.0722\n",
      "      3        \u001b[36m0.6328\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6232\u001b[0m  0.0740\n",
      "      4        \u001b[36m0.5762\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5862\u001b[0m  0.0775\n",
      "      5        \u001b[36m0.5343\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5648\u001b[0m  0.0417\n",
      "      6        \u001b[36m0.5070\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5574\u001b[0m  0.0651\n",
      "      7        \u001b[36m0.4897\u001b[0m       0.7422        \u001b[35m0.5547\u001b[0m  0.0563\n",
      "      8        \u001b[36m0.4800\u001b[0m       0.7422        \u001b[35m0.5511\u001b[0m  0.0745\n",
      "      9        \u001b[36m0.4717\u001b[0m       0.7500        \u001b[35m0.5484\u001b[0m  0.0574\n",
      "     10        \u001b[36m0.4656\u001b[0m       0.7578        \u001b[35m0.5471\u001b[0m  0.0685\n",
      "     11        \u001b[36m0.4591\u001b[0m       0.7422        \u001b[35m0.5413\u001b[0m  0.0545\n",
      "     12        \u001b[36m0.4525\u001b[0m       0.7422        \u001b[35m0.5385\u001b[0m  0.0867\n",
      "     13        \u001b[36m0.4473\u001b[0m       0.7422        0.5390  0.0576\n",
      "     14        \u001b[36m0.4443\u001b[0m       0.7422        0.5393  0.0484\n",
      "     15        \u001b[36m0.4422\u001b[0m       0.7422        0.5403  0.0850\n",
      "     16        \u001b[36m0.4408\u001b[0m       0.7344        0.5399  0.0753\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5823\u001b[0m       \u001b[32m0.7438\u001b[0m        \u001b[35m0.5287\u001b[0m  0.1108\n",
      "      2        \u001b[36m0.5223\u001b[0m       0.7375        \u001b[35m0.5176\u001b[0m  0.1070\n",
      "      3        \u001b[36m0.5207\u001b[0m       0.7438        \u001b[35m0.5165\u001b[0m  0.1023\n",
      "      4        \u001b[36m0.5116\u001b[0m       0.7312        \u001b[35m0.5064\u001b[0m  0.0811\n",
      "      5        \u001b[36m0.5078\u001b[0m       0.7250        0.5178  0.0959\n",
      "      6        \u001b[36m0.5025\u001b[0m       0.7375        0.5107  0.0578\n",
      "      7        \u001b[36m0.4897\u001b[0m       0.6813        0.5281  0.0949\n",
      "      8        0.5091       0.7312        0.5326  0.0630\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best parameters found:\n",
      "\n",
      "{'optimizer__momentum': 0.9, 'module__num_units': 7, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 32}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.755 (+/-0.138) for {'optimizer__momentum': 0.3, 'module__num_units': 5, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 32}\n",
      "0.787 (+/-0.048) for {'optimizer__momentum': 0.9, 'module__num_units': 7, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 32}\n",
      "0.756 (+/-0.070) for {'optimizer__momentum': 0.6, 'module__num_units': 3, 'module__dropout': 0.5, 'lr': 0.1, 'batch_size': 16}\n",
      "0.696 (+/-0.034) for {'optimizer__momentum': 0.9, 'module__num_units': 3, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 16}\n",
      "0.753 (+/-0.048) for {'optimizer__momentum': 0.1, 'module__num_units': 4, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 32}\n",
      "0.760 (+/-0.090) for {'optimizer__momentum': 0.3, 'module__num_units': 6, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 16}\n",
      "0.752 (+/-0.061) for {'optimizer__momentum': 0.9, 'module__num_units': 8, 'module__dropout': 0.5, 'lr': 0.01, 'batch_size': 64}\n",
      "0.758 (+/-0.079) for {'optimizer__momentum': 0.6, 'module__num_units': 9, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 16}\n",
      "0.747 (+/-0.059) for {'optimizer__momentum': 0.6, 'module__num_units': 4, 'module__dropout': 0.5, 'lr': 0.01, 'batch_size': 32}\n",
      "0.759 (+/-0.049) for {'optimizer__momentum': 0.9, 'module__num_units': 3, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 32}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6345\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4585\u001b[0m  0.0614\n",
      "      2        \u001b[36m0.5884\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.3989\u001b[0m  0.0865\n",
      "      3        \u001b[36m0.5658\u001b[0m       0.7891        0.4890  0.1207\n",
      "      4        0.5866       0.7891        0.4352  0.0655\n",
      "      5        \u001b[36m0.5624\u001b[0m       0.7812        0.4413  0.0774\n",
      "      6        0.5900       0.7578        0.4646  0.0880\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6117\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5404\u001b[0m  0.0998\n",
      "      2        \u001b[36m0.5422\u001b[0m       0.7344        0.5784  0.0544\n",
      "      3        0.5633       0.7031        0.5878  0.0912\n",
      "      4        0.5443       0.7031        0.5668  0.0882\n",
      "      5        0.5458       0.7031        \u001b[35m0.5374\u001b[0m  0.0681\n",
      "      6        0.5559       0.7266        0.5405  0.0655\n",
      "      7        0.5518       0.7266        \u001b[35m0.5329\u001b[0m  0.0778\n",
      "      8        0.5494       \u001b[32m0.7812\u001b[0m        \u001b[35m0.5306\u001b[0m  0.0710\n",
      "      9        \u001b[36m0.5324\u001b[0m       0.7188        0.6123  0.0799\n",
      "     10        0.5481       0.7109        0.5500  0.1157\n",
      "     11        0.5329       0.7188        \u001b[35m0.5296\u001b[0m  0.1471\n",
      "     12        \u001b[36m0.5141\u001b[0m       0.7266        \u001b[35m0.5226\u001b[0m  0.1000\n",
      "     13        0.5342       0.7344        0.5576  0.0624\n",
      "     14        0.5308       0.7188        0.5605  0.0438\n",
      "     15        0.5279       0.7500        0.5292  0.0448\n",
      "     16        0.5543       0.7344        0.5702  0.0433\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6310\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5332\u001b[0m  0.0746\n",
      "      2        \u001b[36m0.6151\u001b[0m       \u001b[32m0.7188\u001b[0m        0.5335  0.0428\n",
      "      3        \u001b[36m0.5636\u001b[0m       0.6562        0.6763  0.0678\n",
      "      4        0.5958       \u001b[32m0.7500\u001b[0m        \u001b[35m0.4985\u001b[0m  0.0583\n",
      "      5        \u001b[36m0.5315\u001b[0m       \u001b[32m0.7656\u001b[0m        0.5197  0.0703\n",
      "      6        0.5448       0.6875        0.5842  0.0774\n",
      "      7        0.5753       0.7500        0.5738  0.0691\n",
      "      8        0.5615       0.7188        0.5204  0.0582\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6393\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5225\u001b[0m  0.0482\n",
      "      2        \u001b[36m0.5609\u001b[0m       0.7500        \u001b[35m0.5085\u001b[0m  0.0498\n",
      "      3        \u001b[36m0.5569\u001b[0m       0.7109        0.5500  0.0496\n",
      "      4        \u001b[36m0.5409\u001b[0m       0.6016        0.6578  0.0569\n",
      "      5        0.5804       \u001b[32m0.7656\u001b[0m        0.5380  0.0558\n",
      "      6        0.5468       0.7578        0.5452  0.0611\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6538\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6136\u001b[0m  0.0790\n",
      "      2        \u001b[36m0.5828\u001b[0m       0.6094        0.7022  0.0436\n",
      "      3        0.6424       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5285\u001b[0m  0.0681\n",
      "      4        0.6143       0.7422        0.5569  0.0608\n",
      "      5        \u001b[36m0.5655\u001b[0m       0.6953        0.5435  0.0543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6        \u001b[36m0.5636\u001b[0m       0.7031        0.5685  0.0671\n",
      "      7        0.5638       0.7344        0.5896  0.0495\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7010\u001b[0m       \u001b[32m0.4375\u001b[0m        \u001b[35m0.7062\u001b[0m  0.0663\n",
      "      2        \u001b[36m0.6895\u001b[0m       \u001b[32m0.4453\u001b[0m        \u001b[35m0.6992\u001b[0m  0.0186\n",
      "      3        \u001b[36m0.6862\u001b[0m       0.4375        \u001b[35m0.6932\u001b[0m  0.0408\n",
      "      4        \u001b[36m0.6831\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m0.6871\u001b[0m  0.0220\n",
      "      5        \u001b[36m0.6788\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.6817\u001b[0m  0.0175\n",
      "      6        \u001b[36m0.6694\u001b[0m       0.4844        \u001b[35m0.6765\u001b[0m  0.0178\n",
      "      7        0.6719       0.4844        \u001b[35m0.6717\u001b[0m  0.0399\n",
      "      8        \u001b[36m0.6637\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6672\u001b[0m  0.0195\n",
      "      9        \u001b[36m0.6595\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6632\u001b[0m  0.0472\n",
      "     10        \u001b[36m0.6533\u001b[0m       0.5469        \u001b[35m0.6593\u001b[0m  0.0273\n",
      "     11        0.6560       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6557\u001b[0m  0.0260\n",
      "     12        0.6568       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6521\u001b[0m  0.0191\n",
      "     13        \u001b[36m0.6493\u001b[0m       0.5781        \u001b[35m0.6489\u001b[0m  0.0435\n",
      "     14        \u001b[36m0.6420\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6455\u001b[0m  0.0204\n",
      "     15        \u001b[36m0.6405\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6425\u001b[0m  0.0434\n",
      "     16        0.6444       0.6094        \u001b[35m0.6395\u001b[0m  0.0196\n",
      "     17        \u001b[36m0.6335\u001b[0m       0.6094        \u001b[35m0.6366\u001b[0m  0.0249\n",
      "     18        \u001b[36m0.6296\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6338\u001b[0m  0.0193\n",
      "     19        0.6337       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6312\u001b[0m  0.0229\n",
      "     20        0.6321       0.6406        \u001b[35m0.6285\u001b[0m  0.0197\n",
      "     21        0.6342       0.6406        \u001b[35m0.6260\u001b[0m  0.0395\n",
      "     22        \u001b[36m0.6227\u001b[0m       0.6406        \u001b[35m0.6235\u001b[0m  0.0194\n",
      "     23        0.6283       0.6406        \u001b[35m0.6210\u001b[0m  0.0379\n",
      "     24        \u001b[36m0.6212\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6187\u001b[0m  0.0226\n",
      "     25        0.6213       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6163\u001b[0m  0.0467\n",
      "     26        0.6222       0.6641        \u001b[35m0.6141\u001b[0m  0.0237\n",
      "     27        0.6232       0.6641        \u001b[35m0.6120\u001b[0m  0.0313\n",
      "     28        \u001b[36m0.6071\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6097\u001b[0m  0.0465\n",
      "     29        0.6120       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6075\u001b[0m  0.0205\n",
      "     30        0.6120       0.6797        \u001b[35m0.6054\u001b[0m  0.0274\n",
      "     31        0.6083       0.6797        \u001b[35m0.6034\u001b[0m  0.0197\n",
      "     32        \u001b[36m0.6033\u001b[0m       0.6797        \u001b[35m0.6014\u001b[0m  0.0460\n",
      "     33        0.6059       0.6797        \u001b[35m0.5996\u001b[0m  0.0192\n",
      "     34        \u001b[36m0.6027\u001b[0m       0.6797        \u001b[35m0.5974\u001b[0m  0.0475\n",
      "     35        0.6044       0.6797        \u001b[35m0.5955\u001b[0m  0.0278\n",
      "     36        \u001b[36m0.6000\u001b[0m       0.6797        \u001b[35m0.5936\u001b[0m  0.0219\n",
      "     37        \u001b[36m0.5946\u001b[0m       0.6797        \u001b[35m0.5918\u001b[0m  0.0207\n",
      "     38        0.5972       0.6797        \u001b[35m0.5899\u001b[0m  0.0190\n",
      "     39        0.5999       0.6797        \u001b[35m0.5882\u001b[0m  0.0262\n",
      "     40        0.6034       0.6797        \u001b[35m0.5866\u001b[0m  0.0232\n",
      "     41        0.6006       0.6797        \u001b[35m0.5849\u001b[0m  0.0590\n",
      "     42        0.5983       0.6797        \u001b[35m0.5832\u001b[0m  0.0207\n",
      "     43        \u001b[36m0.5914\u001b[0m       0.6797        \u001b[35m0.5815\u001b[0m  0.0518\n",
      "     44        \u001b[36m0.5905\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5798\u001b[0m  0.0206\n",
      "     45        0.5924       0.6953        \u001b[35m0.5781\u001b[0m  0.0348\n",
      "     46        \u001b[36m0.5839\u001b[0m       0.6953        \u001b[35m0.5764\u001b[0m  0.0216\n",
      "     47        0.5857       0.6953        \u001b[35m0.5747\u001b[0m  0.0315\n",
      "     48        0.5876       0.6953        \u001b[35m0.5732\u001b[0m  0.0254\n",
      "     49        \u001b[36m0.5826\u001b[0m       0.6953        \u001b[35m0.5716\u001b[0m  0.0340\n",
      "     50        0.5896       0.6953        \u001b[35m0.5699\u001b[0m  0.0352\n",
      "     51        0.5826       0.6953        \u001b[35m0.5684\u001b[0m  0.0682\n",
      "     52        0.5841       0.6953        \u001b[35m0.5668\u001b[0m  0.0378\n",
      "     53        \u001b[36m0.5784\u001b[0m       0.6953        \u001b[35m0.5653\u001b[0m  0.0445\n",
      "     54        0.5818       0.6953        \u001b[35m0.5638\u001b[0m  0.0319\n",
      "     55        \u001b[36m0.5723\u001b[0m       0.6953        \u001b[35m0.5621\u001b[0m  0.0273\n",
      "     56        0.5839       0.6953        \u001b[35m0.5607\u001b[0m  0.0336\n",
      "     57        0.5827       0.6953        \u001b[35m0.5593\u001b[0m  0.0267\n",
      "     58        0.5764       0.6953        \u001b[35m0.5579\u001b[0m  0.0262\n",
      "     59        0.5724       0.6953        \u001b[35m0.5565\u001b[0m  0.0267\n",
      "     60        0.5738       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5551\u001b[0m  0.0373\n",
      "     61        0.5795       0.7109        \u001b[35m0.5536\u001b[0m  0.0210\n",
      "     62        0.5752       0.7109        \u001b[35m0.5522\u001b[0m  0.0230\n",
      "     63        \u001b[36m0.5674\u001b[0m       0.7109        \u001b[35m0.5508\u001b[0m  0.0214\n",
      "     64        0.5714       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5494\u001b[0m  0.0251\n",
      "     65        0.5727       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5480\u001b[0m  0.0165\n",
      "     66        \u001b[36m0.5624\u001b[0m       0.7266        \u001b[35m0.5465\u001b[0m  0.0163\n",
      "     67        0.5714       0.7266        \u001b[35m0.5450\u001b[0m  0.0167\n",
      "     68        0.5682       0.7266        \u001b[35m0.5436\u001b[0m  0.0165\n",
      "     69        0.5719       0.7266        \u001b[35m0.5423\u001b[0m  0.0152\n",
      "     70        0.5653       0.7266        \u001b[35m0.5410\u001b[0m  0.0209\n",
      "     71        0.5648       0.7266        \u001b[35m0.5396\u001b[0m  0.0221\n",
      "     72        \u001b[36m0.5585\u001b[0m       0.7266        \u001b[35m0.5382\u001b[0m  0.0230\n",
      "     73        0.5724       0.7266        \u001b[35m0.5369\u001b[0m  0.0215\n",
      "     74        0.5586       0.7266        \u001b[35m0.5354\u001b[0m  0.0202\n",
      "     75        0.5607       0.7266        \u001b[35m0.5342\u001b[0m  0.0202\n",
      "     76        0.5590       0.7266        \u001b[35m0.5329\u001b[0m  0.0178\n",
      "     77        0.5687       0.7266        \u001b[35m0.5315\u001b[0m  0.0217\n",
      "     78        \u001b[36m0.5572\u001b[0m       0.7266        \u001b[35m0.5302\u001b[0m  0.0412\n",
      "     79        0.5596       0.7266        \u001b[35m0.5289\u001b[0m  0.0164\n",
      "     80        \u001b[36m0.5535\u001b[0m       0.7266        \u001b[35m0.5275\u001b[0m  0.0156\n",
      "     81        0.5653       0.7266        \u001b[35m0.5264\u001b[0m  0.0145\n",
      "     82        0.5652       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5253\u001b[0m  0.0392\n",
      "     83        0.5597       0.7344        \u001b[35m0.5242\u001b[0m  0.0168\n",
      "     84        0.5567       0.7344        \u001b[35m0.5229\u001b[0m  0.0162\n",
      "     85        0.5551       0.7344        \u001b[35m0.5217\u001b[0m  0.0137\n",
      "     86        0.5625       0.7344        \u001b[35m0.5205\u001b[0m  0.0416\n",
      "     87        \u001b[36m0.5498\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5192\u001b[0m  0.0171\n",
      "     88        0.5531       0.7422        \u001b[35m0.5178\u001b[0m  0.0240\n",
      "     89        0.5610       0.7422        \u001b[35m0.5166\u001b[0m  0.0157\n",
      "     90        0.5529       0.7422        \u001b[35m0.5154\u001b[0m  0.0176\n",
      "     91        \u001b[36m0.5487\u001b[0m       0.7422        \u001b[35m0.5142\u001b[0m  0.0313\n",
      "     92        0.5593       0.7422        \u001b[35m0.5129\u001b[0m  0.0311\n",
      "     93        \u001b[36m0.5413\u001b[0m       0.7422        \u001b[35m0.5116\u001b[0m  0.0172\n",
      "     94        0.5516       0.7422        \u001b[35m0.5104\u001b[0m  0.0198\n",
      "     95        0.5491       0.7422        \u001b[35m0.5092\u001b[0m  0.0298\n",
      "     96        0.5477       0.7422        \u001b[35m0.5080\u001b[0m  0.0260\n",
      "     97        0.5489       0.7422        \u001b[35m0.5068\u001b[0m  0.0246\n",
      "     98        0.5468       0.7344        \u001b[35m0.5057\u001b[0m  0.0256\n",
      "     99        \u001b[36m0.5387\u001b[0m       0.7344        \u001b[35m0.5045\u001b[0m  0.0281\n",
      "    100        0.5391       0.7344        \u001b[35m0.5032\u001b[0m  0.0323\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7921\u001b[0m       \u001b[32m0.4453\u001b[0m        \u001b[35m0.7716\u001b[0m  0.0222\n",
      "      2        \u001b[36m0.7745\u001b[0m       0.4453        \u001b[35m0.7577\u001b[0m  0.0307\n",
      "      3        \u001b[36m0.7642\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m0.7452\u001b[0m  0.0153\n",
      "      4        \u001b[36m0.7544\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m0.7342\u001b[0m  0.0191\n",
      "      5        \u001b[36m0.7409\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m0.7238\u001b[0m  0.0256\n",
      "      6        \u001b[36m0.7283\u001b[0m       0.4609        \u001b[35m0.7145\u001b[0m  0.0255\n",
      "      7        \u001b[36m0.7152\u001b[0m       0.4688        \u001b[35m0.7062\u001b[0m  0.0157\n",
      "      8        \u001b[36m0.7113\u001b[0m       \u001b[32m0.4844\u001b[0m        \u001b[35m0.6984\u001b[0m  0.0161\n",
      "      9        \u001b[36m0.7005\u001b[0m       0.4688        \u001b[35m0.6913\u001b[0m  0.0257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        \u001b[36m0.6956\u001b[0m       0.4766        \u001b[35m0.6849\u001b[0m  0.0233\n",
      "     11        \u001b[36m0.6884\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6784\u001b[0m  0.0161\n",
      "     12        \u001b[36m0.6813\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6728\u001b[0m  0.0373\n",
      "     13        \u001b[36m0.6795\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6674\u001b[0m  0.0320\n",
      "     14        \u001b[36m0.6746\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6619\u001b[0m  0.0209\n",
      "     15        \u001b[36m0.6697\u001b[0m       0.6797        \u001b[35m0.6565\u001b[0m  0.0236\n",
      "     16        \u001b[36m0.6639\u001b[0m       0.7031        \u001b[35m0.6514\u001b[0m  0.0165\n",
      "     17        \u001b[36m0.6623\u001b[0m       0.6953        \u001b[35m0.6468\u001b[0m  0.0259\n",
      "     18        \u001b[36m0.6556\u001b[0m       0.6875        \u001b[35m0.6423\u001b[0m  0.0275\n",
      "     19        \u001b[36m0.6546\u001b[0m       0.6875        \u001b[35m0.6378\u001b[0m  0.0275\n",
      "     20        \u001b[36m0.6449\u001b[0m       0.6797        \u001b[35m0.6335\u001b[0m  0.0323\n",
      "     21        \u001b[36m0.6445\u001b[0m       0.6797        \u001b[35m0.6293\u001b[0m  0.0267\n",
      "     22        \u001b[36m0.6350\u001b[0m       0.6875        \u001b[35m0.6250\u001b[0m  0.0214\n",
      "     23        \u001b[36m0.6269\u001b[0m       0.6953        \u001b[35m0.6205\u001b[0m  0.0145\n",
      "     24        0.6292       0.7031        \u001b[35m0.6165\u001b[0m  0.0245\n",
      "     25        \u001b[36m0.6268\u001b[0m       0.7031        \u001b[35m0.6128\u001b[0m  0.0159\n",
      "     26        \u001b[36m0.6155\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6089\u001b[0m  0.0257\n",
      "     27        0.6200       0.7109        \u001b[35m0.6054\u001b[0m  0.0241\n",
      "     28        0.6157       0.7109        \u001b[35m0.6019\u001b[0m  0.0146\n",
      "     29        \u001b[36m0.6102\u001b[0m       0.7109        \u001b[35m0.5984\u001b[0m  0.0266\n",
      "     30        \u001b[36m0.6074\u001b[0m       0.7109        \u001b[35m0.5952\u001b[0m  0.0320\n",
      "     31        \u001b[36m0.5973\u001b[0m       0.7109        \u001b[35m0.5919\u001b[0m  0.0314\n",
      "     32        0.5989       0.7109        \u001b[35m0.5887\u001b[0m  0.0201\n",
      "     33        0.5999       0.7031        \u001b[35m0.5857\u001b[0m  0.0158\n",
      "     34        0.6026       0.7031        \u001b[35m0.5830\u001b[0m  0.0287\n",
      "     35        0.6030       0.7031        \u001b[35m0.5806\u001b[0m  0.0243\n",
      "     36        \u001b[36m0.5922\u001b[0m       0.7031        \u001b[35m0.5779\u001b[0m  0.0170\n",
      "     37        \u001b[36m0.5902\u001b[0m       0.7031        \u001b[35m0.5755\u001b[0m  0.0275\n",
      "     38        \u001b[36m0.5858\u001b[0m       0.7031        \u001b[35m0.5729\u001b[0m  0.0273\n",
      "     39        \u001b[36m0.5836\u001b[0m       0.7031        \u001b[35m0.5706\u001b[0m  0.0173\n",
      "     40        0.5864       0.7031        \u001b[35m0.5684\u001b[0m  0.0264\n",
      "     41        0.5911       0.7031        \u001b[35m0.5665\u001b[0m  0.0165\n",
      "     42        \u001b[36m0.5799\u001b[0m       0.7109        \u001b[35m0.5644\u001b[0m  0.0195\n",
      "     43        \u001b[36m0.5718\u001b[0m       0.7109        \u001b[35m0.5624\u001b[0m  0.0199\n",
      "     44        0.5849       0.7109        \u001b[35m0.5606\u001b[0m  0.0245\n",
      "     45        0.5755       0.7109        \u001b[35m0.5586\u001b[0m  0.0265\n",
      "     46        0.5829       0.7109        \u001b[35m0.5571\u001b[0m  0.0342\n",
      "     47        0.5782       0.7109        \u001b[35m0.5555\u001b[0m  0.0171\n",
      "     48        \u001b[36m0.5593\u001b[0m       0.7109        \u001b[35m0.5538\u001b[0m  0.0287\n",
      "     49        0.5750       0.7109        \u001b[35m0.5523\u001b[0m  0.0298\n",
      "     50        0.5764       0.7109        \u001b[35m0.5511\u001b[0m  0.0296\n",
      "     51        0.5792       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5499\u001b[0m  0.0247\n",
      "     52        0.5832       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5489\u001b[0m  0.0255\n",
      "     53        0.5653       0.7266        \u001b[35m0.5476\u001b[0m  0.0232\n",
      "     54        0.5663       0.7188        \u001b[35m0.5464\u001b[0m  0.0218\n",
      "     55        0.5702       0.7188        \u001b[35m0.5453\u001b[0m  0.0142\n",
      "     56        0.5813       0.7188        \u001b[35m0.5445\u001b[0m  0.0134\n",
      "     57        \u001b[36m0.5578\u001b[0m       0.7266        \u001b[35m0.5433\u001b[0m  0.0230\n",
      "     58        0.5670       0.7266        \u001b[35m0.5422\u001b[0m  0.0249\n",
      "     59        0.5656       0.7266        \u001b[35m0.5412\u001b[0m  0.0160\n",
      "     60        0.5607       0.7266        \u001b[35m0.5402\u001b[0m  0.0397\n",
      "     61        \u001b[36m0.5534\u001b[0m       0.7266        \u001b[35m0.5393\u001b[0m  0.0158\n",
      "     62        0.5636       0.7266        \u001b[35m0.5384\u001b[0m  0.0266\n",
      "     63        0.5686       0.7266        \u001b[35m0.5376\u001b[0m  0.0161\n",
      "     64        0.5573       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5368\u001b[0m  0.0152\n",
      "     65        \u001b[36m0.5491\u001b[0m       0.7344        \u001b[35m0.5360\u001b[0m  0.0210\n",
      "     66        0.5579       0.7344        \u001b[35m0.5353\u001b[0m  0.0208\n",
      "     67        0.5636       0.7344        \u001b[35m0.5346\u001b[0m  0.0152\n",
      "     68        0.5529       0.7266        \u001b[35m0.5339\u001b[0m  0.0135\n",
      "     69        \u001b[36m0.5414\u001b[0m       0.7344        \u001b[35m0.5330\u001b[0m  0.0185\n",
      "     70        0.5516       0.7344        \u001b[35m0.5323\u001b[0m  0.0294\n",
      "     71        \u001b[36m0.5384\u001b[0m       0.7344        \u001b[35m0.5316\u001b[0m  0.0154\n",
      "     72        0.5462       0.7344        \u001b[35m0.5311\u001b[0m  0.0154\n",
      "     73        0.5443       0.7344        \u001b[35m0.5304\u001b[0m  0.0287\n",
      "     74        0.5562       0.7344        \u001b[35m0.5298\u001b[0m  0.0149\n",
      "     75        0.5474       0.7344        \u001b[35m0.5292\u001b[0m  0.0144\n",
      "     76        0.5550       0.7344        \u001b[35m0.5286\u001b[0m  0.0215\n",
      "     77        0.5440       0.7344        \u001b[35m0.5281\u001b[0m  0.0303\n",
      "     78        0.5588       0.7344        \u001b[35m0.5276\u001b[0m  0.0245\n",
      "     79        \u001b[36m0.5352\u001b[0m       0.7344        \u001b[35m0.5270\u001b[0m  0.0313\n",
      "     80        0.5563       0.7344        \u001b[35m0.5265\u001b[0m  0.0386\n",
      "     81        0.5508       0.7344        \u001b[35m0.5262\u001b[0m  0.0156\n",
      "     82        \u001b[36m0.5323\u001b[0m       0.7344        \u001b[35m0.5258\u001b[0m  0.0244\n",
      "     83        0.5522       0.7344        \u001b[35m0.5254\u001b[0m  0.0262\n",
      "     84        0.5602       0.7344        \u001b[35m0.5251\u001b[0m  0.0144\n",
      "     85        0.5708       0.7344        \u001b[35m0.5249\u001b[0m  0.0275\n",
      "     86        0.5544       0.7344        \u001b[35m0.5246\u001b[0m  0.0686\n",
      "     87        0.5411       0.7344        \u001b[35m0.5241\u001b[0m  0.0618\n",
      "     88        \u001b[36m0.5314\u001b[0m       0.7344        \u001b[35m0.5238\u001b[0m  0.0601\n",
      "     89        0.5377       0.7344        \u001b[35m0.5234\u001b[0m  0.0219\n",
      "     90        0.5474       0.7344        \u001b[35m0.5230\u001b[0m  0.0570\n",
      "     91        \u001b[36m0.5272\u001b[0m       0.7344        \u001b[35m0.5226\u001b[0m  0.0251\n",
      "     92        0.5452       0.7344        \u001b[35m0.5223\u001b[0m  0.0178\n",
      "     93        0.5323       0.7344        \u001b[35m0.5220\u001b[0m  0.0273\n",
      "     94        0.5400       0.7344        \u001b[35m0.5218\u001b[0m  0.0299\n",
      "     95        0.5508       0.7344        \u001b[35m0.5216\u001b[0m  0.0263\n",
      "     96        \u001b[36m0.5172\u001b[0m       0.7344        \u001b[35m0.5212\u001b[0m  0.0213\n",
      "     97        0.5308       0.7344        \u001b[35m0.5210\u001b[0m  0.0164\n",
      "     98        0.5352       0.7344        \u001b[35m0.5207\u001b[0m  0.0170\n",
      "     99        0.5462       0.7344        \u001b[35m0.5206\u001b[0m  0.0153\n",
      "    100        0.5456       0.7344        \u001b[35m0.5204\u001b[0m  0.0173\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7524\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7263\u001b[0m  0.0129\n",
      "      2        \u001b[36m0.7414\u001b[0m       0.5000        \u001b[35m0.7052\u001b[0m  0.0160\n",
      "      3        \u001b[36m0.7028\u001b[0m       0.5000        \u001b[35m0.6877\u001b[0m  0.0197\n",
      "      4        \u001b[36m0.6892\u001b[0m       0.5000        \u001b[35m0.6736\u001b[0m  0.0151\n",
      "      5        \u001b[36m0.6798\u001b[0m       0.5000        \u001b[35m0.6623\u001b[0m  0.0267\n",
      "      6        \u001b[36m0.6596\u001b[0m       0.5000        \u001b[35m0.6531\u001b[0m  0.0296\n",
      "      7        \u001b[36m0.6454\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6457\u001b[0m  0.0763\n",
      "      8        \u001b[36m0.6429\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6386\u001b[0m  0.0548\n",
      "      9        \u001b[36m0.6357\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6323\u001b[0m  0.0294\n",
      "     10        \u001b[36m0.6258\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6271\u001b[0m  0.0229\n",
      "     11        \u001b[36m0.6214\u001b[0m       0.7109        \u001b[35m0.6224\u001b[0m  0.0152\n",
      "     12        \u001b[36m0.6176\u001b[0m       0.7031        \u001b[35m0.6182\u001b[0m  0.0213\n",
      "     13        \u001b[36m0.6166\u001b[0m       0.7109        \u001b[35m0.6145\u001b[0m  0.0282\n",
      "     14        \u001b[36m0.6086\u001b[0m       0.7188        \u001b[35m0.6110\u001b[0m  0.0160\n",
      "     15        \u001b[36m0.6052\u001b[0m       0.7109        \u001b[35m0.6079\u001b[0m  0.0220\n",
      "     16        0.6055       0.7031        \u001b[35m0.6052\u001b[0m  0.0183\n",
      "     17        \u001b[36m0.5865\u001b[0m       0.7109        \u001b[35m0.6024\u001b[0m  0.0145\n",
      "     18        0.5902       0.7109        \u001b[35m0.6001\u001b[0m  0.0154\n",
      "     19        \u001b[36m0.5827\u001b[0m       0.7109        \u001b[35m0.5978\u001b[0m  0.0232\n",
      "     20        0.5847       0.7109        \u001b[35m0.5957\u001b[0m  0.0163\n",
      "     21        0.5843       0.7109        \u001b[35m0.5939\u001b[0m  0.0238\n",
      "     22        0.5901       0.7109        \u001b[35m0.5922\u001b[0m  0.0239\n",
      "     23        \u001b[36m0.5785\u001b[0m       0.7109        \u001b[35m0.5905\u001b[0m  0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24        \u001b[36m0.5711\u001b[0m       0.7109        \u001b[35m0.5888\u001b[0m  0.0182\n",
      "     25        0.5739       0.7188        \u001b[35m0.5874\u001b[0m  0.0232\n",
      "     26        0.5755       0.7188        \u001b[35m0.5861\u001b[0m  0.0195\n",
      "     27        0.5769       0.7188        \u001b[35m0.5848\u001b[0m  0.0381\n",
      "     28        \u001b[36m0.5661\u001b[0m       0.7188        \u001b[35m0.5835\u001b[0m  0.0160\n",
      "     29        \u001b[36m0.5638\u001b[0m       0.7188        \u001b[35m0.5821\u001b[0m  0.0168\n",
      "     30        0.5732       0.7188        \u001b[35m0.5810\u001b[0m  0.0320\n",
      "     31        0.5710       0.7188        \u001b[35m0.5800\u001b[0m  0.0182\n",
      "     32        0.5673       0.7188        \u001b[35m0.5790\u001b[0m  0.0183\n",
      "     33        0.5645       0.7188        \u001b[35m0.5780\u001b[0m  0.0186\n",
      "     34        \u001b[36m0.5548\u001b[0m       0.7188        \u001b[35m0.5770\u001b[0m  0.0311\n",
      "     35        0.5571       0.7188        \u001b[35m0.5761\u001b[0m  0.0267\n",
      "     36        0.5633       0.7188        \u001b[35m0.5752\u001b[0m  0.0314\n",
      "     37        0.5703       0.7188        \u001b[35m0.5744\u001b[0m  0.0208\n",
      "     38        0.5613       0.7188        \u001b[35m0.5737\u001b[0m  0.0257\n",
      "     39        \u001b[36m0.5540\u001b[0m       0.7188        \u001b[35m0.5729\u001b[0m  0.0237\n",
      "     40        0.5629       0.7188        \u001b[35m0.5722\u001b[0m  0.0296\n",
      "     41        0.5550       0.7188        \u001b[35m0.5715\u001b[0m  0.0286\n",
      "     42        \u001b[36m0.5509\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5710\u001b[0m  0.0157\n",
      "     43        \u001b[36m0.5506\u001b[0m       0.7266        \u001b[35m0.5703\u001b[0m  0.0147\n",
      "     44        \u001b[36m0.5491\u001b[0m       0.7266        \u001b[35m0.5697\u001b[0m  0.0240\n",
      "     45        \u001b[36m0.5422\u001b[0m       0.7266        \u001b[35m0.5691\u001b[0m  0.0183\n",
      "     46        \u001b[36m0.5413\u001b[0m       0.7188        \u001b[35m0.5684\u001b[0m  0.0246\n",
      "     47        0.5481       0.7188        \u001b[35m0.5680\u001b[0m  0.0187\n",
      "     48        \u001b[36m0.5354\u001b[0m       0.7188        \u001b[35m0.5676\u001b[0m  0.0245\n",
      "     49        0.5554       0.7188        \u001b[35m0.5671\u001b[0m  0.0205\n",
      "     50        0.5453       0.7188        \u001b[35m0.5667\u001b[0m  0.0232\n",
      "     51        0.5490       0.7188        \u001b[35m0.5662\u001b[0m  0.0267\n",
      "     52        0.5366       0.7188        \u001b[35m0.5657\u001b[0m  0.0209\n",
      "     53        0.5377       0.7188        \u001b[35m0.5651\u001b[0m  0.0277\n",
      "     54        0.5374       0.7188        \u001b[35m0.5645\u001b[0m  0.0143\n",
      "     55        \u001b[36m0.5319\u001b[0m       0.7188        \u001b[35m0.5642\u001b[0m  0.0219\n",
      "     56        0.5442       0.7188        \u001b[35m0.5639\u001b[0m  0.0227\n",
      "     57        0.5426       0.7188        \u001b[35m0.5635\u001b[0m  0.0397\n",
      "     58        0.5355       0.7188        \u001b[35m0.5631\u001b[0m  0.0262\n",
      "     59        0.5377       0.7188        \u001b[35m0.5627\u001b[0m  0.0217\n",
      "     60        \u001b[36m0.5298\u001b[0m       0.7188        \u001b[35m0.5625\u001b[0m  0.0163\n",
      "     61        0.5446       0.7188        \u001b[35m0.5620\u001b[0m  0.0229\n",
      "     62        \u001b[36m0.5283\u001b[0m       0.7188        \u001b[35m0.5618\u001b[0m  0.0156\n",
      "     63        0.5394       0.7188        \u001b[35m0.5616\u001b[0m  0.0214\n",
      "     64        0.5285       0.7266        \u001b[35m0.5614\u001b[0m  0.0291\n",
      "     65        0.5367       0.7266        \u001b[35m0.5611\u001b[0m  0.0264\n",
      "     66        0.5411       0.7266        \u001b[35m0.5608\u001b[0m  0.0173\n",
      "     67        \u001b[36m0.5283\u001b[0m       0.7266        \u001b[35m0.5606\u001b[0m  0.0382\n",
      "     68        0.5360       0.7188        \u001b[35m0.5602\u001b[0m  0.0241\n",
      "     69        0.5326       0.7266        \u001b[35m0.5600\u001b[0m  0.0206\n",
      "     70        \u001b[36m0.5277\u001b[0m       0.7266        \u001b[35m0.5597\u001b[0m  0.0165\n",
      "     71        \u001b[36m0.5225\u001b[0m       0.7266        \u001b[35m0.5593\u001b[0m  0.0290\n",
      "     72        0.5360       0.7188        \u001b[35m0.5591\u001b[0m  0.0314\n",
      "     73        0.5405       0.7188        \u001b[35m0.5589\u001b[0m  0.0195\n",
      "     74        \u001b[36m0.5211\u001b[0m       0.7188        \u001b[35m0.5585\u001b[0m  0.0189\n",
      "     75        \u001b[36m0.5141\u001b[0m       0.7188        0.5585  0.0195\n",
      "     76        0.5331       0.7266        0.5585  0.0158\n",
      "     77        0.5206       0.7266        \u001b[35m0.5583\u001b[0m  0.0293\n",
      "     78        0.5235       0.7266        \u001b[35m0.5581\u001b[0m  0.0163\n",
      "     79        0.5198       0.7266        \u001b[35m0.5580\u001b[0m  0.0233\n",
      "     80        0.5224       0.7266        \u001b[35m0.5576\u001b[0m  0.0252\n",
      "     81        0.5273       0.7266        \u001b[35m0.5573\u001b[0m  0.0243\n",
      "     82        0.5361       0.7266        \u001b[35m0.5570\u001b[0m  0.0250\n",
      "     83        0.5194       0.7266        \u001b[35m0.5568\u001b[0m  0.0254\n",
      "     84        0.5228       0.7266        \u001b[35m0.5565\u001b[0m  0.0225\n",
      "     85        0.5209       0.7266        \u001b[35m0.5564\u001b[0m  0.0223\n",
      "     86        0.5246       0.7266        \u001b[35m0.5560\u001b[0m  0.0240\n",
      "     87        0.5205       0.7266        \u001b[35m0.5558\u001b[0m  0.0246\n",
      "     88        0.5310       0.7188        \u001b[35m0.5557\u001b[0m  0.0239\n",
      "     89        0.5254       0.7188        \u001b[35m0.5555\u001b[0m  0.0220\n",
      "     90        0.5209       0.7188        \u001b[35m0.5552\u001b[0m  0.0253\n",
      "     91        0.5181       0.7188        \u001b[35m0.5551\u001b[0m  0.0256\n",
      "     92        0.5243       0.7188        \u001b[35m0.5548\u001b[0m  0.0303\n",
      "     93        0.5258       0.7188        \u001b[35m0.5546\u001b[0m  0.0215\n",
      "     94        0.5269       0.7188        \u001b[35m0.5542\u001b[0m  0.0225\n",
      "     95        \u001b[36m0.5117\u001b[0m       0.7188        \u001b[35m0.5542\u001b[0m  0.0242\n",
      "     96        0.5286       0.7188        \u001b[35m0.5540\u001b[0m  0.0212\n",
      "     97        \u001b[36m0.5073\u001b[0m       0.7188        0.5541  0.0176\n",
      "     98        0.5102       0.7188        \u001b[35m0.5539\u001b[0m  0.0164\n",
      "     99        0.5128       0.7188        \u001b[35m0.5537\u001b[0m  0.0170\n",
      "    100        0.5218       0.7188        \u001b[35m0.5536\u001b[0m  0.0237\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7054\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6997\u001b[0m  0.0313\n",
      "      2        \u001b[36m0.6919\u001b[0m       0.5156        \u001b[35m0.6895\u001b[0m  0.0247\n",
      "      3        \u001b[36m0.6875\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6810\u001b[0m  0.0211\n",
      "      4        \u001b[36m0.6813\u001b[0m       0.5234        \u001b[35m0.6734\u001b[0m  0.0172\n",
      "      5        \u001b[36m0.6689\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6661\u001b[0m  0.0178\n",
      "      6        \u001b[36m0.6649\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6598\u001b[0m  0.0247\n",
      "      7        \u001b[36m0.6578\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6539\u001b[0m  0.0203\n",
      "      8        \u001b[36m0.6569\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6491\u001b[0m  0.0176\n",
      "      9        \u001b[36m0.6462\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6444\u001b[0m  0.0223\n",
      "     10        \u001b[36m0.6351\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6399\u001b[0m  0.0253\n",
      "     11        0.6398       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6360\u001b[0m  0.0299\n",
      "     12        \u001b[36m0.6290\u001b[0m       0.6328        \u001b[35m0.6321\u001b[0m  0.0242\n",
      "     13        0.6325       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6285\u001b[0m  0.0169\n",
      "     14        \u001b[36m0.6170\u001b[0m       0.6484        \u001b[35m0.6250\u001b[0m  0.0172\n",
      "     15        0.6218       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6217\u001b[0m  0.0187\n",
      "     16        0.6210       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6186\u001b[0m  0.0188\n",
      "     17        \u001b[36m0.6160\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6154\u001b[0m  0.0157\n",
      "     18        \u001b[36m0.6129\u001b[0m       0.7031        \u001b[35m0.6127\u001b[0m  0.0137\n",
      "     19        \u001b[36m0.6081\u001b[0m       0.7031        \u001b[35m0.6097\u001b[0m  0.0161\n",
      "     20        \u001b[36m0.6051\u001b[0m       0.7031        \u001b[35m0.6070\u001b[0m  0.0153\n",
      "     21        \u001b[36m0.6041\u001b[0m       0.7031        \u001b[35m0.6044\u001b[0m  0.0137\n",
      "     22        \u001b[36m0.6017\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6019\u001b[0m  0.0180\n",
      "     23        \u001b[36m0.5933\u001b[0m       0.7031        \u001b[35m0.5993\u001b[0m  0.0174\n",
      "     24        0.5939       0.7031        \u001b[35m0.5970\u001b[0m  0.0163\n",
      "     25        \u001b[36m0.5860\u001b[0m       0.7031        \u001b[35m0.5946\u001b[0m  0.0188\n",
      "     26        \u001b[36m0.5849\u001b[0m       0.7031        \u001b[35m0.5921\u001b[0m  0.0164\n",
      "     27        \u001b[36m0.5804\u001b[0m       0.6953        \u001b[35m0.5897\u001b[0m  0.0154\n",
      "     28        0.5908       0.7031        \u001b[35m0.5876\u001b[0m  0.0293\n",
      "     29        0.5811       0.7109        \u001b[35m0.5854\u001b[0m  0.0185\n",
      "     30        0.5874       0.7109        \u001b[35m0.5834\u001b[0m  0.0149\n",
      "     31        \u001b[36m0.5710\u001b[0m       0.7109        \u001b[35m0.5813\u001b[0m  0.0166\n",
      "     32        0.5786       0.7109        \u001b[35m0.5794\u001b[0m  0.0162\n",
      "     33        \u001b[36m0.5700\u001b[0m       0.7109        \u001b[35m0.5776\u001b[0m  0.0163\n",
      "     34        0.5727       0.7109        \u001b[35m0.5760\u001b[0m  0.0191\n",
      "     35        0.5798       0.7109        \u001b[35m0.5743\u001b[0m  0.0204\n",
      "     36        0.5702       0.7109        \u001b[35m0.5725\u001b[0m  0.0225\n",
      "     37        0.5766       0.7109        \u001b[35m0.5710\u001b[0m  0.0271\n",
      "     38        \u001b[36m0.5476\u001b[0m       0.7109        \u001b[35m0.5691\u001b[0m  0.0298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     39        0.5523       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5675\u001b[0m  0.0235\n",
      "     40        0.5731       0.7109        \u001b[35m0.5662\u001b[0m  0.0159\n",
      "     41        0.5541       0.7109        \u001b[35m0.5649\u001b[0m  0.0162\n",
      "     42        0.5567       0.7109        \u001b[35m0.5635\u001b[0m  0.0160\n",
      "     43        0.5598       0.7188        \u001b[35m0.5625\u001b[0m  0.0162\n",
      "     44        0.5566       0.7188        \u001b[35m0.5613\u001b[0m  0.0161\n",
      "     45        \u001b[36m0.5451\u001b[0m       0.7109        \u001b[35m0.5601\u001b[0m  0.0172\n",
      "     46        0.5570       0.7109        \u001b[35m0.5590\u001b[0m  0.0168\n",
      "     47        \u001b[36m0.5389\u001b[0m       0.7109        \u001b[35m0.5579\u001b[0m  0.0159\n",
      "     48        0.5493       0.7109        \u001b[35m0.5570\u001b[0m  0.0167\n",
      "     49        0.5399       0.7109        \u001b[35m0.5559\u001b[0m  0.0175\n",
      "     50        0.5428       0.7188        \u001b[35m0.5550\u001b[0m  0.0154\n",
      "     51        0.5469       0.7188        \u001b[35m0.5541\u001b[0m  0.0143\n",
      "     52        \u001b[36m0.5325\u001b[0m       0.7188        \u001b[35m0.5531\u001b[0m  0.0163\n",
      "     53        0.5456       0.7188        \u001b[35m0.5523\u001b[0m  0.0161\n",
      "     54        0.5334       0.7188        \u001b[35m0.5514\u001b[0m  0.0146\n",
      "     55        \u001b[36m0.5305\u001b[0m       0.7188        \u001b[35m0.5506\u001b[0m  0.0164\n",
      "     56        0.5432       0.7109        \u001b[35m0.5500\u001b[0m  0.0159\n",
      "     57        0.5338       0.7109        \u001b[35m0.5493\u001b[0m  0.0161\n",
      "     58        0.5323       0.7109        \u001b[35m0.5486\u001b[0m  0.0162\n",
      "     59        0.5313       0.7109        \u001b[35m0.5479\u001b[0m  0.0280\n",
      "     60        0.5361       0.7109        \u001b[35m0.5473\u001b[0m  0.0355\n",
      "     61        \u001b[36m0.5270\u001b[0m       0.7109        \u001b[35m0.5467\u001b[0m  0.0173\n",
      "     62        \u001b[36m0.5145\u001b[0m       0.7109        \u001b[35m0.5461\u001b[0m  0.0165\n",
      "     63        0.5380       0.7109        \u001b[35m0.5456\u001b[0m  0.0167\n",
      "     64        0.5362       0.7031        \u001b[35m0.5451\u001b[0m  0.0164\n",
      "     65        0.5311       0.7031        \u001b[35m0.5446\u001b[0m  0.0181\n",
      "     66        0.5358       0.7031        \u001b[35m0.5442\u001b[0m  0.0171\n",
      "     67        0.5290       0.7031        \u001b[35m0.5436\u001b[0m  0.0294\n",
      "     68        0.5233       0.7031        \u001b[35m0.5432\u001b[0m  0.0222\n",
      "     69        0.5364       0.7031        \u001b[35m0.5428\u001b[0m  0.0178\n",
      "     70        0.5299       0.7031        \u001b[35m0.5424\u001b[0m  0.0183\n",
      "     71        0.5410       0.7031        \u001b[35m0.5420\u001b[0m  0.0185\n",
      "     72        0.5243       0.7031        \u001b[35m0.5416\u001b[0m  0.0202\n",
      "     73        0.5184       0.7031        \u001b[35m0.5413\u001b[0m  0.0307\n",
      "     74        \u001b[36m0.5099\u001b[0m       0.7031        \u001b[35m0.5410\u001b[0m  0.0173\n",
      "     75        0.5366       0.7109        \u001b[35m0.5407\u001b[0m  0.0204\n",
      "     76        0.5169       0.7109        \u001b[35m0.5404\u001b[0m  0.0186\n",
      "     77        0.5280       0.7109        \u001b[35m0.5402\u001b[0m  0.0296\n",
      "     78        0.5106       0.7109        \u001b[35m0.5398\u001b[0m  0.0182\n",
      "     79        0.5237       0.7109        \u001b[35m0.5397\u001b[0m  0.0318\n",
      "     80        0.5157       0.7109        \u001b[35m0.5394\u001b[0m  0.0284\n",
      "     81        0.5116       0.7109        \u001b[35m0.5392\u001b[0m  0.0233\n",
      "     82        0.5189       0.7109        \u001b[35m0.5388\u001b[0m  0.0266\n",
      "     83        0.5251       0.7109        \u001b[35m0.5384\u001b[0m  0.0268\n",
      "     84        \u001b[36m0.5072\u001b[0m       0.7109        \u001b[35m0.5383\u001b[0m  0.0189\n",
      "     85        0.5185       0.7188        \u001b[35m0.5380\u001b[0m  0.0164\n",
      "     86        0.5288       0.7188        \u001b[35m0.5378\u001b[0m  0.0177\n",
      "     87        0.5229       0.7188        \u001b[35m0.5376\u001b[0m  0.0172\n",
      "     88        0.5267       0.7188        \u001b[35m0.5374\u001b[0m  0.0215\n",
      "     89        0.5135       0.7188        \u001b[35m0.5372\u001b[0m  0.0222\n",
      "     90        0.5167       0.7109        \u001b[35m0.5370\u001b[0m  0.0250\n",
      "     91        0.5199       0.7109        \u001b[35m0.5368\u001b[0m  0.0222\n",
      "     92        0.5085       0.7109        0.5368  0.0193\n",
      "     93        0.5335       0.7109        \u001b[35m0.5366\u001b[0m  0.0259\n",
      "     94        0.5152       0.7109        \u001b[35m0.5364\u001b[0m  0.0197\n",
      "     95        0.5260       0.7109        \u001b[35m0.5363\u001b[0m  0.0166\n",
      "     96        0.5281       0.7109        \u001b[35m0.5362\u001b[0m  0.0150\n",
      "     97        0.5203       0.7109        \u001b[35m0.5360\u001b[0m  0.0152\n",
      "     98        0.5155       0.7109        \u001b[35m0.5359\u001b[0m  0.0166\n",
      "     99        \u001b[36m0.5042\u001b[0m       0.7031        \u001b[35m0.5357\u001b[0m  0.0135\n",
      "    100        \u001b[36m0.4960\u001b[0m       0.7031        \u001b[35m0.5355\u001b[0m  0.0140\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7773\u001b[0m       \u001b[32m0.4297\u001b[0m        \u001b[35m0.7817\u001b[0m  0.0145\n",
      "      2        \u001b[36m0.7709\u001b[0m       0.4219        \u001b[35m0.7698\u001b[0m  0.0162\n",
      "      3        \u001b[36m0.7498\u001b[0m       0.4297        \u001b[35m0.7593\u001b[0m  0.0281\n",
      "      4        \u001b[36m0.7411\u001b[0m       \u001b[32m0.4375\u001b[0m        \u001b[35m0.7501\u001b[0m  0.0246\n",
      "      5        \u001b[36m0.7341\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m0.7411\u001b[0m  0.0159\n",
      "      6        \u001b[36m0.7264\u001b[0m       0.4531        \u001b[35m0.7329\u001b[0m  0.0142\n",
      "      7        \u001b[36m0.7105\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m0.7260\u001b[0m  0.0142\n",
      "      8        0.7174       \u001b[32m0.4844\u001b[0m        \u001b[35m0.7188\u001b[0m  0.0165\n",
      "      9        \u001b[36m0.7071\u001b[0m       0.4844        \u001b[35m0.7124\u001b[0m  0.0168\n",
      "     10        \u001b[36m0.6953\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7063\u001b[0m  0.0244\n",
      "     11        \u001b[36m0.6945\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.7004\u001b[0m  0.0165\n",
      "     12        \u001b[36m0.6819\u001b[0m       0.5234        \u001b[35m0.6950\u001b[0m  0.0163\n",
      "     13        \u001b[36m0.6752\u001b[0m       0.5156        \u001b[35m0.6898\u001b[0m  0.0271\n",
      "     14        \u001b[36m0.6676\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6851\u001b[0m  0.0253\n",
      "     15        0.6718       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6803\u001b[0m  0.0162\n",
      "     16        \u001b[36m0.6641\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6758\u001b[0m  0.0277\n",
      "     17        \u001b[36m0.6639\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6713\u001b[0m  0.0283\n",
      "     18        \u001b[36m0.6507\u001b[0m       0.6016        \u001b[35m0.6668\u001b[0m  0.0175\n",
      "     19        0.6560       0.6094        \u001b[35m0.6627\u001b[0m  0.0164\n",
      "     20        \u001b[36m0.6468\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6587\u001b[0m  0.0299\n",
      "     21        \u001b[36m0.6401\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6547\u001b[0m  0.0172\n",
      "     22        \u001b[36m0.6277\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6510\u001b[0m  0.0145\n",
      "     23        0.6338       0.6562        \u001b[35m0.6472\u001b[0m  0.0280\n",
      "     24        0.6301       0.6484        \u001b[35m0.6437\u001b[0m  0.0282\n",
      "     25        \u001b[36m0.6141\u001b[0m       0.6562        \u001b[35m0.6401\u001b[0m  0.0159\n",
      "     26        0.6172       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6366\u001b[0m  0.0155\n",
      "     27        \u001b[36m0.6117\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6331\u001b[0m  0.0392\n",
      "     28        0.6143       0.6875        \u001b[35m0.6298\u001b[0m  0.0214\n",
      "     29        0.6182       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6268\u001b[0m  0.0166\n",
      "     30        \u001b[36m0.6044\u001b[0m       0.6953        \u001b[35m0.6237\u001b[0m  0.0150\n",
      "     31        \u001b[36m0.5962\u001b[0m       0.6953        \u001b[35m0.6207\u001b[0m  0.0154\n",
      "     32        0.5970       0.6875        \u001b[35m0.6179\u001b[0m  0.0266\n",
      "     33        \u001b[36m0.5910\u001b[0m       0.6953        \u001b[35m0.6150\u001b[0m  0.0222\n",
      "     34        \u001b[36m0.5876\u001b[0m       0.6953        \u001b[35m0.6121\u001b[0m  0.0307\n",
      "     35        0.5877       0.6953        \u001b[35m0.6094\u001b[0m  0.0157\n",
      "     36        \u001b[36m0.5799\u001b[0m       0.6953        \u001b[35m0.6068\u001b[0m  0.0167\n",
      "     37        0.5800       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6041\u001b[0m  0.0160\n",
      "     38        \u001b[36m0.5771\u001b[0m       0.6953        \u001b[35m0.6018\u001b[0m  0.0177\n",
      "     39        0.5780       0.6953        \u001b[35m0.5993\u001b[0m  0.0276\n",
      "     40        \u001b[36m0.5738\u001b[0m       0.6953        \u001b[35m0.5970\u001b[0m  0.0150\n",
      "     41        \u001b[36m0.5735\u001b[0m       0.6953        \u001b[35m0.5948\u001b[0m  0.0154\n",
      "     42        \u001b[36m0.5677\u001b[0m       0.6953        \u001b[35m0.5927\u001b[0m  0.0155\n",
      "     43        \u001b[36m0.5625\u001b[0m       0.6953        \u001b[35m0.5905\u001b[0m  0.0144\n",
      "     44        \u001b[36m0.5549\u001b[0m       0.6953        \u001b[35m0.5884\u001b[0m  0.0147\n",
      "     45        0.5646       0.6953        \u001b[35m0.5865\u001b[0m  0.0142\n",
      "     46        0.5567       0.6953        \u001b[35m0.5846\u001b[0m  0.0165\n",
      "     47        0.5593       0.6953        \u001b[35m0.5827\u001b[0m  0.0257\n",
      "     48        \u001b[36m0.5488\u001b[0m       0.6953        \u001b[35m0.5810\u001b[0m  0.0145\n",
      "     49        \u001b[36m0.5487\u001b[0m       0.6953        \u001b[35m0.5794\u001b[0m  0.0140\n",
      "     50        0.5487       0.6953        \u001b[35m0.5777\u001b[0m  0.0148\n",
      "     51        \u001b[36m0.5456\u001b[0m       0.6953        \u001b[35m0.5760\u001b[0m  0.0137\n",
      "     52        0.5535       0.6953        \u001b[35m0.5745\u001b[0m  0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     53        \u001b[36m0.5283\u001b[0m       0.6953        \u001b[35m0.5731\u001b[0m  0.0163\n",
      "     54        0.5350       0.6953        \u001b[35m0.5716\u001b[0m  0.0158\n",
      "     55        0.5320       0.6953        \u001b[35m0.5703\u001b[0m  0.0389\n",
      "     56        0.5316       0.7031        \u001b[35m0.5689\u001b[0m  0.0162\n",
      "     57        \u001b[36m0.5270\u001b[0m       0.7031        \u001b[35m0.5676\u001b[0m  0.0152\n",
      "     58        0.5315       0.7031        \u001b[35m0.5664\u001b[0m  0.0162\n",
      "     59        0.5279       0.7031        \u001b[35m0.5652\u001b[0m  0.0280\n",
      "     60        0.5365       0.7031        \u001b[35m0.5642\u001b[0m  0.0177\n",
      "     61        \u001b[36m0.5156\u001b[0m       0.7031        \u001b[35m0.5631\u001b[0m  0.0295\n",
      "     62        0.5269       0.7031        \u001b[35m0.5621\u001b[0m  0.0159\n",
      "     63        \u001b[36m0.5103\u001b[0m       0.6953        \u001b[35m0.5610\u001b[0m  0.0152\n",
      "     64        0.5163       0.6953        \u001b[35m0.5600\u001b[0m  0.0389\n",
      "     65        0.5377       0.6953        \u001b[35m0.5590\u001b[0m  0.0155\n",
      "     66        0.5190       0.6953        \u001b[35m0.5582\u001b[0m  0.0334\n",
      "     67        0.5173       0.7031        \u001b[35m0.5574\u001b[0m  0.0192\n",
      "     68        \u001b[36m0.5086\u001b[0m       0.7031        \u001b[35m0.5565\u001b[0m  0.0298\n",
      "     69        0.5237       0.7031        \u001b[35m0.5557\u001b[0m  0.0222\n",
      "     70        0.5281       0.7031        \u001b[35m0.5550\u001b[0m  0.0365\n",
      "     71        0.5120       0.7031        \u001b[35m0.5543\u001b[0m  0.0287\n",
      "     72        0.5243       0.7031        \u001b[35m0.5535\u001b[0m  0.0358\n",
      "     73        \u001b[36m0.4975\u001b[0m       0.7031        \u001b[35m0.5529\u001b[0m  0.0157\n",
      "     74        0.5055       0.7031        \u001b[35m0.5522\u001b[0m  0.0247\n",
      "     75        0.5117       0.6953        \u001b[35m0.5516\u001b[0m  0.0166\n",
      "     76        0.5125       0.6953        \u001b[35m0.5509\u001b[0m  0.0262\n",
      "     77        0.5111       0.6953        \u001b[35m0.5505\u001b[0m  0.0324\n",
      "     78        0.5150       0.6953        \u001b[35m0.5498\u001b[0m  0.0341\n",
      "     79        0.5113       0.6953        \u001b[35m0.5493\u001b[0m  0.0167\n",
      "     80        0.5086       0.6953        \u001b[35m0.5486\u001b[0m  0.0303\n",
      "     81        0.5121       0.6953        \u001b[35m0.5480\u001b[0m  0.0290\n",
      "     82        0.5123       0.6953        \u001b[35m0.5475\u001b[0m  0.0528\n",
      "     83        0.5069       0.6953        \u001b[35m0.5469\u001b[0m  0.0402\n",
      "     84        0.5034       0.6953        \u001b[35m0.5466\u001b[0m  0.0294\n",
      "     85        \u001b[36m0.4918\u001b[0m       0.6875        \u001b[35m0.5461\u001b[0m  0.0254\n",
      "     86        0.4973       0.6953        \u001b[35m0.5456\u001b[0m  0.0278\n",
      "     87        0.5029       0.6953        \u001b[35m0.5451\u001b[0m  0.0335\n",
      "     88        0.5069       0.6953        \u001b[35m0.5447\u001b[0m  0.0231\n",
      "     89        0.4991       0.6953        \u001b[35m0.5443\u001b[0m  0.0234\n",
      "     90        0.4981       0.6953        \u001b[35m0.5439\u001b[0m  0.0213\n",
      "     91        0.5112       0.6953        \u001b[35m0.5434\u001b[0m  0.0251\n",
      "     92        \u001b[36m0.4917\u001b[0m       0.6953        \u001b[35m0.5430\u001b[0m  0.0224\n",
      "     93        0.5106       0.6953        \u001b[35m0.5426\u001b[0m  0.0237\n",
      "     94        \u001b[36m0.4900\u001b[0m       0.6953        \u001b[35m0.5423\u001b[0m  0.0180\n",
      "     95        \u001b[36m0.4830\u001b[0m       0.6953        \u001b[35m0.5420\u001b[0m  0.0166\n",
      "     96        0.4920       0.6953        \u001b[35m0.5416\u001b[0m  0.0247\n",
      "     97        \u001b[36m0.4791\u001b[0m       0.6953        \u001b[35m0.5413\u001b[0m  0.0305\n",
      "     98        0.4945       0.6953        \u001b[35m0.5410\u001b[0m  0.0161\n",
      "     99        0.4830       0.6953        \u001b[35m0.5405\u001b[0m  0.0236\n",
      "    100        0.4927       0.6953        \u001b[35m0.5401\u001b[0m  0.0188\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7023\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6995\u001b[0m  0.0320\n",
      "      2        \u001b[36m0.6947\u001b[0m       0.5000        \u001b[35m0.6952\u001b[0m  0.0243\n",
      "      3        \u001b[36m0.6891\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6907\u001b[0m  0.0437\n",
      "      4        \u001b[36m0.6825\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6866\u001b[0m  0.0341\n",
      "      5        \u001b[36m0.6803\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6830\u001b[0m  0.0401\n",
      "      6        \u001b[36m0.6801\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6795\u001b[0m  0.0462\n",
      "      7        \u001b[36m0.6750\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6762\u001b[0m  0.0480\n",
      "      8        0.6754       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6729\u001b[0m  0.0500\n",
      "      9        \u001b[36m0.6730\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6694\u001b[0m  0.0255\n",
      "     10        \u001b[36m0.6678\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6661\u001b[0m  0.0354\n",
      "     11        \u001b[36m0.6673\u001b[0m       0.6641        \u001b[35m0.6629\u001b[0m  0.0357\n",
      "     12        \u001b[36m0.6632\u001b[0m       0.6562        \u001b[35m0.6594\u001b[0m  0.0303\n",
      "     13        \u001b[36m0.6584\u001b[0m       0.6562        \u001b[35m0.6561\u001b[0m  0.0366\n",
      "     14        0.6591       0.6562        \u001b[35m0.6524\u001b[0m  0.0339\n",
      "     15        \u001b[36m0.6556\u001b[0m       0.6562        \u001b[35m0.6489\u001b[0m  0.0209\n",
      "     16        \u001b[36m0.6496\u001b[0m       0.6484        \u001b[35m0.6452\u001b[0m  0.0204\n",
      "     17        \u001b[36m0.6487\u001b[0m       0.6641        \u001b[35m0.6418\u001b[0m  0.0201\n",
      "     18        \u001b[36m0.6437\u001b[0m       0.6641        \u001b[35m0.6378\u001b[0m  0.0251\n",
      "     19        \u001b[36m0.6403\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6339\u001b[0m  0.0346\n",
      "     20        \u001b[36m0.6382\u001b[0m       0.6875        \u001b[35m0.6300\u001b[0m  0.0353\n",
      "     21        \u001b[36m0.6334\u001b[0m       0.6875        \u001b[35m0.6260\u001b[0m  0.0379\n",
      "     22        \u001b[36m0.6300\u001b[0m       0.6875        \u001b[35m0.6218\u001b[0m  0.0309\n",
      "     23        \u001b[36m0.6235\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6176\u001b[0m  0.0249\n",
      "     24        0.6250       0.7031        \u001b[35m0.6133\u001b[0m  0.0311\n",
      "     25        \u001b[36m0.6218\u001b[0m       0.7031        \u001b[35m0.6091\u001b[0m  0.0344\n",
      "     26        \u001b[36m0.6165\u001b[0m       0.7031        \u001b[35m0.6045\u001b[0m  0.0333\n",
      "     27        0.6240       0.7031        \u001b[35m0.6007\u001b[0m  0.0483\n",
      "     28        0.6179       0.7031        \u001b[35m0.5965\u001b[0m  0.0249\n",
      "     29        \u001b[36m0.6046\u001b[0m       0.7031        \u001b[35m0.5919\u001b[0m  0.0317\n",
      "     30        0.6074       0.7031        \u001b[35m0.5874\u001b[0m  0.0212\n",
      "     31        0.6082       0.7031        \u001b[35m0.5831\u001b[0m  0.0319\n",
      "     32        \u001b[36m0.5946\u001b[0m       0.7031        \u001b[35m0.5785\u001b[0m  0.0478\n",
      "     33        0.6043       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5739\u001b[0m  0.0370\n",
      "     34        \u001b[36m0.5926\u001b[0m       0.7109        \u001b[35m0.5698\u001b[0m  0.0216\n",
      "     35        \u001b[36m0.5903\u001b[0m       0.7109        \u001b[35m0.5658\u001b[0m  0.0375\n",
      "     36        \u001b[36m0.5825\u001b[0m       0.7109        \u001b[35m0.5617\u001b[0m  0.0260\n",
      "     37        \u001b[36m0.5749\u001b[0m       0.7109        \u001b[35m0.5577\u001b[0m  0.0323\n",
      "     38        0.5912       0.7109        \u001b[35m0.5542\u001b[0m  0.0255\n",
      "     39        0.5868       0.7109        \u001b[35m0.5503\u001b[0m  0.0328\n",
      "     40        \u001b[36m0.5678\u001b[0m       0.7109        \u001b[35m0.5463\u001b[0m  0.0276\n",
      "     41        0.5800       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5426\u001b[0m  0.0365\n",
      "     42        0.5776       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5390\u001b[0m  0.0341\n",
      "     43        0.5706       0.7344        \u001b[35m0.5358\u001b[0m  0.0321\n",
      "     44        0.5701       0.7344        \u001b[35m0.5320\u001b[0m  0.0323\n",
      "     45        0.5700       0.7344        \u001b[35m0.5286\u001b[0m  0.0377\n",
      "     46        \u001b[36m0.5652\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5252\u001b[0m  0.0396\n",
      "     47        \u001b[36m0.5605\u001b[0m       0.7344        \u001b[35m0.5219\u001b[0m  0.0380\n",
      "     48        \u001b[36m0.5540\u001b[0m       0.7422        \u001b[35m0.5187\u001b[0m  0.0356\n",
      "     49        0.5604       0.7422        \u001b[35m0.5158\u001b[0m  0.0297\n",
      "     50        \u001b[36m0.5464\u001b[0m       0.7422        \u001b[35m0.5130\u001b[0m  0.0262\n",
      "     51        0.5565       0.7422        \u001b[35m0.5103\u001b[0m  0.0373\n",
      "     52        0.5548       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5081\u001b[0m  0.0247\n",
      "     53        0.5517       0.7500        \u001b[35m0.5055\u001b[0m  0.0262\n",
      "     54        \u001b[36m0.5458\u001b[0m       0.7500        \u001b[35m0.5026\u001b[0m  0.0233\n",
      "     55        0.5551       0.7422        \u001b[35m0.5003\u001b[0m  0.0311\n",
      "     56        0.5507       0.7422        \u001b[35m0.4980\u001b[0m  0.0327\n",
      "     57        0.5477       0.7422        \u001b[35m0.4960\u001b[0m  0.0232\n",
      "     58        \u001b[36m0.5379\u001b[0m       0.7422        \u001b[35m0.4938\u001b[0m  0.0575\n",
      "     59        \u001b[36m0.5313\u001b[0m       0.7422        \u001b[35m0.4915\u001b[0m  0.0329\n",
      "     60        0.5368       0.7422        \u001b[35m0.4896\u001b[0m  0.0781\n",
      "     61        0.5402       0.7422        \u001b[35m0.4875\u001b[0m  0.0293\n",
      "     62        0.5478       0.7422        \u001b[35m0.4856\u001b[0m  0.0248\n",
      "     63        0.5363       0.7422        \u001b[35m0.4835\u001b[0m  0.0341\n",
      "     64        0.5384       0.7422        \u001b[35m0.4813\u001b[0m  0.0265\n",
      "     65        \u001b[36m0.5289\u001b[0m       0.7422        \u001b[35m0.4792\u001b[0m  0.0256\n",
      "     66        0.5319       0.7422        \u001b[35m0.4775\u001b[0m  0.0352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     67        \u001b[36m0.5285\u001b[0m       0.7422        \u001b[35m0.4756\u001b[0m  0.0256\n",
      "     68        0.5329       0.7422        \u001b[35m0.4737\u001b[0m  0.0432\n",
      "     69        \u001b[36m0.5241\u001b[0m       0.7422        \u001b[35m0.4718\u001b[0m  0.0239\n",
      "     70        0.5255       0.7422        \u001b[35m0.4701\u001b[0m  0.0363\n",
      "     71        0.5299       0.7422        \u001b[35m0.4687\u001b[0m  0.1076\n",
      "     72        0.5264       0.7422        \u001b[35m0.4671\u001b[0m  0.0685\n",
      "     73        0.5248       0.7422        \u001b[35m0.4653\u001b[0m  0.0602\n",
      "     74        0.5252       0.7422        \u001b[35m0.4637\u001b[0m  0.0603\n",
      "     75        \u001b[36m0.5192\u001b[0m       0.7422        \u001b[35m0.4620\u001b[0m  0.0525\n",
      "     76        \u001b[36m0.5135\u001b[0m       0.7422        \u001b[35m0.4606\u001b[0m  0.0312\n",
      "     77        0.5273       0.7422        \u001b[35m0.4591\u001b[0m  0.0758\n",
      "     78        0.5212       0.7422        \u001b[35m0.4575\u001b[0m  0.0740\n",
      "     79        0.5324       0.7500        \u001b[35m0.4565\u001b[0m  0.0418\n",
      "     80        0.5240       0.7422        \u001b[35m0.4553\u001b[0m  0.0272\n",
      "     81        0.5156       0.7422        \u001b[35m0.4537\u001b[0m  0.0292\n",
      "     82        0.5238       0.7422        \u001b[35m0.4526\u001b[0m  0.0556\n",
      "     83        \u001b[36m0.5082\u001b[0m       0.7422        \u001b[35m0.4516\u001b[0m  0.0308\n",
      "     84        \u001b[36m0.5057\u001b[0m       0.7422        \u001b[35m0.4501\u001b[0m  0.0283\n",
      "     85        0.5143       0.7500        \u001b[35m0.4487\u001b[0m  0.0296\n",
      "     86        0.5074       \u001b[32m0.7578\u001b[0m        \u001b[35m0.4470\u001b[0m  0.0213\n",
      "     87        0.5158       0.7578        \u001b[35m0.4459\u001b[0m  0.0277\n",
      "     88        0.5169       0.7578        \u001b[35m0.4453\u001b[0m  0.0346\n",
      "     89        0.5140       0.7578        \u001b[35m0.4443\u001b[0m  0.0236\n",
      "     90        0.5131       0.7578        \u001b[35m0.4435\u001b[0m  0.0296\n",
      "     91        0.5147       0.7578        \u001b[35m0.4427\u001b[0m  0.0207\n",
      "     92        0.5189       0.7578        \u001b[35m0.4420\u001b[0m  0.0350\n",
      "     93        0.5086       0.7578        \u001b[35m0.4414\u001b[0m  0.0672\n",
      "     94        0.5091       0.7578        \u001b[35m0.4405\u001b[0m  0.0310\n",
      "     95        0.5086       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4395\u001b[0m  0.0374\n",
      "     96        0.5218       0.7734        \u001b[35m0.4387\u001b[0m  0.0362\n",
      "     97        \u001b[36m0.4934\u001b[0m       0.7734        \u001b[35m0.4374\u001b[0m  0.0326\n",
      "     98        0.5079       0.7734        \u001b[35m0.4361\u001b[0m  0.0386\n",
      "     99        0.5136       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4352\u001b[0m  0.0248\n",
      "    100        0.5097       0.7812        \u001b[35m0.4345\u001b[0m  0.0320\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6794\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6744\u001b[0m  0.0222\n",
      "      2        \u001b[36m0.6725\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6653\u001b[0m  0.0327\n",
      "      3        \u001b[36m0.6650\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6560\u001b[0m  0.0338\n",
      "      4        \u001b[36m0.6536\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6475\u001b[0m  0.0303\n",
      "      5        \u001b[36m0.6442\u001b[0m       0.6641        \u001b[35m0.6401\u001b[0m  0.0306\n",
      "      6        \u001b[36m0.6422\u001b[0m       0.6484        \u001b[35m0.6330\u001b[0m  0.0314\n",
      "      7        \u001b[36m0.6335\u001b[0m       0.6562        \u001b[35m0.6265\u001b[0m  0.0276\n",
      "      8        \u001b[36m0.6233\u001b[0m       0.6562        \u001b[35m0.6206\u001b[0m  0.0446\n",
      "      9        \u001b[36m0.6197\u001b[0m       0.6484        \u001b[35m0.6149\u001b[0m  0.0325\n",
      "     10        \u001b[36m0.5988\u001b[0m       0.6406        \u001b[35m0.6090\u001b[0m  0.0348\n",
      "     11        0.6101       0.6484        \u001b[35m0.6043\u001b[0m  0.0265\n",
      "     12        0.5994       0.6641        \u001b[35m0.5996\u001b[0m  0.0363\n",
      "     13        \u001b[36m0.5882\u001b[0m       0.6641        \u001b[35m0.5948\u001b[0m  0.0391\n",
      "     14        0.5930       \u001b[32m0.6719\u001b[0m        \u001b[35m0.5908\u001b[0m  0.0304\n",
      "     15        0.5965       0.6719        \u001b[35m0.5873\u001b[0m  0.0315\n",
      "     16        \u001b[36m0.5876\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5839\u001b[0m  0.0345\n",
      "     17        0.5895       0.6797        \u001b[35m0.5807\u001b[0m  0.0242\n",
      "     18        \u001b[36m0.5726\u001b[0m       0.6797        \u001b[35m0.5774\u001b[0m  0.0323\n",
      "     19        \u001b[36m0.5650\u001b[0m       0.6797        \u001b[35m0.5742\u001b[0m  0.0323\n",
      "     20        0.5774       0.6797        \u001b[35m0.5711\u001b[0m  0.0338\n",
      "     21        0.5662       0.6797        \u001b[35m0.5686\u001b[0m  0.0326\n",
      "     22        0.5660       0.6797        \u001b[35m0.5660\u001b[0m  0.0373\n",
      "     23        \u001b[36m0.5550\u001b[0m       0.6797        \u001b[35m0.5635\u001b[0m  0.0386\n",
      "     24        0.5657       0.6797        \u001b[35m0.5615\u001b[0m  0.0312\n",
      "     25        \u001b[36m0.5510\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5595\u001b[0m  0.0319\n",
      "     26        \u001b[36m0.5458\u001b[0m       0.6875        \u001b[35m0.5576\u001b[0m  0.0405\n",
      "     27        0.5464       0.6875        \u001b[35m0.5559\u001b[0m  0.0321\n",
      "     28        \u001b[36m0.5439\u001b[0m       0.6875        \u001b[35m0.5542\u001b[0m  0.0346\n",
      "     29        0.5455       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5526\u001b[0m  0.0518\n",
      "     30        \u001b[36m0.5388\u001b[0m       0.6953        \u001b[35m0.5511\u001b[0m  0.0284\n",
      "     31        0.5538       0.6953        \u001b[35m0.5499\u001b[0m  0.0389\n",
      "     32        0.5468       0.6953        \u001b[35m0.5488\u001b[0m  0.0248\n",
      "     33        0.5497       0.6953        \u001b[35m0.5477\u001b[0m  0.0290\n",
      "     34        \u001b[36m0.5312\u001b[0m       0.6953        \u001b[35m0.5464\u001b[0m  0.0288\n",
      "     35        0.5353       0.6875        \u001b[35m0.5454\u001b[0m  0.0308\n",
      "     36        0.5348       0.6875        \u001b[35m0.5444\u001b[0m  0.0258\n",
      "     37        0.5432       0.6875        \u001b[35m0.5436\u001b[0m  0.0338\n",
      "     38        0.5467       0.6875        \u001b[35m0.5428\u001b[0m  0.0324\n",
      "     39        0.5448       0.6875        \u001b[35m0.5421\u001b[0m  0.0371\n",
      "     40        \u001b[36m0.5162\u001b[0m       0.6875        \u001b[35m0.5413\u001b[0m  0.0270\n",
      "     41        0.5298       0.6875        \u001b[35m0.5408\u001b[0m  0.0344\n",
      "     42        0.5367       0.6875        \u001b[35m0.5401\u001b[0m  0.0270\n",
      "     43        0.5218       0.6953        \u001b[35m0.5396\u001b[0m  0.0692\n",
      "     44        \u001b[36m0.5156\u001b[0m       0.6953        \u001b[35m0.5391\u001b[0m  0.0476\n",
      "     45        0.5330       0.6953        \u001b[35m0.5386\u001b[0m  0.0659\n",
      "     46        0.5206       0.6953        \u001b[35m0.5382\u001b[0m  0.0500\n",
      "     47        0.5309       0.6953        \u001b[35m0.5378\u001b[0m  0.0340\n",
      "     48        0.5277       0.6953        \u001b[35m0.5373\u001b[0m  0.0505\n",
      "     49        0.5330       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5365\u001b[0m  0.0287\n",
      "     50        0.5296       0.6953        \u001b[35m0.5361\u001b[0m  0.0435\n",
      "     51        0.5209       0.6953        \u001b[35m0.5355\u001b[0m  0.0332\n",
      "     52        0.5308       0.6953        \u001b[35m0.5350\u001b[0m  0.0423\n",
      "     53        0.5209       0.6953        \u001b[35m0.5346\u001b[0m  0.0507\n",
      "     54        0.5286       0.6953        \u001b[35m0.5341\u001b[0m  0.0444\n",
      "     55        \u001b[36m0.5106\u001b[0m       0.6953        \u001b[35m0.5339\u001b[0m  0.0330\n",
      "     56        0.5216       0.6953        \u001b[35m0.5337\u001b[0m  0.0408\n",
      "     57        \u001b[36m0.5094\u001b[0m       0.6953        \u001b[35m0.5334\u001b[0m  0.0303\n",
      "     58        \u001b[36m0.5090\u001b[0m       0.6953        \u001b[35m0.5332\u001b[0m  0.0346\n",
      "     59        \u001b[36m0.5043\u001b[0m       0.6953        \u001b[35m0.5328\u001b[0m  0.0479\n",
      "     60        0.5069       0.6953        \u001b[35m0.5325\u001b[0m  0.0224\n",
      "     61        0.5243       0.6953        \u001b[35m0.5321\u001b[0m  0.0516\n",
      "     62        0.5210       0.6953        \u001b[35m0.5318\u001b[0m  0.0291\n",
      "     63        0.5223       0.6953        \u001b[35m0.5314\u001b[0m  0.0433\n",
      "     64        0.5133       0.6953        \u001b[35m0.5312\u001b[0m  0.0353\n",
      "     65        0.5115       0.6953        \u001b[35m0.5309\u001b[0m  0.0368\n",
      "     66        0.5108       0.6953        \u001b[35m0.5308\u001b[0m  0.0682\n",
      "     67        0.5059       0.7031        \u001b[35m0.5306\u001b[0m  0.1330\n",
      "     68        0.5059       0.6953        \u001b[35m0.5305\u001b[0m  0.0630\n",
      "     69        \u001b[36m0.5016\u001b[0m       0.6953        \u001b[35m0.5304\u001b[0m  0.0552\n",
      "     70        0.5064       0.6953        \u001b[35m0.5303\u001b[0m  0.0709\n",
      "     71        0.5182       0.6953        \u001b[35m0.5300\u001b[0m  0.0385\n",
      "     72        0.5160       0.6953        \u001b[35m0.5299\u001b[0m  0.0418\n",
      "     73        0.5030       0.6953        \u001b[35m0.5297\u001b[0m  0.0370\n",
      "     74        0.5121       0.6953        \u001b[35m0.5295\u001b[0m  0.0647\n",
      "     75        0.5115       0.6953        0.5296  0.0436\n",
      "     76        0.5150       0.6953        0.5296  0.0349\n",
      "     77        0.5133       0.6953        \u001b[35m0.5295\u001b[0m  0.0320\n",
      "     78        0.5079       0.6953        \u001b[35m0.5292\u001b[0m  0.0477\n",
      "     79        0.5036       0.7031        \u001b[35m0.5291\u001b[0m  0.0410\n",
      "     80        \u001b[36m0.5005\u001b[0m       0.7031        \u001b[35m0.5290\u001b[0m  0.0258\n",
      "     81        0.5124       0.6953        \u001b[35m0.5288\u001b[0m  0.1143\n",
      "     82        0.5033       0.6953        \u001b[35m0.5287\u001b[0m  0.0398\n",
      "     83        0.5021       0.6953        \u001b[35m0.5286\u001b[0m  0.0460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     84        \u001b[36m0.4981\u001b[0m       0.6953        \u001b[35m0.5285\u001b[0m  0.0595\n",
      "     85        0.5008       0.6953        \u001b[35m0.5285\u001b[0m  0.0455\n",
      "     86        0.5014       0.6953        \u001b[35m0.5284\u001b[0m  0.0446\n",
      "     87        0.5036       0.6953        \u001b[35m0.5282\u001b[0m  0.0817\n",
      "     88        0.5028       0.6953        \u001b[35m0.5281\u001b[0m  0.0406\n",
      "     89        0.5014       0.6953        0.5282  0.0482\n",
      "     90        \u001b[36m0.4937\u001b[0m       0.6953        0.5281  0.0358\n",
      "     91        0.5016       0.6953        \u001b[35m0.5280\u001b[0m  0.0383\n",
      "     92        0.4966       0.6953        \u001b[35m0.5279\u001b[0m  0.0288\n",
      "     93        0.5131       0.6953        \u001b[35m0.5278\u001b[0m  0.0295\n",
      "     94        \u001b[36m0.4849\u001b[0m       0.6953        0.5280  0.0322\n",
      "     95        0.4931       0.6953        0.5279  0.0464\n",
      "     96        0.4964       0.6953        0.5280  0.0407\n",
      "     97        0.4970       0.6875        0.5281  0.0621\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6531\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6652\u001b[0m  0.0345\n",
      "      2        \u001b[36m0.6487\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6553\u001b[0m  0.0310\n",
      "      3        \u001b[36m0.6387\u001b[0m       0.5781        \u001b[35m0.6465\u001b[0m  0.0301\n",
      "      4        \u001b[36m0.6338\u001b[0m       0.5781        \u001b[35m0.6378\u001b[0m  0.0371\n",
      "      5        \u001b[36m0.6148\u001b[0m       0.5703        \u001b[35m0.6304\u001b[0m  0.0342\n",
      "      6        \u001b[36m0.6107\u001b[0m       0.5859        \u001b[35m0.6232\u001b[0m  0.0395\n",
      "      7        \u001b[36m0.6041\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6169\u001b[0m  0.0494\n",
      "      8        \u001b[36m0.5952\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6106\u001b[0m  0.0434\n",
      "      9        \u001b[36m0.5946\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6052\u001b[0m  0.0671\n",
      "     10        \u001b[36m0.5881\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6002\u001b[0m  0.0373\n",
      "     11        \u001b[36m0.5777\u001b[0m       0.6562        \u001b[35m0.5957\u001b[0m  0.0522\n",
      "     12        \u001b[36m0.5738\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.5913\u001b[0m  0.0585\n",
      "     13        \u001b[36m0.5704\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5874\u001b[0m  0.0767\n",
      "     14        0.5708       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5838\u001b[0m  0.0929\n",
      "     15        \u001b[36m0.5669\u001b[0m       0.6875        \u001b[35m0.5808\u001b[0m  0.0507\n",
      "     16        0.5678       0.6875        \u001b[35m0.5783\u001b[0m  0.0962\n",
      "     17        \u001b[36m0.5575\u001b[0m       0.6875        \u001b[35m0.5755\u001b[0m  0.0312\n",
      "     18        \u001b[36m0.5493\u001b[0m       0.6875        \u001b[35m0.5730\u001b[0m  0.0743\n",
      "     19        0.5588       0.6875        \u001b[35m0.5709\u001b[0m  0.0468\n",
      "     20        \u001b[36m0.5480\u001b[0m       0.6875        \u001b[35m0.5690\u001b[0m  0.0354\n",
      "     21        \u001b[36m0.5410\u001b[0m       0.6875        \u001b[35m0.5670\u001b[0m  0.0513\n",
      "     22        0.5468       0.6875        \u001b[35m0.5651\u001b[0m  0.0305\n",
      "     23        0.5431       0.6875        \u001b[35m0.5635\u001b[0m  0.0731\n",
      "     24        \u001b[36m0.5302\u001b[0m       0.6875        \u001b[35m0.5619\u001b[0m  0.0803\n",
      "     25        0.5393       0.6875        \u001b[35m0.5604\u001b[0m  0.0550\n",
      "     26        0.5352       0.6875        \u001b[35m0.5592\u001b[0m  0.0588\n",
      "     27        0.5326       0.6875        \u001b[35m0.5581\u001b[0m  0.0365\n",
      "     28        \u001b[36m0.5212\u001b[0m       0.6875        \u001b[35m0.5570\u001b[0m  0.0384\n",
      "     29        0.5261       0.6797        \u001b[35m0.5563\u001b[0m  0.0423\n",
      "     30        0.5379       0.6719        \u001b[35m0.5556\u001b[0m  0.0365\n",
      "     31        \u001b[36m0.5209\u001b[0m       0.6719        \u001b[35m0.5548\u001b[0m  0.0299\n",
      "     32        0.5273       0.6875        \u001b[35m0.5536\u001b[0m  0.0322\n",
      "     33        \u001b[36m0.5192\u001b[0m       0.6875        \u001b[35m0.5530\u001b[0m  0.0368\n",
      "     34        \u001b[36m0.5139\u001b[0m       0.6797        \u001b[35m0.5522\u001b[0m  0.0312\n",
      "     35        0.5181       0.6797        \u001b[35m0.5512\u001b[0m  0.0244\n",
      "     36        \u001b[36m0.5113\u001b[0m       0.6797        \u001b[35m0.5505\u001b[0m  0.0238\n",
      "     37        0.5152       0.6797        \u001b[35m0.5499\u001b[0m  0.0367\n",
      "     38        \u001b[36m0.5059\u001b[0m       0.6797        \u001b[35m0.5494\u001b[0m  0.0256\n",
      "     39        0.5092       0.6797        \u001b[35m0.5488\u001b[0m  0.0310\n",
      "     40        0.5078       0.6797        \u001b[35m0.5482\u001b[0m  0.0709\n",
      "     41        0.5131       0.6797        \u001b[35m0.5476\u001b[0m  0.0648\n",
      "     42        0.5118       0.6797        \u001b[35m0.5473\u001b[0m  0.0804\n",
      "     43        \u001b[36m0.5044\u001b[0m       0.6875        \u001b[35m0.5469\u001b[0m  0.1604\n",
      "     44        0.5049       0.6875        \u001b[35m0.5466\u001b[0m  0.0261\n",
      "     45        0.5096       0.6875        \u001b[35m0.5462\u001b[0m  0.0268\n",
      "     46        0.5294       0.6875        \u001b[35m0.5457\u001b[0m  0.0342\n",
      "     47        \u001b[36m0.4972\u001b[0m       0.6875        \u001b[35m0.5454\u001b[0m  0.0300\n",
      "     48        0.4993       0.6875        \u001b[35m0.5452\u001b[0m  0.0375\n",
      "     49        0.5031       0.6875        \u001b[35m0.5450\u001b[0m  0.0269\n",
      "     50        0.5108       0.6875        \u001b[35m0.5448\u001b[0m  0.0304\n",
      "     51        0.5027       0.6875        \u001b[35m0.5445\u001b[0m  0.0314\n",
      "     52        0.4996       0.6797        \u001b[35m0.5442\u001b[0m  0.0316\n",
      "     53        0.5062       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5439\u001b[0m  0.0287\n",
      "     54        0.5221       0.6797        \u001b[35m0.5437\u001b[0m  0.0302\n",
      "     55        \u001b[36m0.4963\u001b[0m       0.6875        \u001b[35m0.5435\u001b[0m  0.0265\n",
      "     56        0.5142       0.6875        \u001b[35m0.5432\u001b[0m  0.0348\n",
      "     57        0.5111       0.6797        0.5433  0.0333\n",
      "     58        0.4994       0.6875        \u001b[35m0.5430\u001b[0m  0.0241\n",
      "     59        \u001b[36m0.4936\u001b[0m       0.6875        \u001b[35m0.5426\u001b[0m  0.0299\n",
      "     60        0.4996       0.6797        \u001b[35m0.5424\u001b[0m  0.0300\n",
      "     61        0.4973       0.6797        \u001b[35m0.5423\u001b[0m  0.0235\n",
      "     62        0.5019       0.6797        \u001b[35m0.5421\u001b[0m  0.0304\n",
      "     63        0.4954       0.6797        0.5422  0.0332\n",
      "     64        \u001b[36m0.4824\u001b[0m       0.6797        0.5421  0.0261\n",
      "     65        0.4895       0.6797        \u001b[35m0.5419\u001b[0m  0.0279\n",
      "     66        0.5063       0.6797        \u001b[35m0.5416\u001b[0m  0.0307\n",
      "     67        0.5079       0.6797        \u001b[35m0.5414\u001b[0m  0.0293\n",
      "     68        0.5013       0.6875        \u001b[35m0.5410\u001b[0m  0.0319\n",
      "     69        0.4897       0.6797        \u001b[35m0.5409\u001b[0m  0.0307\n",
      "     70        0.5011       0.6875        \u001b[35m0.5406\u001b[0m  0.0227\n",
      "     71        0.4941       0.6875        \u001b[35m0.5404\u001b[0m  0.0321\n",
      "     72        0.4899       0.6875        \u001b[35m0.5402\u001b[0m  0.0262\n",
      "     73        0.4834       0.6797        \u001b[35m0.5401\u001b[0m  0.0286\n",
      "     74        0.5073       0.6953        \u001b[35m0.5399\u001b[0m  0.0276\n",
      "     75        0.5004       0.6875        \u001b[35m0.5399\u001b[0m  0.0305\n",
      "     76        0.4944       0.6953        \u001b[35m0.5396\u001b[0m  0.0322\n",
      "     77        0.4954       0.6953        \u001b[35m0.5394\u001b[0m  0.0232\n",
      "     78        0.4936       0.6953        \u001b[35m0.5392\u001b[0m  0.0359\n",
      "     79        0.4911       0.6953        0.5392  0.0250\n",
      "     80        0.4888       0.6953        \u001b[35m0.5391\u001b[0m  0.0286\n",
      "     81        0.4903       0.6953        0.5393  0.0270\n",
      "     82        0.4931       0.6953        \u001b[35m0.5390\u001b[0m  0.0295\n",
      "     83        0.4882       0.6953        \u001b[35m0.5390\u001b[0m  0.0278\n",
      "     84        \u001b[36m0.4703\u001b[0m       \u001b[32m0.7031\u001b[0m        0.5390  0.0315\n",
      "     85        0.4829       0.6953        \u001b[35m0.5386\u001b[0m  0.0247\n",
      "     86        0.4966       0.6953        \u001b[35m0.5382\u001b[0m  0.0331\n",
      "     87        0.4909       0.6953        \u001b[35m0.5378\u001b[0m  0.0467\n",
      "     88        0.4855       0.7031        0.5378  0.0786\n",
      "     89        0.4939       0.7031        \u001b[35m0.5375\u001b[0m  0.0654\n",
      "     90        0.4934       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5372\u001b[0m  0.0705\n",
      "     91        0.4831       0.7109        \u001b[35m0.5372\u001b[0m  0.0424\n",
      "     92        0.4949       0.7109        \u001b[35m0.5370\u001b[0m  0.0858\n",
      "     93        0.4996       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5367\u001b[0m  0.0551\n",
      "     94        0.4928       0.7188        \u001b[35m0.5365\u001b[0m  0.0697\n",
      "     95        0.4899       0.7188        \u001b[35m0.5364\u001b[0m  0.0584\n",
      "     96        0.4923       0.7188        \u001b[35m0.5363\u001b[0m  0.0498\n",
      "     97        0.4836       0.7188        \u001b[35m0.5361\u001b[0m  0.0656\n",
      "     98        0.4831       0.7188        \u001b[35m0.5360\u001b[0m  0.0351\n",
      "     99        0.4758       0.7188        \u001b[35m0.5358\u001b[0m  0.0351\n",
      "    100        0.4925       0.7188        \u001b[35m0.5354\u001b[0m  0.0436\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7424\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7241\u001b[0m  0.0738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.7243\u001b[0m       0.5000        \u001b[35m0.7071\u001b[0m  0.0545\n",
      "      3        \u001b[36m0.7018\u001b[0m       0.5000        \u001b[35m0.6933\u001b[0m  0.0586\n",
      "      4        \u001b[36m0.6935\u001b[0m       0.5000        \u001b[35m0.6828\u001b[0m  0.1038\n",
      "      5        \u001b[36m0.6792\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6738\u001b[0m  0.0668\n",
      "      6        \u001b[36m0.6715\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6664\u001b[0m  0.0540\n",
      "      7        \u001b[36m0.6622\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6601\u001b[0m  0.0414\n",
      "      8        \u001b[36m0.6547\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6542\u001b[0m  0.0293\n",
      "      9        0.6557       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6491\u001b[0m  0.0327\n",
      "     10        \u001b[36m0.6493\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6442\u001b[0m  0.0305\n",
      "     11        \u001b[36m0.6366\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6395\u001b[0m  0.0288\n",
      "     12        0.6385       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6352\u001b[0m  0.0292\n",
      "     13        \u001b[36m0.6270\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6305\u001b[0m  0.0331\n",
      "     14        \u001b[36m0.6253\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6261\u001b[0m  0.0275\n",
      "     15        \u001b[36m0.6187\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6219\u001b[0m  0.0317\n",
      "     16        0.6194       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6178\u001b[0m  0.0287\n",
      "     17        \u001b[36m0.5988\u001b[0m       0.7188        \u001b[35m0.6134\u001b[0m  0.0530\n",
      "     18        \u001b[36m0.5981\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6093\u001b[0m  0.0768\n",
      "     19        0.6051       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6054\u001b[0m  0.0548\n",
      "     20        0.5999       0.7422        \u001b[35m0.6015\u001b[0m  0.0424\n",
      "     21        \u001b[36m0.5891\u001b[0m       0.7344        \u001b[35m0.5973\u001b[0m  0.0827\n",
      "     22        \u001b[36m0.5881\u001b[0m       0.7422        \u001b[35m0.5938\u001b[0m  0.0389\n",
      "     23        \u001b[36m0.5790\u001b[0m       0.7422        \u001b[35m0.5898\u001b[0m  0.0352\n",
      "     24        0.5808       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5863\u001b[0m  0.0247\n",
      "     25        \u001b[36m0.5743\u001b[0m       0.7500        \u001b[35m0.5828\u001b[0m  0.0329\n",
      "     26        \u001b[36m0.5677\u001b[0m       0.7500        \u001b[35m0.5796\u001b[0m  0.0320\n",
      "     27        0.5704       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5764\u001b[0m  0.0432\n",
      "     28        \u001b[36m0.5646\u001b[0m       0.7578        \u001b[35m0.5736\u001b[0m  0.0332\n",
      "     29        \u001b[36m0.5610\u001b[0m       0.7578        \u001b[35m0.5706\u001b[0m  0.0322\n",
      "     30        \u001b[36m0.5568\u001b[0m       0.7578        \u001b[35m0.5680\u001b[0m  0.0283\n",
      "     31        \u001b[36m0.5536\u001b[0m       0.7578        \u001b[35m0.5654\u001b[0m  0.0277\n",
      "     32        \u001b[36m0.5494\u001b[0m       0.7578        \u001b[35m0.5629\u001b[0m  0.0284\n",
      "     33        \u001b[36m0.5470\u001b[0m       0.7500        \u001b[35m0.5606\u001b[0m  0.0260\n",
      "     34        0.5475       0.7500        \u001b[35m0.5585\u001b[0m  0.0206\n",
      "     35        \u001b[36m0.5448\u001b[0m       0.7500        \u001b[35m0.5563\u001b[0m  0.0314\n",
      "     36        0.5524       0.7500        \u001b[35m0.5546\u001b[0m  0.0327\n",
      "     37        \u001b[36m0.5349\u001b[0m       0.7422        \u001b[35m0.5529\u001b[0m  0.0299\n",
      "     38        0.5422       0.7422        \u001b[35m0.5513\u001b[0m  0.0245\n",
      "     39        0.5394       0.7344        \u001b[35m0.5497\u001b[0m  0.0300\n",
      "     40        0.5392       0.7344        \u001b[35m0.5483\u001b[0m  0.0239\n",
      "     41        0.5391       0.7344        \u001b[35m0.5469\u001b[0m  0.0316\n",
      "     42        0.5430       0.7344        \u001b[35m0.5458\u001b[0m  0.0302\n",
      "     43        \u001b[36m0.5273\u001b[0m       0.7344        \u001b[35m0.5445\u001b[0m  0.0243\n",
      "     44        0.5286       0.7422        \u001b[35m0.5435\u001b[0m  0.0321\n",
      "     45        \u001b[36m0.5232\u001b[0m       0.7344        \u001b[35m0.5423\u001b[0m  0.0333\n",
      "     46        \u001b[36m0.5225\u001b[0m       0.7344        \u001b[35m0.5410\u001b[0m  0.0330\n",
      "     47        \u001b[36m0.5083\u001b[0m       0.7422        \u001b[35m0.5397\u001b[0m  0.0301\n",
      "     48        \u001b[36m0.5066\u001b[0m       0.7344        \u001b[35m0.5383\u001b[0m  0.0656\n",
      "     49        0.5078       0.7344        \u001b[35m0.5373\u001b[0m  0.0324\n",
      "     50        0.5157       0.7344        \u001b[35m0.5363\u001b[0m  0.0252\n",
      "     51        0.5226       0.7344        \u001b[35m0.5355\u001b[0m  0.0289\n",
      "     52        0.5144       0.7344        \u001b[35m0.5347\u001b[0m  0.0343\n",
      "     53        \u001b[36m0.5011\u001b[0m       0.7344        \u001b[35m0.5339\u001b[0m  0.0228\n",
      "     54        0.5066       0.7344        \u001b[35m0.5331\u001b[0m  0.0270\n",
      "     55        0.5117       0.7344        \u001b[35m0.5325\u001b[0m  0.0241\n",
      "     56        0.5133       0.7344        \u001b[35m0.5318\u001b[0m  0.0286\n",
      "     57        0.5065       0.7344        \u001b[35m0.5310\u001b[0m  0.0375\n",
      "     58        0.5170       0.7344        \u001b[35m0.5305\u001b[0m  0.0236\n",
      "     59        0.5051       0.7344        \u001b[35m0.5298\u001b[0m  0.0377\n",
      "     60        \u001b[36m0.4995\u001b[0m       0.7344        \u001b[35m0.5293\u001b[0m  0.0260\n",
      "     61        0.5074       0.7344        \u001b[35m0.5286\u001b[0m  0.0301\n",
      "     62        0.4995       0.7344        \u001b[35m0.5282\u001b[0m  0.0305\n",
      "     63        0.5128       0.7266        \u001b[35m0.5279\u001b[0m  0.0291\n",
      "     64        0.5034       0.7266        \u001b[35m0.5276\u001b[0m  0.0335\n",
      "     65        0.5102       0.7266        \u001b[35m0.5272\u001b[0m  0.0290\n",
      "     66        0.5023       0.7266        \u001b[35m0.5267\u001b[0m  0.0550\n",
      "     67        0.5052       0.7344        \u001b[35m0.5261\u001b[0m  0.0619\n",
      "     68        \u001b[36m0.4818\u001b[0m       0.7344        \u001b[35m0.5257\u001b[0m  0.0556\n",
      "     69        0.4952       0.7344        \u001b[35m0.5254\u001b[0m  0.0480\n",
      "     70        0.4961       0.7344        \u001b[35m0.5250\u001b[0m  0.0432\n",
      "     71        0.4971       0.7344        \u001b[35m0.5246\u001b[0m  0.0251\n",
      "     72        0.5030       0.7344        \u001b[35m0.5245\u001b[0m  0.0340\n",
      "     73        0.5039       0.7344        \u001b[35m0.5242\u001b[0m  0.0456\n",
      "     74        0.4895       0.7344        \u001b[35m0.5237\u001b[0m  0.0296\n",
      "     75        0.4980       0.7344        \u001b[35m0.5233\u001b[0m  0.0353\n",
      "     76        \u001b[36m0.4805\u001b[0m       0.7344        \u001b[35m0.5231\u001b[0m  0.0459\n",
      "     77        0.4959       0.7344        \u001b[35m0.5228\u001b[0m  0.0538\n",
      "     78        0.4876       0.7344        \u001b[35m0.5227\u001b[0m  0.0536\n",
      "     79        0.4989       0.7344        \u001b[35m0.5223\u001b[0m  0.0718\n",
      "     80        0.4885       0.7344        \u001b[35m0.5221\u001b[0m  0.1509\n",
      "     81        0.4811       0.7344        \u001b[35m0.5220\u001b[0m  0.0558\n",
      "     82        0.5014       0.7344        \u001b[35m0.5217\u001b[0m  0.0630\n",
      "     83        0.4971       0.7344        \u001b[35m0.5215\u001b[0m  0.0615\n",
      "     84        0.4856       0.7344        \u001b[35m0.5214\u001b[0m  0.0407\n",
      "     85        0.4915       0.7344        \u001b[35m0.5212\u001b[0m  0.0641\n",
      "     86        0.4857       0.7344        \u001b[35m0.5211\u001b[0m  0.0645\n",
      "     87        0.4962       0.7344        \u001b[35m0.5209\u001b[0m  0.0815\n",
      "     88        \u001b[36m0.4754\u001b[0m       0.7344        \u001b[35m0.5208\u001b[0m  0.0475\n",
      "     89        0.5043       0.7344        \u001b[35m0.5204\u001b[0m  0.1049\n",
      "     90        0.5041       0.7344        \u001b[35m0.5201\u001b[0m  0.0818\n",
      "     91        0.5006       0.7344        \u001b[35m0.5198\u001b[0m  0.0855\n",
      "     92        0.4947       0.7344        \u001b[35m0.5197\u001b[0m  0.0436\n",
      "     93        0.4983       0.7266        \u001b[35m0.5193\u001b[0m  0.0566\n",
      "     94        0.4923       0.7266        \u001b[35m0.5191\u001b[0m  0.0601\n",
      "     95        0.4917       0.7266        \u001b[35m0.5189\u001b[0m  0.0302\n",
      "     96        0.4982       0.7266        \u001b[35m0.5186\u001b[0m  0.0273\n",
      "     97        0.4865       0.7266        \u001b[35m0.5184\u001b[0m  0.0417\n",
      "     98        0.4924       0.7266        \u001b[35m0.5181\u001b[0m  0.0603\n",
      "     99        0.4760       0.7188        \u001b[35m0.5180\u001b[0m  0.0898\n",
      "    100        \u001b[36m0.4750\u001b[0m       0.7188        \u001b[35m0.5179\u001b[0m  0.1333\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7676\u001b[0m       \u001b[32m0.3594\u001b[0m        \u001b[35m0.7706\u001b[0m  0.0508\n",
      "      2        \u001b[36m0.7396\u001b[0m       0.3594        \u001b[35m0.7551\u001b[0m  0.0860\n",
      "      3        \u001b[36m0.7342\u001b[0m       \u001b[32m0.3750\u001b[0m        \u001b[35m0.7426\u001b[0m  0.0363\n",
      "      4        \u001b[36m0.7248\u001b[0m       \u001b[32m0.4141\u001b[0m        \u001b[35m0.7317\u001b[0m  0.0358\n",
      "      5        \u001b[36m0.7069\u001b[0m       \u001b[32m0.4375\u001b[0m        \u001b[35m0.7233\u001b[0m  0.0508\n",
      "      6        \u001b[36m0.7004\u001b[0m       \u001b[32m0.4453\u001b[0m        \u001b[35m0.7163\u001b[0m  0.0514\n",
      "      7        \u001b[36m0.7000\u001b[0m       0.4453        \u001b[35m0.7093\u001b[0m  0.0311\n",
      "      8        \u001b[36m0.6801\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m0.7035\u001b[0m  0.0422\n",
      "      9        \u001b[36m0.6759\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.6975\u001b[0m  0.0377\n",
      "     10        \u001b[36m0.6724\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6911\u001b[0m  0.0605\n",
      "     11        \u001b[36m0.6625\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6851\u001b[0m  0.0935\n",
      "     12        \u001b[36m0.6584\u001b[0m       0.5938        \u001b[35m0.6786\u001b[0m  0.0428\n",
      "     13        \u001b[36m0.6510\u001b[0m       0.5938        \u001b[35m0.6722\u001b[0m  0.0468\n",
      "     14        \u001b[36m0.6449\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6659\u001b[0m  0.0346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15        \u001b[36m0.6353\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6595\u001b[0m  0.0815\n",
      "     16        \u001b[36m0.6290\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6529\u001b[0m  0.0487\n",
      "     17        0.6303       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6468\u001b[0m  0.0231\n",
      "     18        \u001b[36m0.6138\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6401\u001b[0m  0.0217\n",
      "     19        \u001b[36m0.6094\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6334\u001b[0m  0.0364\n",
      "     20        0.6188       0.6641        \u001b[35m0.6271\u001b[0m  0.0827\n",
      "     21        \u001b[36m0.5987\u001b[0m       0.6484        \u001b[35m0.6210\u001b[0m  0.0372\n",
      "     22        0.6080       0.6484        \u001b[35m0.6154\u001b[0m  0.0532\n",
      "     23        \u001b[36m0.5882\u001b[0m       0.6562        \u001b[35m0.6098\u001b[0m  0.0485\n",
      "     24        \u001b[36m0.5795\u001b[0m       0.6484        \u001b[35m0.6043\u001b[0m  0.0399\n",
      "     25        0.5813       0.6484        \u001b[35m0.5989\u001b[0m  0.0678\n",
      "     26        \u001b[36m0.5635\u001b[0m       0.6484        \u001b[35m0.5936\u001b[0m  0.0794\n",
      "     27        0.5677       0.6484        \u001b[35m0.5886\u001b[0m  0.0640\n",
      "     28        \u001b[36m0.5504\u001b[0m       0.6484        \u001b[35m0.5838\u001b[0m  0.0526\n",
      "     29        0.5542       0.6562        \u001b[35m0.5796\u001b[0m  0.0378\n",
      "     30        0.5535       0.6719        \u001b[35m0.5756\u001b[0m  0.0378\n",
      "     31        \u001b[36m0.5417\u001b[0m       0.6719        \u001b[35m0.5722\u001b[0m  0.0321\n",
      "     32        0.5461       0.6719        \u001b[35m0.5687\u001b[0m  0.0216\n",
      "     33        \u001b[36m0.5242\u001b[0m       0.6719        \u001b[35m0.5653\u001b[0m  0.0286\n",
      "     34        0.5338       0.6719        \u001b[35m0.5624\u001b[0m  0.0260\n",
      "     35        0.5273       0.6719        \u001b[35m0.5593\u001b[0m  0.0328\n",
      "     36        0.5357       0.6719        \u001b[35m0.5569\u001b[0m  0.0332\n",
      "     37        \u001b[36m0.5143\u001b[0m       0.6719        \u001b[35m0.5544\u001b[0m  0.0460\n",
      "     38        \u001b[36m0.5091\u001b[0m       0.6719        \u001b[35m0.5521\u001b[0m  0.0341\n",
      "     39        0.5244       0.6719        \u001b[35m0.5500\u001b[0m  0.0302\n",
      "     40        0.5129       0.6719        \u001b[35m0.5483\u001b[0m  0.0272\n",
      "     41        0.5121       0.6719        \u001b[35m0.5468\u001b[0m  0.0258\n",
      "     42        0.5181       0.6719        \u001b[35m0.5456\u001b[0m  0.0496\n",
      "     43        0.5172       0.6719        \u001b[35m0.5445\u001b[0m  0.0476\n",
      "     44        0.5104       0.6719        \u001b[35m0.5435\u001b[0m  0.0306\n",
      "     45        \u001b[36m0.5073\u001b[0m       0.6719        \u001b[35m0.5426\u001b[0m  0.0350\n",
      "     46        0.5164       0.6719        \u001b[35m0.5415\u001b[0m  0.0294\n",
      "     47        \u001b[36m0.4975\u001b[0m       0.6719        \u001b[35m0.5408\u001b[0m  0.0232\n",
      "     48        \u001b[36m0.4963\u001b[0m       0.6641        \u001b[35m0.5400\u001b[0m  0.0267\n",
      "     49        \u001b[36m0.4963\u001b[0m       0.6719        \u001b[35m0.5389\u001b[0m  0.0289\n",
      "     50        0.5057       0.6719        \u001b[35m0.5382\u001b[0m  0.0723\n",
      "     51        \u001b[36m0.4924\u001b[0m       0.6719        \u001b[35m0.5377\u001b[0m  0.0638\n",
      "     52        0.4978       0.6719        \u001b[35m0.5374\u001b[0m  0.0425\n",
      "     53        \u001b[36m0.4915\u001b[0m       0.6719        \u001b[35m0.5371\u001b[0m  0.0313\n",
      "     54        0.4991       0.6719        \u001b[35m0.5369\u001b[0m  0.0311\n",
      "     55        \u001b[36m0.4893\u001b[0m       0.6719        \u001b[35m0.5364\u001b[0m  0.0231\n",
      "     56        0.5036       0.6719        \u001b[35m0.5363\u001b[0m  0.0307\n",
      "     57        0.4940       0.6719        \u001b[35m0.5361\u001b[0m  0.0321\n",
      "     58        \u001b[36m0.4863\u001b[0m       0.6719        \u001b[35m0.5360\u001b[0m  0.0243\n",
      "     59        0.4866       0.6719        \u001b[35m0.5356\u001b[0m  0.0539\n",
      "     60        \u001b[36m0.4694\u001b[0m       0.6719        0.5356  0.0379\n",
      "     61        0.4751       0.6719        \u001b[35m0.5354\u001b[0m  0.0336\n",
      "     62        0.4768       0.6719        \u001b[35m0.5351\u001b[0m  0.0349\n",
      "     63        0.4757       0.6719        0.5353  0.0277\n",
      "     64        0.4828       0.6719        \u001b[35m0.5351\u001b[0m  0.0315\n",
      "     65        0.4843       0.6719        \u001b[35m0.5348\u001b[0m  0.0204\n",
      "     66        0.4906       0.6719        0.5350  0.0288\n",
      "     67        \u001b[36m0.4665\u001b[0m       0.6719        0.5350  0.0389\n",
      "     68        0.4749       0.6719        0.5348  0.0291\n",
      "     69        0.4817       0.6797        \u001b[35m0.5344\u001b[0m  0.0386\n",
      "     70        0.4927       0.6797        \u001b[35m0.5341\u001b[0m  0.0252\n",
      "     71        0.4872       0.6797        \u001b[35m0.5340\u001b[0m  0.0340\n",
      "     72        0.4794       0.6797        \u001b[35m0.5338\u001b[0m  0.0316\n",
      "     73        0.4735       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5337\u001b[0m  0.0216\n",
      "     74        \u001b[36m0.4603\u001b[0m       0.6875        0.5337  0.0301\n",
      "     75        0.4815       0.6875        \u001b[35m0.5333\u001b[0m  0.0302\n",
      "     76        0.4624       0.6875        \u001b[35m0.5332\u001b[0m  0.0220\n",
      "     77        0.4760       0.6875        0.5333  0.0342\n",
      "     78        0.4692       0.6875        0.5334  0.0241\n",
      "     79        0.4717       0.6875        \u001b[35m0.5331\u001b[0m  0.0295\n",
      "     80        0.4808       0.6875        \u001b[35m0.5329\u001b[0m  0.0283\n",
      "     81        0.4678       0.6875        \u001b[35m0.5326\u001b[0m  0.0230\n",
      "     82        0.4737       0.6875        \u001b[35m0.5324\u001b[0m  0.0298\n",
      "     83        0.4719       0.6875        0.5327  0.0264\n",
      "     84        0.4762       0.6875        \u001b[35m0.5324\u001b[0m  0.0375\n",
      "     85        0.4770       0.6875        \u001b[35m0.5323\u001b[0m  0.0342\n",
      "     86        0.4629       0.6875        0.5327  0.0375\n",
      "     87        \u001b[36m0.4555\u001b[0m       0.6875        0.5325  0.0301\n",
      "     88        0.4655       0.6875        0.5328  0.0316\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6265\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.4943\u001b[0m  0.0158\n",
      "      2        \u001b[36m0.5583\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4264\u001b[0m  0.0159\n",
      "      3        \u001b[36m0.5290\u001b[0m       \u001b[32m0.8359\u001b[0m        \u001b[35m0.4110\u001b[0m  0.0240\n",
      "      4        \u001b[36m0.5145\u001b[0m       0.8125        0.4182  0.0145\n",
      "      5        \u001b[36m0.5091\u001b[0m       0.7969        0.4184  0.0344\n",
      "      6        \u001b[36m0.5000\u001b[0m       0.8047        \u001b[35m0.4039\u001b[0m  0.0208\n",
      "      7        \u001b[36m0.4985\u001b[0m       0.8125        \u001b[35m0.4008\u001b[0m  0.0164\n",
      "      8        0.5023       0.8281        0.4015  0.0277\n",
      "      9        0.5060       \u001b[32m0.8438\u001b[0m        0.4051  0.0246\n",
      "     10        \u001b[36m0.4923\u001b[0m       0.8438        \u001b[35m0.3937\u001b[0m  0.0223\n",
      "     11        \u001b[36m0.4859\u001b[0m       0.8359        \u001b[35m0.3893\u001b[0m  0.0152\n",
      "     12        0.4877       0.8125        0.3974  0.0149\n",
      "     13        \u001b[36m0.4764\u001b[0m       0.8359        \u001b[35m0.3847\u001b[0m  0.0220\n",
      "     14        \u001b[36m0.4715\u001b[0m       0.8281        \u001b[35m0.3838\u001b[0m  0.0243\n",
      "     15        0.4719       0.8281        \u001b[35m0.3717\u001b[0m  0.0164\n",
      "     16        0.4867       0.8203        0.3923  0.0164\n",
      "     17        0.4726       0.8203        0.3831  0.0255\n",
      "     18        0.4733       0.8203        0.3929  0.0173\n",
      "     19        \u001b[36m0.4653\u001b[0m       0.8281        0.3805  0.0389\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5752\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5846\u001b[0m  0.0330\n",
      "      2        \u001b[36m0.5494\u001b[0m       0.6875        \u001b[35m0.5679\u001b[0m  0.0160\n",
      "      3        \u001b[36m0.5263\u001b[0m       0.7031        \u001b[35m0.5484\u001b[0m  0.0159\n",
      "      4        \u001b[36m0.5131\u001b[0m       \u001b[32m0.7500\u001b[0m        0.5750  0.0214\n",
      "      5        0.5131       0.7266        \u001b[35m0.5319\u001b[0m  0.0157\n",
      "      6        \u001b[36m0.4881\u001b[0m       0.7266        0.5530  0.0146\n",
      "      7        \u001b[36m0.4851\u001b[0m       0.7031        \u001b[35m0.5317\u001b[0m  0.0225\n",
      "      8        \u001b[36m0.4684\u001b[0m       0.7109        0.5437  0.0250\n",
      "      9        0.4687       0.7109        0.5797  0.0154\n",
      "     10        0.4917       0.6875        0.5629  0.0136\n",
      "     11        \u001b[36m0.4575\u001b[0m       0.7266        \u001b[35m0.5246\u001b[0m  0.0155\n",
      "     12        0.4672       0.7109        0.5284  0.0250\n",
      "     13        0.4596       0.7188        \u001b[35m0.5110\u001b[0m  0.0228\n",
      "     14        \u001b[36m0.4409\u001b[0m       0.7500        0.5542  0.0159\n",
      "     15        0.4736       0.7422        0.5139  0.0147\n",
      "     16        0.4891       0.7266        0.5229  0.0159\n",
      "     17        0.4567       0.7344        0.5201  0.0220\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6268\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.5652\u001b[0m  0.0180\n",
      "      2        \u001b[36m0.5214\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5634\u001b[0m  0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        0.5315       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5358\u001b[0m  0.0148\n",
      "      4        \u001b[36m0.4981\u001b[0m       \u001b[32m0.7266\u001b[0m        0.5556  0.0246\n",
      "      5        \u001b[36m0.4939\u001b[0m       0.7031        \u001b[35m0.5312\u001b[0m  0.0147\n",
      "      6        0.5083       0.7188        \u001b[35m0.5266\u001b[0m  0.0230\n",
      "      7        \u001b[36m0.4665\u001b[0m       \u001b[32m0.7500\u001b[0m        0.5367  0.0163\n",
      "      8        0.4736       0.7344        \u001b[35m0.5243\u001b[0m  0.0367\n",
      "      9        0.4863       \u001b[32m0.7578\u001b[0m        0.5246  0.0164\n",
      "     10        \u001b[36m0.4648\u001b[0m       0.7422        0.5251  0.0161\n",
      "     11        \u001b[36m0.4572\u001b[0m       0.7500        \u001b[35m0.5201\u001b[0m  0.0313\n",
      "     12        \u001b[36m0.4571\u001b[0m       0.7578        0.5400  0.0199\n",
      "     13        0.4790       0.7031        0.5387  0.0155\n",
      "     14        0.4667       0.7266        0.5397  0.0207\n",
      "     15        0.4576       0.7500        0.5364  0.0243\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6034\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6263\u001b[0m  0.0154\n",
      "      2        \u001b[36m0.5382\u001b[0m       0.6875        \u001b[35m0.5833\u001b[0m  0.0166\n",
      "      3        \u001b[36m0.5124\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5579\u001b[0m  0.0273\n",
      "      4        \u001b[36m0.4861\u001b[0m       0.6953        \u001b[35m0.5477\u001b[0m  0.0356\n",
      "      5        \u001b[36m0.4794\u001b[0m       0.6953        \u001b[35m0.5384\u001b[0m  0.0136\n",
      "      6        0.4931       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5262\u001b[0m  0.0381\n",
      "      7        \u001b[36m0.4674\u001b[0m       0.7109        \u001b[35m0.5245\u001b[0m  0.0152\n",
      "      8        0.4692       \u001b[32m0.7266\u001b[0m        0.5391  0.0286\n",
      "      9        0.5002       0.6797        \u001b[35m0.5133\u001b[0m  0.0270\n",
      "     10        0.4775       \u001b[32m0.7344\u001b[0m        0.5350  0.0158\n",
      "     11        0.4709       0.6797        0.5277  0.0259\n",
      "     12        0.4831       0.7266        0.5220  0.0380\n",
      "     13        0.4805       0.7109        0.5196  0.0166\n",
      "     14        0.4809       0.7266        \u001b[35m0.5131\u001b[0m  0.0300\n",
      "     15        0.4771       0.7109        0.5393  0.0154\n",
      "     16        0.4707       0.7031        0.5408  0.0273\n",
      "     17        0.4827       0.6719        0.5313  0.0154\n",
      "     18        0.4754       0.7188        0.5337  0.0233\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6206\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5897\u001b[0m  0.0154\n",
      "      2        \u001b[36m0.5349\u001b[0m       \u001b[32m0.7031\u001b[0m        0.6038  0.0144\n",
      "      3        \u001b[36m0.5073\u001b[0m       0.6953        \u001b[35m0.5579\u001b[0m  0.0162\n",
      "      4        \u001b[36m0.4911\u001b[0m       0.6875        0.5720  0.0179\n",
      "      5        0.4925       0.6797        0.5595  0.0336\n",
      "      6        0.4925       0.6797        \u001b[35m0.5543\u001b[0m  0.0168\n",
      "      7        \u001b[36m0.4828\u001b[0m       0.6797        \u001b[35m0.5511\u001b[0m  0.0268\n",
      "      8        0.4996       0.6797        0.5535  0.0178\n",
      "      9        0.4934       \u001b[32m0.7109\u001b[0m        0.5772  0.0165\n",
      "     10        0.4881       0.6797        \u001b[35m0.5419\u001b[0m  0.0369\n",
      "     11        \u001b[36m0.4783\u001b[0m       0.6875        0.5420  0.0150\n",
      "     12        0.4821       0.6719        0.5566  0.0237\n",
      "     13        0.4784       0.6953        0.5801  0.0257\n",
      "     14        \u001b[36m0.4696\u001b[0m       0.6641        0.5787  0.0230\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6966\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6759\u001b[0m  0.0298\n",
      "      2        \u001b[36m0.6709\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6722\u001b[0m  0.0203\n",
      "      3        0.6850       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6681\u001b[0m  0.0160\n",
      "      4        0.6853       0.6172        \u001b[35m0.6646\u001b[0m  0.0215\n",
      "      5        0.6812       0.6094        \u001b[35m0.6609\u001b[0m  0.0175\n",
      "      6        0.6829       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6582\u001b[0m  0.0391\n",
      "      7        0.6803       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6552\u001b[0m  0.0161\n",
      "      8        0.6764       0.6328        \u001b[35m0.6524\u001b[0m  0.0166\n",
      "      9        0.6717       0.6406        \u001b[35m0.6495\u001b[0m  0.0340\n",
      "     10        \u001b[36m0.6618\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6470\u001b[0m  0.0159\n",
      "     11        0.6640       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6444\u001b[0m  0.0244\n",
      "     12        0.6641       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6419\u001b[0m  0.0167\n",
      "     13        0.6728       0.6875        \u001b[35m0.6392\u001b[0m  0.0158\n",
      "     14        \u001b[36m0.6513\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6372\u001b[0m  0.0203\n",
      "     15        0.6683       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6353\u001b[0m  0.0246\n",
      "     16        0.6582       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6331\u001b[0m  0.0158\n",
      "     17        0.6618       0.7188        \u001b[35m0.6312\u001b[0m  0.0170\n",
      "     18        \u001b[36m0.6478\u001b[0m       0.7188        \u001b[35m0.6289\u001b[0m  0.0236\n",
      "     19        0.6635       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6271\u001b[0m  0.0368\n",
      "     20        0.6630       0.7266        \u001b[35m0.6253\u001b[0m  0.0150\n",
      "     21        0.6502       0.7266        \u001b[35m0.6233\u001b[0m  0.0231\n",
      "     22        \u001b[36m0.6397\u001b[0m       0.7266        \u001b[35m0.6208\u001b[0m  0.0242\n",
      "     23        0.6616       0.7266        \u001b[35m0.6192\u001b[0m  0.0163\n",
      "     24        0.6426       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6169\u001b[0m  0.0149\n",
      "     25        0.6572       0.7422        \u001b[35m0.6153\u001b[0m  0.0345\n",
      "     26        0.6518       0.7422        \u001b[35m0.6137\u001b[0m  0.0140\n",
      "     27        0.6460       0.7422        \u001b[35m0.6118\u001b[0m  0.0132\n",
      "     28        0.6407       \u001b[32m0.7734\u001b[0m        \u001b[35m0.6097\u001b[0m  0.0251\n",
      "     29        0.6488       0.7734        \u001b[35m0.6080\u001b[0m  0.0253\n",
      "     30        0.6452       0.7734        \u001b[35m0.6063\u001b[0m  0.0262\n",
      "     31        0.6432       0.7734        \u001b[35m0.6044\u001b[0m  0.0143\n",
      "     32        \u001b[36m0.6351\u001b[0m       0.7734        \u001b[35m0.6027\u001b[0m  0.0159\n",
      "     33        \u001b[36m0.6266\u001b[0m       0.7734        \u001b[35m0.6006\u001b[0m  0.0228\n",
      "     34        0.6311       0.7734        \u001b[35m0.5987\u001b[0m  0.0276\n",
      "     35        0.6376       0.7734        \u001b[35m0.5973\u001b[0m  0.0159\n",
      "     36        \u001b[36m0.6252\u001b[0m       0.7734        \u001b[35m0.5955\u001b[0m  0.0256\n",
      "     37        0.6298       \u001b[32m0.7812\u001b[0m        \u001b[35m0.5937\u001b[0m  0.0210\n",
      "     38        0.6332       0.7812        \u001b[35m0.5920\u001b[0m  0.0186\n",
      "     39        0.6412       0.7812        \u001b[35m0.5907\u001b[0m  0.0274\n",
      "     40        0.6426       \u001b[32m0.7891\u001b[0m        \u001b[35m0.5895\u001b[0m  0.0366\n",
      "     41        0.6269       0.7891        \u001b[35m0.5880\u001b[0m  0.0179\n",
      "     42        0.6283       0.7812        \u001b[35m0.5864\u001b[0m  0.0152\n",
      "     43        0.6352       0.7812        \u001b[35m0.5851\u001b[0m  0.0198\n",
      "     44        0.6445       0.7812        \u001b[35m0.5843\u001b[0m  0.0265\n",
      "     45        0.6376       0.7891        \u001b[35m0.5832\u001b[0m  0.0165\n",
      "     46        \u001b[36m0.6136\u001b[0m       0.7891        \u001b[35m0.5815\u001b[0m  0.0161\n",
      "     47        0.6286       0.7891        \u001b[35m0.5804\u001b[0m  0.0174\n",
      "     48        0.6182       0.7812        \u001b[35m0.5789\u001b[0m  0.0240\n",
      "     49        0.6191       0.7812        \u001b[35m0.5773\u001b[0m  0.0305\n",
      "     50        0.6267       0.7812        \u001b[35m0.5761\u001b[0m  0.0162\n",
      "     51        0.6226       0.7812        \u001b[35m0.5748\u001b[0m  0.0278\n",
      "     52        0.6236       0.7812        \u001b[35m0.5735\u001b[0m  0.0145\n",
      "     53        0.6294       0.7734        \u001b[35m0.5724\u001b[0m  0.0157\n",
      "     54        \u001b[36m0.6058\u001b[0m       0.7734        \u001b[35m0.5705\u001b[0m  0.0164\n",
      "     55        0.6204       0.7812        \u001b[35m0.5694\u001b[0m  0.0217\n",
      "     56        0.6073       0.7812        \u001b[35m0.5678\u001b[0m  0.0217\n",
      "     57        0.6261       0.7812        \u001b[35m0.5668\u001b[0m  0.0229\n",
      "     58        0.6136       0.7812        \u001b[35m0.5653\u001b[0m  0.0168\n",
      "     59        \u001b[36m0.6002\u001b[0m       0.7812        \u001b[35m0.5637\u001b[0m  0.0141\n",
      "     60        0.6261       0.7812        \u001b[35m0.5627\u001b[0m  0.0260\n",
      "     61        0.6059       0.7812        \u001b[35m0.5612\u001b[0m  0.0267\n",
      "     62        0.6062       0.7812        \u001b[35m0.5598\u001b[0m  0.0208\n",
      "     63        0.6143       0.7812        \u001b[35m0.5587\u001b[0m  0.0161\n",
      "     64        0.6127       0.7812        \u001b[35m0.5573\u001b[0m  0.0148\n",
      "     65        0.6106       0.7812        \u001b[35m0.5561\u001b[0m  0.0264\n",
      "     66        0.6276       0.7812        \u001b[35m0.5553\u001b[0m  0.0228\n",
      "     67        0.6248       0.7734        \u001b[35m0.5545\u001b[0m  0.0274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     68        0.6089       0.7734        \u001b[35m0.5534\u001b[0m  0.0251\n",
      "     69        0.6147       0.7734        \u001b[35m0.5524\u001b[0m  0.0252\n",
      "     70        0.6048       0.7734        \u001b[35m0.5513\u001b[0m  0.0242\n",
      "     71        0.6053       0.7734        \u001b[35m0.5503\u001b[0m  0.0300\n",
      "     72        0.6122       0.7734        \u001b[35m0.5491\u001b[0m  0.0206\n",
      "     73        0.6039       0.7734        \u001b[35m0.5480\u001b[0m  0.0179\n",
      "     74        0.6125       0.7734        \u001b[35m0.5469\u001b[0m  0.0164\n",
      "     75        \u001b[36m0.5989\u001b[0m       0.7734        \u001b[35m0.5456\u001b[0m  0.0205\n",
      "     76        \u001b[36m0.5984\u001b[0m       0.7734        \u001b[35m0.5444\u001b[0m  0.0185\n",
      "     77        0.6101       0.7734        \u001b[35m0.5434\u001b[0m  0.0150\n",
      "     78        \u001b[36m0.5876\u001b[0m       0.7734        \u001b[35m0.5420\u001b[0m  0.0217\n",
      "     79        0.6022       0.7734        \u001b[35m0.5409\u001b[0m  0.0222\n",
      "     80        0.5887       0.7734        \u001b[35m0.5395\u001b[0m  0.0232\n",
      "     81        0.6029       0.7734        \u001b[35m0.5385\u001b[0m  0.0228\n",
      "     82        0.6000       0.7734        \u001b[35m0.5373\u001b[0m  0.0161\n",
      "     83        0.5945       0.7734        \u001b[35m0.5363\u001b[0m  0.0147\n",
      "     84        \u001b[36m0.5832\u001b[0m       0.7812        \u001b[35m0.5350\u001b[0m  0.0269\n",
      "     85        0.5962       0.7812        \u001b[35m0.5341\u001b[0m  0.0231\n",
      "     86        0.5928       0.7812        \u001b[35m0.5330\u001b[0m  0.0216\n",
      "     87        0.5996       0.7812        \u001b[35m0.5318\u001b[0m  0.0216\n",
      "     88        0.6101       0.7812        \u001b[35m0.5312\u001b[0m  0.0158\n",
      "     89        0.5956       0.7812        \u001b[35m0.5304\u001b[0m  0.0363\n",
      "     90        0.5920       0.7812        \u001b[35m0.5295\u001b[0m  0.0161\n",
      "     91        0.5913       0.7812        \u001b[35m0.5286\u001b[0m  0.0149\n",
      "     92        0.6063       0.7812        \u001b[35m0.5281\u001b[0m  0.0204\n",
      "     93        0.5911       0.7891        \u001b[35m0.5272\u001b[0m  0.0153\n",
      "     94        \u001b[36m0.5774\u001b[0m       0.7891        \u001b[35m0.5260\u001b[0m  0.0144\n",
      "     95        0.5860       0.7812        \u001b[35m0.5248\u001b[0m  0.0271\n",
      "     96        0.5821       0.7812        \u001b[35m0.5239\u001b[0m  0.0184\n",
      "     97        0.6013       0.7812        \u001b[35m0.5232\u001b[0m  0.0241\n",
      "     98        0.6058       0.7891        \u001b[35m0.5226\u001b[0m  0.0224\n",
      "     99        0.5969       0.7891        \u001b[35m0.5220\u001b[0m  0.0179\n",
      "    100        0.5830       0.7891        \u001b[35m0.5210\u001b[0m  0.0286\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8528\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7881\u001b[0m  0.0130\n",
      "      2        \u001b[36m0.8221\u001b[0m       0.5000        \u001b[35m0.7771\u001b[0m  0.0141\n",
      "      3        \u001b[36m0.8045\u001b[0m       0.5000        \u001b[35m0.7670\u001b[0m  0.0233\n",
      "      4        \u001b[36m0.7881\u001b[0m       0.5000        \u001b[35m0.7583\u001b[0m  0.0153\n",
      "      5        \u001b[36m0.7714\u001b[0m       0.4922        \u001b[35m0.7508\u001b[0m  0.0303\n",
      "      6        0.7786       0.4922        \u001b[35m0.7436\u001b[0m  0.0138\n",
      "      7        0.7745       0.4922        \u001b[35m0.7373\u001b[0m  0.0146\n",
      "      8        \u001b[36m0.7681\u001b[0m       0.4922        \u001b[35m0.7311\u001b[0m  0.0210\n",
      "      9        \u001b[36m0.7644\u001b[0m       0.4922        \u001b[35m0.7254\u001b[0m  0.0257\n",
      "     10        \u001b[36m0.7475\u001b[0m       0.5000        \u001b[35m0.7203\u001b[0m  0.0153\n",
      "     11        0.7530       0.5000        \u001b[35m0.7160\u001b[0m  0.0152\n",
      "     12        \u001b[36m0.7407\u001b[0m       0.5000        \u001b[35m0.7116\u001b[0m  0.0320\n",
      "     13        \u001b[36m0.7269\u001b[0m       0.5000        \u001b[35m0.7076\u001b[0m  0.0140\n",
      "     14        0.7305       0.5000        \u001b[35m0.7040\u001b[0m  0.0315\n",
      "     15        0.7324       0.5000        \u001b[35m0.7008\u001b[0m  0.0128\n",
      "     16        \u001b[36m0.7153\u001b[0m       0.5000        \u001b[35m0.6973\u001b[0m  0.0203\n",
      "     17        0.7275       0.5000        \u001b[35m0.6944\u001b[0m  0.0157\n",
      "     18        0.7156       0.5000        \u001b[35m0.6915\u001b[0m  0.0238\n",
      "     19        \u001b[36m0.7082\u001b[0m       0.4922        \u001b[35m0.6888\u001b[0m  0.0138\n",
      "     20        \u001b[36m0.7022\u001b[0m       0.5000        \u001b[35m0.6862\u001b[0m  0.0154\n",
      "     21        \u001b[36m0.6968\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6840\u001b[0m  0.0159\n",
      "     22        0.7014       0.5078        \u001b[35m0.6818\u001b[0m  0.0323\n",
      "     23        0.7010       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6795\u001b[0m  0.0153\n",
      "     24        0.6988       0.5156        \u001b[35m0.6773\u001b[0m  0.0214\n",
      "     25        \u001b[36m0.6939\u001b[0m       0.5156        \u001b[35m0.6756\u001b[0m  0.0219\n",
      "     26        \u001b[36m0.6881\u001b[0m       0.5156        \u001b[35m0.6736\u001b[0m  0.0182\n",
      "     27        0.6887       0.5156        \u001b[35m0.6714\u001b[0m  0.0156\n",
      "     28        \u001b[36m0.6820\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6696\u001b[0m  0.0188\n",
      "     29        0.6897       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6679\u001b[0m  0.0221\n",
      "     30        \u001b[36m0.6810\u001b[0m       0.5391        \u001b[35m0.6658\u001b[0m  0.0165\n",
      "     31        0.6887       0.5391        \u001b[35m0.6638\u001b[0m  0.0256\n",
      "     32        \u001b[36m0.6795\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6620\u001b[0m  0.0328\n",
      "     33        \u001b[36m0.6781\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6601\u001b[0m  0.0158\n",
      "     34        \u001b[36m0.6775\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6584\u001b[0m  0.0162\n",
      "     35        \u001b[36m0.6749\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6566\u001b[0m  0.0342\n",
      "     36        0.6770       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6550\u001b[0m  0.0162\n",
      "     37        \u001b[36m0.6685\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6532\u001b[0m  0.0165\n",
      "     38        \u001b[36m0.6652\u001b[0m       0.6328        \u001b[35m0.6512\u001b[0m  0.0219\n",
      "     39        0.6692       0.6328        \u001b[35m0.6495\u001b[0m  0.0301\n",
      "     40        \u001b[36m0.6614\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6478\u001b[0m  0.0157\n",
      "     41        0.6688       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6461\u001b[0m  0.0165\n",
      "     42        0.6667       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6444\u001b[0m  0.0228\n",
      "     43        0.6684       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6430\u001b[0m  0.0331\n",
      "     44        \u001b[36m0.6490\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6411\u001b[0m  0.0237\n",
      "     45        0.6597       0.6875        \u001b[35m0.6395\u001b[0m  0.0228\n",
      "     46        0.6709       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6384\u001b[0m  0.0199\n",
      "     47        0.6663       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6370\u001b[0m  0.0154\n",
      "     48        0.6553       0.7109        \u001b[35m0.6354\u001b[0m  0.0216\n",
      "     49        0.6599       0.7031        \u001b[35m0.6339\u001b[0m  0.0228\n",
      "     50        0.6548       0.7031        \u001b[35m0.6325\u001b[0m  0.0231\n",
      "     51        0.6630       0.7031        \u001b[35m0.6314\u001b[0m  0.0171\n",
      "     52        0.6589       0.7031        \u001b[35m0.6301\u001b[0m  0.0304\n",
      "     53        0.6517       0.7031        \u001b[35m0.6288\u001b[0m  0.0195\n",
      "     54        \u001b[36m0.6416\u001b[0m       0.7109        \u001b[35m0.6270\u001b[0m  0.0159\n",
      "     55        0.6465       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6256\u001b[0m  0.0227\n",
      "     56        0.6538       0.7188        \u001b[35m0.6244\u001b[0m  0.0209\n",
      "     57        0.6445       0.7188        \u001b[35m0.6228\u001b[0m  0.0210\n",
      "     58        0.6504       0.7188        \u001b[35m0.6215\u001b[0m  0.0358\n",
      "     59        \u001b[36m0.6413\u001b[0m       0.7188        \u001b[35m0.6200\u001b[0m  0.0236\n",
      "     60        0.6435       0.7188        \u001b[35m0.6186\u001b[0m  0.0177\n",
      "     61        \u001b[36m0.6361\u001b[0m       0.7109        \u001b[35m0.6169\u001b[0m  0.0207\n",
      "     62        0.6419       0.7109        \u001b[35m0.6155\u001b[0m  0.0294\n",
      "     63        0.6390       0.7109        \u001b[35m0.6137\u001b[0m  0.0169\n",
      "     64        \u001b[36m0.6344\u001b[0m       0.7109        \u001b[35m0.6123\u001b[0m  0.0180\n",
      "     65        \u001b[36m0.6337\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6109\u001b[0m  0.0252\n",
      "     66        \u001b[36m0.6336\u001b[0m       0.7266        \u001b[35m0.6095\u001b[0m  0.0154\n",
      "     67        \u001b[36m0.6260\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6080\u001b[0m  0.0254\n",
      "     68        0.6500       0.7344        \u001b[35m0.6071\u001b[0m  0.0197\n",
      "     69        0.6307       0.7344        \u001b[35m0.6057\u001b[0m  0.0304\n",
      "     70        0.6445       0.7109        \u001b[35m0.6047\u001b[0m  0.0144\n",
      "     71        \u001b[36m0.6152\u001b[0m       0.7109        \u001b[35m0.6032\u001b[0m  0.0135\n",
      "     72        0.6357       0.7109        \u001b[35m0.6021\u001b[0m  0.0138\n",
      "     73        0.6381       0.7109        \u001b[35m0.6009\u001b[0m  0.0137\n",
      "     74        0.6408       0.7031        \u001b[35m0.6000\u001b[0m  0.0147\n",
      "     75        0.6304       0.7031        \u001b[35m0.5990\u001b[0m  0.0194\n",
      "     76        0.6364       0.7031        \u001b[35m0.5977\u001b[0m  0.0189\n",
      "     77        0.6218       0.7031        \u001b[35m0.5963\u001b[0m  0.0178\n",
      "     78        0.6230       0.7031        \u001b[35m0.5949\u001b[0m  0.0161\n",
      "     79        0.6156       0.7031        \u001b[35m0.5935\u001b[0m  0.0338\n",
      "     80        0.6239       0.7109        \u001b[35m0.5921\u001b[0m  0.0236\n",
      "     81        0.6171       0.7344        \u001b[35m0.5908\u001b[0m  0.0201\n",
      "     82        0.6171       0.7344        \u001b[35m0.5895\u001b[0m  0.0162\n",
      "     83        0.6211       0.7344        \u001b[35m0.5882\u001b[0m  0.0315\n",
      "     84        0.6214       0.7344        \u001b[35m0.5870\u001b[0m  0.0197\n",
      "     85        0.6159       0.7344        \u001b[35m0.5858\u001b[0m  0.0175\n",
      "     86        0.6248       0.7344        \u001b[35m0.5847\u001b[0m  0.0281\n",
      "     87        \u001b[36m0.6039\u001b[0m       0.7344        \u001b[35m0.5834\u001b[0m  0.0241\n",
      "     88        0.6231       0.7344        \u001b[35m0.5824\u001b[0m  0.0190\n",
      "     89        0.6172       0.7266        \u001b[35m0.5813\u001b[0m  0.0213\n",
      "     90        0.6150       0.7266        \u001b[35m0.5802\u001b[0m  0.0198\n",
      "     91        \u001b[36m0.5973\u001b[0m       0.7266        \u001b[35m0.5787\u001b[0m  0.0196\n",
      "     92        0.6130       0.7266        \u001b[35m0.5778\u001b[0m  0.0201\n",
      "     93        0.6202       0.7266        \u001b[35m0.5771\u001b[0m  0.0173\n",
      "     94        0.5975       0.7266        \u001b[35m0.5758\u001b[0m  0.0261\n",
      "     95        \u001b[36m0.5938\u001b[0m       0.7266        \u001b[35m0.5746\u001b[0m  0.0148\n",
      "     96        0.6282       0.7266        \u001b[35m0.5740\u001b[0m  0.0223\n",
      "     97        0.6156       0.7344        \u001b[35m0.5732\u001b[0m  0.0161\n",
      "     98        0.6075       0.7344        \u001b[35m0.5722\u001b[0m  0.0135\n",
      "     99        0.6131       0.7344        \u001b[35m0.5715\u001b[0m  0.0307\n",
      "    100        0.6111       0.7344        \u001b[35m0.5707\u001b[0m  0.0183\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7780\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7508\u001b[0m  0.0179\n",
      "      2        \u001b[36m0.7458\u001b[0m       0.5000        \u001b[35m0.7347\u001b[0m  0.0173\n",
      "      3        \u001b[36m0.7147\u001b[0m       0.5000        \u001b[35m0.7214\u001b[0m  0.0182\n",
      "      4        0.7340       0.5000        \u001b[35m0.7081\u001b[0m  0.0273\n",
      "      5        \u001b[36m0.6987\u001b[0m       0.5000        \u001b[35m0.6968\u001b[0m  0.0194\n",
      "      6        \u001b[36m0.6862\u001b[0m       0.5000        \u001b[35m0.6887\u001b[0m  0.0162\n",
      "      7        0.6970       0.5000        \u001b[35m0.6801\u001b[0m  0.0223\n",
      "      8        0.6881       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6727\u001b[0m  0.0175\n",
      "      9        \u001b[36m0.6746\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6658\u001b[0m  0.0242\n",
      "     10        0.6762       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6600\u001b[0m  0.0186\n",
      "     11        \u001b[36m0.6577\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6550\u001b[0m  0.0219\n",
      "     12        0.6625       0.6094        \u001b[35m0.6509\u001b[0m  0.0179\n",
      "     13        \u001b[36m0.6380\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6467\u001b[0m  0.0222\n",
      "     14        0.6518       0.6328        \u001b[35m0.6436\u001b[0m  0.0206\n",
      "     15        \u001b[36m0.6353\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6403\u001b[0m  0.0157\n",
      "     16        \u001b[36m0.6279\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6370\u001b[0m  0.0228\n",
      "     17        \u001b[36m0.6170\u001b[0m       0.6484        \u001b[35m0.6339\u001b[0m  0.0257\n",
      "     18        0.6512       0.6562        \u001b[35m0.6309\u001b[0m  0.0152\n",
      "     19        0.6235       0.6641        \u001b[35m0.6279\u001b[0m  0.0258\n",
      "     20        0.6453       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6256\u001b[0m  0.0272\n",
      "     21        0.6282       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6229\u001b[0m  0.0341\n",
      "     22        0.6223       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6205\u001b[0m  0.0239\n",
      "     23        0.6267       0.7031        \u001b[35m0.6183\u001b[0m  0.0344\n",
      "     24        0.6257       0.6953        \u001b[35m0.6164\u001b[0m  0.0240\n",
      "     25        0.6186       0.6953        \u001b[35m0.6145\u001b[0m  0.0238\n",
      "     26        0.6239       0.6953        \u001b[35m0.6128\u001b[0m  0.0263\n",
      "     27        \u001b[36m0.6041\u001b[0m       0.6953        \u001b[35m0.6108\u001b[0m  0.0186\n",
      "     28        \u001b[36m0.6020\u001b[0m       0.7031        \u001b[35m0.6088\u001b[0m  0.0156\n",
      "     29        0.6189       0.7031        \u001b[35m0.6073\u001b[0m  0.0163\n",
      "     30        0.6253       0.7031        \u001b[35m0.6061\u001b[0m  0.0208\n",
      "     31        0.6089       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6045\u001b[0m  0.0178\n",
      "     32        0.6076       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6029\u001b[0m  0.0189\n",
      "     33        \u001b[36m0.5996\u001b[0m       0.7188        \u001b[35m0.6015\u001b[0m  0.0276\n",
      "     34        0.6019       0.7109        \u001b[35m0.6000\u001b[0m  0.0228\n",
      "     35        0.6112       0.7109        \u001b[35m0.5987\u001b[0m  0.0275\n",
      "     36        0.6129       0.7109        \u001b[35m0.5975\u001b[0m  0.0135\n",
      "     37        0.6196       0.7031        \u001b[35m0.5967\u001b[0m  0.0266\n",
      "     38        0.6017       0.7109        \u001b[35m0.5956\u001b[0m  0.0270\n",
      "     39        0.6090       0.7109        \u001b[35m0.5944\u001b[0m  0.0265\n",
      "     40        0.6159       0.7031        \u001b[35m0.5934\u001b[0m  0.0270\n",
      "     41        \u001b[36m0.5990\u001b[0m       0.7031        \u001b[35m0.5924\u001b[0m  0.0254\n",
      "     42        \u001b[36m0.5990\u001b[0m       0.7031        \u001b[35m0.5914\u001b[0m  0.0187\n",
      "     43        \u001b[36m0.5957\u001b[0m       0.7031        \u001b[35m0.5904\u001b[0m  0.0206\n",
      "     44        0.6024       0.7031        \u001b[35m0.5897\u001b[0m  0.0176\n",
      "     45        0.5993       0.7031        \u001b[35m0.5888\u001b[0m  0.0134\n",
      "     46        \u001b[36m0.5904\u001b[0m       0.7031        \u001b[35m0.5877\u001b[0m  0.0200\n",
      "     47        0.5937       0.7031        \u001b[35m0.5867\u001b[0m  0.0173\n",
      "     48        \u001b[36m0.5900\u001b[0m       0.7031        \u001b[35m0.5859\u001b[0m  0.0162\n",
      "     49        0.6099       0.7031        \u001b[35m0.5854\u001b[0m  0.0144\n",
      "     50        0.5918       0.7031        \u001b[35m0.5848\u001b[0m  0.0144\n",
      "     51        \u001b[36m0.5835\u001b[0m       0.7031        \u001b[35m0.5839\u001b[0m  0.0148\n",
      "     52        0.5871       0.7031        \u001b[35m0.5830\u001b[0m  0.0157\n",
      "     53        0.6041       0.7031        \u001b[35m0.5824\u001b[0m  0.0209\n",
      "     54        0.5906       0.7031        \u001b[35m0.5816\u001b[0m  0.1525\n",
      "     55        0.5952       0.7031        \u001b[35m0.5809\u001b[0m  0.0172\n",
      "     56        \u001b[36m0.5803\u001b[0m       0.7031        \u001b[35m0.5801\u001b[0m  0.0184\n",
      "     57        \u001b[36m0.5744\u001b[0m       0.7031        \u001b[35m0.5790\u001b[0m  0.0206\n",
      "     58        0.5888       0.7031        \u001b[35m0.5783\u001b[0m  0.0498\n",
      "     59        0.6040       0.7031        \u001b[35m0.5777\u001b[0m  0.0240\n",
      "     60        0.6135       0.7031        \u001b[35m0.5774\u001b[0m  0.0216\n",
      "     61        0.5945       0.7031        \u001b[35m0.5767\u001b[0m  0.0295\n",
      "     62        0.6048       0.7031        \u001b[35m0.5763\u001b[0m  0.0242\n",
      "     63        0.5940       0.7031        \u001b[35m0.5757\u001b[0m  0.0190\n",
      "     64        0.6038       0.7031        \u001b[35m0.5753\u001b[0m  0.0176\n",
      "     65        0.5933       0.7109        \u001b[35m0.5748\u001b[0m  0.0166\n",
      "     66        0.5915       0.7109        \u001b[35m0.5742\u001b[0m  0.0230\n",
      "     67        0.5908       0.7109        \u001b[35m0.5737\u001b[0m  0.0216\n",
      "     68        \u001b[36m0.5602\u001b[0m       0.7109        \u001b[35m0.5730\u001b[0m  0.0273\n",
      "     69        0.5845       0.7109        \u001b[35m0.5724\u001b[0m  0.0223\n",
      "     70        0.5919       0.7109        \u001b[35m0.5720\u001b[0m  0.0240\n",
      "     71        0.5995       0.7109        \u001b[35m0.5716\u001b[0m  0.0217\n",
      "     72        0.5855       0.7109        \u001b[35m0.5711\u001b[0m  0.0137\n",
      "     73        0.5838       0.7109        \u001b[35m0.5707\u001b[0m  0.0185\n",
      "     74        0.5704       0.7109        \u001b[35m0.5701\u001b[0m  0.0174\n",
      "     75        0.5819       0.7109        \u001b[35m0.5696\u001b[0m  0.0172\n",
      "     76        0.5750       0.7109        \u001b[35m0.5691\u001b[0m  0.0253\n",
      "     77        0.5905       0.7109        \u001b[35m0.5687\u001b[0m  0.0226\n",
      "     78        0.5899       0.7109        \u001b[35m0.5685\u001b[0m  0.0190\n",
      "     79        0.5833       0.7109        \u001b[35m0.5680\u001b[0m  0.0177\n",
      "     80        0.5793       0.7109        \u001b[35m0.5677\u001b[0m  0.0163\n",
      "     81        0.5862       0.7109        \u001b[35m0.5672\u001b[0m  0.0359\n",
      "     82        0.5610       0.7109        \u001b[35m0.5666\u001b[0m  0.0221\n",
      "     83        0.5810       0.7031        \u001b[35m0.5661\u001b[0m  0.0232\n",
      "     84        0.5725       0.7031        \u001b[35m0.5658\u001b[0m  0.0180\n",
      "     85        0.5834       0.7031        \u001b[35m0.5655\u001b[0m  0.0243\n",
      "     86        0.5774       0.7031        \u001b[35m0.5651\u001b[0m  0.0128\n",
      "     87        0.5738       0.7031        \u001b[35m0.5646\u001b[0m  0.0149\n",
      "     88        0.5840       0.7031        \u001b[35m0.5643\u001b[0m  0.0197\n",
      "     89        0.5817       0.7031        \u001b[35m0.5641\u001b[0m  0.0206\n",
      "     90        0.5694       0.7031        \u001b[35m0.5638\u001b[0m  0.0160\n",
      "     91        0.5982       0.7031        \u001b[35m0.5637\u001b[0m  0.0158\n",
      "     92        0.5911       0.7031        \u001b[35m0.5634\u001b[0m  0.0151\n",
      "     93        \u001b[36m0.5594\u001b[0m       0.7031        \u001b[35m0.5630\u001b[0m  0.0251\n",
      "     94        0.5923       0.7031        \u001b[35m0.5627\u001b[0m  0.0231\n",
      "     95        0.5784       0.7031        \u001b[35m0.5625\u001b[0m  0.0218\n",
      "     96        \u001b[36m0.5553\u001b[0m       0.7031        \u001b[35m0.5621\u001b[0m  0.0226\n",
      "     97        0.5680       0.7031        \u001b[35m0.5619\u001b[0m  0.0162\n",
      "     98        0.5709       0.7031        \u001b[35m0.5617\u001b[0m  0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     99        0.5574       0.7031        \u001b[35m0.5614\u001b[0m  0.0165\n",
      "    100        0.5643       0.7031        \u001b[35m0.5612\u001b[0m  0.0169\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6777\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6614\u001b[0m  0.0166\n",
      "      2        \u001b[36m0.6740\u001b[0m       0.6797        \u001b[35m0.6593\u001b[0m  0.0193\n",
      "      3        \u001b[36m0.6633\u001b[0m       0.6797        \u001b[35m0.6570\u001b[0m  0.0198\n",
      "      4        0.6774       0.6797        \u001b[35m0.6551\u001b[0m  0.0170\n",
      "      5        0.6664       0.6797        \u001b[35m0.6531\u001b[0m  0.0307\n",
      "      6        0.6653       0.6797        \u001b[35m0.6512\u001b[0m  0.0174\n",
      "      7        \u001b[36m0.6613\u001b[0m       0.6797        \u001b[35m0.6492\u001b[0m  0.0229\n",
      "      8        0.6701       0.6797        \u001b[35m0.6473\u001b[0m  0.0162\n",
      "      9        \u001b[36m0.6496\u001b[0m       0.6797        \u001b[35m0.6454\u001b[0m  0.0247\n",
      "     10        0.6532       0.6797        \u001b[35m0.6434\u001b[0m  0.0162\n",
      "     11        0.6672       0.6797        \u001b[35m0.6418\u001b[0m  0.0296\n",
      "     12        \u001b[36m0.6485\u001b[0m       0.6797        \u001b[35m0.6400\u001b[0m  0.0224\n",
      "     13        0.6501       0.6719        \u001b[35m0.6384\u001b[0m  0.0161\n",
      "     14        \u001b[36m0.6336\u001b[0m       0.6719        \u001b[35m0.6366\u001b[0m  0.0160\n",
      "     15        0.6499       0.6719        \u001b[35m0.6350\u001b[0m  0.0234\n",
      "     16        0.6485       0.6719        \u001b[35m0.6335\u001b[0m  0.0243\n",
      "     17        0.6534       0.6875        \u001b[35m0.6320\u001b[0m  0.0173\n",
      "     18        0.6338       0.6875        \u001b[35m0.6303\u001b[0m  0.0262\n",
      "     19        \u001b[36m0.6279\u001b[0m       0.6875        \u001b[35m0.6286\u001b[0m  0.0160\n",
      "     20        0.6288       0.6875        \u001b[35m0.6271\u001b[0m  0.0219\n",
      "     21        0.6394       0.6953        \u001b[35m0.6257\u001b[0m  0.0207\n",
      "     22        \u001b[36m0.6147\u001b[0m       0.6953        \u001b[35m0.6243\u001b[0m  0.0156\n",
      "     23        0.6180       0.6953        \u001b[35m0.6226\u001b[0m  0.0221\n",
      "     24        0.6274       0.6875        \u001b[35m0.6212\u001b[0m  0.0137\n",
      "     25        0.6157       0.6875        \u001b[35m0.6198\u001b[0m  0.0212\n",
      "     26        0.6279       0.6875        \u001b[35m0.6184\u001b[0m  0.0139\n",
      "     27        0.6157       0.6875        \u001b[35m0.6170\u001b[0m  0.0208\n",
      "     28        0.6271       0.6875        \u001b[35m0.6159\u001b[0m  0.0131\n",
      "     29        0.6301       0.6797        \u001b[35m0.6148\u001b[0m  0.0222\n",
      "     30        \u001b[36m0.6135\u001b[0m       0.6797        \u001b[35m0.6135\u001b[0m  0.0216\n",
      "     31        0.6230       0.6953        \u001b[35m0.6122\u001b[0m  0.0146\n",
      "     32        0.6338       0.6953        \u001b[35m0.6113\u001b[0m  0.0199\n",
      "     33        0.6153       0.6953        \u001b[35m0.6101\u001b[0m  0.0140\n",
      "     34        0.6160       0.6875        \u001b[35m0.6091\u001b[0m  0.0199\n",
      "     35        \u001b[36m0.6053\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6077\u001b[0m  0.0141\n",
      "     36        0.6155       0.6953        \u001b[35m0.6067\u001b[0m  0.0228\n",
      "     37        0.6197       0.6953        \u001b[35m0.6058\u001b[0m  0.0168\n",
      "     38        \u001b[36m0.6002\u001b[0m       0.6953        \u001b[35m0.6048\u001b[0m  0.0159\n",
      "     39        0.6141       0.6953        \u001b[35m0.6037\u001b[0m  0.0306\n",
      "     40        0.6097       0.6875        \u001b[35m0.6027\u001b[0m  0.0172\n",
      "     41        \u001b[36m0.5978\u001b[0m       0.6875        \u001b[35m0.6014\u001b[0m  0.0223\n",
      "     42        0.6180       0.6953        \u001b[35m0.6005\u001b[0m  0.0207\n",
      "     43        0.6148       0.6953        \u001b[35m0.5994\u001b[0m  0.0134\n",
      "     44        0.6059       0.7031        \u001b[35m0.5984\u001b[0m  0.0186\n",
      "     45        \u001b[36m0.5899\u001b[0m       0.7031        \u001b[35m0.5973\u001b[0m  0.0154\n",
      "     46        0.6041       0.7031        \u001b[35m0.5962\u001b[0m  0.0191\n",
      "     47        0.6019       0.7031        \u001b[35m0.5953\u001b[0m  0.0145\n",
      "     48        0.6046       0.7031        \u001b[35m0.5944\u001b[0m  0.0211\n",
      "     49        0.6045       0.6953        \u001b[35m0.5936\u001b[0m  0.0202\n",
      "     50        0.5937       0.6953        \u001b[35m0.5927\u001b[0m  0.0142\n",
      "     51        0.5964       0.6953        \u001b[35m0.5919\u001b[0m  0.0219\n",
      "     52        0.5973       0.6953        \u001b[35m0.5910\u001b[0m  0.0209\n",
      "     53        \u001b[36m0.5839\u001b[0m       0.6953        \u001b[35m0.5899\u001b[0m  0.0136\n",
      "     54        0.6072       0.7031        \u001b[35m0.5890\u001b[0m  0.0193\n",
      "     55        0.5852       0.7031        \u001b[35m0.5880\u001b[0m  0.0225\n",
      "     56        \u001b[36m0.5817\u001b[0m       0.7031        \u001b[35m0.5869\u001b[0m  0.0184\n",
      "     57        0.5878       0.7031        \u001b[35m0.5861\u001b[0m  0.0190\n",
      "     58        0.5989       0.7031        \u001b[35m0.5854\u001b[0m  0.0140\n",
      "     59        0.6005       0.6875        \u001b[35m0.5845\u001b[0m  0.0198\n",
      "     60        0.5906       0.6875        \u001b[35m0.5839\u001b[0m  0.0193\n",
      "     61        \u001b[36m0.5758\u001b[0m       0.6875        \u001b[35m0.5828\u001b[0m  0.0135\n",
      "     62        0.5834       0.6953        \u001b[35m0.5820\u001b[0m  0.0190\n",
      "     63        0.5878       0.6875        \u001b[35m0.5811\u001b[0m  0.0216\n",
      "     64        0.5846       0.6875        \u001b[35m0.5801\u001b[0m  0.0132\n",
      "     65        0.5868       0.6875        \u001b[35m0.5792\u001b[0m  0.0223\n",
      "     66        0.5917       0.6875        \u001b[35m0.5785\u001b[0m  0.0183\n",
      "     67        0.5798       0.6953        \u001b[35m0.5776\u001b[0m  0.0246\n",
      "     68        \u001b[36m0.5667\u001b[0m       0.6875        \u001b[35m0.5766\u001b[0m  0.0173\n",
      "     69        0.6021       0.6875        \u001b[35m0.5760\u001b[0m  0.0216\n",
      "     70        0.5832       0.6875        \u001b[35m0.5754\u001b[0m  0.0156\n",
      "     71        0.5816       0.6875        \u001b[35m0.5747\u001b[0m  0.0139\n",
      "     72        0.5982       0.6953        \u001b[35m0.5742\u001b[0m  0.0267\n",
      "     73        0.5748       0.6953        \u001b[35m0.5732\u001b[0m  0.0180\n",
      "     74        0.6065       0.7031        \u001b[35m0.5729\u001b[0m  0.0240\n",
      "     75        0.5704       0.7031        \u001b[35m0.5723\u001b[0m  0.0225\n",
      "     76        0.5888       0.7031        \u001b[35m0.5717\u001b[0m  0.0221\n",
      "     77        0.5904       0.7031        \u001b[35m0.5709\u001b[0m  0.0128\n",
      "     78        0.5828       0.7031        \u001b[35m0.5703\u001b[0m  0.0192\n",
      "     79        0.5805       0.7031        \u001b[35m0.5697\u001b[0m  0.0201\n",
      "     80        0.5861       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5690\u001b[0m  0.0147\n",
      "     81        0.5777       0.7109        \u001b[35m0.5684\u001b[0m  0.0130\n",
      "     82        0.5771       0.7109        \u001b[35m0.5678\u001b[0m  0.0196\n",
      "     83        0.5793       0.7109        \u001b[35m0.5672\u001b[0m  0.0154\n",
      "     84        0.5717       0.7109        \u001b[35m0.5663\u001b[0m  0.0137\n",
      "     85        \u001b[36m0.5663\u001b[0m       0.7109        \u001b[35m0.5657\u001b[0m  0.0194\n",
      "     86        0.5865       0.7109        \u001b[35m0.5652\u001b[0m  0.0221\n",
      "     87        \u001b[36m0.5641\u001b[0m       0.7109        \u001b[35m0.5646\u001b[0m  0.0219\n",
      "     88        0.5776       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5639\u001b[0m  0.0202\n",
      "     89        0.5775       0.7188        \u001b[35m0.5631\u001b[0m  0.0137\n",
      "     90        0.5687       0.7188        \u001b[35m0.5626\u001b[0m  0.0136\n",
      "     91        0.5842       0.7188        \u001b[35m0.5622\u001b[0m  0.0187\n",
      "     92        0.5831       0.7188        \u001b[35m0.5617\u001b[0m  0.0192\n",
      "     93        0.5713       0.7109        \u001b[35m0.5612\u001b[0m  0.0146\n",
      "     94        0.5713       0.7109        \u001b[35m0.5607\u001b[0m  0.0142\n",
      "     95        0.5665       0.7109        \u001b[35m0.5603\u001b[0m  0.0177\n",
      "     96        0.5672       0.7188        \u001b[35m0.5597\u001b[0m  0.0234\n",
      "     97        0.5903       0.7188        \u001b[35m0.5593\u001b[0m  0.0194\n",
      "     98        \u001b[36m0.5592\u001b[0m       0.7188        \u001b[35m0.5587\u001b[0m  0.0133\n",
      "     99        0.5810       0.7188        \u001b[35m0.5583\u001b[0m  0.0221\n",
      "    100        0.5730       0.7188        \u001b[35m0.5578\u001b[0m  0.0200\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6895\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6911\u001b[0m  0.0145\n",
      "      2        \u001b[36m0.6814\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6877\u001b[0m  0.0186\n",
      "      3        0.6892       0.5000        \u001b[35m0.6854\u001b[0m  0.0159\n",
      "      4        \u001b[36m0.6747\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6828\u001b[0m  0.0246\n",
      "      5        0.6872       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6805\u001b[0m  0.0224\n",
      "      6        \u001b[36m0.6689\u001b[0m       0.5547        \u001b[35m0.6780\u001b[0m  0.0208\n",
      "      7        0.6800       0.5547        \u001b[35m0.6757\u001b[0m  0.0218\n",
      "      8        0.6754       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6741\u001b[0m  0.0157\n",
      "      9        \u001b[36m0.6663\u001b[0m       0.5859        \u001b[35m0.6720\u001b[0m  0.0251\n",
      "     10        0.6699       0.5938        \u001b[35m0.6703\u001b[0m  0.0161\n",
      "     11        \u001b[36m0.6644\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6688\u001b[0m  0.0196\n",
      "     12        \u001b[36m0.6614\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6672\u001b[0m  0.0165\n",
      "     13        0.6689       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6658\u001b[0m  0.0161\n",
      "     14        \u001b[36m0.6594\u001b[0m       0.6562        \u001b[35m0.6644\u001b[0m  0.0246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15        0.6600       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6629\u001b[0m  0.0191\n",
      "     16        \u001b[36m0.6594\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6615\u001b[0m  0.0161\n",
      "     17        \u001b[36m0.6587\u001b[0m       0.6719        \u001b[35m0.6602\u001b[0m  0.0208\n",
      "     18        \u001b[36m0.6581\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6589\u001b[0m  0.0250\n",
      "     19        0.6631       0.6953        \u001b[35m0.6576\u001b[0m  0.0178\n",
      "     20        \u001b[36m0.6531\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6560\u001b[0m  0.0157\n",
      "     21        \u001b[36m0.6478\u001b[0m       0.7031        \u001b[35m0.6544\u001b[0m  0.0279\n",
      "     22        0.6524       0.7031        \u001b[35m0.6530\u001b[0m  0.0196\n",
      "     23        \u001b[36m0.6470\u001b[0m       0.7031        \u001b[35m0.6517\u001b[0m  0.0233\n",
      "     24        0.6474       0.7031        \u001b[35m0.6501\u001b[0m  0.0185\n",
      "     25        0.6522       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6489\u001b[0m  0.0145\n",
      "     26        0.6495       0.7109        \u001b[35m0.6478\u001b[0m  0.0211\n",
      "     27        0.6499       0.7109        \u001b[35m0.6465\u001b[0m  0.0173\n",
      "     28        0.6528       0.7109        \u001b[35m0.6454\u001b[0m  0.0164\n",
      "     29        \u001b[36m0.6460\u001b[0m       0.7109        \u001b[35m0.6440\u001b[0m  0.0290\n",
      "     30        0.6503       0.7109        \u001b[35m0.6428\u001b[0m  0.0139\n",
      "     31        0.6470       0.7109        \u001b[35m0.6416\u001b[0m  0.0247\n",
      "     32        \u001b[36m0.6386\u001b[0m       0.7109        \u001b[35m0.6400\u001b[0m  0.0240\n",
      "     33        \u001b[36m0.6291\u001b[0m       0.7109        \u001b[35m0.6385\u001b[0m  0.0182\n",
      "     34        0.6375       0.7109        \u001b[35m0.6372\u001b[0m  0.0182\n",
      "     35        0.6323       0.7109        \u001b[35m0.6357\u001b[0m  0.0155\n",
      "     36        0.6339       0.7109        \u001b[35m0.6341\u001b[0m  0.0330\n",
      "     37        0.6329       0.7109        \u001b[35m0.6326\u001b[0m  0.0175\n",
      "     38        \u001b[36m0.6281\u001b[0m       0.7109        \u001b[35m0.6313\u001b[0m  0.0218\n",
      "     39        0.6347       0.7109        \u001b[35m0.6299\u001b[0m  0.0140\n",
      "     40        \u001b[36m0.6218\u001b[0m       0.7109        \u001b[35m0.6281\u001b[0m  0.0206\n",
      "     41        0.6249       0.7109        \u001b[35m0.6267\u001b[0m  0.0260\n",
      "     42        0.6356       0.7109        \u001b[35m0.6255\u001b[0m  0.0164\n",
      "     43        0.6504       0.7109        \u001b[35m0.6246\u001b[0m  0.0221\n",
      "     44        \u001b[36m0.6174\u001b[0m       0.7109        \u001b[35m0.6230\u001b[0m  0.0143\n",
      "     45        0.6238       0.7109        \u001b[35m0.6217\u001b[0m  0.0221\n",
      "     46        0.6281       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6205\u001b[0m  0.0195\n",
      "     47        \u001b[36m0.6067\u001b[0m       0.7188        \u001b[35m0.6187\u001b[0m  0.0137\n",
      "     48        0.6270       0.7188        \u001b[35m0.6175\u001b[0m  0.0197\n",
      "     49        0.6132       0.7188        \u001b[35m0.6159\u001b[0m  0.0146\n",
      "     50        0.6190       0.7188        \u001b[35m0.6145\u001b[0m  0.0184\n",
      "     51        0.6280       0.7188        \u001b[35m0.6133\u001b[0m  0.0155\n",
      "     52        0.6231       0.7188        \u001b[35m0.6122\u001b[0m  0.0150\n",
      "     53        0.6221       0.7188        \u001b[35m0.6111\u001b[0m  0.0199\n",
      "     54        0.6074       0.7188        \u001b[35m0.6096\u001b[0m  0.0146\n",
      "     55        \u001b[36m0.6050\u001b[0m       0.7109        \u001b[35m0.6080\u001b[0m  0.0219\n",
      "     56        0.6264       0.7109        \u001b[35m0.6069\u001b[0m  0.0139\n",
      "     57        0.6105       0.7109        \u001b[35m0.6056\u001b[0m  0.0202\n",
      "     58        0.6128       0.7188        \u001b[35m0.6044\u001b[0m  0.0250\n",
      "     59        0.6126       0.7188        \u001b[35m0.6032\u001b[0m  0.0158\n",
      "     60        0.6228       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6023\u001b[0m  0.0240\n",
      "     61        \u001b[36m0.6045\u001b[0m       0.7266        \u001b[35m0.6010\u001b[0m  0.0165\n",
      "     62        \u001b[36m0.6037\u001b[0m       0.7266        \u001b[35m0.5998\u001b[0m  0.0233\n",
      "     63        \u001b[36m0.5998\u001b[0m       0.7266        \u001b[35m0.5984\u001b[0m  0.0204\n",
      "     64        0.6113       0.7266        \u001b[35m0.5976\u001b[0m  0.0128\n",
      "     65        0.6136       0.7266        \u001b[35m0.5965\u001b[0m  0.0168\n",
      "     66        0.6131       0.7266        \u001b[35m0.5953\u001b[0m  0.0151\n",
      "     67        0.6147       0.7266        \u001b[35m0.5945\u001b[0m  0.0157\n",
      "     68        0.6128       0.7266        \u001b[35m0.5935\u001b[0m  0.0219\n",
      "     69        0.6137       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5926\u001b[0m  0.0157\n",
      "     70        \u001b[36m0.5870\u001b[0m       0.7344        \u001b[35m0.5913\u001b[0m  0.0203\n",
      "     71        0.6055       0.7344        \u001b[35m0.5902\u001b[0m  0.0153\n",
      "     72        0.6036       0.7344        \u001b[35m0.5891\u001b[0m  0.0170\n",
      "     73        0.5990       0.7344        \u001b[35m0.5880\u001b[0m  0.0207\n",
      "     74        0.5967       0.7344        \u001b[35m0.5869\u001b[0m  0.0154\n",
      "     75        0.5873       0.7344        \u001b[35m0.5858\u001b[0m  0.0175\n",
      "     76        0.5915       0.7344        \u001b[35m0.5846\u001b[0m  0.0149\n",
      "     77        0.6009       0.7344        \u001b[35m0.5836\u001b[0m  0.0167\n",
      "     78        0.5969       0.7344        \u001b[35m0.5828\u001b[0m  0.0227\n",
      "     79        0.5935       0.7344        \u001b[35m0.5818\u001b[0m  0.0126\n",
      "     80        0.5975       0.7344        \u001b[35m0.5810\u001b[0m  0.0182\n",
      "     81        \u001b[36m0.5855\u001b[0m       0.7344        \u001b[35m0.5799\u001b[0m  0.0158\n",
      "     82        0.5989       0.7344        \u001b[35m0.5792\u001b[0m  0.0157\n",
      "     83        0.5989       0.7344        \u001b[35m0.5782\u001b[0m  0.0176\n",
      "     84        0.5883       0.7344        \u001b[35m0.5771\u001b[0m  0.0197\n",
      "     85        0.5992       0.7344        \u001b[35m0.5762\u001b[0m  0.0148\n",
      "     86        0.5893       0.7344        \u001b[35m0.5753\u001b[0m  0.0181\n",
      "     87        0.5911       0.7344        \u001b[35m0.5744\u001b[0m  0.0181\n",
      "     88        \u001b[36m0.5848\u001b[0m       0.7344        \u001b[35m0.5735\u001b[0m  0.0156\n",
      "     89        0.5897       0.7266        \u001b[35m0.5727\u001b[0m  0.0152\n",
      "     90        0.5932       0.7266        \u001b[35m0.5720\u001b[0m  0.0147\n",
      "     91        \u001b[36m0.5767\u001b[0m       0.7266        \u001b[35m0.5711\u001b[0m  0.0158\n",
      "     92        0.5873       0.7266        \u001b[35m0.5702\u001b[0m  0.0149\n",
      "     93        0.5927       0.7266        \u001b[35m0.5695\u001b[0m  0.0148\n",
      "     94        0.5858       0.7266        \u001b[35m0.5686\u001b[0m  0.0177\n",
      "     95        0.5854       0.7266        \u001b[35m0.5679\u001b[0m  0.0169\n",
      "     96        0.5885       0.7266        \u001b[35m0.5672\u001b[0m  0.0166\n",
      "     97        0.5806       0.7266        \u001b[35m0.5664\u001b[0m  0.0147\n",
      "     98        0.5973       0.7266        \u001b[35m0.5657\u001b[0m  0.0208\n",
      "     99        0.5883       0.7266        \u001b[35m0.5653\u001b[0m  0.0176\n",
      "    100        \u001b[36m0.5668\u001b[0m       0.7266        \u001b[35m0.5644\u001b[0m  0.0144\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6958\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6888\u001b[0m  0.0120\n",
      "      2        \u001b[36m0.6887\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6748\u001b[0m  0.0157\n",
      "      3        \u001b[36m0.6742\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6575\u001b[0m  0.0153\n",
      "      4        \u001b[36m0.6610\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6400\u001b[0m  0.0140\n",
      "      5        \u001b[36m0.6431\u001b[0m       0.7109        \u001b[35m0.6186\u001b[0m  0.0176\n",
      "      6        \u001b[36m0.6224\u001b[0m       0.7109        \u001b[35m0.5966\u001b[0m  0.0150\n",
      "      7        \u001b[36m0.6178\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5802\u001b[0m  0.0188\n",
      "      8        \u001b[36m0.5857\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5621\u001b[0m  0.0167\n",
      "      9        0.5967       0.7344        \u001b[35m0.5492\u001b[0m  0.0167\n",
      "     10        0.5902       0.7266        \u001b[35m0.5378\u001b[0m  0.0147\n",
      "     11        \u001b[36m0.5688\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5256\u001b[0m  0.0154\n",
      "     12        \u001b[36m0.5666\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5181\u001b[0m  0.0160\n",
      "     13        \u001b[36m0.5601\u001b[0m       0.7656        \u001b[35m0.5099\u001b[0m  0.0173\n",
      "     14        \u001b[36m0.5601\u001b[0m       0.7656        \u001b[35m0.5021\u001b[0m  0.0143\n",
      "     15        \u001b[36m0.5505\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4949\u001b[0m  0.0180\n",
      "     16        0.5547       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4899\u001b[0m  0.0136\n",
      "     17        0.5543       0.7812        \u001b[35m0.4846\u001b[0m  0.0142\n",
      "     18        \u001b[36m0.5485\u001b[0m       0.7812        \u001b[35m0.4810\u001b[0m  0.0137\n",
      "     19        \u001b[36m0.5452\u001b[0m       0.7734        \u001b[35m0.4748\u001b[0m  0.0173\n",
      "     20        \u001b[36m0.5389\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4701\u001b[0m  0.0174\n",
      "     21        \u001b[36m0.5367\u001b[0m       0.7812        \u001b[35m0.4657\u001b[0m  0.0132\n",
      "     22        \u001b[36m0.5350\u001b[0m       0.7891        \u001b[35m0.4620\u001b[0m  0.0151\n",
      "     23        \u001b[36m0.5274\u001b[0m       0.7891        \u001b[35m0.4589\u001b[0m  0.0139\n",
      "     24        0.5614       0.7891        \u001b[35m0.4584\u001b[0m  0.0181\n",
      "     25        0.5469       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4583\u001b[0m  0.0132\n",
      "     26        0.5416       0.8047        \u001b[35m0.4567\u001b[0m  0.0135\n",
      "     27        \u001b[36m0.5229\u001b[0m       0.8047        \u001b[35m0.4540\u001b[0m  0.0136\n",
      "     28        0.5454       0.8047        \u001b[35m0.4530\u001b[0m  0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     29        0.5306       0.8047        \u001b[35m0.4490\u001b[0m  0.0138\n",
      "     30        \u001b[36m0.5226\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4488\u001b[0m  0.0192\n",
      "     31        0.5396       0.8125        \u001b[35m0.4467\u001b[0m  0.0132\n",
      "     32        0.5275       0.8125        \u001b[35m0.4454\u001b[0m  0.0137\n",
      "     33        0.5325       0.8125        \u001b[35m0.4445\u001b[0m  0.0137\n",
      "     34        0.5268       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4440\u001b[0m  0.0187\n",
      "     35        0.5361       0.8125        0.4449  0.0261\n",
      "     36        \u001b[36m0.5068\u001b[0m       0.8203        \u001b[35m0.4394\u001b[0m  0.0155\n",
      "     37        0.5200       0.8203        \u001b[35m0.4383\u001b[0m  0.0195\n",
      "     38        0.5284       0.8125        0.4397  0.0134\n",
      "     39        0.5391       0.8203        0.4392  0.0171\n",
      "     40        0.5349       0.8203        \u001b[35m0.4370\u001b[0m  0.0185\n",
      "     41        0.5247       0.8203        \u001b[35m0.4350\u001b[0m  0.0132\n",
      "     42        0.5207       0.8203        \u001b[35m0.4349\u001b[0m  0.0179\n",
      "     43        0.5197       0.8203        \u001b[35m0.4344\u001b[0m  0.0167\n",
      "     44        0.5355       0.8203        0.4350  0.0189\n",
      "     45        0.5141       0.8125        0.4349  0.0177\n",
      "     46        0.5254       0.8203        \u001b[35m0.4339\u001b[0m  0.0151\n",
      "     47        0.5348       0.8203        0.4353  0.0189\n",
      "     48        0.5120       0.8203        \u001b[35m0.4333\u001b[0m  0.0220\n",
      "     49        0.5259       0.8203        \u001b[35m0.4321\u001b[0m  0.0169\n",
      "     50        0.5180       0.8203        0.4322  0.0163\n",
      "     51        0.5328       0.8203        0.4323  0.0191\n",
      "     52        0.5219       0.8125        \u001b[35m0.4318\u001b[0m  0.0146\n",
      "     53        0.5128       0.8203        \u001b[35m0.4304\u001b[0m  0.0176\n",
      "     54        \u001b[36m0.5034\u001b[0m       0.8203        \u001b[35m0.4287\u001b[0m  0.0147\n",
      "     55        0.5283       0.8203        \u001b[35m0.4273\u001b[0m  0.0173\n",
      "     56        0.5314       0.8203        \u001b[35m0.4263\u001b[0m  0.0144\n",
      "     57        0.5358       0.8203        0.4270  0.0183\n",
      "     58        0.5128       0.8203        0.4265  0.0151\n",
      "     59        0.5068       0.8203        \u001b[35m0.4251\u001b[0m  0.0191\n",
      "     60        0.5125       0.8203        \u001b[35m0.4243\u001b[0m  0.0184\n",
      "     61        0.5093       0.8203        \u001b[35m0.4230\u001b[0m  0.0140\n",
      "     62        0.5196       0.8203        \u001b[35m0.4214\u001b[0m  0.0150\n",
      "     63        0.5149       0.8203        0.4217  0.0166\n",
      "     64        0.5061       0.8203        \u001b[35m0.4205\u001b[0m  0.0142\n",
      "     65        0.5182       0.8203        0.4205  0.0182\n",
      "     66        0.5190       0.8203        0.4209  0.0174\n",
      "     67        0.5089       0.8203        \u001b[35m0.4179\u001b[0m  0.0176\n",
      "     68        \u001b[36m0.4990\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m0.4168\u001b[0m  0.0125\n",
      "     69        0.5040       0.8203        \u001b[35m0.4151\u001b[0m  0.0177\n",
      "     70        0.5129       0.8203        \u001b[35m0.4141\u001b[0m  0.0138\n",
      "     71        \u001b[36m0.4936\u001b[0m       0.8203        \u001b[35m0.4128\u001b[0m  0.0187\n",
      "     72        0.4962       0.8203        \u001b[35m0.4107\u001b[0m  0.0144\n",
      "     73        0.5041       0.8203        \u001b[35m0.4086\u001b[0m  0.0194\n",
      "     74        0.5088       0.8203        0.4090  0.0202\n",
      "     75        0.5021       0.8203        0.4099  0.0152\n",
      "     76        0.5131       0.8203        \u001b[35m0.4084\u001b[0m  0.0186\n",
      "     77        0.5130       0.8203        0.4087  0.0141\n",
      "     78        0.5021       0.8203        \u001b[35m0.4080\u001b[0m  0.0198\n",
      "     79        0.5069       0.8203        \u001b[35m0.4079\u001b[0m  0.0160\n",
      "     80        0.5119       0.8203        0.4088  0.0146\n",
      "     81        \u001b[36m0.4915\u001b[0m       0.8203        0.4079  0.0163\n",
      "     82        0.4995       0.8281        \u001b[35m0.4065\u001b[0m  0.0152\n",
      "     83        \u001b[36m0.4915\u001b[0m       0.8281        0.4075  0.0179\n",
      "     84        0.5055       0.8281        0.4074  0.0136\n",
      "     85        \u001b[36m0.4888\u001b[0m       0.8281        \u001b[35m0.4056\u001b[0m  0.0167\n",
      "     86        0.4997       0.8281        \u001b[35m0.4047\u001b[0m  0.0153\n",
      "     87        \u001b[36m0.4881\u001b[0m       0.8281        \u001b[35m0.4041\u001b[0m  0.0135\n",
      "     88        0.5052       0.8281        0.4045  0.0192\n",
      "     89        \u001b[36m0.4847\u001b[0m       \u001b[32m0.8359\u001b[0m        \u001b[35m0.4026\u001b[0m  0.0129\n",
      "     90        0.4948       0.8281        0.4036  0.0165\n",
      "     91        0.4982       0.8281        0.4036  0.0140\n",
      "     92        0.4946       0.8281        \u001b[35m0.4024\u001b[0m  0.0139\n",
      "     93        0.5004       0.8281        0.4027  0.0183\n",
      "     94        0.5003       0.8203        0.4056  0.0139\n",
      "     95        0.5058       0.8281        0.4052  0.0165\n",
      "     96        0.5046       0.8281        0.4053  0.0148\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6857\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6837\u001b[0m  0.0137\n",
      "      2        \u001b[36m0.6709\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6704\u001b[0m  0.0138\n",
      "      3        \u001b[36m0.6506\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6512\u001b[0m  0.0135\n",
      "      4        \u001b[36m0.6350\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6293\u001b[0m  0.0146\n",
      "      5        \u001b[36m0.6133\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6072\u001b[0m  0.0215\n",
      "      6        \u001b[36m0.5927\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5898\u001b[0m  0.0157\n",
      "      7        \u001b[36m0.5745\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5751\u001b[0m  0.0213\n",
      "      8        \u001b[36m0.5571\u001b[0m       0.7031        \u001b[35m0.5645\u001b[0m  0.0188\n",
      "      9        \u001b[36m0.5523\u001b[0m       0.7031        \u001b[35m0.5582\u001b[0m  0.0156\n",
      "     10        \u001b[36m0.5435\u001b[0m       0.7031        \u001b[35m0.5538\u001b[0m  0.0150\n",
      "     11        0.5491       0.7031        \u001b[35m0.5495\u001b[0m  0.0203\n",
      "     12        0.5509       0.7031        \u001b[35m0.5475\u001b[0m  0.0159\n",
      "     13        \u001b[36m0.5313\u001b[0m       0.6875        \u001b[35m0.5469\u001b[0m  0.0150\n",
      "     14        0.5316       0.6719        \u001b[35m0.5465\u001b[0m  0.0209\n",
      "     15        0.5623       0.6953        \u001b[35m0.5452\u001b[0m  0.0208\n",
      "     16        \u001b[36m0.5245\u001b[0m       0.6875        0.5456  0.0170\n",
      "     17        0.5271       0.6797        \u001b[35m0.5448\u001b[0m  0.0154\n",
      "     18        0.5260       0.6797        0.5450  0.0172\n",
      "     19        \u001b[36m0.5160\u001b[0m       0.7031        \u001b[35m0.5436\u001b[0m  0.0152\n",
      "     20        0.5283       0.6797        0.5442  0.0142\n",
      "     21        \u001b[36m0.5146\u001b[0m       0.6797        0.5440  0.0188\n",
      "     22        \u001b[36m0.5084\u001b[0m       0.6719        0.5440  0.0152\n",
      "     23        0.5532       0.6875        \u001b[35m0.5428\u001b[0m  0.0132\n",
      "     24        0.5220       0.6875        0.5434  0.0178\n",
      "     25        0.5259       0.6953        \u001b[35m0.5413\u001b[0m  0.0142\n",
      "     26        0.5146       0.6875        0.5423  0.0143\n",
      "     27        0.5202       0.6953        \u001b[35m0.5407\u001b[0m  0.0231\n",
      "     28        0.5134       0.6953        0.5411  0.0151\n",
      "     29        0.5126       0.6953        0.5414  0.0174\n",
      "     30        \u001b[36m0.5055\u001b[0m       0.6953        0.5426  0.0153\n",
      "     31        0.5121       0.6719        0.5434  0.0136\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6309\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6125\u001b[0m  0.0164\n",
      "      2        \u001b[36m0.5977\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5899\u001b[0m  0.0151\n",
      "      3        \u001b[36m0.5850\u001b[0m       0.7266        \u001b[35m0.5740\u001b[0m  0.0172\n",
      "      4        \u001b[36m0.5716\u001b[0m       0.7188        \u001b[35m0.5644\u001b[0m  0.0150\n",
      "      5        \u001b[36m0.5666\u001b[0m       0.7031        \u001b[35m0.5568\u001b[0m  0.0177\n",
      "      6        \u001b[36m0.5486\u001b[0m       0.7031        \u001b[35m0.5505\u001b[0m  0.0155\n",
      "      7        \u001b[36m0.5461\u001b[0m       0.7031        \u001b[35m0.5463\u001b[0m  0.0143\n",
      "      8        0.5498       0.7031        \u001b[35m0.5438\u001b[0m  0.0180\n",
      "      9        \u001b[36m0.5214\u001b[0m       0.7031        \u001b[35m0.5412\u001b[0m  0.0141\n",
      "     10        0.5382       0.7188        \u001b[35m0.5395\u001b[0m  0.0172\n",
      "     11        0.5385       0.7188        \u001b[35m0.5386\u001b[0m  0.0152\n",
      "     12        \u001b[36m0.5151\u001b[0m       0.7188        \u001b[35m0.5377\u001b[0m  0.0129\n",
      "     13        0.5395       0.7188        \u001b[35m0.5360\u001b[0m  0.0152\n",
      "     14        \u001b[36m0.5150\u001b[0m       0.7188        0.5370  0.0160\n",
      "     15        0.5308       0.7109        0.5364  0.0151\n",
      "     16        0.5169       0.7031        0.5371  0.0171\n",
      "     17        0.5357       0.7031        0.5367  0.0137\n",
      "     18        0.5230       0.7031        \u001b[35m0.5351\u001b[0m  0.0140\n",
      "     19        0.5239       0.7031        \u001b[35m0.5346\u001b[0m  0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     20        0.5245       0.6953        0.5355  0.0139\n",
      "     21        0.5314       0.7031        \u001b[35m0.5344\u001b[0m  0.0161\n",
      "     22        0.5162       0.7031        0.5346  0.0174\n",
      "     23        0.5276       0.7031        0.5345  0.0156\n",
      "     24        \u001b[36m0.5046\u001b[0m       0.7031        0.5354  0.0170\n",
      "     25        0.5108       0.7031        0.5352  0.0211\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7406\u001b[0m       \u001b[32m0.4219\u001b[0m        \u001b[35m0.7219\u001b[0m  0.0139\n",
      "      2        \u001b[36m0.7084\u001b[0m       \u001b[32m0.4453\u001b[0m        \u001b[35m0.7043\u001b[0m  0.0198\n",
      "      3        \u001b[36m0.6983\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6940\u001b[0m  0.0181\n",
      "      4        \u001b[36m0.6888\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6853\u001b[0m  0.0162\n",
      "      5        \u001b[36m0.6820\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6762\u001b[0m  0.0248\n",
      "      6        \u001b[36m0.6698\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6641\u001b[0m  0.0204\n",
      "      7        \u001b[36m0.6544\u001b[0m       0.6641        \u001b[35m0.6492\u001b[0m  0.0150\n",
      "      8        \u001b[36m0.6383\u001b[0m       0.6797        \u001b[35m0.6345\u001b[0m  0.0193\n",
      "      9        \u001b[36m0.6162\u001b[0m       0.6875        \u001b[35m0.6206\u001b[0m  0.0196\n",
      "     10        \u001b[36m0.5968\u001b[0m       0.6875        \u001b[35m0.6097\u001b[0m  0.0151\n",
      "     11        \u001b[36m0.5866\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6033\u001b[0m  0.0182\n",
      "     12        \u001b[36m0.5556\u001b[0m       0.6953        \u001b[35m0.5986\u001b[0m  0.0152\n",
      "     13        0.5639       0.6953        \u001b[35m0.5971\u001b[0m  0.0180\n",
      "     14        0.5946       0.6875        \u001b[35m0.5964\u001b[0m  0.0142\n",
      "     15        0.5728       0.6797        \u001b[35m0.5951\u001b[0m  0.0237\n",
      "     16        0.5662       0.6875        \u001b[35m0.5937\u001b[0m  0.0186\n",
      "     17        \u001b[36m0.5546\u001b[0m       0.6797        \u001b[35m0.5894\u001b[0m  0.0153\n",
      "     18        \u001b[36m0.5544\u001b[0m       0.6875        \u001b[35m0.5875\u001b[0m  0.0211\n",
      "     19        \u001b[36m0.5517\u001b[0m       0.6875        \u001b[35m0.5848\u001b[0m  0.0144\n",
      "     20        \u001b[36m0.5502\u001b[0m       0.6875        \u001b[35m0.5821\u001b[0m  0.0247\n",
      "     21        \u001b[36m0.5250\u001b[0m       0.6953        \u001b[35m0.5814\u001b[0m  0.0138\n",
      "     22        0.5477       0.6875        \u001b[35m0.5798\u001b[0m  0.0192\n",
      "     23        \u001b[36m0.5211\u001b[0m       0.6953        \u001b[35m0.5790\u001b[0m  0.0147\n",
      "     24        \u001b[36m0.5191\u001b[0m       0.6953        \u001b[35m0.5777\u001b[0m  0.0232\n",
      "     25        \u001b[36m0.5154\u001b[0m       0.6875        \u001b[35m0.5771\u001b[0m  0.0174\n",
      "     26        \u001b[36m0.5104\u001b[0m       0.6797        0.5777  0.0147\n",
      "     27        0.5236       0.6797        \u001b[35m0.5768\u001b[0m  0.0178\n",
      "     28        0.5241       0.6875        \u001b[35m0.5756\u001b[0m  0.0147\n",
      "     29        0.5133       0.6797        \u001b[35m0.5726\u001b[0m  0.0184\n",
      "     30        \u001b[36m0.5104\u001b[0m       0.6797        \u001b[35m0.5723\u001b[0m  0.0163\n",
      "     31        0.5106       0.6875        \u001b[35m0.5718\u001b[0m  0.0289\n",
      "     32        0.5205       0.6875        \u001b[35m0.5718\u001b[0m  0.0318\n",
      "     33        0.5147       0.6875        \u001b[35m0.5699\u001b[0m  0.0145\n",
      "     34        \u001b[36m0.5007\u001b[0m       0.6797        \u001b[35m0.5689\u001b[0m  0.0181\n",
      "     35        0.5199       0.6875        \u001b[35m0.5659\u001b[0m  0.0146\n",
      "     36        0.5241       0.6875        \u001b[35m0.5635\u001b[0m  0.0192\n",
      "     37        \u001b[36m0.4994\u001b[0m       0.6797        \u001b[35m0.5627\u001b[0m  0.0150\n",
      "     38        0.5084       0.6797        \u001b[35m0.5613\u001b[0m  0.0178\n",
      "     39        0.5075       0.6797        \u001b[35m0.5598\u001b[0m  0.0219\n",
      "     40        0.5177       0.6797        \u001b[35m0.5578\u001b[0m  0.0153\n",
      "     41        0.4999       0.6797        \u001b[35m0.5565\u001b[0m  0.0201\n",
      "     42        0.5036       0.6797        \u001b[35m0.5532\u001b[0m  0.0152\n",
      "     43        0.5021       0.6797        \u001b[35m0.5502\u001b[0m  0.0189\n",
      "     44        0.5104       0.6797        \u001b[35m0.5485\u001b[0m  0.0156\n",
      "     45        \u001b[36m0.4986\u001b[0m       0.6797        \u001b[35m0.5481\u001b[0m  0.0152\n",
      "     46        \u001b[36m0.4972\u001b[0m       0.6875        \u001b[35m0.5465\u001b[0m  0.0139\n",
      "     47        0.4978       0.6875        \u001b[35m0.5442\u001b[0m  0.0201\n",
      "     48        0.5036       0.6797        \u001b[35m0.5431\u001b[0m  0.0146\n",
      "     49        \u001b[36m0.4900\u001b[0m       0.6875        \u001b[35m0.5421\u001b[0m  0.0212\n",
      "     50        0.4960       0.6875        \u001b[35m0.5409\u001b[0m  0.0150\n",
      "     51        0.5026       0.6875        \u001b[35m0.5397\u001b[0m  0.0260\n",
      "     52        0.5183       0.6875        \u001b[35m0.5381\u001b[0m  0.0220\n",
      "     53        0.5058       0.6797        0.5384  0.0157\n",
      "     54        0.5178       0.6797        0.5400  0.0171\n",
      "     55        0.5049       0.6797        0.5386  0.0144\n",
      "     56        0.5146       0.6797        0.5384  0.0161\n",
      "     57        0.5172       0.6719        \u001b[35m0.5376\u001b[0m  0.0149\n",
      "     58        0.4958       0.6719        0.5383  0.0170\n",
      "     59        0.5039       0.6797        0.5391  0.0154\n",
      "     60        0.5053       0.6719        0.5393  0.0218\n",
      "     61        0.5085       0.6719        0.5406  0.0154\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7252\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m0.7140\u001b[0m  0.0122\n",
      "      2        \u001b[36m0.7052\u001b[0m       0.4453        \u001b[35m0.6990\u001b[0m  0.0134\n",
      "      3        \u001b[36m0.6921\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6864\u001b[0m  0.0136\n",
      "      4        \u001b[36m0.6732\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6710\u001b[0m  0.0151\n",
      "      5        \u001b[36m0.6533\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6485\u001b[0m  0.0192\n",
      "      6        \u001b[36m0.6288\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6241\u001b[0m  0.0133\n",
      "      7        \u001b[36m0.6011\u001b[0m       0.7031        \u001b[35m0.6000\u001b[0m  0.0247\n",
      "      8        \u001b[36m0.5815\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5812\u001b[0m  0.0152\n",
      "      9        \u001b[36m0.5698\u001b[0m       0.7109        \u001b[35m0.5673\u001b[0m  0.0188\n",
      "     10        \u001b[36m0.5394\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5549\u001b[0m  0.0191\n",
      "     11        0.5415       0.7266        \u001b[35m0.5468\u001b[0m  0.0167\n",
      "     12        \u001b[36m0.5019\u001b[0m       0.7266        \u001b[35m0.5399\u001b[0m  0.0138\n",
      "     13        0.5205       0.7188        \u001b[35m0.5350\u001b[0m  0.0150\n",
      "     14        0.5300       0.7188        \u001b[35m0.5310\u001b[0m  0.0202\n",
      "     15        0.5160       0.7266        \u001b[35m0.5279\u001b[0m  0.0144\n",
      "     16        0.5123       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5257\u001b[0m  0.0160\n",
      "     17        0.5067       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5239\u001b[0m  0.0151\n",
      "     18        0.5086       0.7344        \u001b[35m0.5237\u001b[0m  0.0198\n",
      "     19        0.5092       0.7344        \u001b[35m0.5227\u001b[0m  0.0138\n",
      "     20        \u001b[36m0.4929\u001b[0m       0.7266        \u001b[35m0.5216\u001b[0m  0.0167\n",
      "     21        0.4963       0.7188        \u001b[35m0.5210\u001b[0m  0.0149\n",
      "     22        0.5046       0.7188        \u001b[35m0.5203\u001b[0m  0.0213\n",
      "     23        \u001b[36m0.4724\u001b[0m       0.7188        0.5217  0.0143\n",
      "     24        0.4833       0.7266        \u001b[35m0.5200\u001b[0m  0.0184\n",
      "     25        \u001b[36m0.4607\u001b[0m       0.7188        \u001b[35m0.5199\u001b[0m  0.0154\n",
      "     26        0.4776       0.7266        0.5200  0.0153\n",
      "     27        0.5001       0.7266        \u001b[35m0.5187\u001b[0m  0.0222\n",
      "     28        0.4835       0.7188        \u001b[35m0.5180\u001b[0m  0.0165\n",
      "     29        0.4992       0.7266        \u001b[35m0.5161\u001b[0m  0.0171\n",
      "     30        0.5001       0.7344        0.5163  0.0153\n",
      "     31        0.4842       0.7422        0.5170  0.0207\n",
      "     32        0.4912       0.7266        0.5191  0.0153\n",
      "     33        0.4770       0.7422        \u001b[35m0.5157\u001b[0m  0.0173\n",
      "     34        0.5052       0.7422        0.5166  0.0146\n",
      "     35        0.4789       0.7422        0.5177  0.0155\n",
      "     36        0.5049       0.7422        0.5184  0.0227\n",
      "     37        0.4825       0.7422        0.5191  0.0163\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7567\u001b[0m       \u001b[32m0.3359\u001b[0m        \u001b[35m0.7488\u001b[0m  0.0151\n",
      "      2        \u001b[36m0.7265\u001b[0m       0.3359        \u001b[35m0.7122\u001b[0m  0.0150\n",
      "      3        \u001b[36m0.6974\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6857\u001b[0m  0.0173\n",
      "      4        \u001b[36m0.6780\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6654\u001b[0m  0.0148\n",
      "      5        \u001b[36m0.6599\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6462\u001b[0m  0.0172\n",
      "      6        \u001b[36m0.6428\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6255\u001b[0m  0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7        \u001b[36m0.6245\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6024\u001b[0m  0.0175\n",
      "      8        \u001b[36m0.6050\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5782\u001b[0m  0.0149\n",
      "      9        \u001b[36m0.5858\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5545\u001b[0m  0.0146\n",
      "     10        \u001b[36m0.5686\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5318\u001b[0m  0.0197\n",
      "     11        \u001b[36m0.5535\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5119\u001b[0m  0.0200\n",
      "     12        \u001b[36m0.5400\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4965\u001b[0m  0.0143\n",
      "     13        \u001b[36m0.5320\u001b[0m       0.7578        \u001b[35m0.4824\u001b[0m  0.0189\n",
      "     14        \u001b[36m0.5246\u001b[0m       0.7500        \u001b[35m0.4713\u001b[0m  0.0194\n",
      "     15        \u001b[36m0.5192\u001b[0m       0.7578        \u001b[35m0.4624\u001b[0m  0.0144\n",
      "     16        \u001b[36m0.5156\u001b[0m       0.7578        \u001b[35m0.4550\u001b[0m  0.0188\n",
      "     17        \u001b[36m0.5127\u001b[0m       0.7578        \u001b[35m0.4481\u001b[0m  0.0201\n",
      "     18        \u001b[36m0.5099\u001b[0m       0.7578        \u001b[35m0.4433\u001b[0m  0.0189\n",
      "     19        \u001b[36m0.5081\u001b[0m       0.7656        \u001b[35m0.4388\u001b[0m  0.0192\n",
      "     20        \u001b[36m0.5063\u001b[0m       0.7578        \u001b[35m0.4339\u001b[0m  0.0204\n",
      "     21        \u001b[36m0.5050\u001b[0m       0.7578        \u001b[35m0.4308\u001b[0m  0.0147\n",
      "     22        \u001b[36m0.5029\u001b[0m       0.7656        \u001b[35m0.4275\u001b[0m  0.0180\n",
      "     23        \u001b[36m0.5016\u001b[0m       0.7656        \u001b[35m0.4247\u001b[0m  0.0195\n",
      "     24        \u001b[36m0.5001\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4226\u001b[0m  0.0149\n",
      "     25        \u001b[36m0.4987\u001b[0m       0.7812        \u001b[35m0.4215\u001b[0m  0.0206\n",
      "     26        \u001b[36m0.4977\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4210\u001b[0m  0.0196\n",
      "     27        \u001b[36m0.4965\u001b[0m       0.7812        \u001b[35m0.4185\u001b[0m  0.0194\n",
      "     28        \u001b[36m0.4950\u001b[0m       0.7812        \u001b[35m0.4174\u001b[0m  0.0195\n",
      "     29        \u001b[36m0.4934\u001b[0m       0.7891        \u001b[35m0.4168\u001b[0m  0.0149\n",
      "     30        \u001b[36m0.4929\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4158\u001b[0m  0.0178\n",
      "     31        \u001b[36m0.4917\u001b[0m       0.7891        \u001b[35m0.4145\u001b[0m  0.0149\n",
      "     32        \u001b[36m0.4911\u001b[0m       0.7891        \u001b[35m0.4134\u001b[0m  0.0184\n",
      "     33        \u001b[36m0.4901\u001b[0m       0.7891        \u001b[35m0.4125\u001b[0m  0.0228\n",
      "     34        \u001b[36m0.4893\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4123\u001b[0m  0.0144\n",
      "     35        \u001b[36m0.4887\u001b[0m       0.7969        \u001b[35m0.4118\u001b[0m  0.0208\n",
      "     36        \u001b[36m0.4879\u001b[0m       0.8047        \u001b[35m0.4108\u001b[0m  0.0148\n",
      "     37        \u001b[36m0.4872\u001b[0m       0.7969        \u001b[35m0.4100\u001b[0m  0.0191\n",
      "     38        \u001b[36m0.4863\u001b[0m       0.7969        0.4103  0.0171\n",
      "     39        \u001b[36m0.4859\u001b[0m       0.7891        \u001b[35m0.4089\u001b[0m  0.0171\n",
      "     40        \u001b[36m0.4851\u001b[0m       0.7969        \u001b[35m0.4081\u001b[0m  0.0188\n",
      "     41        \u001b[36m0.4843\u001b[0m       0.7891        0.4085  0.0175\n",
      "     42        \u001b[36m0.4838\u001b[0m       0.8047        0.4086  0.0231\n",
      "     43        \u001b[36m0.4828\u001b[0m       0.7969        \u001b[35m0.4062\u001b[0m  0.0215\n",
      "     44        \u001b[36m0.4816\u001b[0m       0.8047        \u001b[35m0.4055\u001b[0m  0.0162\n",
      "     45        \u001b[36m0.4812\u001b[0m       0.7969        0.4062  0.0223\n",
      "     46        \u001b[36m0.4802\u001b[0m       \u001b[32m0.8125\u001b[0m        0.4057  0.0184\n",
      "     47        \u001b[36m0.4793\u001b[0m       0.8047        \u001b[35m0.4054\u001b[0m  0.0154\n",
      "     48        \u001b[36m0.4786\u001b[0m       0.8047        \u001b[35m0.4052\u001b[0m  0.0206\n",
      "     49        \u001b[36m0.4775\u001b[0m       0.8125        \u001b[35m0.4045\u001b[0m  0.0203\n",
      "     50        \u001b[36m0.4769\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4029\u001b[0m  0.0165\n",
      "     51        \u001b[36m0.4761\u001b[0m       0.8125        \u001b[35m0.4016\u001b[0m  0.0186\n",
      "     52        \u001b[36m0.4753\u001b[0m       0.8125        \u001b[35m0.3995\u001b[0m  0.0171\n",
      "     53        \u001b[36m0.4743\u001b[0m       0.8047        \u001b[35m0.3994\u001b[0m  0.0251\n",
      "     54        \u001b[36m0.4739\u001b[0m       0.8047        0.4011  0.0197\n",
      "     55        \u001b[36m0.4729\u001b[0m       0.8125        0.4006  0.0138\n",
      "     56        \u001b[36m0.4723\u001b[0m       0.8125        \u001b[35m0.3991\u001b[0m  0.0184\n",
      "     57        \u001b[36m0.4717\u001b[0m       0.8125        \u001b[35m0.3979\u001b[0m  0.0241\n",
      "     58        \u001b[36m0.4713\u001b[0m       0.8125        \u001b[35m0.3973\u001b[0m  0.0211\n",
      "     59        \u001b[36m0.4711\u001b[0m       0.8125        0.3981  0.0189\n",
      "     60        \u001b[36m0.4708\u001b[0m       0.8125        \u001b[35m0.3954\u001b[0m  0.0169\n",
      "     61        \u001b[36m0.4698\u001b[0m       0.8125        \u001b[35m0.3953\u001b[0m  0.0287\n",
      "     62        \u001b[36m0.4690\u001b[0m       0.8125        0.3956  0.0145\n",
      "     63        \u001b[36m0.4684\u001b[0m       0.8125        \u001b[35m0.3947\u001b[0m  0.0219\n",
      "     64        \u001b[36m0.4684\u001b[0m       0.8203        \u001b[35m0.3945\u001b[0m  0.0145\n",
      "     65        \u001b[36m0.4674\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m0.3943\u001b[0m  0.0191\n",
      "     66        \u001b[36m0.4674\u001b[0m       0.8203        0.3950  0.0150\n",
      "     67        \u001b[36m0.4666\u001b[0m       0.8203        \u001b[35m0.3939\u001b[0m  0.0207\n",
      "     68        \u001b[36m0.4665\u001b[0m       0.8281        \u001b[35m0.3938\u001b[0m  0.0142\n",
      "     69        \u001b[36m0.4658\u001b[0m       \u001b[32m0.8359\u001b[0m        \u001b[35m0.3928\u001b[0m  0.0155\n",
      "     70        \u001b[36m0.4655\u001b[0m       0.8281        0.3936  0.0174\n",
      "     71        \u001b[36m0.4652\u001b[0m       0.8203        0.3932  0.0154\n",
      "     72        \u001b[36m0.4644\u001b[0m       0.8281        \u001b[35m0.3927\u001b[0m  0.0206\n",
      "     73        \u001b[36m0.4639\u001b[0m       0.8359        \u001b[35m0.3924\u001b[0m  0.0157\n",
      "     74        \u001b[36m0.4639\u001b[0m       0.8359        0.3930  0.0216\n",
      "     75        \u001b[36m0.4631\u001b[0m       0.8359        0.3928  0.0147\n",
      "     76        0.4635       0.8281        \u001b[35m0.3907\u001b[0m  0.0176\n",
      "     77        \u001b[36m0.4626\u001b[0m       0.8281        0.3909  0.0180\n",
      "     78        \u001b[36m0.4617\u001b[0m       0.8281        0.3907  0.0237\n",
      "     79        \u001b[36m0.4616\u001b[0m       0.8281        0.3917  0.0130\n",
      "     80        \u001b[36m0.4610\u001b[0m       0.8281        0.3907  0.0190\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7530\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.7485\u001b[0m  0.0162\n",
      "      2        \u001b[36m0.7134\u001b[0m       0.5000        \u001b[35m0.7067\u001b[0m  0.0155\n",
      "      3        \u001b[36m0.6787\u001b[0m       0.4844        \u001b[35m0.6792\u001b[0m  0.0171\n",
      "      4        \u001b[36m0.6559\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6615\u001b[0m  0.0149\n",
      "      5        \u001b[36m0.6389\u001b[0m       0.5938        \u001b[35m0.6467\u001b[0m  0.0203\n",
      "      6        \u001b[36m0.6224\u001b[0m       0.6250        \u001b[35m0.6308\u001b[0m  0.0135\n",
      "      7        \u001b[36m0.6031\u001b[0m       0.6250        \u001b[35m0.6159\u001b[0m  0.0155\n",
      "      8        \u001b[36m0.5858\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6032\u001b[0m  0.0155\n",
      "      9        \u001b[36m0.5703\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5927\u001b[0m  0.0173\n",
      "     10        \u001b[36m0.5560\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5841\u001b[0m  0.0130\n",
      "     11        \u001b[36m0.5436\u001b[0m       0.6953        \u001b[35m0.5769\u001b[0m  0.0146\n",
      "     12        \u001b[36m0.5326\u001b[0m       0.6875        \u001b[35m0.5713\u001b[0m  0.0174\n",
      "     13        \u001b[36m0.5253\u001b[0m       0.6953        \u001b[35m0.5668\u001b[0m  0.0131\n",
      "     14        \u001b[36m0.5177\u001b[0m       0.6953        \u001b[35m0.5622\u001b[0m  0.0136\n",
      "     15        \u001b[36m0.5115\u001b[0m       0.6953        \u001b[35m0.5590\u001b[0m  0.0130\n",
      "     16        \u001b[36m0.5068\u001b[0m       0.6953        \u001b[35m0.5565\u001b[0m  0.0128\n",
      "     17        \u001b[36m0.5033\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5541\u001b[0m  0.0146\n",
      "     18        \u001b[36m0.5003\u001b[0m       0.7109        \u001b[35m0.5517\u001b[0m  0.0151\n",
      "     19        \u001b[36m0.4976\u001b[0m       0.7109        \u001b[35m0.5495\u001b[0m  0.0144\n",
      "     20        \u001b[36m0.4956\u001b[0m       0.7109        \u001b[35m0.5475\u001b[0m  0.0167\n",
      "     21        \u001b[36m0.4936\u001b[0m       0.7109        \u001b[35m0.5447\u001b[0m  0.0128\n",
      "     22        \u001b[36m0.4918\u001b[0m       0.7109        \u001b[35m0.5423\u001b[0m  0.0129\n",
      "     23        \u001b[36m0.4901\u001b[0m       0.6953        \u001b[35m0.5407\u001b[0m  0.0147\n",
      "     24        \u001b[36m0.4885\u001b[0m       0.6953        \u001b[35m0.5394\u001b[0m  0.0130\n",
      "     25        \u001b[36m0.4877\u001b[0m       0.7031        \u001b[35m0.5375\u001b[0m  0.0127\n",
      "     26        \u001b[36m0.4859\u001b[0m       0.6953        \u001b[35m0.5361\u001b[0m  0.0126\n",
      "     27        \u001b[36m0.4848\u001b[0m       0.6953        \u001b[35m0.5353\u001b[0m  0.0136\n",
      "     28        \u001b[36m0.4830\u001b[0m       0.6953        \u001b[35m0.5329\u001b[0m  0.0164\n",
      "     29        \u001b[36m0.4813\u001b[0m       0.7031        \u001b[35m0.5313\u001b[0m  0.0275\n",
      "     30        \u001b[36m0.4801\u001b[0m       0.6953        \u001b[35m0.5299\u001b[0m  0.0193\n",
      "     31        \u001b[36m0.4789\u001b[0m       0.6953        \u001b[35m0.5294\u001b[0m  0.0167\n",
      "     32        \u001b[36m0.4777\u001b[0m       0.7031        \u001b[35m0.5292\u001b[0m  0.0164\n",
      "     33        \u001b[36m0.4765\u001b[0m       0.7031        \u001b[35m0.5285\u001b[0m  0.0191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34        \u001b[36m0.4755\u001b[0m       0.7031        \u001b[35m0.5275\u001b[0m  0.0206\n",
      "     35        \u001b[36m0.4749\u001b[0m       0.6953        \u001b[35m0.5262\u001b[0m  0.0251\n",
      "     36        \u001b[36m0.4736\u001b[0m       0.7031        \u001b[35m0.5249\u001b[0m  0.0291\n",
      "     37        \u001b[36m0.4728\u001b[0m       0.7031        \u001b[35m0.5239\u001b[0m  0.0241\n",
      "     38        \u001b[36m0.4723\u001b[0m       0.6953        \u001b[35m0.5233\u001b[0m  0.0334\n",
      "     39        \u001b[36m0.4713\u001b[0m       0.6953        \u001b[35m0.5231\u001b[0m  0.0171\n",
      "     40        \u001b[36m0.4701\u001b[0m       0.6953        \u001b[35m0.5221\u001b[0m  0.0125\n",
      "     41        \u001b[36m0.4694\u001b[0m       0.6953        \u001b[35m0.5219\u001b[0m  0.0155\n",
      "     42        \u001b[36m0.4684\u001b[0m       0.7031        \u001b[35m0.5216\u001b[0m  0.0146\n",
      "     43        \u001b[36m0.4676\u001b[0m       0.7031        \u001b[35m0.5206\u001b[0m  0.0260\n",
      "     44        \u001b[36m0.4669\u001b[0m       0.7031        \u001b[35m0.5196\u001b[0m  0.0167\n",
      "     45        \u001b[36m0.4662\u001b[0m       0.7031        0.5202  0.0127\n",
      "     46        \u001b[36m0.4654\u001b[0m       0.7031        \u001b[35m0.5187\u001b[0m  0.0197\n",
      "     47        \u001b[36m0.4647\u001b[0m       0.6953        \u001b[35m0.5182\u001b[0m  0.0137\n",
      "     48        \u001b[36m0.4639\u001b[0m       0.7031        0.5182  0.0159\n",
      "     49        \u001b[36m0.4634\u001b[0m       0.7109        \u001b[35m0.5179\u001b[0m  0.0147\n",
      "     50        \u001b[36m0.4625\u001b[0m       0.7031        \u001b[35m0.5179\u001b[0m  0.0183\n",
      "     51        \u001b[36m0.4621\u001b[0m       0.7031        \u001b[35m0.5173\u001b[0m  0.0189\n",
      "     52        \u001b[36m0.4616\u001b[0m       0.7109        \u001b[35m0.5167\u001b[0m  0.0131\n",
      "     53        \u001b[36m0.4613\u001b[0m       0.7031        0.5170  0.0181\n",
      "     54        \u001b[36m0.4609\u001b[0m       0.7031        0.5173  0.0127\n",
      "     55        \u001b[36m0.4601\u001b[0m       0.7109        \u001b[35m0.5165\u001b[0m  0.0169\n",
      "     56        \u001b[36m0.4599\u001b[0m       0.7031        \u001b[35m0.5159\u001b[0m  0.0131\n",
      "     57        \u001b[36m0.4594\u001b[0m       0.7109        \u001b[35m0.5150\u001b[0m  0.0165\n",
      "     58        \u001b[36m0.4592\u001b[0m       0.7109        0.5157  0.0221\n",
      "     59        \u001b[36m0.4587\u001b[0m       0.7109        \u001b[35m0.5146\u001b[0m  0.0163\n",
      "     60        \u001b[36m0.4584\u001b[0m       0.7031        0.5147  0.0144\n",
      "     61        \u001b[36m0.4581\u001b[0m       0.7109        \u001b[35m0.5144\u001b[0m  0.0176\n",
      "     62        \u001b[36m0.4575\u001b[0m       0.7109        \u001b[35m0.5137\u001b[0m  0.0133\n",
      "     63        0.4576       0.7109        \u001b[35m0.5129\u001b[0m  0.0163\n",
      "     64        \u001b[36m0.4565\u001b[0m       \u001b[32m0.7188\u001b[0m        0.5131  0.0154\n",
      "     65        \u001b[36m0.4561\u001b[0m       0.7109        \u001b[35m0.5124\u001b[0m  0.0173\n",
      "     66        \u001b[36m0.4561\u001b[0m       0.7109        0.5133  0.0155\n",
      "     67        \u001b[36m0.4551\u001b[0m       0.7109        0.5125  0.0175\n",
      "     68        \u001b[36m0.4548\u001b[0m       0.7109        \u001b[35m0.5111\u001b[0m  0.0172\n",
      "     69        \u001b[36m0.4544\u001b[0m       0.7109        \u001b[35m0.5104\u001b[0m  0.0137\n",
      "     70        \u001b[36m0.4538\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5094\u001b[0m  0.0166\n",
      "     71        \u001b[36m0.4533\u001b[0m       \u001b[32m0.7344\u001b[0m        0.5094  0.0135\n",
      "     72        \u001b[36m0.4526\u001b[0m       0.7344        \u001b[35m0.5090\u001b[0m  0.0170\n",
      "     73        \u001b[36m0.4520\u001b[0m       0.7344        \u001b[35m0.5082\u001b[0m  0.0139\n",
      "     74        \u001b[36m0.4516\u001b[0m       0.7344        \u001b[35m0.5071\u001b[0m  0.0142\n",
      "     75        \u001b[36m0.4512\u001b[0m       0.7266        \u001b[35m0.5065\u001b[0m  0.0168\n",
      "     76        \u001b[36m0.4508\u001b[0m       0.7188        \u001b[35m0.5060\u001b[0m  0.0165\n",
      "     77        \u001b[36m0.4500\u001b[0m       0.7188        0.5062  0.0169\n",
      "     78        \u001b[36m0.4496\u001b[0m       0.7344        \u001b[35m0.5055\u001b[0m  0.0138\n",
      "     79        \u001b[36m0.4493\u001b[0m       0.7266        \u001b[35m0.5050\u001b[0m  0.0178\n",
      "     80        \u001b[36m0.4492\u001b[0m       0.7266        0.5054  0.0144\n",
      "     81        \u001b[36m0.4489\u001b[0m       0.7188        \u001b[35m0.5040\u001b[0m  0.0176\n",
      "     82        \u001b[36m0.4482\u001b[0m       0.7188        \u001b[35m0.5037\u001b[0m  0.0155\n",
      "     83        \u001b[36m0.4481\u001b[0m       0.7188        \u001b[35m0.5033\u001b[0m  0.0153\n",
      "     84        \u001b[36m0.4472\u001b[0m       0.7109        \u001b[35m0.5029\u001b[0m  0.0165\n",
      "     85        \u001b[36m0.4471\u001b[0m       0.7188        0.5032  0.0153\n",
      "     86        \u001b[36m0.4467\u001b[0m       0.7109        \u001b[35m0.5024\u001b[0m  0.0143\n",
      "     87        \u001b[36m0.4463\u001b[0m       0.7188        0.5029  0.0189\n",
      "     88        \u001b[36m0.4455\u001b[0m       0.7188        \u001b[35m0.5022\u001b[0m  0.0138\n",
      "     89        \u001b[36m0.4449\u001b[0m       0.7188        \u001b[35m0.5020\u001b[0m  0.0167\n",
      "     90        \u001b[36m0.4442\u001b[0m       0.7188        0.5022  0.0157\n",
      "     91        \u001b[36m0.4434\u001b[0m       0.7109        0.5025  0.0153\n",
      "     92        0.4436       0.7109        0.5027  0.0175\n",
      "     93        0.4435       0.7031        0.5025  0.0155\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7478\u001b[0m       \u001b[32m0.4062\u001b[0m        \u001b[35m0.7300\u001b[0m  0.0155\n",
      "      2        \u001b[36m0.7261\u001b[0m       0.3438        \u001b[35m0.7120\u001b[0m  0.0147\n",
      "      3        \u001b[36m0.7098\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.6982\u001b[0m  0.0129\n",
      "      4        \u001b[36m0.6972\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6903\u001b[0m  0.0247\n",
      "      5        \u001b[36m0.6894\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6848\u001b[0m  0.0157\n",
      "      6        \u001b[36m0.6835\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6791\u001b[0m  0.0193\n",
      "      7        \u001b[36m0.6776\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6730\u001b[0m  0.0129\n",
      "      8        \u001b[36m0.6708\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6665\u001b[0m  0.0213\n",
      "      9        \u001b[36m0.6626\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6583\u001b[0m  0.0153\n",
      "     10        \u001b[36m0.6528\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6484\u001b[0m  0.0158\n",
      "     11        \u001b[36m0.6408\u001b[0m       0.6641        \u001b[35m0.6370\u001b[0m  0.0130\n",
      "     12        \u001b[36m0.6265\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6240\u001b[0m  0.0148\n",
      "     13        \u001b[36m0.6113\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6089\u001b[0m  0.0165\n",
      "     14        \u001b[36m0.5921\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5950\u001b[0m  0.0175\n",
      "     15        \u001b[36m0.5740\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5821\u001b[0m  0.0169\n",
      "     16        \u001b[36m0.5562\u001b[0m       0.7344        \u001b[35m0.5716\u001b[0m  0.0173\n",
      "     17        \u001b[36m0.5407\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5640\u001b[0m  0.0138\n",
      "     18        \u001b[36m0.5281\u001b[0m       0.7266        \u001b[35m0.5584\u001b[0m  0.0152\n",
      "     19        \u001b[36m0.5182\u001b[0m       0.7344        \u001b[35m0.5546\u001b[0m  0.0171\n",
      "     20        \u001b[36m0.5103\u001b[0m       0.7344        \u001b[35m0.5510\u001b[0m  0.0151\n",
      "     21        \u001b[36m0.5037\u001b[0m       0.7109        \u001b[35m0.5480\u001b[0m  0.0177\n",
      "     22        \u001b[36m0.4979\u001b[0m       0.7109        \u001b[35m0.5455\u001b[0m  0.0151\n",
      "     23        \u001b[36m0.4928\u001b[0m       0.7188        \u001b[35m0.5428\u001b[0m  0.0127\n",
      "     24        \u001b[36m0.4887\u001b[0m       0.7188        \u001b[35m0.5402\u001b[0m  0.0143\n",
      "     25        \u001b[36m0.4841\u001b[0m       0.7188        \u001b[35m0.5377\u001b[0m  0.0167\n",
      "     26        \u001b[36m0.4803\u001b[0m       0.7109        \u001b[35m0.5351\u001b[0m  0.0158\n",
      "     27        \u001b[36m0.4768\u001b[0m       0.7109        \u001b[35m0.5327\u001b[0m  0.0126\n",
      "     28        \u001b[36m0.4734\u001b[0m       0.7109        \u001b[35m0.5312\u001b[0m  0.0146\n",
      "     29        \u001b[36m0.4704\u001b[0m       0.7031        \u001b[35m0.5295\u001b[0m  0.0202\n",
      "     30        \u001b[36m0.4673\u001b[0m       0.7109        \u001b[35m0.5280\u001b[0m  0.0141\n",
      "     31        \u001b[36m0.4655\u001b[0m       0.7188        \u001b[35m0.5262\u001b[0m  0.0135\n",
      "     32        \u001b[36m0.4633\u001b[0m       0.7266        \u001b[35m0.5249\u001b[0m  0.0144\n",
      "     33        \u001b[36m0.4616\u001b[0m       0.7266        \u001b[35m0.5242\u001b[0m  0.0186\n",
      "     34        \u001b[36m0.4599\u001b[0m       0.7266        \u001b[35m0.5232\u001b[0m  0.0131\n",
      "     35        \u001b[36m0.4582\u001b[0m       0.7188        \u001b[35m0.5224\u001b[0m  0.0140\n",
      "     36        \u001b[36m0.4568\u001b[0m       0.7188        \u001b[35m0.5210\u001b[0m  0.0167\n",
      "     37        \u001b[36m0.4556\u001b[0m       0.7266        \u001b[35m0.5195\u001b[0m  0.0132\n",
      "     38        \u001b[36m0.4543\u001b[0m       0.7266        \u001b[35m0.5194\u001b[0m  0.0147\n",
      "     39        \u001b[36m0.4528\u001b[0m       0.7266        \u001b[35m0.5185\u001b[0m  0.0127\n",
      "     40        \u001b[36m0.4517\u001b[0m       0.7266        \u001b[35m0.5183\u001b[0m  0.0178\n",
      "     41        \u001b[36m0.4512\u001b[0m       0.7422        \u001b[35m0.5182\u001b[0m  0.0127\n",
      "     42        \u001b[36m0.4499\u001b[0m       0.7344        0.5184  0.0146\n",
      "     43        \u001b[36m0.4489\u001b[0m       0.7344        \u001b[35m0.5178\u001b[0m  0.0149\n",
      "     44        \u001b[36m0.4479\u001b[0m       0.7344        \u001b[35m0.5177\u001b[0m  0.0133\n",
      "     45        \u001b[36m0.4472\u001b[0m       0.7344        \u001b[35m0.5174\u001b[0m  0.0145\n",
      "     46        \u001b[36m0.4463\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5170\u001b[0m  0.0169\n",
      "     47        \u001b[36m0.4454\u001b[0m       0.7500        0.5172  0.0169\n",
      "     48        \u001b[36m0.4446\u001b[0m       0.7500        0.5175  0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     49        \u001b[36m0.4436\u001b[0m       0.7500        0.5175  0.0128\n",
      "     50        \u001b[36m0.4427\u001b[0m       0.7500        0.5179  0.0149\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7440\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7136\u001b[0m  0.0148\n",
      "      2        \u001b[36m0.7125\u001b[0m       0.4922        \u001b[35m0.6843\u001b[0m  0.0195\n",
      "      3        \u001b[36m0.6847\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6712\u001b[0m  0.0163\n",
      "      4        \u001b[36m0.6699\u001b[0m       0.6406        \u001b[35m0.6642\u001b[0m  0.0190\n",
      "      5        \u001b[36m0.6609\u001b[0m       0.6484        \u001b[35m0.6580\u001b[0m  0.0211\n",
      "      6        \u001b[36m0.6499\u001b[0m       0.6406        \u001b[35m0.6493\u001b[0m  0.0140\n",
      "      7        \u001b[36m0.6368\u001b[0m       0.6562        \u001b[35m0.6387\u001b[0m  0.0255\n",
      "      8        \u001b[36m0.6219\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6265\u001b[0m  0.0200\n",
      "      9        \u001b[36m0.6042\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6142\u001b[0m  0.0158\n",
      "     10        \u001b[36m0.5857\u001b[0m       0.7188        \u001b[35m0.6014\u001b[0m  0.0155\n",
      "     11        \u001b[36m0.5649\u001b[0m       0.6953        \u001b[35m0.5921\u001b[0m  0.0220\n",
      "     12        \u001b[36m0.5466\u001b[0m       0.6797        \u001b[35m0.5859\u001b[0m  0.0185\n",
      "     13        \u001b[36m0.5292\u001b[0m       0.6875        \u001b[35m0.5828\u001b[0m  0.0150\n",
      "     14        \u001b[36m0.5173\u001b[0m       0.6875        \u001b[35m0.5827\u001b[0m  0.0149\n",
      "     15        \u001b[36m0.5082\u001b[0m       0.6875        0.5841  0.0192\n",
      "     16        \u001b[36m0.5005\u001b[0m       0.7031        0.5838  0.0200\n",
      "     17        \u001b[36m0.4964\u001b[0m       0.7031        0.5842  0.0153\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7715\u001b[0m       \u001b[32m0.3125\u001b[0m        \u001b[35m0.7473\u001b[0m  0.0216\n",
      "      2        \u001b[36m0.7397\u001b[0m       \u001b[32m0.3672\u001b[0m        \u001b[35m0.7170\u001b[0m  0.0144\n",
      "      3        \u001b[36m0.7097\u001b[0m       \u001b[32m0.4844\u001b[0m        \u001b[35m0.6940\u001b[0m  0.0186\n",
      "      4        \u001b[36m0.6873\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6791\u001b[0m  0.0153\n",
      "      5        \u001b[36m0.6716\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6665\u001b[0m  0.0167\n",
      "      6        \u001b[36m0.6563\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6522\u001b[0m  0.0184\n",
      "      7        \u001b[36m0.6383\u001b[0m       0.6641        \u001b[35m0.6356\u001b[0m  0.0136\n",
      "      8        \u001b[36m0.6163\u001b[0m       0.6797        \u001b[35m0.6160\u001b[0m  0.0174\n",
      "      9        \u001b[36m0.5901\u001b[0m       0.6797        \u001b[35m0.5955\u001b[0m  0.0145\n",
      "     10        \u001b[36m0.5617\u001b[0m       0.6875        \u001b[35m0.5774\u001b[0m  0.0189\n",
      "     11        \u001b[36m0.5369\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5634\u001b[0m  0.0146\n",
      "     12        \u001b[36m0.5146\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5573\u001b[0m  0.0198\n",
      "     13        \u001b[36m0.4968\u001b[0m       0.7344        0.5577  0.0194\n",
      "     14        \u001b[36m0.4866\u001b[0m       0.7266        0.5617  0.0137\n",
      "     15        \u001b[36m0.4792\u001b[0m       0.7266        0.5670  0.0167\n",
      "     16        \u001b[36m0.4752\u001b[0m       0.7188        0.5723  0.0179\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6086\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4691\u001b[0m  0.0425\n",
      "      2        \u001b[36m0.5789\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4379\u001b[0m  0.0370\n",
      "      3        \u001b[36m0.5439\u001b[0m       0.7812        \u001b[35m0.4196\u001b[0m  0.0321\n",
      "      4        0.5662       0.7891        0.4397  0.0366\n",
      "      5        0.5629       0.7812        0.4808  0.0373\n",
      "      6        \u001b[36m0.5432\u001b[0m       0.7891        0.4744  0.0328\n",
      "      7        0.5535       0.8047        \u001b[35m0.4147\u001b[0m  0.0367\n",
      "      8        \u001b[36m0.5290\u001b[0m       0.7812        0.4548  0.0348\n",
      "      9        0.5431       \u001b[32m0.8281\u001b[0m        0.4425  0.0333\n",
      "     10        \u001b[36m0.5231\u001b[0m       0.8125        \u001b[35m0.3917\u001b[0m  0.0376\n",
      "     11        0.5495       0.7734        0.4499  0.0359\n",
      "     12        0.5348       0.7891        0.4314  0.0343\n",
      "     13        \u001b[36m0.5226\u001b[0m       0.8047        0.4801  0.0391\n",
      "     14        0.5302       0.7188        0.4980  0.0340\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5833\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5334\u001b[0m  0.0289\n",
      "      2        \u001b[36m0.5523\u001b[0m       0.7578        \u001b[35m0.5130\u001b[0m  0.0327\n",
      "      3        0.5564       0.7344        0.5221  0.0360\n",
      "      4        \u001b[36m0.5395\u001b[0m       0.7578        \u001b[35m0.5022\u001b[0m  0.0358\n",
      "      5        \u001b[36m0.5370\u001b[0m       0.7578        0.5041  0.0338\n",
      "      6        \u001b[36m0.5255\u001b[0m       \u001b[32m0.7656\u001b[0m        0.5282  0.0358\n",
      "      7        \u001b[36m0.5177\u001b[0m       0.6328        0.6174  0.0361\n",
      "      8        0.5231       \u001b[32m0.7734\u001b[0m        0.5190  0.0342\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5865\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5623\u001b[0m  0.0343\n",
      "      2        \u001b[36m0.5466\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5266\u001b[0m  0.0411\n",
      "      3        0.5537       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5160\u001b[0m  0.0356\n",
      "      4        0.5716       0.7031        0.5651  0.0332\n",
      "      5        \u001b[36m0.5387\u001b[0m       0.7109        0.6367  0.0363\n",
      "      6        \u001b[36m0.5377\u001b[0m       0.7188        0.5518  0.0356\n",
      "      7        \u001b[36m0.5325\u001b[0m       0.7031        0.6599  0.0343\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6352\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6606\u001b[0m  0.0335\n",
      "      2        0.6527       0.6875        0.6629  0.0367\n",
      "      3        0.6523       0.6953        \u001b[35m0.6094\u001b[0m  0.0358\n",
      "      4        \u001b[36m0.6248\u001b[0m       0.6562        0.6404  0.0360\n",
      "      5        \u001b[36m0.6145\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6082\u001b[0m  0.0380\n",
      "      6        0.6530       0.5078        0.7356  0.0384\n",
      "      7        0.6555       0.6641        0.6117  0.0334\n",
      "      8        0.6207       0.6641        0.6485  0.0396\n",
      "      9        0.6459       0.5938        0.6607  0.0356\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5912\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.5427\u001b[0m  0.0290\n",
      "      2        \u001b[36m0.5615\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5352\u001b[0m  0.0346\n",
      "      3        \u001b[36m0.5427\u001b[0m       0.7188        0.5640  0.0382\n",
      "      4        \u001b[36m0.4951\u001b[0m       0.7500        0.6605  0.0360\n",
      "      5        \u001b[36m0.4913\u001b[0m       0.7031        0.6392  0.0337\n",
      "      6        0.5015       0.7344        0.5545  0.0351\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6508\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5016\u001b[0m  0.0181\n",
      "      2        \u001b[36m0.5535\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4803\u001b[0m  0.0200\n",
      "      3        0.5635       0.7656        0.4919  0.0228\n",
      "      4        \u001b[36m0.5298\u001b[0m       0.7500        0.4891  0.0225\n",
      "      5        0.5396       \u001b[32m0.8281\u001b[0m        \u001b[35m0.3916\u001b[0m  0.0258\n",
      "      6        \u001b[36m0.5111\u001b[0m       0.8047        0.4091  0.0200\n",
      "      7        \u001b[36m0.5063\u001b[0m       0.7891        0.4111  0.0253\n",
      "      8        0.5204       0.8125        0.4357  0.0212\n",
      "      9        \u001b[36m0.4899\u001b[0m       \u001b[32m0.8516\u001b[0m        \u001b[35m0.3860\u001b[0m  0.0238\n",
      "     10        0.5041       0.8125        0.3977  0.0247\n",
      "     11        \u001b[36m0.4803\u001b[0m       0.8125        0.4093  0.0204\n",
      "     12        0.4816       0.8203        \u001b[35m0.3755\u001b[0m  0.0224\n",
      "     13        0.4848       0.8125        0.4135  0.0224\n",
      "     14        0.4804       0.8203        \u001b[35m0.3735\u001b[0m  0.0198\n",
      "     15        0.4923       0.7969        0.4066  0.0240\n",
      "     16        0.4987       0.8047        0.3951  0.0242\n",
      "     17        \u001b[36m0.4724\u001b[0m       0.8203        0.3912  0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        \u001b[36m0.4719\u001b[0m       0.8047        0.4075  0.0227\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6377\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6128\u001b[0m  0.0245\n",
      "      2        \u001b[36m0.5299\u001b[0m       0.6250        \u001b[35m0.5911\u001b[0m  0.0383\n",
      "      3        0.5329       \u001b[32m0.6641\u001b[0m        \u001b[35m0.5414\u001b[0m  0.0190\n",
      "      4        \u001b[36m0.5038\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5340\u001b[0m  0.0198\n",
      "      5        \u001b[36m0.4978\u001b[0m       \u001b[32m0.7109\u001b[0m        0.5498  0.0291\n",
      "      6        0.5089       \u001b[32m0.7500\u001b[0m        0.5896  0.0262\n",
      "      7        0.5016       0.7109        \u001b[35m0.5184\u001b[0m  0.0229\n",
      "      8        \u001b[36m0.4885\u001b[0m       0.7422        0.5349  0.0199\n",
      "      9        0.4946       0.6875        0.5293  0.0223\n",
      "     10        \u001b[36m0.4853\u001b[0m       0.7188        0.5504  0.0264\n",
      "     11        0.4890       0.7188        0.5328  0.0220\n",
      "     12        0.4890       0.7031        \u001b[35m0.5124\u001b[0m  0.0222\n",
      "     13        0.4890       0.7500        0.5532  0.0212\n",
      "     14        0.4858       0.7500        0.5214  0.0234\n",
      "     15        \u001b[36m0.4703\u001b[0m       0.7031        0.5529  0.0221\n",
      "     16        0.4755       0.7031        0.5151  0.0227\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5601\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5794\u001b[0m  0.0180\n",
      "      2        \u001b[36m0.5081\u001b[0m       0.6875        \u001b[35m0.5624\u001b[0m  0.0203\n",
      "      3        \u001b[36m0.4965\u001b[0m       0.6797        0.5880  0.0333\n",
      "      4        \u001b[36m0.4795\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5576\u001b[0m  0.0230\n",
      "      5        \u001b[36m0.4748\u001b[0m       0.7109        \u001b[35m0.5575\u001b[0m  0.0219\n",
      "      6        \u001b[36m0.4738\u001b[0m       0.7109        \u001b[35m0.5562\u001b[0m  0.0199\n",
      "      7        \u001b[36m0.4658\u001b[0m       0.7031        0.5588  0.0239\n",
      "      8        \u001b[36m0.4619\u001b[0m       0.7109        \u001b[35m0.5505\u001b[0m  0.0215\n",
      "      9        \u001b[36m0.4531\u001b[0m       \u001b[32m0.7266\u001b[0m        0.5798  0.0206\n",
      "     10        0.4725       0.7266        0.5601  0.0205\n",
      "     11        0.4602       0.7109        0.5718  0.0236\n",
      "     12        \u001b[36m0.4516\u001b[0m       0.7188        0.5757  0.0195\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6016\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5761\u001b[0m  0.0166\n",
      "      2        \u001b[36m0.5317\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5398\u001b[0m  0.0189\n",
      "      3        \u001b[36m0.4956\u001b[0m       0.7031        \u001b[35m0.5285\u001b[0m  0.0201\n",
      "      4        \u001b[36m0.4940\u001b[0m       0.7031        \u001b[35m0.5244\u001b[0m  0.0204\n",
      "      5        \u001b[36m0.4881\u001b[0m       0.6953        0.5346  0.0243\n",
      "      6        \u001b[36m0.4737\u001b[0m       \u001b[32m0.7422\u001b[0m        0.5602  0.0217\n",
      "      7        0.4785       0.6641        0.5359  0.0271\n",
      "      8        \u001b[36m0.4614\u001b[0m       0.6875        0.5784  0.0200\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5253\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5985\u001b[0m  0.0228\n",
      "      2        \u001b[36m0.4606\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5312\u001b[0m  0.0221\n",
      "      3        0.4718       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5025\u001b[0m  0.0220\n",
      "      4        \u001b[36m0.4379\u001b[0m       0.6641        0.5619  0.0237\n",
      "      5        0.4555       0.6875        0.5560  0.0215\n",
      "      6        0.4441       0.7266        0.5397  0.0238\n",
      "      7        \u001b[36m0.4349\u001b[0m       0.7344        0.5571  0.0224\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7078\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6622\u001b[0m  0.0170\n",
      "      2        \u001b[36m0.6393\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.4786\u001b[0m  0.0219\n",
      "      3        \u001b[36m0.5810\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4461\u001b[0m  0.0214\n",
      "      4        0.5820       0.7969        \u001b[35m0.4396\u001b[0m  0.0264\n",
      "      5        0.5850       0.7891        \u001b[35m0.4379\u001b[0m  0.0218\n",
      "      6        \u001b[36m0.5651\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4212\u001b[0m  0.0287\n",
      "      7        0.5682       0.7734        0.4621  0.0212\n",
      "      8        \u001b[36m0.5402\u001b[0m       0.7812        0.4405  0.0258\n",
      "      9        0.5685       0.7891        \u001b[35m0.4206\u001b[0m  0.0218\n",
      "     10        0.5511       0.7812        0.4377  0.0250\n",
      "     11        0.5686       0.8047        \u001b[35m0.4107\u001b[0m  0.0337\n",
      "     12        0.5669       0.7656        0.4630  0.0215\n",
      "     13        0.5529       0.7734        0.4289  0.0254\n",
      "     14        0.5625       0.8125        0.4403  0.0215\n",
      "     15        0.5459       0.7656        0.4248  0.0208\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6850\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6248\u001b[0m  0.0188\n",
      "      2        \u001b[36m0.6252\u001b[0m       0.6875        \u001b[35m0.5594\u001b[0m  0.0201\n",
      "      3        \u001b[36m0.5953\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5543\u001b[0m  0.0265\n",
      "      4        \u001b[36m0.5822\u001b[0m       0.6797        \u001b[35m0.5421\u001b[0m  0.0233\n",
      "      5        \u001b[36m0.5571\u001b[0m       0.6953        \u001b[35m0.5317\u001b[0m  0.0244\n",
      "      6        \u001b[36m0.5422\u001b[0m       \u001b[32m0.7344\u001b[0m        0.5372  0.0203\n",
      "      7        \u001b[36m0.5417\u001b[0m       0.6875        0.5323  0.0234\n",
      "      8        \u001b[36m0.5325\u001b[0m       0.6719        \u001b[35m0.5281\u001b[0m  0.0250\n",
      "      9        0.5422       \u001b[32m0.7578\u001b[0m        \u001b[35m0.4998\u001b[0m  0.0228\n",
      "     10        0.5429       0.6797        0.5357  0.0229\n",
      "     11        0.5559       0.7344        0.5064  0.0214\n",
      "     12        0.5418       0.6719        0.5174  0.0231\n",
      "     13        \u001b[36m0.5041\u001b[0m       0.6719        0.5384  0.0275\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6951\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6514\u001b[0m  0.0202\n",
      "      2        \u001b[36m0.6244\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5348\u001b[0m  0.0209\n",
      "      3        \u001b[36m0.5579\u001b[0m       0.7422        \u001b[35m0.5226\u001b[0m  0.0352\n",
      "      4        \u001b[36m0.5344\u001b[0m       0.7344        \u001b[35m0.5164\u001b[0m  0.0271\n",
      "      5        \u001b[36m0.5198\u001b[0m       0.7344        0.5387  0.0264\n",
      "      6        \u001b[36m0.4992\u001b[0m       0.7266        0.5327  0.0240\n",
      "      7        0.5344       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5108\u001b[0m  0.0209\n",
      "      8        0.5298       0.7344        0.5217  0.0252\n",
      "      9        0.5451       0.7344        0.5208  0.0247\n",
      "     10        0.5331       0.7344        0.5418  0.0210\n",
      "     11        0.5616       0.7422        0.5222  0.0227\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6762\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5747\u001b[0m  0.0233\n",
      "      2        \u001b[36m0.5703\u001b[0m       0.7109        \u001b[35m0.5241\u001b[0m  0.0250\n",
      "      3        0.5912       0.7109        0.5502  0.0290\n",
      "      4        \u001b[36m0.5509\u001b[0m       0.7109        0.5289  0.0230\n",
      "      5        \u001b[36m0.5414\u001b[0m       0.7031        0.5366  0.0253\n",
      "      6        0.5467       0.6953        \u001b[35m0.5229\u001b[0m  0.0211\n",
      "      7        0.5421       0.7109        0.5233  0.0238\n",
      "      8        \u001b[36m0.5200\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5070\u001b[0m  0.0238\n",
      "      9        0.5260       \u001b[32m0.7500\u001b[0m        0.5141  0.0214\n",
      "     10        \u001b[36m0.5144\u001b[0m       0.6719        0.5279  0.0263\n",
      "     11        0.5536       0.6719        0.5278  0.0258\n",
      "     12        0.5255       0.6953        0.5193  0.0248\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6715\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5802\u001b[0m  0.0238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.5736\u001b[0m       0.7422        \u001b[35m0.5211\u001b[0m  0.0221\n",
      "      3        \u001b[36m0.5352\u001b[0m       0.7266        0.5270  0.0304\n",
      "      4        \u001b[36m0.5053\u001b[0m       0.7109        0.5448  0.0254\n",
      "      5        \u001b[36m0.4937\u001b[0m       0.6953        0.5688  0.0220\n",
      "      6        0.5228       0.6797        0.5246  0.0231\n",
      "      7        0.5236       0.7422        \u001b[35m0.5106\u001b[0m  0.0239\n",
      "      8        0.5199       0.7578        0.5522  0.0237\n",
      "      9        0.5182       0.6875        0.5165  0.0239\n",
      "     10        0.5145       0.6797        0.5260  0.0244\n",
      "     11        0.5303       0.6875        0.5290  0.0228\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5916\u001b[0m       \u001b[32m0.7125\u001b[0m        \u001b[35m0.5069\u001b[0m  0.0169\n",
      "      2        \u001b[36m0.5398\u001b[0m       \u001b[32m0.7562\u001b[0m        \u001b[35m0.4936\u001b[0m  0.0197\n",
      "      3        \u001b[36m0.5035\u001b[0m       0.7312        0.5079  0.0318\n",
      "      4        \u001b[36m0.4976\u001b[0m       \u001b[32m0.7688\u001b[0m        0.5020  0.0223\n",
      "      5        \u001b[36m0.4855\u001b[0m       0.7500        0.5051  0.0277\n",
      "      6        \u001b[36m0.4662\u001b[0m       0.7500        0.5154  0.0244\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best parameters found:\n",
      "\n",
      "{'optimizer__momentum': 0.3, 'module__num_units': 8, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 64}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.828 (+/-0.056) for {'optimizer__momentum': 0.3, 'module__num_units': 8, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 16}\n",
      "0.830 (+/-0.053) for {'optimizer__momentum': 0.3, 'module__num_units': 8, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 64}\n",
      "0.841 (+/-0.050) for {'optimizer__momentum': 0.1, 'module__num_units': 7, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 32}\n",
      "0.844 (+/-0.071) for {'optimizer__momentum': 0.3, 'module__num_units': 8, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 64}\n",
      "0.819 (+/-0.066) for {'optimizer__momentum': 0.1, 'module__num_units': 5, 'module__dropout': 0.5, 'lr': 0.01, 'batch_size': 64}\n",
      "0.832 (+/-0.068) for {'optimizer__momentum': 0.3, 'module__num_units': 3, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 64}\n",
      "0.842 (+/-0.079) for {'optimizer__momentum': 0.9, 'module__num_units': 5, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 64}\n",
      "0.816 (+/-0.068) for {'optimizer__momentum': 0.3, 'module__num_units': 4, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 16}\n",
      "0.832 (+/-0.062) for {'optimizer__momentum': 0.1, 'module__num_units': 4, 'module__dropout': 0.0, 'lr': 1, 'batch_size': 32}\n",
      "0.836 (+/-0.056) for {'optimizer__momentum': 0.9, 'module__num_units': 6, 'module__dropout': 0.5, 'lr': 0.1, 'batch_size': 32}\n",
      "\n",
      "Time taken in seconds: 332.91\n"
     ]
    }
   ],
   "source": [
    "# Perform Randomized Search on the neuron network with one hidden layer\n",
    "\n",
    "# Start timer\n",
    "tic = time()\n",
    "\n",
    "# Define the search values of the hyperparameters\n",
    "tuned_parameters = [{'module__num_units':[3,4,5,6,7,8,9],\n",
    "                    'optimizer__momentum':[0.1,0.3,0.6,0.9],\n",
    "                    'lr':[1,0.1,0.01],\n",
    "                    'module__dropout':[0.0,0.2,0.5],\n",
    "                    'batch_size':[16,32,64]}]\n",
    "\n",
    "# Print the accuracy, precision, recall, F1 score and AUC score for each set of hyperparameters\n",
    "for score in ['accuracy','precision','recall','f1','roc_auc']:\n",
    " print(\"# Tuning hyper-parameters for %s\" %score)\n",
    " print()\n",
    " classifier = RandomizedSearchCV(searchNet, tuned_parameters, scoring=score, cv=5)\n",
    " classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    " print(\"Best parameters found:\")\n",
    " print()\n",
    " print(classifier.best_params_)\n",
    " print()\n",
    " print(\"Randomized search scores on training set:\")\n",
    " print()\n",
    " means = classifier.cv_results_['mean_test_score']\n",
    " stds = classifier.cv_results_['std_test_score']\n",
    " for mean, std, params in zip(means, stds, classifier.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    \n",
    " print()\n",
    "\n",
    "# Print time required in seconds for the search\n",
    "toc = time()\n",
    "print('Time taken in seconds: %.2f'%(toc-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different optimal hyperparameters were given by the different performance metrics.\n",
    "\n",
    "Highest accuracy was attained with 'optimizer__momentum': 0.9, 'module__num_units': 9, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 64. We will use these parameters in the best SVM model.\n",
    "\n",
    "Highest precision was achieved with 'optimizer__momentum': 0.9, 'module__num_units': 7, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 32.\n",
    "\n",
    "Highest recall was attained with 'optimizer__momentum': 0.3, 'module__num_units': 4, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 64.\n",
    "\n",
    "Highest F1 score was achieved with 'optimizer__momentum': 0.9, 'module__num_units': 7, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 32.\n",
    "\n",
    "Highest AUC score of 0.844 was obtained with 'optimizer__momentum': 0.3, 'module__num_units': 8, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 64. \n",
    "\n",
    "We will check whether any MLP model with two hidden layers has higher AUC score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform randomized search on MLP model with two hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform randomized search on combinations of the following hyperparameters for the 5-fold cross-validated MLP model with two hidden layers.\n",
    "- number of neurons in first hidden layer 'module__num_unitsA': four options, 3, 6, 9 or 12.\n",
    "- number of neurons in second hidden layer 'module__num_unitsB': four options, 3, 6, 9 or 12.\n",
    "- optimizer momentum 'optimizer__momentum': four options, 0.1, 0.3, 0.6 or 0.9.\n",
    "- learning rate 'lr': three options, 1, 0.1 or 0.01.\n",
    "- dropout 'module__dropout': three options, 0.0, 0.2 or 0.5.\n",
    "- batch size 'batch_size': 16, 32 or 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network that has two hidden layers \n",
    "\n",
    "# Set number of neurons in each hidden layer equal to 3\n",
    "num_unitsA = 3\n",
    "num_unitsB = 3\n",
    "\n",
    "class NetModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_unitsA=num_unitsA,\n",
    "            num_unitsB=num_unitsB,\n",
    "            dropout=0.5\n",
    "    ):\n",
    "        super(NetModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.num_unitsA = nn.Linear(X.shape[1], num_unitsA)\n",
    "        self.num_unitsB = nn.Linear(num_unitsA, num_unitsB)\n",
    "        self.output = nn.Linear(num_unitsB, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.num_unitsA(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.relu(self.num_unitsB(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X),dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters for the neural network\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "searchNet = NeuralNetClassifier(module=NetModule, \n",
    "                    lr = 0.1, \n",
    "                    max_epochs=100,\n",
    "                    callbacks=[EarlyStopping()],        \n",
    "                    device=device,\n",
    "                    batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7095\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7667\u001b[0m  0.0199\n",
      "      2        0.7928       0.5000        \u001b[35m0.7297\u001b[0m  0.0224\n",
      "      3        0.7311       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6859\u001b[0m  0.0203\n",
      "      4        \u001b[36m0.6548\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6491\u001b[0m  0.0221\n",
      "      5        \u001b[36m0.6261\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6239\u001b[0m  0.0316\n",
      "      6        \u001b[36m0.6176\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6030\u001b[0m  0.0337\n",
      "      7        \u001b[36m0.6113\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5831\u001b[0m  0.0297\n",
      "      8        \u001b[36m0.6015\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5630\u001b[0m  0.0318\n",
      "      9        \u001b[36m0.5916\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5472\u001b[0m  0.0274\n",
      "     10        \u001b[36m0.5796\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5370\u001b[0m  0.0502\n",
      "     11        \u001b[36m0.5745\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5322\u001b[0m  0.0312\n",
      "     12        \u001b[36m0.5723\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5235\u001b[0m  0.0214\n",
      "     13        \u001b[36m0.5680\u001b[0m       0.7422        \u001b[35m0.5179\u001b[0m  0.0335\n",
      "     14        \u001b[36m0.5641\u001b[0m       0.7422        \u001b[35m0.5118\u001b[0m  0.0390\n",
      "     15        \u001b[36m0.5605\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5061\u001b[0m  0.0309\n",
      "     16        \u001b[36m0.5571\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.4993\u001b[0m  0.0354\n",
      "     17        \u001b[36m0.5542\u001b[0m       0.7578        \u001b[35m0.4930\u001b[0m  0.0217\n",
      "     18        \u001b[36m0.5507\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4877\u001b[0m  0.0248\n",
      "     19        \u001b[36m0.5483\u001b[0m       0.7656        \u001b[35m0.4845\u001b[0m  0.0524\n",
      "     20        \u001b[36m0.5454\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4818\u001b[0m  0.0985\n",
      "     21        \u001b[36m0.5436\u001b[0m       0.7734        \u001b[35m0.4775\u001b[0m  0.0397\n",
      "     22        \u001b[36m0.5396\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4742\u001b[0m  0.0448\n",
      "     23        \u001b[36m0.5380\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4700\u001b[0m  0.0589\n",
      "     24        \u001b[36m0.5333\u001b[0m       0.7734        \u001b[35m0.4689\u001b[0m  0.0429\n",
      "     25        \u001b[36m0.5316\u001b[0m       0.7578        0.4694  0.0324\n",
      "     26        \u001b[36m0.5294\u001b[0m       0.7578        \u001b[35m0.4648\u001b[0m  0.0437\n",
      "     27        \u001b[36m0.5266\u001b[0m       0.7578        \u001b[35m0.4625\u001b[0m  0.0486\n",
      "     28        \u001b[36m0.5247\u001b[0m       0.7500        \u001b[35m0.4593\u001b[0m  0.0349\n",
      "     29        \u001b[36m0.5212\u001b[0m       0.7500        \u001b[35m0.4570\u001b[0m  0.0288\n",
      "     30        \u001b[36m0.5178\u001b[0m       0.7500        \u001b[35m0.4570\u001b[0m  0.0434\n",
      "     31        \u001b[36m0.5171\u001b[0m       0.7656        \u001b[35m0.4528\u001b[0m  0.1103\n",
      "     32        \u001b[36m0.5115\u001b[0m       0.7656        0.4537  0.0403\n",
      "     33        \u001b[36m0.5090\u001b[0m       0.7578        0.4560  0.0683\n",
      "     34        \u001b[36m0.5076\u001b[0m       0.7656        0.4555  0.0470\n",
      "     35        \u001b[36m0.5065\u001b[0m       0.7656        0.4541  0.0305\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7104\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7751\u001b[0m  0.1009\n",
      "      2        0.8107       0.5000        \u001b[35m0.7238\u001b[0m  0.0925\n",
      "      3        0.7526       0.5000        \u001b[35m0.7042\u001b[0m  0.0498\n",
      "      4        \u001b[36m0.6868\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6772\u001b[0m  0.0365\n",
      "      5        \u001b[36m0.6347\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6586\u001b[0m  0.0288\n",
      "      6        \u001b[36m0.6158\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6385\u001b[0m  0.0624\n",
      "      7        \u001b[36m0.6032\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6164\u001b[0m  0.0406\n",
      "      8        \u001b[36m0.5902\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6015\u001b[0m  0.0260\n",
      "      9        \u001b[36m0.5790\u001b[0m       0.7109        \u001b[35m0.5936\u001b[0m  0.0349\n",
      "     10        \u001b[36m0.5692\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5859\u001b[0m  0.0402\n",
      "     11        \u001b[36m0.5608\u001b[0m       0.7266        \u001b[35m0.5819\u001b[0m  0.0867\n",
      "     12        \u001b[36m0.5527\u001b[0m       0.7188        \u001b[35m0.5773\u001b[0m  0.0527\n",
      "     13        \u001b[36m0.5452\u001b[0m       0.7109        \u001b[35m0.5763\u001b[0m  0.0563\n",
      "     14        \u001b[36m0.5403\u001b[0m       0.7188        \u001b[35m0.5743\u001b[0m  0.0427\n",
      "     15        \u001b[36m0.5349\u001b[0m       0.7188        \u001b[35m0.5687\u001b[0m  0.0362\n",
      "     16        \u001b[36m0.5289\u001b[0m       0.7188        \u001b[35m0.5663\u001b[0m  0.0323\n",
      "     17        \u001b[36m0.5248\u001b[0m       0.7188        \u001b[35m0.5642\u001b[0m  0.0332\n",
      "     18        \u001b[36m0.5220\u001b[0m       0.7266        \u001b[35m0.5601\u001b[0m  0.0342\n",
      "     19        \u001b[36m0.5172\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5587\u001b[0m  0.0364\n",
      "     20        \u001b[36m0.5143\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5553\u001b[0m  0.0361\n",
      "     21        \u001b[36m0.5112\u001b[0m       0.7500        \u001b[35m0.5509\u001b[0m  0.0363\n",
      "     22        \u001b[36m0.5055\u001b[0m       0.7500        0.5516  0.0340\n",
      "     23        \u001b[36m0.5048\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5486\u001b[0m  0.0381\n",
      "     24        \u001b[36m0.4985\u001b[0m       0.7500        \u001b[35m0.5451\u001b[0m  0.0369\n",
      "     25        \u001b[36m0.4964\u001b[0m       0.7578        \u001b[35m0.5423\u001b[0m  0.0271\n",
      "     26        \u001b[36m0.4932\u001b[0m       0.7578        \u001b[35m0.5394\u001b[0m  0.0271\n",
      "     27        \u001b[36m0.4901\u001b[0m       0.7500        \u001b[35m0.5374\u001b[0m  0.0411\n",
      "     28        \u001b[36m0.4849\u001b[0m       0.7578        \u001b[35m0.5348\u001b[0m  0.0397\n",
      "     29        \u001b[36m0.4835\u001b[0m       0.7500        \u001b[35m0.5324\u001b[0m  0.0301\n",
      "     30        \u001b[36m0.4813\u001b[0m       0.7422        \u001b[35m0.5309\u001b[0m  0.0282\n",
      "     31        \u001b[36m0.4787\u001b[0m       0.7422        \u001b[35m0.5302\u001b[0m  0.0299\n",
      "     32        \u001b[36m0.4765\u001b[0m       0.7500        \u001b[35m0.5290\u001b[0m  0.0428\n",
      "     33        \u001b[36m0.4756\u001b[0m       0.7578        \u001b[35m0.5277\u001b[0m  0.0397\n",
      "     34        \u001b[36m0.4731\u001b[0m       0.7578        0.5289  0.0298\n",
      "     35        \u001b[36m0.4729\u001b[0m       0.7422        0.5291  0.0295\n",
      "     36        \u001b[36m0.4716\u001b[0m       0.7344        \u001b[35m0.5263\u001b[0m  0.0470\n",
      "     37        \u001b[36m0.4694\u001b[0m       0.7500        0.5286  0.0710\n",
      "     38        \u001b[36m0.4688\u001b[0m       0.7422        0.5272  0.1392\n",
      "     39        \u001b[36m0.4674\u001b[0m       0.7500        0.5278  0.0334\n",
      "     40        \u001b[36m0.4664\u001b[0m       0.7500        \u001b[35m0.5261\u001b[0m  0.0372\n",
      "     41        \u001b[36m0.4648\u001b[0m       0.7500        0.5265  0.0381\n",
      "     42        \u001b[36m0.4640\u001b[0m       0.7500        0.5269  0.1452\n",
      "     43        \u001b[36m0.4635\u001b[0m       0.7500        0.5265  0.0380\n",
      "     44        \u001b[36m0.4624\u001b[0m       0.7500        \u001b[35m0.5244\u001b[0m  0.1143\n",
      "     45        \u001b[36m0.4620\u001b[0m       0.7500        \u001b[35m0.5240\u001b[0m  0.0924\n",
      "     46        \u001b[36m0.4605\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5236\u001b[0m  0.0471\n",
      "     47        \u001b[36m0.4599\u001b[0m       0.7656        \u001b[35m0.5230\u001b[0m  0.0294\n",
      "     48        \u001b[36m0.4592\u001b[0m       0.7656        0.5236  0.0258\n",
      "     49        \u001b[36m0.4586\u001b[0m       0.7656        0.5231  0.0267\n",
      "     50        \u001b[36m0.4584\u001b[0m       0.7656        0.5238  0.0276\n",
      "     51        \u001b[36m0.4578\u001b[0m       0.7656        0.5241  0.0362\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7460\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7506\u001b[0m  0.0406\n",
      "      2        \u001b[36m0.7396\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6675\u001b[0m  0.0300\n",
      "      3        \u001b[36m0.6469\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6286\u001b[0m  0.0330\n",
      "      4        \u001b[36m0.6047\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6106\u001b[0m  0.0283\n",
      "      5        \u001b[36m0.5857\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5934\u001b[0m  0.0466\n",
      "      6        \u001b[36m0.5680\u001b[0m       0.7266        \u001b[35m0.5785\u001b[0m  0.0658\n",
      "      7        \u001b[36m0.5547\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5691\u001b[0m  0.0520\n",
      "      8        \u001b[36m0.5463\u001b[0m       0.7500        \u001b[35m0.5610\u001b[0m  0.0506\n",
      "      9        \u001b[36m0.5394\u001b[0m       0.7500        \u001b[35m0.5593\u001b[0m  0.0488\n",
      "     10        \u001b[36m0.5356\u001b[0m       0.7500        \u001b[35m0.5561\u001b[0m  0.0798\n",
      "     11        \u001b[36m0.5304\u001b[0m       0.7422        \u001b[35m0.5550\u001b[0m  0.0416\n",
      "     12        \u001b[36m0.5254\u001b[0m       0.7500        0.5559  0.1058\n",
      "     13        \u001b[36m0.5224\u001b[0m       0.7422        0.5567  0.0446\n",
      "     14        \u001b[36m0.5185\u001b[0m       0.7266        0.5577  0.0242\n",
      "     15        \u001b[36m0.5146\u001b[0m       0.7188        0.5596  0.0316\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6763\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6730\u001b[0m  0.0308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.6358\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5999\u001b[0m  0.0378\n",
      "      3        \u001b[36m0.5616\u001b[0m       0.7422        \u001b[35m0.5759\u001b[0m  0.0626\n",
      "      4        \u001b[36m0.5478\u001b[0m       0.7344        \u001b[35m0.5705\u001b[0m  0.0674\n",
      "      5        \u001b[36m0.5340\u001b[0m       0.7344        0.5712  0.0711\n",
      "      6        \u001b[36m0.5225\u001b[0m       0.7266        0.5743  0.0558\n",
      "      7        \u001b[36m0.5144\u001b[0m       0.7344        0.5774  0.0310\n",
      "      8        \u001b[36m0.5075\u001b[0m       0.7266        0.5808  0.0404\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7563\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7320\u001b[0m  0.0351\n",
      "      2        \u001b[36m0.7374\u001b[0m       0.5000        \u001b[35m0.7077\u001b[0m  0.0998\n",
      "      3        \u001b[36m0.6810\u001b[0m       0.5000        0.7150  0.0758\n",
      "      4        \u001b[36m0.6367\u001b[0m       \u001b[32m0.6953\u001b[0m        0.7319  0.0735\n",
      "      5        \u001b[36m0.6123\u001b[0m       \u001b[32m0.7344\u001b[0m        0.7350  0.0409\n",
      "      6        \u001b[36m0.5974\u001b[0m       0.7344        0.7471  0.0366\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6988\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6910\u001b[0m  0.0547\n",
      "      2        \u001b[36m0.6953\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6878\u001b[0m  0.0550\n",
      "      3        \u001b[36m0.6932\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6845\u001b[0m  0.0304\n",
      "      4        \u001b[36m0.6918\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6814\u001b[0m  0.0294\n",
      "      5        \u001b[36m0.6891\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6786\u001b[0m  0.0273\n",
      "      6        \u001b[36m0.6824\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6754\u001b[0m  0.0288\n",
      "      7        \u001b[36m0.6801\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6724\u001b[0m  0.0295\n",
      "      8        0.6819       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6698\u001b[0m  0.0268\n",
      "      9        \u001b[36m0.6780\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6668\u001b[0m  0.0257\n",
      "     10        \u001b[36m0.6747\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6638\u001b[0m  0.0297\n",
      "     11        0.6751       0.7344        \u001b[35m0.6607\u001b[0m  0.0426\n",
      "     12        \u001b[36m0.6666\u001b[0m       0.7344        \u001b[35m0.6572\u001b[0m  0.0315\n",
      "     13        0.6679       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6535\u001b[0m  0.0306\n",
      "     14        \u001b[36m0.6643\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.6499\u001b[0m  0.0720\n",
      "     15        \u001b[36m0.6630\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.6461\u001b[0m  0.0766\n",
      "     16        \u001b[36m0.6625\u001b[0m       0.7656        \u001b[35m0.6420\u001b[0m  0.0791\n",
      "     17        \u001b[36m0.6607\u001b[0m       0.7656        \u001b[35m0.6380\u001b[0m  0.0480\n",
      "     18        \u001b[36m0.6529\u001b[0m       0.7734        \u001b[35m0.6335\u001b[0m  0.0533\n",
      "     19        0.6618       0.7734        \u001b[35m0.6295\u001b[0m  0.0421\n",
      "     20        \u001b[36m0.6443\u001b[0m       0.7344        \u001b[35m0.6241\u001b[0m  0.0429\n",
      "     21        0.6501       0.7422        \u001b[35m0.6198\u001b[0m  0.0359\n",
      "     22        \u001b[36m0.6367\u001b[0m       0.7344        \u001b[35m0.6143\u001b[0m  0.0278\n",
      "     23        0.6421       0.7344        \u001b[35m0.6095\u001b[0m  0.0298\n",
      "     24        0.6373       0.7422        \u001b[35m0.6043\u001b[0m  0.0301\n",
      "     25        \u001b[36m0.6226\u001b[0m       0.7422        \u001b[35m0.5979\u001b[0m  0.0280\n",
      "     26        0.6288       0.7422        \u001b[35m0.5923\u001b[0m  0.0281\n",
      "     27        0.6286       0.7422        \u001b[35m0.5868\u001b[0m  0.0279\n",
      "     28        0.6233       0.7500        \u001b[35m0.5814\u001b[0m  0.0331\n",
      "     29        \u001b[36m0.6076\u001b[0m       0.7500        \u001b[35m0.5746\u001b[0m  0.0510\n",
      "     30        \u001b[36m0.6050\u001b[0m       0.7578        \u001b[35m0.5683\u001b[0m  0.0513\n",
      "     31        0.6211       0.7578        \u001b[35m0.5629\u001b[0m  0.0843\n",
      "     32        \u001b[36m0.6031\u001b[0m       0.7656        \u001b[35m0.5565\u001b[0m  0.1296\n",
      "     33        \u001b[36m0.5991\u001b[0m       0.7656        \u001b[35m0.5508\u001b[0m  0.0500\n",
      "     34        0.6070       0.7656        \u001b[35m0.5456\u001b[0m  0.0530\n",
      "     35        0.6077       0.7656        \u001b[35m0.5410\u001b[0m  0.0562\n",
      "     36        0.6021       0.7656        \u001b[35m0.5365\u001b[0m  0.0653\n",
      "     37        \u001b[36m0.5867\u001b[0m       0.7656        \u001b[35m0.5314\u001b[0m  0.0652\n",
      "     38        0.5998       0.7578        \u001b[35m0.5268\u001b[0m  0.0740\n",
      "     39        \u001b[36m0.5851\u001b[0m       0.7734        \u001b[35m0.5221\u001b[0m  0.0500\n",
      "     40        \u001b[36m0.5739\u001b[0m       0.7734        \u001b[35m0.5163\u001b[0m  0.0307\n",
      "     41        0.5932       0.7734        \u001b[35m0.5126\u001b[0m  0.0291\n",
      "     42        \u001b[36m0.5714\u001b[0m       0.7734        \u001b[35m0.5078\u001b[0m  0.0280\n",
      "     43        \u001b[36m0.5592\u001b[0m       0.7734        \u001b[35m0.5026\u001b[0m  0.0292\n",
      "     44        0.5683       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4993\u001b[0m  0.0276\n",
      "     45        0.5699       0.7812        \u001b[35m0.4955\u001b[0m  0.0260\n",
      "     46        0.5731       0.7812        \u001b[35m0.4922\u001b[0m  0.0257\n",
      "     47        0.5710       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4890\u001b[0m  0.0273\n",
      "     48        \u001b[36m0.5550\u001b[0m       0.7891        \u001b[35m0.4853\u001b[0m  0.0260\n",
      "     49        0.5622       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4825\u001b[0m  0.0235\n",
      "     50        0.5569       0.8047        \u001b[35m0.4791\u001b[0m  0.0237\n",
      "     51        \u001b[36m0.5478\u001b[0m       0.8047        \u001b[35m0.4765\u001b[0m  0.0264\n",
      "     52        0.5482       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4742\u001b[0m  0.0293\n",
      "     53        0.5657       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4722\u001b[0m  0.0226\n",
      "     54        0.5689       0.8203        \u001b[35m0.4702\u001b[0m  0.0241\n",
      "     55        0.5498       0.8203        \u001b[35m0.4679\u001b[0m  0.0243\n",
      "     56        0.5486       0.8203        \u001b[35m0.4659\u001b[0m  0.0238\n",
      "     57        0.5501       \u001b[32m0.8281\u001b[0m        \u001b[35m0.4637\u001b[0m  0.0235\n",
      "     58        0.5612       0.8281        \u001b[35m0.4628\u001b[0m  0.0247\n",
      "     59        \u001b[36m0.5450\u001b[0m       0.8281        \u001b[35m0.4605\u001b[0m  0.0249\n",
      "     60        \u001b[36m0.5440\u001b[0m       0.8281        \u001b[35m0.4581\u001b[0m  0.0236\n",
      "     61        0.5681       0.8281        \u001b[35m0.4566\u001b[0m  0.0276\n",
      "     62        \u001b[36m0.5373\u001b[0m       0.8281        \u001b[35m0.4543\u001b[0m  0.0302\n",
      "     63        \u001b[36m0.5289\u001b[0m       0.8281        \u001b[35m0.4519\u001b[0m  0.0292\n",
      "     64        0.5462       0.8281        \u001b[35m0.4507\u001b[0m  0.0369\n",
      "     65        0.5411       0.8281        \u001b[35m0.4490\u001b[0m  0.0270\n",
      "     66        0.5371       0.8281        \u001b[35m0.4476\u001b[0m  0.0329\n",
      "     67        0.5436       0.8281        \u001b[35m0.4468\u001b[0m  0.0335\n",
      "     68        0.5412       0.8281        \u001b[35m0.4452\u001b[0m  0.0306\n",
      "     69        0.5400       0.8281        \u001b[35m0.4443\u001b[0m  0.0284\n",
      "     70        0.5363       0.8281        \u001b[35m0.4429\u001b[0m  0.0282\n",
      "     71        0.5437       0.8281        \u001b[35m0.4415\u001b[0m  0.0233\n",
      "     72        0.5375       0.8281        \u001b[35m0.4404\u001b[0m  0.0224\n",
      "     73        0.5510       0.8281        \u001b[35m0.4403\u001b[0m  0.0279\n",
      "     74        0.5344       0.8281        \u001b[35m0.4391\u001b[0m  0.0302\n",
      "     75        0.5294       0.8281        \u001b[35m0.4371\u001b[0m  0.0294\n",
      "     76        0.5380       0.8281        \u001b[35m0.4369\u001b[0m  0.0220\n",
      "     77        0.5435       0.8281        \u001b[35m0.4362\u001b[0m  0.0364\n",
      "     78        0.5360       0.8281        \u001b[35m0.4353\u001b[0m  0.0228\n",
      "     79        0.5382       0.8281        \u001b[35m0.4346\u001b[0m  0.0222\n",
      "     80        0.5405       0.8281        \u001b[35m0.4336\u001b[0m  0.0282\n",
      "     81        0.5474       0.8281        \u001b[35m0.4333\u001b[0m  0.0285\n",
      "     82        0.5415       0.8281        \u001b[35m0.4331\u001b[0m  0.0282\n",
      "     83        0.5378       0.8281        \u001b[35m0.4320\u001b[0m  0.0223\n",
      "     84        \u001b[36m0.5238\u001b[0m       0.8281        \u001b[35m0.4308\u001b[0m  0.0299\n",
      "     85        0.5322       0.8281        \u001b[35m0.4301\u001b[0m  0.0256\n",
      "     86        \u001b[36m0.5188\u001b[0m       0.8281        \u001b[35m0.4280\u001b[0m  0.0223\n",
      "     87        0.5378       0.8281        0.4281  0.0267\n",
      "     88        0.5552       0.8281        0.4287  0.0305\n",
      "     89        0.5333       0.8281        \u001b[35m0.4276\u001b[0m  0.0223\n",
      "     90        0.5196       0.8281        \u001b[35m0.4264\u001b[0m  0.0291\n",
      "     91        0.5383       \u001b[32m0.8359\u001b[0m        \u001b[35m0.4262\u001b[0m  0.0279\n",
      "     92        0.5405       0.8359        0.4271  0.0231\n",
      "     93        0.5249       0.8359        \u001b[35m0.4261\u001b[0m  0.0312\n",
      "     94        0.5275       0.8359        0.4262  0.0262\n",
      "     95        0.5267       0.8359        \u001b[35m0.4253\u001b[0m  0.0215\n",
      "     96        0.5438       \u001b[32m0.8438\u001b[0m        0.4263  0.0294\n",
      "     97        0.5265       0.8438        0.4260  0.0244\n",
      "     98        0.5457       0.8438        0.4266  0.0294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     99        \u001b[36m0.5059\u001b[0m       0.8438        \u001b[35m0.4243\u001b[0m  0.0282\n",
      "    100        0.5230       0.8359        \u001b[35m0.4231\u001b[0m  0.0217\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6899\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6873\u001b[0m  0.0290\n",
      "      2        \u001b[36m0.6871\u001b[0m       0.5312        \u001b[35m0.6861\u001b[0m  0.0275\n",
      "      3        0.6931       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6852\u001b[0m  0.0310\n",
      "      4        \u001b[36m0.6852\u001b[0m       0.5859        \u001b[35m0.6842\u001b[0m  0.0247\n",
      "      5        0.6855       0.5547        \u001b[35m0.6831\u001b[0m  0.0310\n",
      "      6        \u001b[36m0.6834\u001b[0m       0.5625        \u001b[35m0.6820\u001b[0m  0.0243\n",
      "      7        \u001b[36m0.6823\u001b[0m       0.5703        \u001b[35m0.6807\u001b[0m  0.0279\n",
      "      8        0.6833       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6795\u001b[0m  0.0253\n",
      "      9        0.6826       0.5938        \u001b[35m0.6782\u001b[0m  0.0279\n",
      "     10        \u001b[36m0.6798\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6768\u001b[0m  0.0248\n",
      "     11        \u001b[36m0.6776\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6752\u001b[0m  0.0291\n",
      "     12        \u001b[36m0.6718\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6734\u001b[0m  0.0295\n",
      "     13        0.6772       0.6328        \u001b[35m0.6718\u001b[0m  0.0295\n",
      "     14        \u001b[36m0.6714\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6701\u001b[0m  0.0295\n",
      "     15        \u001b[36m0.6702\u001b[0m       0.6406        \u001b[35m0.6682\u001b[0m  0.0289\n",
      "     16        \u001b[36m0.6638\u001b[0m       0.6406        \u001b[35m0.6660\u001b[0m  0.0292\n",
      "     17        0.6670       0.6406        \u001b[35m0.6638\u001b[0m  0.0308\n",
      "     18        0.6649       0.6406        \u001b[35m0.6614\u001b[0m  0.0267\n",
      "     19        \u001b[36m0.6579\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6590\u001b[0m  0.0312\n",
      "     20        0.6621       0.6484        \u001b[35m0.6567\u001b[0m  0.0748\n",
      "     21        \u001b[36m0.6545\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6541\u001b[0m  0.0433\n",
      "     22        \u001b[36m0.6483\u001b[0m       0.6562        \u001b[35m0.6511\u001b[0m  0.0430\n",
      "     23        \u001b[36m0.6460\u001b[0m       0.6562        \u001b[35m0.6480\u001b[0m  0.0439\n",
      "     24        0.6590       0.6484        \u001b[35m0.6457\u001b[0m  0.0416\n",
      "     25        \u001b[36m0.6453\u001b[0m       0.6484        \u001b[35m0.6423\u001b[0m  0.0807\n",
      "     26        \u001b[36m0.6403\u001b[0m       0.6484        \u001b[35m0.6388\u001b[0m  0.0621\n",
      "     27        0.6449       0.6484        \u001b[35m0.6359\u001b[0m  0.0498\n",
      "     28        \u001b[36m0.6375\u001b[0m       0.6562        \u001b[35m0.6326\u001b[0m  0.0596\n",
      "     29        0.6413       0.6562        \u001b[35m0.6294\u001b[0m  0.0524\n",
      "     30        0.6436       0.6562        \u001b[35m0.6267\u001b[0m  0.0767\n",
      "     31        0.6384       0.6562        \u001b[35m0.6240\u001b[0m  0.0532\n",
      "     32        \u001b[36m0.6222\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6207\u001b[0m  0.0383\n",
      "     33        \u001b[36m0.6157\u001b[0m       0.6797        \u001b[35m0.6174\u001b[0m  0.0555\n",
      "     34        0.6234       0.6797        \u001b[35m0.6145\u001b[0m  0.0262\n",
      "     35        \u001b[36m0.6126\u001b[0m       0.6797        \u001b[35m0.6114\u001b[0m  0.0317\n",
      "     36        0.6223       0.6797        \u001b[35m0.6087\u001b[0m  0.0314\n",
      "     37        \u001b[36m0.6078\u001b[0m       0.6797        \u001b[35m0.6057\u001b[0m  0.0280\n",
      "     38        \u001b[36m0.6074\u001b[0m       0.6797        \u001b[35m0.6030\u001b[0m  0.0281\n",
      "     39        0.6077       0.6797        \u001b[35m0.6006\u001b[0m  0.0325\n",
      "     40        0.6173       0.6797        \u001b[35m0.5985\u001b[0m  0.0417\n",
      "     41        \u001b[36m0.5846\u001b[0m       0.6797        \u001b[35m0.5958\u001b[0m  0.0545\n",
      "     42        0.6011       0.6797        \u001b[35m0.5935\u001b[0m  0.0620\n",
      "     43        \u001b[36m0.5828\u001b[0m       0.6797        \u001b[35m0.5910\u001b[0m  0.0701\n",
      "     44        0.6027       0.6797        \u001b[35m0.5892\u001b[0m  0.0509\n",
      "     45        0.5971       0.6797        \u001b[35m0.5874\u001b[0m  0.0478\n",
      "     46        0.5890       0.6797        \u001b[35m0.5854\u001b[0m  0.0372\n",
      "     47        0.5857       0.6797        \u001b[35m0.5837\u001b[0m  0.0277\n",
      "     48        \u001b[36m0.5821\u001b[0m       0.6797        \u001b[35m0.5819\u001b[0m  0.0281\n",
      "     49        \u001b[36m0.5687\u001b[0m       0.6797        \u001b[35m0.5802\u001b[0m  0.0254\n",
      "     50        0.5903       0.6797        \u001b[35m0.5794\u001b[0m  0.0328\n",
      "     51        0.5837       0.6797        \u001b[35m0.5781\u001b[0m  0.0396\n",
      "     52        \u001b[36m0.5587\u001b[0m       0.6797        \u001b[35m0.5768\u001b[0m  0.0862\n",
      "     53        0.5972       0.6797        \u001b[35m0.5759\u001b[0m  0.0539\n",
      "     54        0.5708       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5746\u001b[0m  0.0736\n",
      "     55        0.5828       0.6875        \u001b[35m0.5736\u001b[0m  0.0449\n",
      "     56        0.5649       0.6875        \u001b[35m0.5722\u001b[0m  0.0387\n",
      "     57        0.5776       0.6875        \u001b[35m0.5708\u001b[0m  0.0239\n",
      "     58        0.5806       0.6875        \u001b[35m0.5700\u001b[0m  0.0357\n",
      "     59        \u001b[36m0.5526\u001b[0m       0.6875        \u001b[35m0.5690\u001b[0m  0.0565\n",
      "     60        0.5903       0.6875        \u001b[35m0.5683\u001b[0m  0.0511\n",
      "     61        0.5582       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5674\u001b[0m  0.0308\n",
      "     62        \u001b[36m0.5477\u001b[0m       0.6875        \u001b[35m0.5667\u001b[0m  0.0293\n",
      "     63        0.5701       0.6875        \u001b[35m0.5659\u001b[0m  0.0280\n",
      "     64        0.5773       0.6875        \u001b[35m0.5655\u001b[0m  0.0230\n",
      "     65        0.5529       0.6797        \u001b[35m0.5651\u001b[0m  0.0281\n",
      "     66        0.5757       0.6797        \u001b[35m0.5642\u001b[0m  0.0317\n",
      "     67        0.5814       0.6719        \u001b[35m0.5637\u001b[0m  0.0313\n",
      "     68        0.5569       0.6719        \u001b[35m0.5629\u001b[0m  0.0226\n",
      "     69        0.5760       0.6719        \u001b[35m0.5624\u001b[0m  0.0326\n",
      "     70        0.5669       0.6641        \u001b[35m0.5618\u001b[0m  0.0322\n",
      "     71        0.5641       0.6641        \u001b[35m0.5612\u001b[0m  0.0266\n",
      "     72        0.5726       0.6641        \u001b[35m0.5610\u001b[0m  0.0341\n",
      "     73        0.5605       0.6641        \u001b[35m0.5606\u001b[0m  0.0302\n",
      "     74        0.5559       0.6641        \u001b[35m0.5601\u001b[0m  0.0283\n",
      "     75        0.5600       0.6641        \u001b[35m0.5598\u001b[0m  0.0306\n",
      "     76        0.5507       0.6641        \u001b[35m0.5596\u001b[0m  0.0255\n",
      "     77        \u001b[36m0.5418\u001b[0m       0.6641        \u001b[35m0.5589\u001b[0m  0.0325\n",
      "     78        0.5545       0.6641        \u001b[35m0.5586\u001b[0m  0.0257\n",
      "     79        0.5540       0.6719        \u001b[35m0.5582\u001b[0m  0.0470\n",
      "     80        0.5549       0.6719        \u001b[35m0.5579\u001b[0m  0.0325\n",
      "     81        0.5591       0.6719        \u001b[35m0.5577\u001b[0m  0.0239\n",
      "     82        0.5550       0.6719        \u001b[35m0.5572\u001b[0m  0.0327\n",
      "     83        0.5657       0.6719        \u001b[35m0.5569\u001b[0m  0.0339\n",
      "     84        0.5510       0.6719        \u001b[35m0.5567\u001b[0m  0.0298\n",
      "     85        \u001b[36m0.5388\u001b[0m       0.6719        \u001b[35m0.5560\u001b[0m  0.0325\n",
      "     86        0.5454       0.6719        \u001b[35m0.5556\u001b[0m  0.0342\n",
      "     87        0.5603       0.6719        \u001b[35m0.5554\u001b[0m  0.0328\n",
      "     88        0.5400       0.6719        \u001b[35m0.5553\u001b[0m  0.0242\n",
      "     89        0.5581       0.6719        \u001b[35m0.5552\u001b[0m  0.0326\n",
      "     90        0.5550       0.6719        \u001b[35m0.5547\u001b[0m  0.0333\n",
      "     91        \u001b[36m0.5338\u001b[0m       0.6797        \u001b[35m0.5542\u001b[0m  0.0268\n",
      "     92        0.5399       0.6797        \u001b[35m0.5541\u001b[0m  0.0343\n",
      "     93        0.5466       0.6797        \u001b[35m0.5537\u001b[0m  0.0223\n",
      "     94        0.5488       0.6797        0.5538  0.0379\n",
      "     95        0.5599       0.6797        \u001b[35m0.5535\u001b[0m  0.0318\n",
      "     96        0.5536       0.6797        \u001b[35m0.5532\u001b[0m  0.0345\n",
      "     97        0.5509       0.6797        \u001b[35m0.5530\u001b[0m  0.0271\n",
      "     98        0.5604       0.6797        \u001b[35m0.5526\u001b[0m  0.0334\n",
      "     99        0.5416       0.6797        \u001b[35m0.5524\u001b[0m  0.0247\n",
      "    100        0.5532       0.6797        \u001b[35m0.5524\u001b[0m  0.0359\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7095\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6956\u001b[0m  0.0227\n",
      "      2        \u001b[36m0.7039\u001b[0m       0.5000        \u001b[35m0.6924\u001b[0m  0.0313\n",
      "      3        \u001b[36m0.6956\u001b[0m       0.5000        \u001b[35m0.6895\u001b[0m  0.0423\n",
      "      4        0.6966       0.5000        \u001b[35m0.6867\u001b[0m  0.0297\n",
      "      5        \u001b[36m0.6924\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6841\u001b[0m  0.0491\n",
      "      6        \u001b[36m0.6898\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6817\u001b[0m  0.0326\n",
      "      7        \u001b[36m0.6853\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6791\u001b[0m  0.0375\n",
      "      8        \u001b[36m0.6835\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6763\u001b[0m  0.0314\n",
      "      9        \u001b[36m0.6770\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6734\u001b[0m  0.0304\n",
      "     10        \u001b[36m0.6756\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6704\u001b[0m  0.0271\n",
      "     11        0.6772       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6675\u001b[0m  0.0329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12        0.6763       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6648\u001b[0m  0.0301\n",
      "     13        \u001b[36m0.6660\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6616\u001b[0m  0.0286\n",
      "     14        \u001b[36m0.6604\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6582\u001b[0m  0.0316\n",
      "     15        \u001b[36m0.6553\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6544\u001b[0m  0.0288\n",
      "     16        0.6570       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6507\u001b[0m  0.0291\n",
      "     17        0.6557       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6471\u001b[0m  0.0287\n",
      "     18        \u001b[36m0.6464\u001b[0m       0.7031        \u001b[35m0.6429\u001b[0m  0.0305\n",
      "     19        0.6478       0.7031        \u001b[35m0.6388\u001b[0m  0.0296\n",
      "     20        \u001b[36m0.6389\u001b[0m       0.7031        \u001b[35m0.6342\u001b[0m  0.0313\n",
      "     21        \u001b[36m0.6323\u001b[0m       0.7109        \u001b[35m0.6294\u001b[0m  0.0308\n",
      "     22        \u001b[36m0.6242\u001b[0m       0.7031        \u001b[35m0.6245\u001b[0m  0.0301\n",
      "     23        0.6284       0.7109        \u001b[35m0.6197\u001b[0m  0.0279\n",
      "     24        \u001b[36m0.6180\u001b[0m       0.7109        \u001b[35m0.6149\u001b[0m  0.0372\n",
      "     25        \u001b[36m0.6156\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6101\u001b[0m  0.0357\n",
      "     26        \u001b[36m0.6010\u001b[0m       0.7188        \u001b[35m0.6049\u001b[0m  0.0411\n",
      "     27        \u001b[36m0.5987\u001b[0m       0.7188        \u001b[35m0.6001\u001b[0m  0.0332\n",
      "     28        0.6012       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5958\u001b[0m  0.0356\n",
      "     29        \u001b[36m0.5839\u001b[0m       0.7188        \u001b[35m0.5911\u001b[0m  0.0373\n",
      "     30        0.5884       0.7188        \u001b[35m0.5869\u001b[0m  0.0445\n",
      "     31        0.5981       0.7266        \u001b[35m0.5833\u001b[0m  0.0487\n",
      "     32        0.5929       0.7188        \u001b[35m0.5798\u001b[0m  0.0434\n",
      "     33        0.5869       0.7109        \u001b[35m0.5763\u001b[0m  0.0416\n",
      "     34        \u001b[36m0.5644\u001b[0m       0.7109        \u001b[35m0.5724\u001b[0m  0.0330\n",
      "     35        \u001b[36m0.5628\u001b[0m       0.7266        \u001b[35m0.5689\u001b[0m  0.0650\n",
      "     36        \u001b[36m0.5625\u001b[0m       0.7266        \u001b[35m0.5658\u001b[0m  0.1123\n",
      "     37        0.5670       0.7266        \u001b[35m0.5632\u001b[0m  0.0613\n",
      "     38        0.5825       0.7266        \u001b[35m0.5613\u001b[0m  0.0497\n",
      "     39        0.5713       0.7266        \u001b[35m0.5595\u001b[0m  0.0502\n",
      "     40        0.5721       0.7188        \u001b[35m0.5574\u001b[0m  0.0291\n",
      "     41        \u001b[36m0.5589\u001b[0m       0.7109        \u001b[35m0.5550\u001b[0m  0.0339\n",
      "     42        \u001b[36m0.5566\u001b[0m       0.7109        \u001b[35m0.5530\u001b[0m  0.0281\n",
      "     43        0.5584       0.7109        \u001b[35m0.5508\u001b[0m  0.0434\n",
      "     44        \u001b[36m0.5559\u001b[0m       0.7109        \u001b[35m0.5490\u001b[0m  0.0775\n",
      "     45        0.5653       0.7109        \u001b[35m0.5475\u001b[0m  0.0734\n",
      "     46        \u001b[36m0.5419\u001b[0m       0.7109        \u001b[35m0.5460\u001b[0m  0.0595\n",
      "     47        \u001b[36m0.5294\u001b[0m       0.7109        \u001b[35m0.5445\u001b[0m  0.0519\n",
      "     48        0.5524       0.7109        \u001b[35m0.5432\u001b[0m  0.0676\n",
      "     49        0.5410       0.7109        \u001b[35m0.5418\u001b[0m  0.0573\n",
      "     50        0.5468       0.7109        \u001b[35m0.5410\u001b[0m  0.0782\n",
      "     51        0.5427       0.7188        \u001b[35m0.5400\u001b[0m  0.0526\n",
      "     52        0.5403       0.7266        \u001b[35m0.5392\u001b[0m  0.0440\n",
      "     53        0.5360       0.7188        \u001b[35m0.5380\u001b[0m  0.0327\n",
      "     54        0.5324       0.7188        \u001b[35m0.5372\u001b[0m  0.0307\n",
      "     55        \u001b[36m0.5267\u001b[0m       0.7188        \u001b[35m0.5362\u001b[0m  0.0345\n",
      "     56        \u001b[36m0.5254\u001b[0m       0.7188        \u001b[35m0.5354\u001b[0m  0.0644\n",
      "     57        0.5286       0.7188        \u001b[35m0.5351\u001b[0m  0.0407\n",
      "     58        0.5259       0.7188        \u001b[35m0.5341\u001b[0m  0.0493\n",
      "     59        0.5299       0.7188        \u001b[35m0.5337\u001b[0m  0.0473\n",
      "     60        0.5338       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5332\u001b[0m  0.0397\n",
      "     61        0.5501       0.7344        \u001b[35m0.5325\u001b[0m  0.0527\n",
      "     62        0.5290       0.7266        \u001b[35m0.5323\u001b[0m  0.0349\n",
      "     63        0.5380       0.7344        0.5323  0.0352\n",
      "     64        \u001b[36m0.5182\u001b[0m       0.7344        \u001b[35m0.5321\u001b[0m  0.0383\n",
      "     65        0.5277       0.7266        \u001b[35m0.5320\u001b[0m  0.0365\n",
      "     66        \u001b[36m0.5105\u001b[0m       0.7266        \u001b[35m0.5314\u001b[0m  0.0358\n",
      "     67        0.5329       0.7344        \u001b[35m0.5309\u001b[0m  0.0300\n",
      "     68        0.5169       0.7344        \u001b[35m0.5305\u001b[0m  0.0316\n",
      "     69        0.5197       0.7344        \u001b[35m0.5301\u001b[0m  0.0304\n",
      "     70        0.5368       0.7344        \u001b[35m0.5296\u001b[0m  0.0355\n",
      "     71        0.5346       0.7344        \u001b[35m0.5295\u001b[0m  0.0318\n",
      "     72        0.5385       0.7344        \u001b[35m0.5290\u001b[0m  0.0309\n",
      "     73        0.5177       0.7344        \u001b[35m0.5285\u001b[0m  0.0273\n",
      "     74        0.5193       0.7344        \u001b[35m0.5282\u001b[0m  0.0327\n",
      "     75        \u001b[36m0.5052\u001b[0m       0.7344        \u001b[35m0.5278\u001b[0m  0.0293\n",
      "     76        0.5132       0.7344        \u001b[35m0.5277\u001b[0m  0.0307\n",
      "     77        0.5116       0.7344        \u001b[35m0.5270\u001b[0m  0.0301\n",
      "     78        \u001b[36m0.5025\u001b[0m       0.7344        \u001b[35m0.5267\u001b[0m  0.0318\n",
      "     79        0.5055       0.7266        \u001b[35m0.5264\u001b[0m  0.0286\n",
      "     80        0.5297       0.7344        \u001b[35m0.5261\u001b[0m  0.0303\n",
      "     81        0.5058       0.7344        \u001b[35m0.5254\u001b[0m  0.0295\n",
      "     82        0.5254       0.7344        0.5255  0.0378\n",
      "     83        0.5106       0.7266        \u001b[35m0.5252\u001b[0m  0.0422\n",
      "     84        0.5122       0.7344        \u001b[35m0.5249\u001b[0m  0.0498\n",
      "     85        0.5168       0.7266        0.5250  0.0417\n",
      "     86        0.5093       0.7266        0.5250  0.0447\n",
      "     87        \u001b[36m0.4987\u001b[0m       0.7266        0.5250  0.0431\n",
      "     88        0.5235       0.7266        0.5252  0.0357\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6981\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6948\u001b[0m  0.0264\n",
      "      2        \u001b[36m0.6947\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6922\u001b[0m  0.0265\n",
      "      3        0.6949       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6895\u001b[0m  0.0423\n",
      "      4        \u001b[36m0.6885\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6870\u001b[0m  0.0399\n",
      "      5        \u001b[36m0.6855\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6845\u001b[0m  0.0375\n",
      "      6        \u001b[36m0.6815\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6816\u001b[0m  0.0309\n",
      "      7        \u001b[36m0.6806\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6788\u001b[0m  0.0372\n",
      "      8        0.6812       0.6250        \u001b[35m0.6758\u001b[0m  0.0367\n",
      "      9        \u001b[36m0.6724\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6724\u001b[0m  0.0339\n",
      "     10        \u001b[36m0.6712\u001b[0m       0.6250        \u001b[35m0.6686\u001b[0m  0.0341\n",
      "     11        \u001b[36m0.6698\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6649\u001b[0m  0.0341\n",
      "     12        \u001b[36m0.6626\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6609\u001b[0m  0.0361\n",
      "     13        \u001b[36m0.6577\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6567\u001b[0m  0.0340\n",
      "     14        \u001b[36m0.6509\u001b[0m       0.6875        \u001b[35m0.6518\u001b[0m  0.0269\n",
      "     15        0.6551       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6476\u001b[0m  0.0385\n",
      "     16        \u001b[36m0.6410\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6426\u001b[0m  0.0397\n",
      "     17        0.6420       0.7188        \u001b[35m0.6378\u001b[0m  0.0314\n",
      "     18        \u001b[36m0.6344\u001b[0m       0.7109        \u001b[35m0.6325\u001b[0m  0.0338\n",
      "     19        \u001b[36m0.6302\u001b[0m       0.7188        \u001b[35m0.6271\u001b[0m  0.0349\n",
      "     20        \u001b[36m0.6231\u001b[0m       0.7031        \u001b[35m0.6219\u001b[0m  0.0329\n",
      "     21        \u001b[36m0.6141\u001b[0m       0.6953        \u001b[35m0.6162\u001b[0m  0.0307\n",
      "     22        \u001b[36m0.6125\u001b[0m       0.7031        \u001b[35m0.6109\u001b[0m  0.0314\n",
      "     23        \u001b[36m0.6025\u001b[0m       0.6953        \u001b[35m0.6054\u001b[0m  0.0291\n",
      "     24        \u001b[36m0.5942\u001b[0m       0.7031        \u001b[35m0.6000\u001b[0m  0.0311\n",
      "     25        0.6012       0.7109        \u001b[35m0.5953\u001b[0m  0.0318\n",
      "     26        \u001b[36m0.5875\u001b[0m       0.6953        \u001b[35m0.5903\u001b[0m  0.0320\n",
      "     27        0.5887       0.7031        \u001b[35m0.5859\u001b[0m  0.0349\n",
      "     28        \u001b[36m0.5772\u001b[0m       0.7109        \u001b[35m0.5815\u001b[0m  0.0294\n",
      "     29        0.5774       0.7109        \u001b[35m0.5773\u001b[0m  0.0309\n",
      "     30        \u001b[36m0.5733\u001b[0m       0.7188        \u001b[35m0.5738\u001b[0m  0.0329\n",
      "     31        \u001b[36m0.5589\u001b[0m       0.7188        \u001b[35m0.5704\u001b[0m  0.0307\n",
      "     32        \u001b[36m0.5551\u001b[0m       0.7188        \u001b[35m0.5670\u001b[0m  0.0321\n",
      "     33        0.5610       0.7188        \u001b[35m0.5641\u001b[0m  0.0327\n",
      "     34        \u001b[36m0.5499\u001b[0m       0.7188        \u001b[35m0.5617\u001b[0m  0.0241\n",
      "     35        0.5552       0.7188        \u001b[35m0.5595\u001b[0m  0.0317\n",
      "     36        \u001b[36m0.5494\u001b[0m       0.7188        \u001b[35m0.5577\u001b[0m  0.0292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     37        0.5500       0.7188        \u001b[35m0.5558\u001b[0m  0.0311\n",
      "     38        0.5705       0.7188        \u001b[35m0.5545\u001b[0m  0.0279\n",
      "     39        \u001b[36m0.5393\u001b[0m       0.7109        \u001b[35m0.5529\u001b[0m  0.0287\n",
      "     40        0.5401       0.7109        \u001b[35m0.5515\u001b[0m  0.0301\n",
      "     41        0.5431       0.7109        \u001b[35m0.5503\u001b[0m  0.0326\n",
      "     42        0.5416       0.7031        \u001b[35m0.5492\u001b[0m  0.0279\n",
      "     43        0.5429       0.7109        \u001b[35m0.5484\u001b[0m  0.0285\n",
      "     44        \u001b[36m0.5267\u001b[0m       0.7031        \u001b[35m0.5477\u001b[0m  0.0246\n",
      "     45        0.5308       0.7188        \u001b[35m0.5468\u001b[0m  0.0295\n",
      "     46        \u001b[36m0.5210\u001b[0m       0.7188        \u001b[35m0.5464\u001b[0m  0.0247\n",
      "     47        0.5303       0.7188        \u001b[35m0.5455\u001b[0m  0.0255\n",
      "     48        0.5397       0.7188        \u001b[35m0.5451\u001b[0m  0.0276\n",
      "     49        0.5348       0.7188        \u001b[35m0.5447\u001b[0m  0.0290\n",
      "     50        0.5301       0.7188        \u001b[35m0.5442\u001b[0m  0.0318\n",
      "     51        \u001b[36m0.5137\u001b[0m       0.7188        \u001b[35m0.5441\u001b[0m  0.0293\n",
      "     52        \u001b[36m0.5030\u001b[0m       0.7188        \u001b[35m0.5438\u001b[0m  0.0285\n",
      "     53        0.5313       0.7188        \u001b[35m0.5434\u001b[0m  0.0230\n",
      "     54        0.5051       0.7188        \u001b[35m0.5432\u001b[0m  0.0250\n",
      "     55        0.5206       0.7109        \u001b[35m0.5429\u001b[0m  0.0250\n",
      "     56        0.5241       0.7109        \u001b[35m0.5424\u001b[0m  0.0274\n",
      "     57        0.5371       0.7109        \u001b[35m0.5419\u001b[0m  0.0287\n",
      "     58        0.5217       0.7109        \u001b[35m0.5416\u001b[0m  0.0316\n",
      "     59        0.5076       0.7031        0.5416  0.0279\n",
      "     60        0.5328       0.7031        \u001b[35m0.5412\u001b[0m  0.0266\n",
      "     61        0.5179       0.7031        \u001b[35m0.5406\u001b[0m  0.0304\n",
      "     62        0.5261       0.6953        0.5406  0.0328\n",
      "     63        0.5108       0.6953        \u001b[35m0.5403\u001b[0m  0.0240\n",
      "     64        0.5329       0.6953        \u001b[35m0.5403\u001b[0m  0.0275\n",
      "     65        0.5268       0.7031        \u001b[35m0.5402\u001b[0m  0.0335\n",
      "     66        0.5091       0.6953        \u001b[35m0.5399\u001b[0m  0.0333\n",
      "     67        \u001b[36m0.5011\u001b[0m       0.6953        0.5402  0.0512\n",
      "     68        0.5117       0.6953        0.5401  0.0477\n",
      "     69        0.5144       0.6875        0.5400  0.0444\n",
      "     70        0.5159       0.6875        0.5400  0.0430\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6893\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6757\u001b[0m  0.0293\n",
      "      2        \u001b[36m0.6859\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6699\u001b[0m  0.0381\n",
      "      3        \u001b[36m0.6726\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6651\u001b[0m  0.0481\n",
      "      4        \u001b[36m0.6721\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6612\u001b[0m  0.0416\n",
      "      5        \u001b[36m0.6661\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6573\u001b[0m  0.0270\n",
      "      6        \u001b[36m0.6626\u001b[0m       0.7109        \u001b[35m0.6537\u001b[0m  0.0275\n",
      "      7        \u001b[36m0.6612\u001b[0m       0.7109        \u001b[35m0.6503\u001b[0m  0.0551\n",
      "      8        \u001b[36m0.6533\u001b[0m       0.7031        \u001b[35m0.6464\u001b[0m  0.0733\n",
      "      9        \u001b[36m0.6456\u001b[0m       0.6953        \u001b[35m0.6418\u001b[0m  0.0364\n",
      "     10        \u001b[36m0.6354\u001b[0m       0.6875        \u001b[35m0.6368\u001b[0m  0.0299\n",
      "     11        0.6422       0.6875        \u001b[35m0.6321\u001b[0m  0.0370\n",
      "     12        0.6392       0.7031        \u001b[35m0.6281\u001b[0m  0.0368\n",
      "     13        \u001b[36m0.6324\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6237\u001b[0m  0.0335\n",
      "     14        \u001b[36m0.6214\u001b[0m       0.7266        \u001b[35m0.6180\u001b[0m  0.0304\n",
      "     15        \u001b[36m0.6176\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6120\u001b[0m  0.0746\n",
      "     16        0.6235       0.7344        \u001b[35m0.6070\u001b[0m  0.1154\n",
      "     17        \u001b[36m0.6048\u001b[0m       0.7344        \u001b[35m0.6008\u001b[0m  0.0762\n",
      "     18        0.6095       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5956\u001b[0m  0.0838\n",
      "     19        0.6060       0.7500        \u001b[35m0.5906\u001b[0m  0.0885\n",
      "     20        \u001b[36m0.6009\u001b[0m       0.7500        \u001b[35m0.5856\u001b[0m  0.0613\n",
      "     21        \u001b[36m0.5772\u001b[0m       0.7344        \u001b[35m0.5795\u001b[0m  0.0456\n",
      "     22        0.5840       0.7344        \u001b[35m0.5740\u001b[0m  0.0363\n",
      "     23        0.5897       0.7500        \u001b[35m0.5697\u001b[0m  0.0251\n",
      "     24        0.5836       0.7266        \u001b[35m0.5650\u001b[0m  0.0413\n",
      "     25        \u001b[36m0.5687\u001b[0m       0.7344        \u001b[35m0.5603\u001b[0m  0.0458\n",
      "     26        \u001b[36m0.5635\u001b[0m       0.7344        \u001b[35m0.5562\u001b[0m  0.0518\n",
      "     27        0.5638       0.7422        \u001b[35m0.5523\u001b[0m  0.0343\n",
      "     28        \u001b[36m0.5514\u001b[0m       0.7344        \u001b[35m0.5486\u001b[0m  0.0321\n",
      "     29        \u001b[36m0.5428\u001b[0m       0.7266        \u001b[35m0.5451\u001b[0m  0.0362\n",
      "     30        0.5536       0.7344        \u001b[35m0.5430\u001b[0m  0.0548\n",
      "     31        0.5491       0.7344        \u001b[35m0.5412\u001b[0m  0.0380\n",
      "     32        0.5440       0.7344        \u001b[35m0.5386\u001b[0m  0.0337\n",
      "     33        \u001b[36m0.5393\u001b[0m       0.7344        \u001b[35m0.5371\u001b[0m  0.0372\n",
      "     34        \u001b[36m0.5373\u001b[0m       0.7422        \u001b[35m0.5355\u001b[0m  0.0263\n",
      "     35        \u001b[36m0.5336\u001b[0m       0.7422        \u001b[35m0.5338\u001b[0m  0.0484\n",
      "     36        0.5493       0.7422        \u001b[35m0.5330\u001b[0m  0.0335\n",
      "     37        0.5469       0.7422        \u001b[35m0.5323\u001b[0m  0.0318\n",
      "     38        \u001b[36m0.5296\u001b[0m       0.7422        \u001b[35m0.5311\u001b[0m  0.0379\n",
      "     39        0.5446       0.7422        \u001b[35m0.5306\u001b[0m  0.0327\n",
      "     40        0.5353       0.7422        \u001b[35m0.5299\u001b[0m  0.0239\n",
      "     41        0.5350       0.7422        \u001b[35m0.5298\u001b[0m  0.0413\n",
      "     42        \u001b[36m0.5249\u001b[0m       0.7422        \u001b[35m0.5291\u001b[0m  0.0529\n",
      "     43        0.5303       0.7344        0.5293  0.0388\n",
      "     44        \u001b[36m0.5128\u001b[0m       0.7344        \u001b[35m0.5287\u001b[0m  0.0350\n",
      "     45        0.5223       0.7344        \u001b[35m0.5278\u001b[0m  0.0258\n",
      "     46        0.5129       0.7344        \u001b[35m0.5275\u001b[0m  0.0317\n",
      "     47        0.5384       0.7266        0.5277  0.0326\n",
      "     48        0.5215       0.7266        0.5276  0.0237\n",
      "     49        \u001b[36m0.5126\u001b[0m       0.7344        \u001b[35m0.5270\u001b[0m  0.0245\n",
      "     50        0.5257       0.7266        0.5271  0.0343\n",
      "     51        0.5285       0.7266        0.5272  0.0261\n",
      "     52        \u001b[36m0.5122\u001b[0m       0.7266        \u001b[35m0.5270\u001b[0m  0.0334\n",
      "     53        0.5281       0.7266        \u001b[35m0.5268\u001b[0m  0.0306\n",
      "     54        0.5193       0.7266        \u001b[35m0.5267\u001b[0m  0.0284\n",
      "     55        0.5367       0.7188        0.5267  0.0308\n",
      "     56        0.5271       0.7266        \u001b[35m0.5262\u001b[0m  0.0310\n",
      "     57        0.5292       0.7188        \u001b[35m0.5259\u001b[0m  0.0471\n",
      "     58        0.5434       0.7188        0.5261  0.0931\n",
      "     59        \u001b[36m0.5081\u001b[0m       0.7188        0.5261  0.0476\n",
      "     60        0.5202       0.7188        0.5262  0.0368\n",
      "     61        0.5094       0.7188        \u001b[35m0.5258\u001b[0m  0.0307\n",
      "     62        0.5344       0.7188        0.5258  0.0244\n",
      "     63        0.5168       0.7188        \u001b[35m0.5256\u001b[0m  0.0391\n",
      "     64        0.5139       0.7109        \u001b[35m0.5254\u001b[0m  0.0276\n",
      "     65        0.5303       0.7109        \u001b[35m0.5253\u001b[0m  0.0359\n",
      "     66        0.5081       0.7109        \u001b[35m0.5251\u001b[0m  0.0251\n",
      "     67        0.5301       0.7188        0.5251  0.0314\n",
      "     68        0.5180       0.7188        \u001b[35m0.5247\u001b[0m  0.0267\n",
      "     69        0.5449       0.7188        0.5248  0.0340\n",
      "     70        0.5154       0.7188        0.5248  0.0218\n",
      "     71        \u001b[36m0.4955\u001b[0m       0.7188        0.5249  0.0229\n",
      "     72        0.5114       0.7188        \u001b[35m0.5247\u001b[0m  0.0353\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6203\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.2798\u001b[0m  0.0422\n",
      "      2        1.9584       0.5000        2.3151  0.0673\n",
      "      3        2.1618       0.5000        \u001b[35m2.1613\u001b[0m  0.0375\n",
      "      4        2.8824       0.5000        4.7268  0.0498\n",
      "      5        2.2541       0.5000        2.2883  0.0372\n",
      "      6        2.0720       0.5000        2.2310  0.0381\n",
      "      7        2.0856       0.5000        2.2123  0.0382\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5927\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.7873\u001b[0m  0.0657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        2.1868       0.5000        \u001b[35m2.0949\u001b[0m  0.0638\n",
      "      3        2.0714       0.5000        2.1375  0.0552\n",
      "      4        2.2521       0.5000        \u001b[35m2.0062\u001b[0m  0.0584\n",
      "      5        2.9651       \u001b[32m0.6953\u001b[0m        \u001b[35m1.0533\u001b[0m  0.0524\n",
      "      6        1.5928       0.6094        1.6323  0.0486\n",
      "      7        1.6261       0.6250        1.7459  0.0435\n",
      "      8        1.9988       0.6719        1.8434  0.0378\n",
      "      9        2.5423       \u001b[32m0.7266\u001b[0m        2.0581  0.0406\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8123\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.1636\u001b[0m  0.0401\n",
      "      2        0.8877       \u001b[32m0.5078\u001b[0m        1.4444  0.0506\n",
      "      3        0.9176       \u001b[32m0.5547\u001b[0m        \u001b[35m1.0885\u001b[0m  0.0456\n",
      "      4        0.8830       \u001b[32m0.6016\u001b[0m        1.1735  0.0473\n",
      "      5        0.9867       0.5000        1.7826  0.0432\n",
      "      6        1.0276       0.5703        1.1484  0.0548\n",
      "      7        1.6694       \u001b[32m0.7422\u001b[0m        1.2263  0.0412\n",
      "      8        1.2675       0.5781        \u001b[35m1.0241\u001b[0m  0.0410\n",
      "      9        1.0082       0.5781        1.1828  0.0607\n",
      "     10        1.0916       0.6016        1.0614  0.0439\n",
      "     11        1.0795       0.6875        \u001b[35m0.8757\u001b[0m  0.0655\n",
      "     12        1.0958       0.6719        0.9517  0.1094\n",
      "     13        1.0870       0.6641        0.9496  0.0469\n",
      "     14        1.0355       0.6875        0.9553  0.0643\n",
      "     15        1.0149       0.6875        \u001b[35m0.8468\u001b[0m  0.0888\n",
      "     16        1.0332       0.6797        0.8617  0.0719\n",
      "     17        1.0003       0.6875        0.9228  0.0879\n",
      "     18        1.0547       0.6797        0.8664  0.0765\n",
      "     19        0.9995       0.6797        0.9719  0.0532\n",
      "     20        1.0244       0.6484        \u001b[35m0.8301\u001b[0m  0.0411\n",
      "     21        1.0269       0.6797        0.8473  0.0422\n",
      "     22        1.0335       0.7031        0.9262  0.0458\n",
      "     23        0.9945       0.6875        0.8317  0.0538\n",
      "     24        0.9800       0.6875        0.9499  0.0420\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7113\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8374\u001b[0m  0.0751\n",
      "      2        0.8417       0.5000        0.8491  0.0423\n",
      "      3        0.9749       0.5000        \u001b[35m0.8117\u001b[0m  0.0412\n",
      "      4        0.8269       0.5000        1.0875  0.0475\n",
      "      5        0.9504       0.5000        1.3322  0.0698\n",
      "      6        0.9492       0.5000        1.0314  0.0568\n",
      "      7        0.9409       0.5000        1.1601  0.0394\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5438\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.6484\u001b[0m  0.0342\n",
      "      2        0.9893       0.5000        2.0153  0.0376\n",
      "      3        1.2880       0.5000        2.0518  0.0450\n",
      "      4        1.6161       0.5000        1.9269  0.0381\n",
      "      5        1.5991       0.5000        1.9040  0.0508\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.3064\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.5967\u001b[0m  0.0555\n",
      "      2        0.4845       0.5000        1.6936  0.0418\n",
      "      3        0.5150       0.5000        1.6936  0.0415\n",
      "      4        0.5150       0.5000        1.6936  0.0366\n",
      "      5        0.5150       0.5000        1.6936  0.0535\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.3803\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.0147\u001b[0m  0.0510\n",
      "      2        0.4846       0.5000        \u001b[35m1.6935\u001b[0m  0.0385\n",
      "      3        0.4760       0.5000        \u001b[35m1.6933\u001b[0m  0.0481\n",
      "      4        0.4693       0.5000        \u001b[35m1.6567\u001b[0m  0.0432\n",
      "      5        \u001b[36m0.3474\u001b[0m       0.5000        \u001b[35m1.6093\u001b[0m  0.0607\n",
      "      6        0.3737       0.5000        \u001b[35m1.5017\u001b[0m  0.0424\n",
      "      7        0.3740       0.5000        1.7006  0.0486\n",
      "      8        0.4264       0.5000        1.6760  0.0445\n",
      "      9        0.4383       \u001b[32m0.5781\u001b[0m        \u001b[35m1.3940\u001b[0m  0.0359\n",
      "     10        0.3916       \u001b[32m0.5938\u001b[0m        \u001b[35m1.3010\u001b[0m  0.0434\n",
      "     11        0.3900       \u001b[32m0.6094\u001b[0m        \u001b[35m1.2560\u001b[0m  0.0484\n",
      "     12        0.4004       \u001b[32m0.6172\u001b[0m        \u001b[35m1.2174\u001b[0m  0.0413\n",
      "     13        0.3865       0.6172        1.2245  0.0474\n",
      "     14        0.3899       0.6172        \u001b[35m1.2111\u001b[0m  0.0361\n",
      "     15        0.4113       0.6016        1.2289  0.0444\n",
      "     16        0.3770       0.6016        \u001b[35m1.2032\u001b[0m  0.0400\n",
      "     17        0.3733       0.6094        \u001b[35m1.2009\u001b[0m  0.0367\n",
      "     18        0.3719       0.5391        1.3170  0.0581\n",
      "     19        0.3796       0.6172        1.2071  0.0360\n",
      "     20        0.3771       0.6016        1.2517  0.0361\n",
      "     21        0.3738       0.6094        1.2161  0.0402\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5190\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.7065\u001b[0m  0.0370\n",
      "      2        0.5745       0.5000        \u001b[35m1.6994\u001b[0m  0.0423\n",
      "      3        0.5713       0.5000        2.0980  0.1034\n",
      "      4        0.5787       0.5000        \u001b[35m1.6196\u001b[0m  0.0393\n",
      "      5        0.5379       0.5000        1.6921  0.0437\n",
      "      6        0.5278       0.5000        1.7680  0.0439\n",
      "      7        0.5206       0.5000        1.7074  0.0429\n",
      "      8        \u001b[36m0.5076\u001b[0m       0.5000        1.6989  0.0353\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4413\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.3587\u001b[0m  0.0327\n",
      "      2        0.4645       0.5000        \u001b[35m1.3027\u001b[0m  0.0901\n",
      "      3        0.4535       \u001b[32m0.5469\u001b[0m        \u001b[35m1.2430\u001b[0m  0.1928\n",
      "      4        \u001b[36m0.4397\u001b[0m       0.5391        1.2840  0.1369\n",
      "      5        0.4430       0.5391        1.3348  0.0908\n",
      "      6        \u001b[36m0.4311\u001b[0m       0.5391        1.3317  0.0556\n",
      "      7        \u001b[36m0.4288\u001b[0m       0.5391        1.3209  0.0412\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4261\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.1936\u001b[0m  0.0620\n",
      "      2        0.4963       0.5000        \u001b[35m1.5954\u001b[0m  0.0627\n",
      "      3        0.4814       0.5000        1.6256  0.0538\n",
      "      4        0.4818       0.5000        1.6213  0.0676\n",
      "      5        0.4681       0.5000        \u001b[35m1.5950\u001b[0m  0.0701\n",
      "      6        0.4512       0.5000        \u001b[35m1.5705\u001b[0m  0.0757\n",
      "      7        0.4394       0.5000        \u001b[35m1.5598\u001b[0m  0.0435\n",
      "      8        \u001b[36m0.4236\u001b[0m       0.5000        1.5780  0.0660\n",
      "      9        \u001b[36m0.4202\u001b[0m       0.5000        \u001b[35m1.5502\u001b[0m  0.0766\n",
      "     10        \u001b[36m0.4190\u001b[0m       0.5000        1.5615  0.0920\n",
      "     11        0.4225       0.5000        1.5640  0.0637\n",
      "     12        \u001b[36m0.4063\u001b[0m       0.5000        1.5554  0.0574\n",
      "     13        0.4116       0.5000        \u001b[35m1.5037\u001b[0m  0.0574\n",
      "     14        \u001b[36m0.3954\u001b[0m       0.5000        1.5265  0.0911\n",
      "     15        0.3962       0.5000        \u001b[35m1.4510\u001b[0m  0.0869\n",
      "     16        \u001b[36m0.3874\u001b[0m       0.5000        1.4975  0.0902\n",
      "     17        0.4127       \u001b[32m0.5078\u001b[0m        \u001b[35m1.4117\u001b[0m  0.0689\n",
      "     18        0.3925       0.5000        1.4781  0.0463\n",
      "     19        0.4339       \u001b[32m0.5234\u001b[0m        1.4976  0.0634\n",
      "     20        0.3926       \u001b[32m0.5312\u001b[0m        \u001b[35m1.3190\u001b[0m  0.0596\n",
      "     21        \u001b[36m0.3775\u001b[0m       0.5234        1.4230  0.0572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22        \u001b[36m0.3676\u001b[0m       0.5312        1.3665  0.0817\n",
      "     23        \u001b[36m0.3641\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m1.2860\u001b[0m  0.0726\n",
      "     24        \u001b[36m0.3506\u001b[0m       0.5156        1.4372  0.0361\n",
      "     25        \u001b[36m0.3391\u001b[0m       0.5547        1.3864  0.0372\n",
      "     26        0.3749       0.5234        1.3706  0.0470\n",
      "     27        0.3668       0.5391        1.4433  0.0562\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5184\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.0336\u001b[0m  0.0630\n",
      "      2        0.6162       0.5000        \u001b[35m0.9486\u001b[0m  0.0827\n",
      "      3        0.5797       0.5000        \u001b[35m0.9344\u001b[0m  0.0690\n",
      "      4        0.5994       \u001b[32m0.5156\u001b[0m        \u001b[35m0.8921\u001b[0m  0.0421\n",
      "      5        0.5843       0.5156        \u001b[35m0.8566\u001b[0m  0.0503\n",
      "      6        0.5393       \u001b[32m0.5703\u001b[0m        \u001b[35m0.8353\u001b[0m  0.0431\n",
      "      7        0.5435       0.5234        0.8628  0.1757\n",
      "      8        0.5618       \u001b[32m0.5859\u001b[0m        \u001b[35m0.7830\u001b[0m  0.1236\n",
      "      9        \u001b[36m0.5122\u001b[0m       0.5156        0.8710  0.0807\n",
      "     10        0.5679       0.5156        0.8613  0.1247\n",
      "     11        0.5624       0.5703        0.7971  0.0814\n",
      "     12        0.5286       0.5781        0.7984  0.0914\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5173\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.0571\u001b[0m  0.1281\n",
      "      2        0.6570       0.5000        \u001b[35m0.9570\u001b[0m  0.1623\n",
      "      3        0.5584       0.5000        \u001b[35m0.9476\u001b[0m  0.0938\n",
      "      4        0.5669       \u001b[32m0.5391\u001b[0m        \u001b[35m0.8716\u001b[0m  0.0565\n",
      "      5        0.5281       0.5391        0.8779  0.0522\n",
      "      6        0.5297       0.5391        0.8782  0.0403\n",
      "      7        0.5468       \u001b[32m0.5859\u001b[0m        \u001b[35m0.8228\u001b[0m  0.0492\n",
      "      8        \u001b[36m0.5171\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.8030\u001b[0m  0.0419\n",
      "      9        0.5200       0.5938        0.8264  0.0395\n",
      "     10        0.5312       0.5859        0.8323  0.0633\n",
      "     11        0.5354       \u001b[32m0.6094\u001b[0m        \u001b[35m0.7947\u001b[0m  0.0507\n",
      "     12        \u001b[36m0.5045\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.7376\u001b[0m  0.0435\n",
      "     13        0.5292       0.5938        0.8203  0.0389\n",
      "     14        0.5199       0.6406        0.7646  0.0473\n",
      "     15        0.5072       0.6406        0.7825  0.0381\n",
      "     16        0.5296       0.6484        0.7423  0.0426\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6976\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8864\u001b[0m  0.0523\n",
      "      2        0.7489       0.5000        \u001b[35m0.8526\u001b[0m  0.0449\n",
      "      3        \u001b[36m0.6566\u001b[0m       0.5000        0.8957  0.0487\n",
      "      4        \u001b[36m0.6458\u001b[0m       0.5000        \u001b[35m0.8397\u001b[0m  0.0510\n",
      "      5        \u001b[36m0.5946\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.8332\u001b[0m  0.0572\n",
      "      6        \u001b[36m0.5657\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.8037\u001b[0m  0.0384\n",
      "      7        \u001b[36m0.5596\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.8024\u001b[0m  0.0383\n",
      "      8        0.5874       \u001b[32m0.6016\u001b[0m        \u001b[35m0.7548\u001b[0m  0.0648\n",
      "      9        \u001b[36m0.5523\u001b[0m       \u001b[32m0.6406\u001b[0m        0.7649  0.0562\n",
      "     10        \u001b[36m0.5442\u001b[0m       0.6250        0.7651  0.0612\n",
      "     11        0.5475       \u001b[32m0.6641\u001b[0m        \u001b[35m0.7179\u001b[0m  0.0632\n",
      "     12        \u001b[36m0.5185\u001b[0m       0.6641        0.7442  0.0488\n",
      "     13        \u001b[36m0.5157\u001b[0m       0.6172        0.7490  0.0377\n",
      "     14        0.5481       0.6406        0.7469  0.0388\n",
      "     15        0.5418       0.6562        0.7307  0.0504\n",
      "     16        \u001b[36m0.4961\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.7091\u001b[0m  0.0446\n",
      "     17        0.4967       0.6562        0.7205  0.0464\n",
      "     18        0.5248       0.6562        0.7185  0.0415\n",
      "     19        0.5140       0.6719        \u001b[35m0.7011\u001b[0m  0.0385\n",
      "     20        0.5161       0.6562        \u001b[35m0.6985\u001b[0m  0.0413\n",
      "     21        0.5063       0.6484        0.7329  0.0494\n",
      "     22        0.5052       0.6641        \u001b[35m0.6933\u001b[0m  0.0442\n",
      "     23        0.5096       0.6719        0.7064  0.0432\n",
      "     24        0.5027       0.6719        0.7324  0.0381\n",
      "     25        0.5079       0.6406        0.7162  0.0392\n",
      "     26        0.5109       0.6719        0.7191  0.0419\n",
      "     27        \u001b[36m0.4943\u001b[0m       0.6797        \u001b[35m0.6670\u001b[0m  0.0512\n",
      "     28        \u001b[36m0.4799\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6653\u001b[0m  0.0438\n",
      "     29        0.4912       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6397\u001b[0m  0.0474\n",
      "     30        0.4963       0.6719        0.6797  0.0442\n",
      "     31        0.4825       0.6719        0.6548  0.0459\n",
      "     32        0.4820       0.6719        0.6861  0.0419\n",
      "     33        0.5000       0.6484        0.7436  0.0411\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6460\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8076\u001b[0m  0.0599\n",
      "      2        \u001b[36m0.6407\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.7539\u001b[0m  0.0838\n",
      "      3        \u001b[36m0.5750\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.7307\u001b[0m  0.0586\n",
      "      4        0.5788       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6961\u001b[0m  0.0623\n",
      "      5        \u001b[36m0.5537\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6925\u001b[0m  0.0465\n",
      "      6        \u001b[36m0.5390\u001b[0m       0.6797        \u001b[35m0.6541\u001b[0m  0.0462\n",
      "      7        0.5556       0.6719        \u001b[35m0.6534\u001b[0m  0.0670\n",
      "      8        \u001b[36m0.5245\u001b[0m       0.6641        0.6711  0.0892\n",
      "      9        0.5441       0.6797        \u001b[35m0.6450\u001b[0m  0.0726\n",
      "     10        0.5250       0.6797        \u001b[35m0.6355\u001b[0m  0.0490\n",
      "     11        \u001b[36m0.5065\u001b[0m       \u001b[32m0.6953\u001b[0m        0.6386  0.0434\n",
      "     12        0.5184       0.6953        0.6421  0.0398\n",
      "     13        0.5219       0.6875        \u001b[35m0.6220\u001b[0m  0.0635\n",
      "     14        \u001b[36m0.4883\u001b[0m       0.6641        0.6222  0.0566\n",
      "     15        0.5059       0.6797        0.6240  0.0472\n",
      "     16        0.5062       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6040\u001b[0m  0.0446\n",
      "     17        0.5027       0.6719        0.6338  0.0391\n",
      "     18        0.4987       0.6875        0.6174  0.0430\n",
      "     19        0.4988       0.6797        0.6147  0.0429\n",
      "     20        0.5010       0.7031        \u001b[35m0.5973\u001b[0m  0.0452\n",
      "     21        \u001b[36m0.4763\u001b[0m       0.6875        \u001b[35m0.5913\u001b[0m  0.0963\n",
      "     22        0.5267       0.6641        0.6107  0.0393\n",
      "     23        0.4904       0.6953        0.6011  0.0408\n",
      "     24        0.4959       0.6641        0.6135  0.0580\n",
      "     25        0.5079       0.6797        0.6010  0.0508\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5058\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.2085\u001b[0m  0.0448\n",
      "      2        0.5485       0.5000        \u001b[35m0.9435\u001b[0m  0.0602\n",
      "      3        0.5193       \u001b[32m0.5391\u001b[0m        \u001b[35m0.8804\u001b[0m  0.0466\n",
      "      4        \u001b[36m0.5043\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.8051\u001b[0m  0.0503\n",
      "      5        \u001b[36m0.4882\u001b[0m       0.6484        \u001b[35m0.7682\u001b[0m  0.0408\n",
      "      6        0.4890       0.6328        0.7919  0.0440\n",
      "      7        \u001b[36m0.4818\u001b[0m       0.6328        0.7798  0.0457\n",
      "      8        \u001b[36m0.4598\u001b[0m       \u001b[32m0.6562\u001b[0m        0.7724  0.0567\n",
      "      9        0.4793       0.6562        \u001b[35m0.7602\u001b[0m  0.0463\n",
      "     10        0.4761       0.6562        \u001b[35m0.7456\u001b[0m  0.0385\n",
      "     11        \u001b[36m0.4563\u001b[0m       0.6562        0.7685  0.0542\n",
      "     12        \u001b[36m0.4367\u001b[0m       0.6562        \u001b[35m0.7183\u001b[0m  0.0479\n",
      "     13        0.4569       0.6562        0.7567  0.0476\n",
      "     14        0.4712       \u001b[32m0.6719\u001b[0m        0.7361  0.0591\n",
      "     15        0.4738       0.6641        0.7727  0.0446\n",
      "     16        0.4388       0.6562        \u001b[35m0.7094\u001b[0m  0.0500\n",
      "     17        0.4808       0.6562        0.7494  0.0425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        0.4516       0.6562        0.7145  0.0483\n",
      "     19        0.4392       0.6641        0.7341  0.0546\n",
      "     20        0.4532       \u001b[32m0.6797\u001b[0m        0.7183  0.0463\n",
      "     21        0.4587       0.6797        \u001b[35m0.6977\u001b[0m  0.0744\n",
      "     22        0.4593       0.6719        \u001b[35m0.6882\u001b[0m  0.0561\n",
      "     23        0.4457       0.6719        0.7227  0.0615\n",
      "     24        0.4549       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6684\u001b[0m  0.0543\n",
      "     25        \u001b[36m0.4366\u001b[0m       0.6797        0.7104  0.0572\n",
      "     26        0.4600       0.6641        0.7236  0.0615\n",
      "     27        0.4606       0.6875        0.6921  0.0669\n",
      "     28        0.4592       0.6641        0.7115  0.0526\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7156\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7030\u001b[0m  0.0361\n",
      "      2        \u001b[36m0.7018\u001b[0m       0.5000        \u001b[35m0.6865\u001b[0m  0.0406\n",
      "      3        \u001b[36m0.6831\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6782\u001b[0m  0.0398\n",
      "      4        \u001b[36m0.6772\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6722\u001b[0m  0.0606\n",
      "      5        0.6798       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6678\u001b[0m  0.0359\n",
      "      6        0.6776       0.6875        \u001b[35m0.6650\u001b[0m  0.0402\n",
      "      7        0.6823       0.6719        \u001b[35m0.6625\u001b[0m  0.0389\n",
      "      8        \u001b[36m0.6730\u001b[0m       0.6719        \u001b[35m0.6579\u001b[0m  0.0557\n",
      "      9        0.6766       0.6875        \u001b[35m0.6561\u001b[0m  0.0360\n",
      "     10        \u001b[36m0.6667\u001b[0m       0.6875        \u001b[35m0.6523\u001b[0m  0.0401\n",
      "     11        0.6729       0.6953        \u001b[35m0.6488\u001b[0m  0.0386\n",
      "     12        \u001b[36m0.6623\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6435\u001b[0m  0.0387\n",
      "     13        \u001b[36m0.6617\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6394\u001b[0m  0.0456\n",
      "     14        0.6684       0.7266        \u001b[35m0.6371\u001b[0m  0.0380\n",
      "     15        \u001b[36m0.6593\u001b[0m       0.7266        \u001b[35m0.6326\u001b[0m  0.0586\n",
      "     16        \u001b[36m0.6527\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6272\u001b[0m  0.0424\n",
      "     17        0.6580       0.7344        \u001b[35m0.6225\u001b[0m  0.0540\n",
      "     18        \u001b[36m0.6523\u001b[0m       0.7266        \u001b[35m0.6183\u001b[0m  0.1030\n",
      "     19        0.6579       0.7266        \u001b[35m0.6143\u001b[0m  0.0770\n",
      "     20        0.6632       0.7266        \u001b[35m0.6115\u001b[0m  0.0599\n",
      "     21        \u001b[36m0.6444\u001b[0m       0.7266        \u001b[35m0.6067\u001b[0m  0.0603\n",
      "     22        0.6582       0.7344        \u001b[35m0.6044\u001b[0m  0.0529\n",
      "     23        0.6569       0.7266        \u001b[35m0.6035\u001b[0m  0.0816\n",
      "     24        \u001b[36m0.6408\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6000\u001b[0m  0.0413\n",
      "     25        0.6506       0.7500        \u001b[35m0.5941\u001b[0m  0.0712\n",
      "     26        0.6461       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5921\u001b[0m  0.0528\n",
      "     27        \u001b[36m0.6296\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5866\u001b[0m  0.0446\n",
      "     28        0.6515       0.7656        \u001b[35m0.5854\u001b[0m  0.0410\n",
      "     29        0.6554       0.7656        \u001b[35m0.5849\u001b[0m  0.0473\n",
      "     30        0.6341       0.7656        \u001b[35m0.5790\u001b[0m  0.0443\n",
      "     31        0.6306       0.7656        \u001b[35m0.5749\u001b[0m  0.0466\n",
      "     32        0.6497       0.7656        0.5750  0.0638\n",
      "     33        \u001b[36m0.6203\u001b[0m       0.7656        \u001b[35m0.5678\u001b[0m  0.0410\n",
      "     34        0.6468       0.7656        0.5679  0.0487\n",
      "     35        0.6318       0.7656        \u001b[35m0.5630\u001b[0m  0.0485\n",
      "     36        \u001b[36m0.6176\u001b[0m       0.7656        \u001b[35m0.5567\u001b[0m  0.0499\n",
      "     37        0.6228       0.7656        \u001b[35m0.5528\u001b[0m  0.0459\n",
      "     38        \u001b[36m0.6148\u001b[0m       0.7656        \u001b[35m0.5505\u001b[0m  0.0579\n",
      "     39        0.6547       0.7656        0.5510  0.0565\n",
      "     40        0.6321       0.7656        \u001b[35m0.5463\u001b[0m  0.0670\n",
      "     41        0.6314       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5437\u001b[0m  0.0863\n",
      "     42        0.6498       0.7734        0.5453  0.0638\n",
      "     43        0.6194       0.7734        \u001b[35m0.5431\u001b[0m  0.0778\n",
      "     44        0.6364       0.7734        \u001b[35m0.5393\u001b[0m  0.0722\n",
      "     45        \u001b[36m0.6093\u001b[0m       0.7734        \u001b[35m0.5345\u001b[0m  0.0591\n",
      "     46        0.6205       \u001b[32m0.7812\u001b[0m        \u001b[35m0.5309\u001b[0m  0.0852\n",
      "     47        0.6134       0.7812        \u001b[35m0.5270\u001b[0m  0.0555\n",
      "     48        0.6246       0.7812        \u001b[35m0.5245\u001b[0m  0.0681\n",
      "     49        \u001b[36m0.6035\u001b[0m       0.7812        \u001b[35m0.5199\u001b[0m  0.0653\n",
      "     50        0.6169       0.7812        \u001b[35m0.5161\u001b[0m  0.1291\n",
      "     51        0.6294       0.7812        \u001b[35m0.5131\u001b[0m  0.0669\n",
      "     52        0.6339       0.7812        0.5137  0.0661\n",
      "     53        0.6226       0.7812        \u001b[35m0.5108\u001b[0m  0.0710\n",
      "     54        0.6145       \u001b[32m0.7891\u001b[0m        \u001b[35m0.5041\u001b[0m  0.0597\n",
      "     55        0.6268       0.7891        \u001b[35m0.5031\u001b[0m  0.0568\n",
      "     56        0.6112       0.7812        \u001b[35m0.5031\u001b[0m  0.0582\n",
      "     57        0.6120       0.7891        \u001b[35m0.4993\u001b[0m  0.0504\n",
      "     58        0.6095       0.7891        \u001b[35m0.4980\u001b[0m  0.0638\n",
      "     59        0.6221       0.7891        0.4981  0.0567\n",
      "     60        \u001b[36m0.6011\u001b[0m       0.7891        \u001b[35m0.4945\u001b[0m  0.0563\n",
      "     61        0.6026       0.7891        \u001b[35m0.4921\u001b[0m  0.0588\n",
      "     62        \u001b[36m0.5882\u001b[0m       0.7891        \u001b[35m0.4857\u001b[0m  0.0630\n",
      "     63        0.5934       0.7891        \u001b[35m0.4810\u001b[0m  0.0561\n",
      "     64        0.6232       0.7891        0.4876  0.0565\n",
      "     65        0.6103       0.7891        0.4859  0.0560\n",
      "     66        0.6230       \u001b[32m0.7969\u001b[0m        0.4891  0.0551\n",
      "     67        \u001b[36m0.5708\u001b[0m       0.7969        0.4824  0.0551\n",
      "     68        0.5896       0.7969        \u001b[35m0.4795\u001b[0m  0.0550\n",
      "     69        0.5963       0.7891        \u001b[35m0.4763\u001b[0m  0.0681\n",
      "     70        0.5814       0.7891        \u001b[35m0.4731\u001b[0m  0.0564\n",
      "     71        0.5854       0.7891        \u001b[35m0.4697\u001b[0m  0.0550\n",
      "     72        0.5758       0.7891        \u001b[35m0.4675\u001b[0m  0.0716\n",
      "     73        0.6035       0.7891        0.4689  0.0516\n",
      "     74        0.6123       0.7891        0.4687  0.0520\n",
      "     75        \u001b[36m0.5610\u001b[0m       0.7891        \u001b[35m0.4638\u001b[0m  0.0679\n",
      "     76        0.6028       0.7891        0.4655  0.0653\n",
      "     77        0.5689       0.7891        \u001b[35m0.4633\u001b[0m  0.0500\n",
      "     78        0.5722       0.7891        \u001b[35m0.4615\u001b[0m  0.0407\n",
      "     79        0.5806       0.7891        0.4617  0.0487\n",
      "     80        0.6105       0.7891        0.4666  0.0484\n",
      "     81        0.5903       0.7891        0.4631  0.0607\n",
      "     82        0.5981       0.7891        0.4649  0.0492\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7372\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7069\u001b[0m  0.0546\n",
      "      2        \u001b[36m0.7124\u001b[0m       0.5000        \u001b[35m0.6942\u001b[0m  0.0588\n",
      "      3        \u001b[36m0.7013\u001b[0m       0.5000        \u001b[35m0.6892\u001b[0m  0.0508\n",
      "      4        0.7050       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6868\u001b[0m  0.0670\n",
      "      5        \u001b[36m0.6851\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6852\u001b[0m  0.0653\n",
      "      6        0.6932       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6850\u001b[0m  0.0665\n",
      "      7        0.6930       0.6484        \u001b[35m0.6847\u001b[0m  0.0667\n",
      "      8        0.6889       0.6094        \u001b[35m0.6837\u001b[0m  0.0519\n",
      "      9        \u001b[36m0.6830\u001b[0m       0.6094        \u001b[35m0.6820\u001b[0m  0.0623\n",
      "     10        0.6854       0.5938        \u001b[35m0.6814\u001b[0m  0.0634\n",
      "     11        0.6866       0.5781        \u001b[35m0.6813\u001b[0m  0.0687\n",
      "     12        \u001b[36m0.6732\u001b[0m       0.6094        \u001b[35m0.6785\u001b[0m  0.0643\n",
      "     13        0.6826       0.6250        \u001b[35m0.6771\u001b[0m  0.0603\n",
      "     14        0.6851       0.6328        \u001b[35m0.6761\u001b[0m  0.0463\n",
      "     15        0.6815       0.6250        \u001b[35m0.6753\u001b[0m  0.0457\n",
      "     16        0.6766       0.6562        \u001b[35m0.6731\u001b[0m  0.0561\n",
      "     17        \u001b[36m0.6711\u001b[0m       0.6797        \u001b[35m0.6696\u001b[0m  0.0618\n",
      "     18        \u001b[36m0.6677\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6663\u001b[0m  0.0599\n",
      "     19        \u001b[36m0.6675\u001b[0m       0.6953        \u001b[35m0.6637\u001b[0m  0.0634\n",
      "     20        \u001b[36m0.6651\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6607\u001b[0m  0.0677\n",
      "     21        \u001b[36m0.6506\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6562\u001b[0m  0.0550\n",
      "     22        0.6557       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6540\u001b[0m  0.0490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     23        0.6642       0.7344        \u001b[35m0.6528\u001b[0m  0.0477\n",
      "     24        0.6515       0.7188        \u001b[35m0.6488\u001b[0m  0.0508\n",
      "     25        \u001b[36m0.6496\u001b[0m       0.7344        \u001b[35m0.6467\u001b[0m  0.0507\n",
      "     26        0.6557       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6456\u001b[0m  0.0559\n",
      "     27        0.6618       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6450\u001b[0m  0.0543\n",
      "     28        \u001b[36m0.6439\u001b[0m       0.7500        \u001b[35m0.6425\u001b[0m  0.0492\n",
      "     29        0.6626       0.7266        \u001b[35m0.6393\u001b[0m  0.0464\n",
      "     30        0.6644       0.7344        \u001b[35m0.6377\u001b[0m  0.0510\n",
      "     31        0.6665       0.7344        \u001b[35m0.6372\u001b[0m  0.0407\n",
      "     32        \u001b[36m0.6362\u001b[0m       0.7422        \u001b[35m0.6327\u001b[0m  0.0383\n",
      "     33        0.6440       0.7422        \u001b[35m0.6305\u001b[0m  0.0378\n",
      "     34        0.6465       0.7422        \u001b[35m0.6294\u001b[0m  0.0417\n",
      "     35        0.6363       0.7422        \u001b[35m0.6262\u001b[0m  0.0606\n",
      "     36        \u001b[36m0.6269\u001b[0m       0.7500        \u001b[35m0.6228\u001b[0m  0.0371\n",
      "     37        0.6453       0.7500        \u001b[35m0.6210\u001b[0m  0.0368\n",
      "     38        \u001b[36m0.6255\u001b[0m       0.7500        \u001b[35m0.6174\u001b[0m  0.0490\n",
      "     39        0.6360       0.7500        \u001b[35m0.6168\u001b[0m  0.0601\n",
      "     40        0.6378       0.7500        \u001b[35m0.6168\u001b[0m  0.0459\n",
      "     41        0.6640       0.7500        0.6192  0.0441\n",
      "     42        0.6284       0.7500        \u001b[35m0.6163\u001b[0m  0.0420\n",
      "     43        0.6422       0.7422        0.6170  0.0387\n",
      "     44        \u001b[36m0.6223\u001b[0m       0.7500        \u001b[35m0.6139\u001b[0m  0.0378\n",
      "     45        0.6272       0.7500        \u001b[35m0.6117\u001b[0m  0.0393\n",
      "     46        0.6291       0.7500        \u001b[35m0.6102\u001b[0m  0.0381\n",
      "     47        \u001b[36m0.6178\u001b[0m       0.7500        \u001b[35m0.6064\u001b[0m  0.0402\n",
      "     48        0.6249       0.7500        \u001b[35m0.6057\u001b[0m  0.0366\n",
      "     49        \u001b[36m0.6076\u001b[0m       0.7500        \u001b[35m0.6047\u001b[0m  0.0442\n",
      "     50        0.6288       0.7500        \u001b[35m0.6032\u001b[0m  0.0363\n",
      "     51        0.6149       0.7500        \u001b[35m0.6019\u001b[0m  0.0399\n",
      "     52        0.6323       0.7422        \u001b[35m0.5991\u001b[0m  0.0376\n",
      "     53        0.6387       0.7422        0.6002  0.0367\n",
      "     54        0.6307       0.7422        \u001b[35m0.5981\u001b[0m  0.0368\n",
      "     55        0.6496       0.7500        0.6007  0.0358\n",
      "     56        0.6195       0.7500        0.5982  0.0364\n",
      "     57        0.6186       0.7422        \u001b[35m0.5938\u001b[0m  0.0371\n",
      "     58        0.6169       0.7422        \u001b[35m0.5927\u001b[0m  0.0360\n",
      "     59        0.6179       0.7422        \u001b[35m0.5915\u001b[0m  0.0424\n",
      "     60        0.6237       0.7422        \u001b[35m0.5900\u001b[0m  0.0358\n",
      "     61        0.6291       0.7422        0.5940  0.0362\n",
      "     62        0.6307       0.7422        0.5965  0.0396\n",
      "     63        0.6185       0.7500        0.5941  0.0387\n",
      "     64        0.6329       0.7422        0.5942  0.0422\n",
      "     65        \u001b[36m0.6058\u001b[0m       0.7422        \u001b[35m0.5896\u001b[0m  0.0366\n",
      "     66        0.6138       0.7422        \u001b[35m0.5891\u001b[0m  0.0364\n",
      "     67        0.6156       0.7422        \u001b[35m0.5889\u001b[0m  0.0357\n",
      "     68        0.6144       0.7422        \u001b[35m0.5888\u001b[0m  0.0358\n",
      "     69        \u001b[36m0.6011\u001b[0m       0.7422        0.5891  0.0360\n",
      "     70        0.6210       0.7422        \u001b[35m0.5879\u001b[0m  0.0370\n",
      "     71        0.6176       0.7344        \u001b[35m0.5836\u001b[0m  0.0358\n",
      "     72        \u001b[36m0.5962\u001b[0m       0.7422        \u001b[35m0.5822\u001b[0m  0.0387\n",
      "     73        \u001b[36m0.5914\u001b[0m       0.7500        \u001b[35m0.5797\u001b[0m  0.0501\n",
      "     74        0.6035       0.7422        \u001b[35m0.5759\u001b[0m  0.0446\n",
      "     75        0.5931       0.7344        \u001b[35m0.5751\u001b[0m  0.0357\n",
      "     76        0.6020       0.7422        \u001b[35m0.5729\u001b[0m  0.0512\n",
      "     77        0.6028       0.7422        \u001b[35m0.5722\u001b[0m  0.0372\n",
      "     78        0.6148       0.7422        \u001b[35m0.5682\u001b[0m  0.0448\n",
      "     79        \u001b[36m0.5908\u001b[0m       0.7422        \u001b[35m0.5650\u001b[0m  0.0361\n",
      "     80        0.6061       0.7422        0.5655  0.0362\n",
      "     81        0.6179       0.7422        0.5674  0.0360\n",
      "     82        0.5957       0.7422        0.5653  0.0365\n",
      "     83        \u001b[36m0.5881\u001b[0m       0.7422        \u001b[35m0.5643\u001b[0m  0.0362\n",
      "     84        0.5954       0.7422        \u001b[35m0.5631\u001b[0m  0.0359\n",
      "     85        0.6110       0.7422        0.5645  0.0384\n",
      "     86        0.6172       0.7344        0.5658  0.0446\n",
      "     87        0.5971       0.7344        0.5666  0.0367\n",
      "     88        0.6034       0.7344        0.5647  0.0361\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7454\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7182\u001b[0m  0.0339\n",
      "      2        \u001b[36m0.7158\u001b[0m       0.5000        \u001b[35m0.7000\u001b[0m  0.0471\n",
      "      3        \u001b[36m0.6930\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6851\u001b[0m  0.0413\n",
      "      4        \u001b[36m0.6789\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6757\u001b[0m  0.0423\n",
      "      5        \u001b[36m0.6760\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6688\u001b[0m  0.0379\n",
      "      6        \u001b[36m0.6718\u001b[0m       0.5938        \u001b[35m0.6643\u001b[0m  0.0385\n",
      "      7        \u001b[36m0.6690\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6597\u001b[0m  0.0415\n",
      "      8        \u001b[36m0.6625\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6544\u001b[0m  0.0371\n",
      "      9        0.6713       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6502\u001b[0m  0.0415\n",
      "     10        0.6741       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6486\u001b[0m  0.0365\n",
      "     11        \u001b[36m0.6622\u001b[0m       0.6875        \u001b[35m0.6447\u001b[0m  0.0429\n",
      "     12        \u001b[36m0.6621\u001b[0m       0.6875        \u001b[35m0.6408\u001b[0m  0.0408\n",
      "     13        0.6646       0.6797        \u001b[35m0.6372\u001b[0m  0.0522\n",
      "     14        \u001b[36m0.6610\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6334\u001b[0m  0.0469\n",
      "     15        \u001b[36m0.6609\u001b[0m       0.6797        \u001b[35m0.6287\u001b[0m  0.0498\n",
      "     16        \u001b[36m0.6488\u001b[0m       0.6719        \u001b[35m0.6237\u001b[0m  0.0441\n",
      "     17        0.6554       0.6875        \u001b[35m0.6210\u001b[0m  0.0426\n",
      "     18        \u001b[36m0.6395\u001b[0m       0.6953        \u001b[35m0.6170\u001b[0m  0.0471\n",
      "     19        0.6417       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6139\u001b[0m  0.0441\n",
      "     20        \u001b[36m0.6352\u001b[0m       0.6953        \u001b[35m0.6122\u001b[0m  0.0451\n",
      "     21        0.6388       0.7031        \u001b[35m0.6080\u001b[0m  0.0422\n",
      "     22        \u001b[36m0.6325\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6045\u001b[0m  0.0442\n",
      "     23        0.6376       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6001\u001b[0m  0.0466\n",
      "     24        0.6426       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5985\u001b[0m  0.0375\n",
      "     25        0.6350       0.7266        \u001b[35m0.5968\u001b[0m  0.0531\n",
      "     26        0.6431       0.7188        \u001b[35m0.5951\u001b[0m  0.0466\n",
      "     27        0.6357       0.7188        \u001b[35m0.5929\u001b[0m  0.0534\n",
      "     28        0.6385       0.7188        \u001b[35m0.5922\u001b[0m  0.0492\n",
      "     29        \u001b[36m0.6249\u001b[0m       0.7188        \u001b[35m0.5905\u001b[0m  0.0379\n",
      "     30        \u001b[36m0.6096\u001b[0m       0.7109        \u001b[35m0.5857\u001b[0m  0.0378\n",
      "     31        0.6580       0.7031        0.5872  0.0372\n",
      "     32        0.6200       0.7031        \u001b[35m0.5840\u001b[0m  0.0399\n",
      "     33        0.6347       0.7109        \u001b[35m0.5837\u001b[0m  0.0468\n",
      "     34        0.6348       0.7109        \u001b[35m0.5830\u001b[0m  0.0468\n",
      "     35        0.6276       0.7188        \u001b[35m0.5815\u001b[0m  0.0458\n",
      "     36        0.6363       0.7109        \u001b[35m0.5810\u001b[0m  0.0455\n",
      "     37        0.6294       0.7109        \u001b[35m0.5803\u001b[0m  0.0471\n",
      "     38        0.6185       0.7109        \u001b[35m0.5773\u001b[0m  0.0466\n",
      "     39        0.6224       0.7109        \u001b[35m0.5763\u001b[0m  0.0474\n",
      "     40        0.6267       0.7109        0.5772  0.0435\n",
      "     41        0.6107       0.7188        \u001b[35m0.5752\u001b[0m  0.0396\n",
      "     42        \u001b[36m0.5828\u001b[0m       0.7188        \u001b[35m0.5693\u001b[0m  0.0385\n",
      "     43        0.6068       0.7188        \u001b[35m0.5679\u001b[0m  0.0388\n",
      "     44        0.5830       0.7266        \u001b[35m0.5636\u001b[0m  0.0466\n",
      "     45        0.6160       0.7188        \u001b[35m0.5626\u001b[0m  0.0443\n",
      "     46        0.6083       0.7188        \u001b[35m0.5610\u001b[0m  0.0436\n",
      "     47        0.5997       0.7188        \u001b[35m0.5598\u001b[0m  0.0375\n",
      "     48        0.5939       0.7031        \u001b[35m0.5581\u001b[0m  0.0413\n",
      "     49        0.6082       0.7188        \u001b[35m0.5571\u001b[0m  0.0406\n",
      "     50        0.5996       0.7266        0.5579  0.0569\n",
      "     51        0.6104       0.7188        \u001b[35m0.5568\u001b[0m  0.0481\n",
      "     52        0.5979       0.7266        \u001b[35m0.5554\u001b[0m  0.0542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     53        0.6152       \u001b[32m0.7344\u001b[0m        0.5576  0.0465\n",
      "     54        0.6149       0.7188        0.5592  0.0502\n",
      "     55        0.6143       0.7344        0.5601  0.0399\n",
      "     56        0.6267       \u001b[32m0.7422\u001b[0m        0.5616  0.0402\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7542\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6851\u001b[0m  0.0417\n",
      "      2        \u001b[36m0.6939\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6700\u001b[0m  0.0572\n",
      "      3        \u001b[36m0.6758\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6622\u001b[0m  0.0475\n",
      "      4        \u001b[36m0.6677\u001b[0m       0.6562        \u001b[35m0.6565\u001b[0m  0.0460\n",
      "      5        \u001b[36m0.6672\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6504\u001b[0m  0.0423\n",
      "      6        \u001b[36m0.6514\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6438\u001b[0m  0.0516\n",
      "      7        0.6832       0.6875        \u001b[35m0.6422\u001b[0m  0.0398\n",
      "      8        \u001b[36m0.6443\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6334\u001b[0m  0.0451\n",
      "      9        0.6459       0.6953        \u001b[35m0.6273\u001b[0m  0.0374\n",
      "     10        \u001b[36m0.6314\u001b[0m       0.6953        \u001b[35m0.6213\u001b[0m  0.0404\n",
      "     11        0.6461       0.7031        \u001b[35m0.6176\u001b[0m  0.0468\n",
      "     12        \u001b[36m0.6157\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6108\u001b[0m  0.0369\n",
      "     13        \u001b[36m0.6121\u001b[0m       0.7109        \u001b[35m0.6045\u001b[0m  0.0399\n",
      "     14        0.6266       0.7031        \u001b[35m0.5993\u001b[0m  0.0465\n",
      "     15        0.6127       0.7188        \u001b[35m0.5970\u001b[0m  0.0398\n",
      "     16        0.6224       0.7188        \u001b[35m0.5943\u001b[0m  0.0489\n",
      "     17        0.6203       0.7188        \u001b[35m0.5924\u001b[0m  0.0507\n",
      "     18        0.6145       0.7188        \u001b[35m0.5903\u001b[0m  0.0522\n",
      "     19        0.6169       0.7188        \u001b[35m0.5881\u001b[0m  0.0483\n",
      "     20        \u001b[36m0.6073\u001b[0m       0.7109        \u001b[35m0.5851\u001b[0m  0.0665\n",
      "     21        0.6200       0.7188        \u001b[35m0.5841\u001b[0m  0.0536\n",
      "     22        \u001b[36m0.6017\u001b[0m       0.7188        \u001b[35m0.5805\u001b[0m  0.0445\n",
      "     23        0.6117       0.7188        \u001b[35m0.5796\u001b[0m  0.0715\n",
      "     24        0.6171       0.7188        \u001b[35m0.5769\u001b[0m  0.0528\n",
      "     25        0.6120       0.7109        \u001b[35m0.5757\u001b[0m  0.0573\n",
      "     26        \u001b[36m0.5836\u001b[0m       0.7109        \u001b[35m0.5703\u001b[0m  0.0439\n",
      "     27        0.5913       0.7109        \u001b[35m0.5686\u001b[0m  0.0450\n",
      "     28        0.5955       0.7031        \u001b[35m0.5655\u001b[0m  0.0384\n",
      "     29        0.5952       0.7031        \u001b[35m0.5643\u001b[0m  0.0468\n",
      "     30        0.6096       0.7031        0.5643  0.0384\n",
      "     31        0.6026       0.7109        0.5659  0.0385\n",
      "     32        0.5924       0.7109        \u001b[35m0.5641\u001b[0m  0.0551\n",
      "     33        0.6135       0.7109        \u001b[35m0.5619\u001b[0m  0.0386\n",
      "     34        0.6189       0.7188        0.5631  0.0430\n",
      "     35        \u001b[36m0.5760\u001b[0m       0.7109        \u001b[35m0.5613\u001b[0m  0.0382\n",
      "     36        0.6007       0.7109        \u001b[35m0.5586\u001b[0m  0.0449\n",
      "     37        0.5833       0.7109        \u001b[35m0.5566\u001b[0m  0.0380\n",
      "     38        0.6025       0.7031        0.5569  0.0403\n",
      "     39        0.5943       0.7031        \u001b[35m0.5555\u001b[0m  0.0417\n",
      "     40        0.6104       \u001b[32m0.7266\u001b[0m        0.5570  0.0373\n",
      "     41        0.5878       0.7031        \u001b[35m0.5554\u001b[0m  0.0404\n",
      "     42        0.5783       0.7031        \u001b[35m0.5521\u001b[0m  0.0414\n",
      "     43        0.5773       0.7031        \u001b[35m0.5492\u001b[0m  0.0400\n",
      "     44        0.5768       0.7031        \u001b[35m0.5478\u001b[0m  0.0443\n",
      "     45        0.6077       0.7031        0.5495  0.0492\n",
      "     46        0.5906       0.7109        \u001b[35m0.5476\u001b[0m  0.0436\n",
      "     47        0.5872       0.7031        \u001b[35m0.5456\u001b[0m  0.0405\n",
      "     48        0.6003       0.6953        0.5464  0.0455\n",
      "     49        0.5939       0.7031        0.5476  0.0391\n",
      "     50        \u001b[36m0.5570\u001b[0m       0.6953        \u001b[35m0.5445\u001b[0m  0.0486\n",
      "     51        0.5670       0.6953        \u001b[35m0.5432\u001b[0m  0.0391\n",
      "     52        0.5780       0.6953        0.5435  0.0375\n",
      "     53        0.5905       0.6953        0.5433  0.0488\n",
      "     54        0.5655       0.6953        \u001b[35m0.5430\u001b[0m  0.0504\n",
      "     55        0.5814       0.6953        \u001b[35m0.5424\u001b[0m  0.0428\n",
      "     56        0.5936       0.6953        0.5425  0.0358\n",
      "     57        0.5666       0.6953        \u001b[35m0.5414\u001b[0m  0.0378\n",
      "     58        0.5868       0.6953        0.5417  0.0359\n",
      "     59        0.5800       0.6953        0.5425  0.0362\n",
      "     60        0.5583       0.6953        0.5434  0.0368\n",
      "     61        0.5732       0.6953        0.5423  0.0362\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7068\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7056\u001b[0m  0.0329\n",
      "      2        \u001b[36m0.7046\u001b[0m       0.5000        \u001b[35m0.6983\u001b[0m  0.0355\n",
      "      3        \u001b[36m0.6909\u001b[0m       0.5000        \u001b[35m0.6940\u001b[0m  0.0388\n",
      "      4        \u001b[36m0.6828\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6902\u001b[0m  0.0413\n",
      "      5        0.6913       0.5312        \u001b[35m0.6874\u001b[0m  0.0396\n",
      "      6        \u001b[36m0.6767\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6840\u001b[0m  0.0422\n",
      "      7        \u001b[36m0.6627\u001b[0m       0.5391        \u001b[35m0.6803\u001b[0m  0.0359\n",
      "      8        0.6718       0.5547        \u001b[35m0.6773\u001b[0m  0.0425\n",
      "      9        0.6718       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6744\u001b[0m  0.0359\n",
      "     10        0.6681       0.5703        \u001b[35m0.6709\u001b[0m  0.0403\n",
      "     11        \u001b[36m0.6602\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6680\u001b[0m  0.0359\n",
      "     12        \u001b[36m0.6599\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6637\u001b[0m  0.0404\n",
      "     13        0.6604       0.6094        \u001b[35m0.6593\u001b[0m  0.0437\n",
      "     14        0.6670       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6569\u001b[0m  0.0447\n",
      "     15        \u001b[36m0.6498\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6520\u001b[0m  0.0517\n",
      "     16        0.6617       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6502\u001b[0m  0.0394\n",
      "     17        0.6603       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6480\u001b[0m  0.0444\n",
      "     18        0.6571       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6451\u001b[0m  0.0355\n",
      "     19        0.6507       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6407\u001b[0m  0.0364\n",
      "     20        0.6704       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6376\u001b[0m  0.0453\n",
      "     21        \u001b[36m0.6487\u001b[0m       0.6797        \u001b[35m0.6345\u001b[0m  0.0358\n",
      "     22        0.6581       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6327\u001b[0m  0.0366\n",
      "     23        \u001b[36m0.6334\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6276\u001b[0m  0.0401\n",
      "     24        0.6434       0.7031        \u001b[35m0.6258\u001b[0m  0.0360\n",
      "     25        0.6426       0.6953        \u001b[35m0.6217\u001b[0m  0.0373\n",
      "     26        \u001b[36m0.6310\u001b[0m       0.6953        \u001b[35m0.6174\u001b[0m  0.0466\n",
      "     27        0.6317       0.6953        \u001b[35m0.6145\u001b[0m  0.0406\n",
      "     28        \u001b[36m0.6287\u001b[0m       0.6953        \u001b[35m0.6124\u001b[0m  0.0371\n",
      "     29        0.6485       0.6953        \u001b[35m0.6121\u001b[0m  0.0375\n",
      "     30        0.6508       0.7031        \u001b[35m0.6117\u001b[0m  0.0415\n",
      "     31        0.6463       0.7031        \u001b[35m0.6115\u001b[0m  0.0363\n",
      "     32        0.6383       0.7031        \u001b[35m0.6107\u001b[0m  0.0368\n",
      "     33        \u001b[36m0.6259\u001b[0m       0.7031        \u001b[35m0.6048\u001b[0m  0.0365\n",
      "     34        0.6627       0.7031        0.6055  0.0404\n",
      "     35        \u001b[36m0.6064\u001b[0m       0.6953        \u001b[35m0.6014\u001b[0m  0.0414\n",
      "     36        0.6185       0.7031        \u001b[35m0.5986\u001b[0m  0.0376\n",
      "     37        0.6361       0.7031        \u001b[35m0.5963\u001b[0m  0.0417\n",
      "     38        0.6333       0.7031        \u001b[35m0.5941\u001b[0m  0.0368\n",
      "     39        0.6179       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5925\u001b[0m  0.0359\n",
      "     40        0.6268       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5909\u001b[0m  0.0361\n",
      "     41        0.6331       0.7109        0.5921  0.0369\n",
      "     42        0.6236       0.7109        \u001b[35m0.5903\u001b[0m  0.0384\n",
      "     43        0.6160       0.7188        \u001b[35m0.5883\u001b[0m  0.0382\n",
      "     44        0.6160       0.7109        0.5883  0.0397\n",
      "     45        0.6310       0.7188        \u001b[35m0.5881\u001b[0m  0.0391\n",
      "     46        0.6184       0.7188        \u001b[35m0.5868\u001b[0m  0.0389\n",
      "     47        \u001b[36m0.6054\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5824\u001b[0m  0.0407\n",
      "     48        0.6206       0.7188        \u001b[35m0.5810\u001b[0m  0.0368\n",
      "     49        0.6200       0.7188        0.5812  0.0361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     50        0.6135       0.7188        \u001b[35m0.5800\u001b[0m  0.0361\n",
      "     51        0.6174       0.7188        0.5802  0.0348\n",
      "     52        0.6188       0.7109        \u001b[35m0.5781\u001b[0m  0.0401\n",
      "     53        \u001b[36m0.5933\u001b[0m       0.7031        \u001b[35m0.5745\u001b[0m  0.0360\n",
      "     54        \u001b[36m0.5874\u001b[0m       0.7031        \u001b[35m0.5721\u001b[0m  0.0358\n",
      "     55        0.5921       0.7031        \u001b[35m0.5692\u001b[0m  0.0362\n",
      "     56        0.6086       0.6953        \u001b[35m0.5677\u001b[0m  0.0357\n",
      "     57        0.5895       0.7266        0.5679  0.0361\n",
      "     58        0.6075       0.7188        0.5678  0.0467\n",
      "     59        0.5932       0.7266        \u001b[35m0.5650\u001b[0m  0.0358\n",
      "     60        0.6096       0.7266        0.5651  0.0356\n",
      "     61        0.5983       0.7266        \u001b[35m0.5643\u001b[0m  0.0358\n",
      "     62        0.6051       0.7266        \u001b[35m0.5640\u001b[0m  0.0357\n",
      "     63        0.5879       0.7266        \u001b[35m0.5618\u001b[0m  0.0358\n",
      "     64        0.6072       0.7266        0.5622  0.0357\n",
      "     65        0.5916       0.7266        \u001b[35m0.5611\u001b[0m  0.0381\n",
      "     66        \u001b[36m0.5788\u001b[0m       0.7266        \u001b[35m0.5587\u001b[0m  0.0434\n",
      "     67        0.5875       0.7266        \u001b[35m0.5579\u001b[0m  0.0536\n",
      "     68        0.5951       0.7266        \u001b[35m0.5565\u001b[0m  0.0494\n",
      "     69        0.5888       0.7188        \u001b[35m0.5553\u001b[0m  0.0443\n",
      "     70        0.5967       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5549\u001b[0m  0.0416\n",
      "     71        0.5906       0.7031        \u001b[35m0.5548\u001b[0m  0.0361\n",
      "     72        0.6008       0.7188        0.5553  0.0362\n",
      "     73        0.5885       0.7188        \u001b[35m0.5543\u001b[0m  0.0359\n",
      "     74        0.5886       0.7188        \u001b[35m0.5540\u001b[0m  0.0362\n",
      "     75        0.5861       0.7266        \u001b[35m0.5532\u001b[0m  0.0375\n",
      "     76        0.5997       0.7266        0.5533  0.0374\n",
      "     77        \u001b[36m0.5637\u001b[0m       0.7188        \u001b[35m0.5522\u001b[0m  0.0368\n",
      "     78        0.5828       0.7266        \u001b[35m0.5511\u001b[0m  0.0364\n",
      "     79        0.5768       0.7266        \u001b[35m0.5509\u001b[0m  0.0364\n",
      "     80        0.5827       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5505\u001b[0m  0.0364\n",
      "     81        0.5925       0.7422        \u001b[35m0.5496\u001b[0m  0.0364\n",
      "     82        0.5858       0.7422        \u001b[35m0.5486\u001b[0m  0.0359\n",
      "     83        0.5798       0.7344        \u001b[35m0.5480\u001b[0m  0.0368\n",
      "     84        0.5722       0.7422        \u001b[35m0.5475\u001b[0m  0.0358\n",
      "     85        0.5818       0.7422        \u001b[35m0.5464\u001b[0m  0.0380\n",
      "     86        0.5752       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5449\u001b[0m  0.0388\n",
      "     87        0.5717       0.7422        \u001b[35m0.5442\u001b[0m  0.0357\n",
      "     88        0.5702       0.7422        \u001b[35m0.5437\u001b[0m  0.0359\n",
      "     89        \u001b[36m0.5595\u001b[0m       0.7266        \u001b[35m0.5421\u001b[0m  0.0364\n",
      "     90        0.5689       0.7422        \u001b[35m0.5409\u001b[0m  0.0358\n",
      "     91        0.5880       0.7500        \u001b[35m0.5408\u001b[0m  0.0358\n",
      "     92        \u001b[36m0.5524\u001b[0m       0.7500        \u001b[35m0.5399\u001b[0m  0.0415\n",
      "     93        \u001b[36m0.5499\u001b[0m       0.7500        0.5401  0.0363\n",
      "     94        0.5800       0.7500        0.5399  0.0496\n",
      "     95        0.5766       0.7422        0.5405  0.0481\n",
      "     96        \u001b[36m0.5463\u001b[0m       0.7344        0.5403  0.0377\n",
      "     97        0.5819       0.7422        \u001b[35m0.5394\u001b[0m  0.0360\n",
      "     98        0.5735       0.7422        \u001b[35m0.5393\u001b[0m  0.0361\n",
      "     99        \u001b[36m0.5394\u001b[0m       0.7266        \u001b[35m0.5384\u001b[0m  0.0371\n",
      "    100        0.5668       0.7266        \u001b[35m0.5380\u001b[0m  0.0356\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6979\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m0.6958\u001b[0m  0.0129\n",
      "      2        \u001b[36m0.6966\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m0.6945\u001b[0m  0.0145\n",
      "      3        \u001b[36m0.6956\u001b[0m       0.4531        \u001b[35m0.6932\u001b[0m  0.0272\n",
      "      4        \u001b[36m0.6946\u001b[0m       0.4453        \u001b[35m0.6920\u001b[0m  0.0166\n",
      "      5        \u001b[36m0.6937\u001b[0m       0.4609        \u001b[35m0.6909\u001b[0m  0.0284\n",
      "      6        \u001b[36m0.6928\u001b[0m       \u001b[32m0.4766\u001b[0m        \u001b[35m0.6898\u001b[0m  0.0166\n",
      "      7        \u001b[36m0.6920\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.6887\u001b[0m  0.0266\n",
      "      8        \u001b[36m0.6913\u001b[0m       0.4922        \u001b[35m0.6878\u001b[0m  0.0279\n",
      "      9        \u001b[36m0.6905\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6868\u001b[0m  0.0353\n",
      "     10        \u001b[36m0.6897\u001b[0m       0.5156        \u001b[35m0.6858\u001b[0m  0.0191\n",
      "     11        \u001b[36m0.6890\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6849\u001b[0m  0.0365\n",
      "     12        \u001b[36m0.6883\u001b[0m       0.5312        \u001b[35m0.6839\u001b[0m  0.0241\n",
      "     13        \u001b[36m0.6877\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6830\u001b[0m  0.0255\n",
      "     14        \u001b[36m0.6870\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6822\u001b[0m  0.0312\n",
      "     15        \u001b[36m0.6864\u001b[0m       0.5703        \u001b[35m0.6813\u001b[0m  0.0190\n",
      "     16        \u001b[36m0.6858\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6805\u001b[0m  0.0225\n",
      "     17        \u001b[36m0.6851\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6797\u001b[0m  0.0172\n",
      "     18        \u001b[36m0.6845\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6789\u001b[0m  0.0166\n",
      "     19        \u001b[36m0.6839\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6781\u001b[0m  0.0341\n",
      "     20        \u001b[36m0.6833\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6772\u001b[0m  0.0233\n",
      "     21        \u001b[36m0.6826\u001b[0m       0.6562        \u001b[35m0.6764\u001b[0m  0.0185\n",
      "     22        \u001b[36m0.6820\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6756\u001b[0m  0.0220\n",
      "     23        \u001b[36m0.6814\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6747\u001b[0m  0.0217\n",
      "     24        \u001b[36m0.6807\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6738\u001b[0m  0.0294\n",
      "     25        \u001b[36m0.6801\u001b[0m       0.6875        \u001b[35m0.6729\u001b[0m  0.0276\n",
      "     26        \u001b[36m0.6794\u001b[0m       0.6875        \u001b[35m0.6721\u001b[0m  0.0193\n",
      "     27        \u001b[36m0.6787\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6712\u001b[0m  0.0211\n",
      "     28        \u001b[36m0.6780\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6702\u001b[0m  0.0200\n",
      "     29        \u001b[36m0.6773\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6693\u001b[0m  0.0195\n",
      "     30        \u001b[36m0.6766\u001b[0m       0.7109        \u001b[35m0.6683\u001b[0m  0.0174\n",
      "     31        \u001b[36m0.6758\u001b[0m       0.7109        \u001b[35m0.6673\u001b[0m  0.0167\n",
      "     32        \u001b[36m0.6750\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6662\u001b[0m  0.0265\n",
      "     33        \u001b[36m0.6742\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6651\u001b[0m  0.0256\n",
      "     34        \u001b[36m0.6733\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6640\u001b[0m  0.0220\n",
      "     35        \u001b[36m0.6725\u001b[0m       0.7344        \u001b[35m0.6628\u001b[0m  0.0205\n",
      "     36        \u001b[36m0.6715\u001b[0m       0.7422        \u001b[35m0.6616\u001b[0m  0.0204\n",
      "     37        \u001b[36m0.6706\u001b[0m       0.7422        \u001b[35m0.6603\u001b[0m  0.0302\n",
      "     38        \u001b[36m0.6696\u001b[0m       0.7500        \u001b[35m0.6590\u001b[0m  0.0200\n",
      "     39        \u001b[36m0.6686\u001b[0m       0.7500        \u001b[35m0.6576\u001b[0m  0.0237\n",
      "     40        \u001b[36m0.6675\u001b[0m       0.7500        \u001b[35m0.6561\u001b[0m  0.0225\n",
      "     41        \u001b[36m0.6664\u001b[0m       0.7500        \u001b[35m0.6546\u001b[0m  0.0157\n",
      "     42        \u001b[36m0.6652\u001b[0m       0.7500        \u001b[35m0.6530\u001b[0m  0.0156\n",
      "     43        \u001b[36m0.6640\u001b[0m       0.7500        \u001b[35m0.6514\u001b[0m  0.0189\n",
      "     44        \u001b[36m0.6627\u001b[0m       0.7500        \u001b[35m0.6496\u001b[0m  0.0213\n",
      "     45        \u001b[36m0.6614\u001b[0m       0.7422        \u001b[35m0.6478\u001b[0m  0.0164\n",
      "     46        \u001b[36m0.6600\u001b[0m       0.7422        \u001b[35m0.6460\u001b[0m  0.0205\n",
      "     47        \u001b[36m0.6586\u001b[0m       0.7500        \u001b[35m0.6440\u001b[0m  0.0250\n",
      "     48        \u001b[36m0.6571\u001b[0m       0.7500        \u001b[35m0.6420\u001b[0m  0.0168\n",
      "     49        \u001b[36m0.6556\u001b[0m       0.7500        \u001b[35m0.6400\u001b[0m  0.0163\n",
      "     50        \u001b[36m0.6540\u001b[0m       0.7500        \u001b[35m0.6378\u001b[0m  0.0292\n",
      "     51        \u001b[36m0.6524\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6356\u001b[0m  0.0173\n",
      "     52        \u001b[36m0.6508\u001b[0m       0.7578        \u001b[35m0.6334\u001b[0m  0.0196\n",
      "     53        \u001b[36m0.6491\u001b[0m       0.7578        \u001b[35m0.6310\u001b[0m  0.0175\n",
      "     54        \u001b[36m0.6473\u001b[0m       0.7578        \u001b[35m0.6286\u001b[0m  0.0182\n",
      "     55        \u001b[36m0.6455\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.6262\u001b[0m  0.0238\n",
      "     56        \u001b[36m0.6437\u001b[0m       0.7656        \u001b[35m0.6236\u001b[0m  0.0179\n",
      "     57        \u001b[36m0.6418\u001b[0m       0.7656        \u001b[35m0.6210\u001b[0m  0.0169\n",
      "     58        \u001b[36m0.6399\u001b[0m       0.7656        \u001b[35m0.6183\u001b[0m  0.0164\n",
      "     59        \u001b[36m0.6379\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.6156\u001b[0m  0.0159\n",
      "     60        \u001b[36m0.6359\u001b[0m       0.7734        \u001b[35m0.6128\u001b[0m  0.0260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     61        \u001b[36m0.6338\u001b[0m       0.7734        \u001b[35m0.6100\u001b[0m  0.0165\n",
      "     62        \u001b[36m0.6318\u001b[0m       0.7734        \u001b[35m0.6071\u001b[0m  0.0186\n",
      "     63        \u001b[36m0.6297\u001b[0m       0.7734        \u001b[35m0.6041\u001b[0m  0.0233\n",
      "     64        \u001b[36m0.6275\u001b[0m       0.7734        \u001b[35m0.6011\u001b[0m  0.0166\n",
      "     65        \u001b[36m0.6253\u001b[0m       0.7734        \u001b[35m0.5981\u001b[0m  0.0169\n",
      "     66        \u001b[36m0.6231\u001b[0m       0.7734        \u001b[35m0.5950\u001b[0m  0.0218\n",
      "     67        \u001b[36m0.6209\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.5919\u001b[0m  0.0228\n",
      "     68        \u001b[36m0.6186\u001b[0m       0.7812        \u001b[35m0.5888\u001b[0m  0.0321\n",
      "     69        \u001b[36m0.6163\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.5856\u001b[0m  0.0254\n",
      "     70        \u001b[36m0.6140\u001b[0m       0.7891        \u001b[35m0.5823\u001b[0m  0.0228\n",
      "     71        \u001b[36m0.6117\u001b[0m       0.7891        \u001b[35m0.5790\u001b[0m  0.0206\n",
      "     72        \u001b[36m0.6093\u001b[0m       0.7891        \u001b[35m0.5757\u001b[0m  0.0205\n",
      "     73        \u001b[36m0.6070\u001b[0m       0.7891        \u001b[35m0.5724\u001b[0m  0.0210\n",
      "     74        \u001b[36m0.6046\u001b[0m       0.7891        \u001b[35m0.5691\u001b[0m  0.0299\n",
      "     75        \u001b[36m0.6022\u001b[0m       0.7891        \u001b[35m0.5658\u001b[0m  0.0198\n",
      "     76        \u001b[36m0.5998\u001b[0m       0.7891        \u001b[35m0.5624\u001b[0m  0.0302\n",
      "     77        \u001b[36m0.5974\u001b[0m       0.7891        \u001b[35m0.5591\u001b[0m  0.0247\n",
      "     78        \u001b[36m0.5950\u001b[0m       0.7891        \u001b[35m0.5558\u001b[0m  0.0278\n",
      "     79        \u001b[36m0.5926\u001b[0m       0.7891        \u001b[35m0.5524\u001b[0m  0.0165\n",
      "     80        \u001b[36m0.5902\u001b[0m       0.7891        \u001b[35m0.5491\u001b[0m  0.0308\n",
      "     81        \u001b[36m0.5878\u001b[0m       0.7891        \u001b[35m0.5458\u001b[0m  0.0278\n",
      "     82        \u001b[36m0.5854\u001b[0m       0.7891        \u001b[35m0.5425\u001b[0m  0.0327\n",
      "     83        \u001b[36m0.5831\u001b[0m       0.7891        \u001b[35m0.5392\u001b[0m  0.0354\n",
      "     84        \u001b[36m0.5807\u001b[0m       0.7891        \u001b[35m0.5359\u001b[0m  0.0252\n",
      "     85        \u001b[36m0.5783\u001b[0m       0.7891        \u001b[35m0.5326\u001b[0m  0.0346\n",
      "     86        \u001b[36m0.5760\u001b[0m       0.7891        \u001b[35m0.5294\u001b[0m  0.0202\n",
      "     87        \u001b[36m0.5738\u001b[0m       0.7891        \u001b[35m0.5262\u001b[0m  0.0253\n",
      "     88        \u001b[36m0.5715\u001b[0m       0.7891        \u001b[35m0.5230\u001b[0m  0.0370\n",
      "     89        \u001b[36m0.5693\u001b[0m       0.7891        \u001b[35m0.5199\u001b[0m  0.0247\n",
      "     90        \u001b[36m0.5671\u001b[0m       0.7812        \u001b[35m0.5169\u001b[0m  0.0300\n",
      "     91        \u001b[36m0.5649\u001b[0m       0.7812        \u001b[35m0.5139\u001b[0m  0.0177\n",
      "     92        \u001b[36m0.5627\u001b[0m       0.7812        \u001b[35m0.5109\u001b[0m  0.0182\n",
      "     93        \u001b[36m0.5606\u001b[0m       0.7812        \u001b[35m0.5080\u001b[0m  0.0184\n",
      "     94        \u001b[36m0.5586\u001b[0m       0.7812        \u001b[35m0.5052\u001b[0m  0.0161\n",
      "     95        \u001b[36m0.5565\u001b[0m       0.7891        \u001b[35m0.5024\u001b[0m  0.0283\n",
      "     96        \u001b[36m0.5546\u001b[0m       0.7891        \u001b[35m0.4997\u001b[0m  0.0186\n",
      "     97        \u001b[36m0.5527\u001b[0m       0.7891        \u001b[35m0.4971\u001b[0m  0.0233\n",
      "     98        \u001b[36m0.5508\u001b[0m       0.7891        \u001b[35m0.4945\u001b[0m  0.0252\n",
      "     99        \u001b[36m0.5490\u001b[0m       0.7891        \u001b[35m0.4920\u001b[0m  0.0176\n",
      "    100        \u001b[36m0.5472\u001b[0m       0.7891        \u001b[35m0.4895\u001b[0m  0.0168\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7087\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7082\u001b[0m  0.0155\n",
      "      2        \u001b[36m0.7059\u001b[0m       0.4922        \u001b[35m0.7056\u001b[0m  0.0189\n",
      "      3        \u001b[36m0.7033\u001b[0m       0.4922        \u001b[35m0.7032\u001b[0m  0.0218\n",
      "      4        \u001b[36m0.7008\u001b[0m       0.4922        \u001b[35m0.7010\u001b[0m  0.0219\n",
      "      5        \u001b[36m0.6984\u001b[0m       0.4922        \u001b[35m0.6988\u001b[0m  0.0190\n",
      "      6        \u001b[36m0.6962\u001b[0m       0.5000        \u001b[35m0.6968\u001b[0m  0.0259\n",
      "      7        \u001b[36m0.6941\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6949\u001b[0m  0.0166\n",
      "      8        \u001b[36m0.6920\u001b[0m       0.5234        \u001b[35m0.6930\u001b[0m  0.0227\n",
      "      9        \u001b[36m0.6901\u001b[0m       0.5234        \u001b[35m0.6913\u001b[0m  0.0226\n",
      "     10        \u001b[36m0.6882\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6896\u001b[0m  0.0260\n",
      "     11        \u001b[36m0.6864\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6879\u001b[0m  0.0217\n",
      "     12        \u001b[36m0.6846\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6864\u001b[0m  0.0182\n",
      "     13        \u001b[36m0.6829\u001b[0m       0.5469        \u001b[35m0.6848\u001b[0m  0.0287\n",
      "     14        \u001b[36m0.6812\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6834\u001b[0m  0.0371\n",
      "     15        \u001b[36m0.6796\u001b[0m       0.5625        \u001b[35m0.6819\u001b[0m  0.0171\n",
      "     16        \u001b[36m0.6780\u001b[0m       0.5625        \u001b[35m0.6805\u001b[0m  0.0177\n",
      "     17        \u001b[36m0.6764\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6791\u001b[0m  0.0237\n",
      "     18        \u001b[36m0.6748\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6778\u001b[0m  0.0198\n",
      "     19        \u001b[36m0.6732\u001b[0m       0.5781        \u001b[35m0.6764\u001b[0m  0.0214\n",
      "     20        \u001b[36m0.6716\u001b[0m       0.5781        \u001b[35m0.6750\u001b[0m  0.0183\n",
      "     21        \u001b[36m0.6701\u001b[0m       0.5781        \u001b[35m0.6736\u001b[0m  0.0186\n",
      "     22        \u001b[36m0.6685\u001b[0m       0.5781        \u001b[35m0.6722\u001b[0m  0.0202\n",
      "     23        \u001b[36m0.6669\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6708\u001b[0m  0.0229\n",
      "     24        \u001b[36m0.6653\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6693\u001b[0m  0.0206\n",
      "     25        \u001b[36m0.6638\u001b[0m       0.5938        \u001b[35m0.6679\u001b[0m  0.0167\n",
      "     26        \u001b[36m0.6622\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6665\u001b[0m  0.0274\n",
      "     27        \u001b[36m0.6606\u001b[0m       0.6094        \u001b[35m0.6651\u001b[0m  0.0161\n",
      "     28        \u001b[36m0.6590\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6636\u001b[0m  0.0210\n",
      "     29        \u001b[36m0.6573\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6621\u001b[0m  0.0153\n",
      "     30        \u001b[36m0.6557\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6606\u001b[0m  0.0141\n",
      "     31        \u001b[36m0.6540\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6591\u001b[0m  0.0288\n",
      "     32        \u001b[36m0.6523\u001b[0m       0.6484        \u001b[35m0.6576\u001b[0m  0.0145\n",
      "     33        \u001b[36m0.6505\u001b[0m       0.6484        \u001b[35m0.6560\u001b[0m  0.0142\n",
      "     34        \u001b[36m0.6487\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6545\u001b[0m  0.0184\n",
      "     35        \u001b[36m0.6469\u001b[0m       0.6719        \u001b[35m0.6528\u001b[0m  0.0263\n",
      "     36        \u001b[36m0.6450\u001b[0m       0.6641        \u001b[35m0.6512\u001b[0m  0.0151\n",
      "     37        \u001b[36m0.6431\u001b[0m       0.6562        \u001b[35m0.6496\u001b[0m  0.0159\n",
      "     38        \u001b[36m0.6413\u001b[0m       0.6562        \u001b[35m0.6479\u001b[0m  0.0156\n",
      "     39        \u001b[36m0.6394\u001b[0m       0.6562        \u001b[35m0.6462\u001b[0m  0.0171\n",
      "     40        \u001b[36m0.6374\u001b[0m       0.6562        \u001b[35m0.6445\u001b[0m  0.0154\n",
      "     41        \u001b[36m0.6355\u001b[0m       0.6641        \u001b[35m0.6428\u001b[0m  0.0161\n",
      "     42        \u001b[36m0.6336\u001b[0m       0.6641        \u001b[35m0.6411\u001b[0m  0.0214\n",
      "     43        \u001b[36m0.6316\u001b[0m       0.6719        \u001b[35m0.6393\u001b[0m  0.0178\n",
      "     44        \u001b[36m0.6296\u001b[0m       0.6641        \u001b[35m0.6376\u001b[0m  0.0170\n",
      "     45        \u001b[36m0.6277\u001b[0m       0.6719        \u001b[35m0.6358\u001b[0m  0.0139\n",
      "     46        \u001b[36m0.6257\u001b[0m       0.6719        \u001b[35m0.6341\u001b[0m  0.0172\n",
      "     47        \u001b[36m0.6238\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6323\u001b[0m  0.0256\n",
      "     48        \u001b[36m0.6218\u001b[0m       0.6797        \u001b[35m0.6306\u001b[0m  0.0152\n",
      "     49        \u001b[36m0.6199\u001b[0m       0.6797        \u001b[35m0.6288\u001b[0m  0.0257\n",
      "     50        \u001b[36m0.6179\u001b[0m       0.6797        \u001b[35m0.6271\u001b[0m  0.0238\n",
      "     51        \u001b[36m0.6159\u001b[0m       0.6797        \u001b[35m0.6253\u001b[0m  0.0282\n",
      "     52        \u001b[36m0.6139\u001b[0m       0.6797        \u001b[35m0.6236\u001b[0m  0.0180\n",
      "     53        \u001b[36m0.6120\u001b[0m       0.6797        \u001b[35m0.6218\u001b[0m  0.0243\n",
      "     54        \u001b[36m0.6100\u001b[0m       0.6797        \u001b[35m0.6201\u001b[0m  0.0240\n",
      "     55        \u001b[36m0.6080\u001b[0m       0.6797        \u001b[35m0.6184\u001b[0m  0.0155\n",
      "     56        \u001b[36m0.6061\u001b[0m       0.6797        \u001b[35m0.6167\u001b[0m  0.0249\n",
      "     57        \u001b[36m0.6042\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6150\u001b[0m  0.0149\n",
      "     58        \u001b[36m0.6023\u001b[0m       0.6875        \u001b[35m0.6133\u001b[0m  0.0259\n",
      "     59        \u001b[36m0.6004\u001b[0m       0.6875        \u001b[35m0.6117\u001b[0m  0.0242\n",
      "     60        \u001b[36m0.5985\u001b[0m       0.6797        \u001b[35m0.6100\u001b[0m  0.0169\n",
      "     61        \u001b[36m0.5967\u001b[0m       0.6875        \u001b[35m0.6084\u001b[0m  0.0149\n",
      "     62        \u001b[36m0.5948\u001b[0m       0.6797        \u001b[35m0.6068\u001b[0m  0.0182\n",
      "     63        \u001b[36m0.5930\u001b[0m       0.6797        \u001b[35m0.6052\u001b[0m  0.0170\n",
      "     64        \u001b[36m0.5912\u001b[0m       0.6797        \u001b[35m0.6037\u001b[0m  0.0183\n",
      "     65        \u001b[36m0.5895\u001b[0m       0.6719        \u001b[35m0.6022\u001b[0m  0.0188\n",
      "     66        \u001b[36m0.5877\u001b[0m       0.6719        \u001b[35m0.6007\u001b[0m  0.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     67        \u001b[36m0.5860\u001b[0m       0.6875        \u001b[35m0.5993\u001b[0m  0.0164\n",
      "     68        \u001b[36m0.5843\u001b[0m       0.6875        \u001b[35m0.5978\u001b[0m  0.0160\n",
      "     69        \u001b[36m0.5827\u001b[0m       0.6875        \u001b[35m0.5964\u001b[0m  0.0196\n",
      "     70        \u001b[36m0.5810\u001b[0m       0.6875        \u001b[35m0.5950\u001b[0m  0.0204\n",
      "     71        \u001b[36m0.5794\u001b[0m       0.6875        \u001b[35m0.5937\u001b[0m  0.0174\n",
      "     72        \u001b[36m0.5778\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5924\u001b[0m  0.0209\n",
      "     73        \u001b[36m0.5763\u001b[0m       0.6953        \u001b[35m0.5911\u001b[0m  0.0161\n",
      "     74        \u001b[36m0.5748\u001b[0m       0.6953        \u001b[35m0.5899\u001b[0m  0.0165\n",
      "     75        \u001b[36m0.5733\u001b[0m       0.6953        \u001b[35m0.5886\u001b[0m  0.0239\n",
      "     76        \u001b[36m0.5718\u001b[0m       0.6953        \u001b[35m0.5874\u001b[0m  0.0331\n",
      "     77        \u001b[36m0.5704\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5863\u001b[0m  0.0240\n",
      "     78        \u001b[36m0.5690\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5852\u001b[0m  0.0166\n",
      "     79        \u001b[36m0.5677\u001b[0m       0.7188        \u001b[35m0.5841\u001b[0m  0.0297\n",
      "     80        \u001b[36m0.5663\u001b[0m       0.7188        \u001b[35m0.5830\u001b[0m  0.0168\n",
      "     81        \u001b[36m0.5650\u001b[0m       0.7188        \u001b[35m0.5820\u001b[0m  0.0184\n",
      "     82        \u001b[36m0.5638\u001b[0m       0.7188        \u001b[35m0.5810\u001b[0m  0.0277\n",
      "     83        \u001b[36m0.5625\u001b[0m       0.7188        \u001b[35m0.5801\u001b[0m  0.0191\n",
      "     84        \u001b[36m0.5613\u001b[0m       0.7188        \u001b[35m0.5792\u001b[0m  0.0232\n",
      "     85        \u001b[36m0.5601\u001b[0m       0.7188        \u001b[35m0.5783\u001b[0m  0.0260\n",
      "     86        \u001b[36m0.5589\u001b[0m       0.7188        \u001b[35m0.5774\u001b[0m  0.0223\n",
      "     87        \u001b[36m0.5578\u001b[0m       0.7109        \u001b[35m0.5766\u001b[0m  0.0213\n",
      "     88        \u001b[36m0.5567\u001b[0m       0.7109        \u001b[35m0.5758\u001b[0m  0.0218\n",
      "     89        \u001b[36m0.5556\u001b[0m       0.7109        \u001b[35m0.5750\u001b[0m  0.0188\n",
      "     90        \u001b[36m0.5545\u001b[0m       0.7109        \u001b[35m0.5742\u001b[0m  0.0296\n",
      "     91        \u001b[36m0.5534\u001b[0m       0.7109        \u001b[35m0.5735\u001b[0m  0.0187\n",
      "     92        \u001b[36m0.5524\u001b[0m       0.7109        \u001b[35m0.5728\u001b[0m  0.0184\n",
      "     93        \u001b[36m0.5514\u001b[0m       0.7109        \u001b[35m0.5721\u001b[0m  0.0248\n",
      "     94        \u001b[36m0.5504\u001b[0m       0.7109        \u001b[35m0.5714\u001b[0m  0.0212\n",
      "     95        \u001b[36m0.5495\u001b[0m       0.7109        \u001b[35m0.5708\u001b[0m  0.0238\n",
      "     96        \u001b[36m0.5485\u001b[0m       0.7109        \u001b[35m0.5702\u001b[0m  0.0196\n",
      "     97        \u001b[36m0.5476\u001b[0m       0.7109        \u001b[35m0.5695\u001b[0m  0.0276\n",
      "     98        \u001b[36m0.5467\u001b[0m       0.7109        \u001b[35m0.5690\u001b[0m  0.0221\n",
      "     99        \u001b[36m0.5458\u001b[0m       0.7109        \u001b[35m0.5684\u001b[0m  0.0203\n",
      "    100        \u001b[36m0.5450\u001b[0m       0.7109        \u001b[35m0.5678\u001b[0m  0.0215\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7092\u001b[0m       \u001b[32m0.4297\u001b[0m        \u001b[35m0.7077\u001b[0m  0.0186\n",
      "      2        \u001b[36m0.7082\u001b[0m       \u001b[32m0.4375\u001b[0m        \u001b[35m0.7068\u001b[0m  0.0261\n",
      "      3        \u001b[36m0.7073\u001b[0m       0.4297        \u001b[35m0.7059\u001b[0m  0.0233\n",
      "      4        \u001b[36m0.7065\u001b[0m       0.4297        \u001b[35m0.7051\u001b[0m  0.0185\n",
      "      5        \u001b[36m0.7056\u001b[0m       0.4297        \u001b[35m0.7042\u001b[0m  0.0249\n",
      "      6        \u001b[36m0.7048\u001b[0m       0.4219        \u001b[35m0.7034\u001b[0m  0.0180\n",
      "      7        \u001b[36m0.7041\u001b[0m       0.4219        \u001b[35m0.7027\u001b[0m  0.0175\n",
      "      8        \u001b[36m0.7033\u001b[0m       0.4297        \u001b[35m0.7019\u001b[0m  0.0333\n",
      "      9        \u001b[36m0.7026\u001b[0m       0.4297        \u001b[35m0.7012\u001b[0m  0.0175\n",
      "     10        \u001b[36m0.7018\u001b[0m       0.4375        \u001b[35m0.7004\u001b[0m  0.0307\n",
      "     11        \u001b[36m0.7011\u001b[0m       0.4375        \u001b[35m0.6997\u001b[0m  0.0167\n",
      "     12        \u001b[36m0.7004\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m0.6990\u001b[0m  0.0179\n",
      "     13        \u001b[36m0.6997\u001b[0m       0.4531        \u001b[35m0.6983\u001b[0m  0.0270\n",
      "     14        \u001b[36m0.6991\u001b[0m       0.4453        \u001b[35m0.6977\u001b[0m  0.0187\n",
      "     15        \u001b[36m0.6984\u001b[0m       0.4453        \u001b[35m0.6970\u001b[0m  0.0228\n",
      "     16        \u001b[36m0.6977\u001b[0m       0.4453        \u001b[35m0.6963\u001b[0m  0.0178\n",
      "     17        \u001b[36m0.6971\u001b[0m       0.4375        \u001b[35m0.6957\u001b[0m  0.0156\n",
      "     18        \u001b[36m0.6964\u001b[0m       0.4375        \u001b[35m0.6950\u001b[0m  0.0142\n",
      "     19        \u001b[36m0.6958\u001b[0m       0.4453        \u001b[35m0.6944\u001b[0m  0.0139\n",
      "     20        \u001b[36m0.6951\u001b[0m       0.4375        \u001b[35m0.6938\u001b[0m  0.0155\n",
      "     21        \u001b[36m0.6945\u001b[0m       0.4375        \u001b[35m0.6931\u001b[0m  0.0147\n",
      "     22        \u001b[36m0.6939\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m0.6925\u001b[0m  0.0140\n",
      "     23        \u001b[36m0.6932\u001b[0m       \u001b[32m0.4844\u001b[0m        \u001b[35m0.6918\u001b[0m  0.0134\n",
      "     24        \u001b[36m0.6926\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6912\u001b[0m  0.0142\n",
      "     25        \u001b[36m0.6919\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6906\u001b[0m  0.0142\n",
      "     26        \u001b[36m0.6913\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6899\u001b[0m  0.0153\n",
      "     27        \u001b[36m0.6906\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6893\u001b[0m  0.0193\n",
      "     28        \u001b[36m0.6900\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6886\u001b[0m  0.0171\n",
      "     29        \u001b[36m0.6893\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6879\u001b[0m  0.0155\n",
      "     30        \u001b[36m0.6886\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6873\u001b[0m  0.0177\n",
      "     31        \u001b[36m0.6880\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6866\u001b[0m  0.0159\n",
      "     32        \u001b[36m0.6873\u001b[0m       0.6641        \u001b[35m0.6859\u001b[0m  0.0152\n",
      "     33        \u001b[36m0.6866\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6852\u001b[0m  0.0167\n",
      "     34        \u001b[36m0.6859\u001b[0m       0.6719        \u001b[35m0.6845\u001b[0m  0.0152\n",
      "     35        \u001b[36m0.6851\u001b[0m       0.6719        \u001b[35m0.6838\u001b[0m  0.0227\n",
      "     36        \u001b[36m0.6844\u001b[0m       0.6719        \u001b[35m0.6831\u001b[0m  0.0165\n",
      "     37        \u001b[36m0.6836\u001b[0m       0.6719        \u001b[35m0.6823\u001b[0m  0.0214\n",
      "     38        \u001b[36m0.6829\u001b[0m       0.6641        \u001b[35m0.6816\u001b[0m  0.0174\n",
      "     39        \u001b[36m0.6821\u001b[0m       0.6641        \u001b[35m0.6808\u001b[0m  0.0141\n",
      "     40        \u001b[36m0.6813\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6800\u001b[0m  0.0154\n",
      "     41        \u001b[36m0.6804\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6792\u001b[0m  0.0205\n",
      "     42        \u001b[36m0.6796\u001b[0m       0.6797        \u001b[35m0.6783\u001b[0m  0.0165\n",
      "     43        \u001b[36m0.6787\u001b[0m       0.6797        \u001b[35m0.6775\u001b[0m  0.0190\n",
      "     44        \u001b[36m0.6778\u001b[0m       0.6641        \u001b[35m0.6766\u001b[0m  0.0173\n",
      "     45        \u001b[36m0.6769\u001b[0m       0.6641        \u001b[35m0.6757\u001b[0m  0.0158\n",
      "     46        \u001b[36m0.6759\u001b[0m       0.6719        \u001b[35m0.6748\u001b[0m  0.0193\n",
      "     47        \u001b[36m0.6750\u001b[0m       0.6719        \u001b[35m0.6739\u001b[0m  0.0179\n",
      "     48        \u001b[36m0.6740\u001b[0m       0.6641        \u001b[35m0.6729\u001b[0m  0.0164\n",
      "     49        \u001b[36m0.6730\u001b[0m       0.6641        \u001b[35m0.6719\u001b[0m  0.0194\n",
      "     50        \u001b[36m0.6719\u001b[0m       0.6641        \u001b[35m0.6709\u001b[0m  0.0193\n",
      "     51        \u001b[36m0.6708\u001b[0m       0.6641        \u001b[35m0.6698\u001b[0m  0.0166\n",
      "     52        \u001b[36m0.6697\u001b[0m       0.6641        \u001b[35m0.6688\u001b[0m  0.0179\n",
      "     53        \u001b[36m0.6685\u001b[0m       0.6641        \u001b[35m0.6677\u001b[0m  0.0157\n",
      "     54        \u001b[36m0.6674\u001b[0m       0.6875        \u001b[35m0.6665\u001b[0m  0.0146\n",
      "     55        \u001b[36m0.6661\u001b[0m       0.6875        \u001b[35m0.6654\u001b[0m  0.0152\n",
      "     56        \u001b[36m0.6649\u001b[0m       0.6953        \u001b[35m0.6642\u001b[0m  0.0132\n",
      "     57        \u001b[36m0.6636\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6629\u001b[0m  0.0324\n",
      "     58        \u001b[36m0.6623\u001b[0m       0.7031        \u001b[35m0.6616\u001b[0m  0.0157\n",
      "     59        \u001b[36m0.6609\u001b[0m       0.7031        \u001b[35m0.6603\u001b[0m  0.0196\n",
      "     60        \u001b[36m0.6595\u001b[0m       0.7031        \u001b[35m0.6590\u001b[0m  0.0162\n",
      "     61        \u001b[36m0.6580\u001b[0m       0.6953        \u001b[35m0.6576\u001b[0m  0.0172\n",
      "     62        \u001b[36m0.6565\u001b[0m       0.6953        \u001b[35m0.6561\u001b[0m  0.0195\n",
      "     63        \u001b[36m0.6549\u001b[0m       0.6953        \u001b[35m0.6547\u001b[0m  0.0182\n",
      "     64        \u001b[36m0.6533\u001b[0m       0.6953        \u001b[35m0.6532\u001b[0m  0.0147\n",
      "     65        \u001b[36m0.6517\u001b[0m       0.6953        \u001b[35m0.6516\u001b[0m  0.0152\n",
      "     66        \u001b[36m0.6500\u001b[0m       0.6953        \u001b[35m0.6500\u001b[0m  0.0180\n",
      "     67        \u001b[36m0.6483\u001b[0m       0.6953        \u001b[35m0.6484\u001b[0m  0.0147\n",
      "     68        \u001b[36m0.6465\u001b[0m       0.6953        \u001b[35m0.6467\u001b[0m  0.0192\n",
      "     69        \u001b[36m0.6447\u001b[0m       0.6953        \u001b[35m0.6450\u001b[0m  0.0167\n",
      "     70        \u001b[36m0.6428\u001b[0m       0.6953        \u001b[35m0.6433\u001b[0m  0.0205\n",
      "     71        \u001b[36m0.6409\u001b[0m       0.7031        \u001b[35m0.6415\u001b[0m  0.0156\n",
      "     72        \u001b[36m0.6390\u001b[0m       0.7031        \u001b[35m0.6397\u001b[0m  0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     73        \u001b[36m0.6370\u001b[0m       0.7031        \u001b[35m0.6378\u001b[0m  0.0147\n",
      "     74        \u001b[36m0.6349\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6359\u001b[0m  0.0154\n",
      "     75        \u001b[36m0.6328\u001b[0m       0.7109        \u001b[35m0.6340\u001b[0m  0.0150\n",
      "     76        \u001b[36m0.6307\u001b[0m       0.7109        \u001b[35m0.6320\u001b[0m  0.0160\n",
      "     77        \u001b[36m0.6286\u001b[0m       0.7109        \u001b[35m0.6300\u001b[0m  0.0246\n",
      "     78        \u001b[36m0.6264\u001b[0m       0.7109        \u001b[35m0.6280\u001b[0m  0.0249\n",
      "     79        \u001b[36m0.6241\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6259\u001b[0m  0.0238\n",
      "     80        \u001b[36m0.6219\u001b[0m       0.7109        \u001b[35m0.6239\u001b[0m  0.0133\n",
      "     81        \u001b[36m0.6196\u001b[0m       0.7109        \u001b[35m0.6218\u001b[0m  0.0148\n",
      "     82        \u001b[36m0.6173\u001b[0m       0.7109        \u001b[35m0.6198\u001b[0m  0.0139\n",
      "     83        \u001b[36m0.6150\u001b[0m       0.7109        \u001b[35m0.6177\u001b[0m  0.0138\n",
      "     84        \u001b[36m0.6126\u001b[0m       0.7109        \u001b[35m0.6156\u001b[0m  0.0137\n",
      "     85        \u001b[36m0.6103\u001b[0m       0.7109        \u001b[35m0.6134\u001b[0m  0.0139\n",
      "     86        \u001b[36m0.6079\u001b[0m       0.7109        \u001b[35m0.6113\u001b[0m  0.0143\n",
      "     87        \u001b[36m0.6055\u001b[0m       0.7109        \u001b[35m0.6092\u001b[0m  0.0138\n",
      "     88        \u001b[36m0.6031\u001b[0m       0.7109        \u001b[35m0.6070\u001b[0m  0.0142\n",
      "     89        \u001b[36m0.6007\u001b[0m       0.7109        \u001b[35m0.6049\u001b[0m  0.0142\n",
      "     90        \u001b[36m0.5983\u001b[0m       0.7109        \u001b[35m0.6028\u001b[0m  0.0244\n",
      "     91        \u001b[36m0.5959\u001b[0m       0.7109        \u001b[35m0.6007\u001b[0m  0.0149\n",
      "     92        \u001b[36m0.5935\u001b[0m       0.7109        \u001b[35m0.5987\u001b[0m  0.0165\n",
      "     93        \u001b[36m0.5911\u001b[0m       0.7031        \u001b[35m0.5966\u001b[0m  0.0303\n",
      "     94        \u001b[36m0.5888\u001b[0m       0.7109        \u001b[35m0.5946\u001b[0m  0.0331\n",
      "     95        \u001b[36m0.5865\u001b[0m       0.7109        \u001b[35m0.5925\u001b[0m  0.0183\n",
      "     96        \u001b[36m0.5842\u001b[0m       0.7188        \u001b[35m0.5905\u001b[0m  0.0153\n",
      "     97        \u001b[36m0.5819\u001b[0m       0.7188        \u001b[35m0.5885\u001b[0m  0.0315\n",
      "     98        \u001b[36m0.5796\u001b[0m       0.7188        \u001b[35m0.5865\u001b[0m  0.0156\n",
      "     99        \u001b[36m0.5773\u001b[0m       0.7188        \u001b[35m0.5846\u001b[0m  0.0225\n",
      "    100        \u001b[36m0.5751\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5827\u001b[0m  0.0148\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7036\u001b[0m       \u001b[32m0.3516\u001b[0m        \u001b[35m0.7018\u001b[0m  0.0147\n",
      "      2        \u001b[36m0.7018\u001b[0m       \u001b[32m0.3906\u001b[0m        \u001b[35m0.7004\u001b[0m  0.0197\n",
      "      3        \u001b[36m0.7001\u001b[0m       \u001b[32m0.4141\u001b[0m        \u001b[35m0.6990\u001b[0m  0.0153\n",
      "      4        \u001b[36m0.6985\u001b[0m       \u001b[32m0.4297\u001b[0m        \u001b[35m0.6977\u001b[0m  0.0241\n",
      "      5        \u001b[36m0.6969\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m0.6964\u001b[0m  0.0232\n",
      "      6        \u001b[36m0.6953\u001b[0m       \u001b[32m0.4844\u001b[0m        \u001b[35m0.6951\u001b[0m  0.0146\n",
      "      7        \u001b[36m0.6938\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6938\u001b[0m  0.0199\n",
      "      8        \u001b[36m0.6923\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6925\u001b[0m  0.0234\n",
      "      9        \u001b[36m0.6908\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6913\u001b[0m  0.0182\n",
      "     10        \u001b[36m0.6893\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6900\u001b[0m  0.0193\n",
      "     11        \u001b[36m0.6878\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6888\u001b[0m  0.0165\n",
      "     12        \u001b[36m0.6863\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6875\u001b[0m  0.0182\n",
      "     13        \u001b[36m0.6848\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6862\u001b[0m  0.0185\n",
      "     14        \u001b[36m0.6833\u001b[0m       0.5938        \u001b[35m0.6850\u001b[0m  0.0217\n",
      "     15        \u001b[36m0.6818\u001b[0m       0.5859        \u001b[35m0.6837\u001b[0m  0.0155\n",
      "     16        \u001b[36m0.6803\u001b[0m       0.5781        \u001b[35m0.6823\u001b[0m  0.0230\n",
      "     17        \u001b[36m0.6787\u001b[0m       0.5781        \u001b[35m0.6810\u001b[0m  0.0179\n",
      "     18        \u001b[36m0.6771\u001b[0m       0.5859        \u001b[35m0.6797\u001b[0m  0.0155\n",
      "     19        \u001b[36m0.6755\u001b[0m       0.5859        \u001b[35m0.6783\u001b[0m  0.0308\n",
      "     20        \u001b[36m0.6739\u001b[0m       0.5859        \u001b[35m0.6769\u001b[0m  0.0154\n",
      "     21        \u001b[36m0.6722\u001b[0m       0.5938        \u001b[35m0.6754\u001b[0m  0.0222\n",
      "     22        \u001b[36m0.6705\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6739\u001b[0m  0.0219\n",
      "     23        \u001b[36m0.6688\u001b[0m       0.6172        \u001b[35m0.6724\u001b[0m  0.0196\n",
      "     24        \u001b[36m0.6670\u001b[0m       0.6172        \u001b[35m0.6709\u001b[0m  0.0300\n",
      "     25        \u001b[36m0.6652\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6693\u001b[0m  0.0396\n",
      "     26        \u001b[36m0.6633\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6677\u001b[0m  0.0267\n",
      "     27        \u001b[36m0.6614\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6660\u001b[0m  0.0196\n",
      "     28        \u001b[36m0.6594\u001b[0m       0.6484        \u001b[35m0.6643\u001b[0m  0.0182\n",
      "     29        \u001b[36m0.6574\u001b[0m       0.6484        \u001b[35m0.6625\u001b[0m  0.0261\n",
      "     30        \u001b[36m0.6553\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6607\u001b[0m  0.0170\n",
      "     31        \u001b[36m0.6532\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6588\u001b[0m  0.0199\n",
      "     32        \u001b[36m0.6510\u001b[0m       0.6719        \u001b[35m0.6568\u001b[0m  0.0296\n",
      "     33        \u001b[36m0.6488\u001b[0m       0.6719        \u001b[35m0.6548\u001b[0m  0.0281\n",
      "     34        \u001b[36m0.6465\u001b[0m       0.6719        \u001b[35m0.6528\u001b[0m  0.0254\n",
      "     35        \u001b[36m0.6442\u001b[0m       0.6719        \u001b[35m0.6507\u001b[0m  0.0262\n",
      "     36        \u001b[36m0.6418\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6485\u001b[0m  0.0289\n",
      "     37        \u001b[36m0.6393\u001b[0m       0.6797        \u001b[35m0.6463\u001b[0m  0.0228\n",
      "     38        \u001b[36m0.6368\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6441\u001b[0m  0.0150\n",
      "     39        \u001b[36m0.6342\u001b[0m       0.6875        \u001b[35m0.6417\u001b[0m  0.0228\n",
      "     40        \u001b[36m0.6315\u001b[0m       0.6875        \u001b[35m0.6393\u001b[0m  0.0207\n",
      "     41        \u001b[36m0.6288\u001b[0m       0.6875        \u001b[35m0.6369\u001b[0m  0.0149\n",
      "     42        \u001b[36m0.6260\u001b[0m       0.6875        \u001b[35m0.6344\u001b[0m  0.0279\n",
      "     43        \u001b[36m0.6232\u001b[0m       0.6875        \u001b[35m0.6319\u001b[0m  0.0199\n",
      "     44        \u001b[36m0.6203\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6293\u001b[0m  0.0268\n",
      "     45        \u001b[36m0.6174\u001b[0m       0.6953        \u001b[35m0.6266\u001b[0m  0.0327\n",
      "     46        \u001b[36m0.6145\u001b[0m       0.6953        \u001b[35m0.6240\u001b[0m  0.0366\n",
      "     47        \u001b[36m0.6115\u001b[0m       0.6953        \u001b[35m0.6213\u001b[0m  0.0267\n",
      "     48        \u001b[36m0.6085\u001b[0m       0.6953        \u001b[35m0.6185\u001b[0m  0.0355\n",
      "     49        \u001b[36m0.6054\u001b[0m       0.6953        \u001b[35m0.6158\u001b[0m  0.0299\n",
      "     50        \u001b[36m0.6023\u001b[0m       0.6953        \u001b[35m0.6130\u001b[0m  0.0236\n",
      "     51        \u001b[36m0.5992\u001b[0m       0.6953        \u001b[35m0.6102\u001b[0m  0.0188\n",
      "     52        \u001b[36m0.5961\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6074\u001b[0m  0.0174\n",
      "     53        \u001b[36m0.5929\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6045\u001b[0m  0.0174\n",
      "     54        \u001b[36m0.5898\u001b[0m       0.7109        \u001b[35m0.6017\u001b[0m  0.0160\n",
      "     55        \u001b[36m0.5866\u001b[0m       0.7109        \u001b[35m0.5989\u001b[0m  0.0202\n",
      "     56        \u001b[36m0.5835\u001b[0m       0.7109        \u001b[35m0.5961\u001b[0m  0.0190\n",
      "     57        \u001b[36m0.5803\u001b[0m       0.7109        \u001b[35m0.5933\u001b[0m  0.0205\n",
      "     58        \u001b[36m0.5771\u001b[0m       0.7109        \u001b[35m0.5905\u001b[0m  0.0265\n",
      "     59        \u001b[36m0.5739\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5877\u001b[0m  0.0302\n",
      "     60        \u001b[36m0.5708\u001b[0m       0.7188        \u001b[35m0.5849\u001b[0m  0.0160\n",
      "     61        \u001b[36m0.5677\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5822\u001b[0m  0.0161\n",
      "     62        \u001b[36m0.5645\u001b[0m       0.7109        \u001b[35m0.5794\u001b[0m  0.0275\n",
      "     63        \u001b[36m0.5614\u001b[0m       0.7188        \u001b[35m0.5767\u001b[0m  0.0320\n",
      "     64        \u001b[36m0.5584\u001b[0m       0.7188        \u001b[35m0.5740\u001b[0m  0.0404\n",
      "     65        \u001b[36m0.5553\u001b[0m       0.7188        \u001b[35m0.5714\u001b[0m  0.0296\n",
      "     66        \u001b[36m0.5523\u001b[0m       0.7188        \u001b[35m0.5688\u001b[0m  0.0157\n",
      "     67        \u001b[36m0.5494\u001b[0m       0.7188        \u001b[35m0.5662\u001b[0m  0.0168\n",
      "     68        \u001b[36m0.5465\u001b[0m       0.7188        \u001b[35m0.5637\u001b[0m  0.0232\n",
      "     69        \u001b[36m0.5437\u001b[0m       0.7266        \u001b[35m0.5613\u001b[0m  0.0174\n",
      "     70        \u001b[36m0.5409\u001b[0m       0.7266        \u001b[35m0.5589\u001b[0m  0.0191\n",
      "     71        \u001b[36m0.5382\u001b[0m       0.7266        \u001b[35m0.5566\u001b[0m  0.0184\n",
      "     72        \u001b[36m0.5355\u001b[0m       0.7266        \u001b[35m0.5544\u001b[0m  0.0178\n",
      "     73        \u001b[36m0.5329\u001b[0m       0.7266        \u001b[35m0.5522\u001b[0m  0.0283\n",
      "     74        \u001b[36m0.5304\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5501\u001b[0m  0.0183\n",
      "     75        \u001b[36m0.5279\u001b[0m       0.7266        \u001b[35m0.5480\u001b[0m  0.0196\n",
      "     76        \u001b[36m0.5254\u001b[0m       0.7266        \u001b[35m0.5460\u001b[0m  0.0155\n",
      "     77        \u001b[36m0.5231\u001b[0m       0.7188        \u001b[35m0.5441\u001b[0m  0.0264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     78        \u001b[36m0.5208\u001b[0m       0.7188        \u001b[35m0.5423\u001b[0m  0.0181\n",
      "     79        \u001b[36m0.5185\u001b[0m       0.7188        \u001b[35m0.5405\u001b[0m  0.0208\n",
      "     80        \u001b[36m0.5163\u001b[0m       0.7188        \u001b[35m0.5387\u001b[0m  0.0184\n",
      "     81        \u001b[36m0.5142\u001b[0m       0.7188        \u001b[35m0.5370\u001b[0m  0.0332\n",
      "     82        \u001b[36m0.5121\u001b[0m       0.7188        \u001b[35m0.5354\u001b[0m  0.0284\n",
      "     83        \u001b[36m0.5101\u001b[0m       0.7188        \u001b[35m0.5338\u001b[0m  0.0226\n",
      "     84        \u001b[36m0.5082\u001b[0m       0.7188        \u001b[35m0.5324\u001b[0m  0.0258\n",
      "     85        \u001b[36m0.5063\u001b[0m       0.7188        \u001b[35m0.5309\u001b[0m  0.0217\n",
      "     86        \u001b[36m0.5045\u001b[0m       0.7188        \u001b[35m0.5296\u001b[0m  0.0221\n",
      "     87        \u001b[36m0.5027\u001b[0m       0.7188        \u001b[35m0.5282\u001b[0m  0.0300\n",
      "     88        \u001b[36m0.5010\u001b[0m       0.7188        \u001b[35m0.5270\u001b[0m  0.0196\n",
      "     89        \u001b[36m0.4994\u001b[0m       0.7188        \u001b[35m0.5257\u001b[0m  0.0145\n",
      "     90        \u001b[36m0.4978\u001b[0m       0.7188        \u001b[35m0.5246\u001b[0m  0.0148\n",
      "     91        \u001b[36m0.4962\u001b[0m       0.7188        \u001b[35m0.5234\u001b[0m  0.0304\n",
      "     92        \u001b[36m0.4947\u001b[0m       0.7188        \u001b[35m0.5224\u001b[0m  0.0140\n",
      "     93        \u001b[36m0.4933\u001b[0m       0.7188        \u001b[35m0.5213\u001b[0m  0.0165\n",
      "     94        \u001b[36m0.4919\u001b[0m       0.7266        \u001b[35m0.5203\u001b[0m  0.0150\n",
      "     95        \u001b[36m0.4905\u001b[0m       0.7266        \u001b[35m0.5194\u001b[0m  0.0287\n",
      "     96        \u001b[36m0.4892\u001b[0m       0.7266        \u001b[35m0.5185\u001b[0m  0.0198\n",
      "     97        \u001b[36m0.4879\u001b[0m       0.7266        \u001b[35m0.5176\u001b[0m  0.0155\n",
      "     98        \u001b[36m0.4866\u001b[0m       0.7266        \u001b[35m0.5167\u001b[0m  0.0174\n",
      "     99        \u001b[36m0.4855\u001b[0m       0.7266        \u001b[35m0.5159\u001b[0m  0.0155\n",
      "    100        \u001b[36m0.4843\u001b[0m       0.7266        \u001b[35m0.5152\u001b[0m  0.0158\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7677\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7678\u001b[0m  0.0125\n",
      "      2        \u001b[36m0.7576\u001b[0m       0.5000        \u001b[35m0.7582\u001b[0m  0.0153\n",
      "      3        \u001b[36m0.7488\u001b[0m       0.5000        \u001b[35m0.7498\u001b[0m  0.0152\n",
      "      4        \u001b[36m0.7411\u001b[0m       0.5000        \u001b[35m0.7424\u001b[0m  0.0140\n",
      "      5        \u001b[36m0.7343\u001b[0m       0.5000        \u001b[35m0.7359\u001b[0m  0.0136\n",
      "      6        \u001b[36m0.7283\u001b[0m       0.5000        \u001b[35m0.7301\u001b[0m  0.0137\n",
      "      7        \u001b[36m0.7230\u001b[0m       0.5000        \u001b[35m0.7249\u001b[0m  0.0164\n",
      "      8        \u001b[36m0.7182\u001b[0m       0.5000        \u001b[35m0.7202\u001b[0m  0.0146\n",
      "      9        \u001b[36m0.7139\u001b[0m       0.5000        \u001b[35m0.7160\u001b[0m  0.0255\n",
      "     10        \u001b[36m0.7100\u001b[0m       0.5000        \u001b[35m0.7122\u001b[0m  0.0143\n",
      "     11        \u001b[36m0.7064\u001b[0m       0.5000        \u001b[35m0.7087\u001b[0m  0.0141\n",
      "     12        \u001b[36m0.7033\u001b[0m       0.5000        \u001b[35m0.7056\u001b[0m  0.0166\n",
      "     13        \u001b[36m0.7003\u001b[0m       0.5000        \u001b[35m0.7027\u001b[0m  0.0281\n",
      "     14        \u001b[36m0.6976\u001b[0m       0.5000        \u001b[35m0.7001\u001b[0m  0.0222\n",
      "     15        \u001b[36m0.6951\u001b[0m       0.5000        \u001b[35m0.6977\u001b[0m  0.0171\n",
      "     16        \u001b[36m0.6928\u001b[0m       0.5000        \u001b[35m0.6954\u001b[0m  0.0219\n",
      "     17        \u001b[36m0.6906\u001b[0m       0.5000        \u001b[35m0.6933\u001b[0m  0.0141\n",
      "     18        \u001b[36m0.6885\u001b[0m       0.5000        \u001b[35m0.6913\u001b[0m  0.0135\n",
      "     19        \u001b[36m0.6865\u001b[0m       0.5000        \u001b[35m0.6895\u001b[0m  0.0184\n",
      "     20        \u001b[36m0.6847\u001b[0m       0.5000        \u001b[35m0.6877\u001b[0m  0.0175\n",
      "     21        \u001b[36m0.6829\u001b[0m       0.5000        \u001b[35m0.6861\u001b[0m  0.0174\n",
      "     22        \u001b[36m0.6812\u001b[0m       0.5000        \u001b[35m0.6845\u001b[0m  0.0204\n",
      "     23        \u001b[36m0.6795\u001b[0m       0.5000        \u001b[35m0.6830\u001b[0m  0.0147\n",
      "     24        \u001b[36m0.6779\u001b[0m       0.5000        \u001b[35m0.6815\u001b[0m  0.0236\n",
      "     25        \u001b[36m0.6763\u001b[0m       0.5000        \u001b[35m0.6801\u001b[0m  0.0168\n",
      "     26        \u001b[36m0.6747\u001b[0m       0.5000        \u001b[35m0.6787\u001b[0m  0.0205\n",
      "     27        \u001b[36m0.6732\u001b[0m       0.5000        \u001b[35m0.6773\u001b[0m  0.0272\n",
      "     28        \u001b[36m0.6717\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6760\u001b[0m  0.0155\n",
      "     29        \u001b[36m0.6701\u001b[0m       0.5078        \u001b[35m0.6747\u001b[0m  0.0259\n",
      "     30        \u001b[36m0.6686\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6734\u001b[0m  0.0223\n",
      "     31        \u001b[36m0.6671\u001b[0m       0.5078        \u001b[35m0.6721\u001b[0m  0.0212\n",
      "     32        \u001b[36m0.6655\u001b[0m       0.5156        \u001b[35m0.6708\u001b[0m  0.0238\n",
      "     33        \u001b[36m0.6640\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6695\u001b[0m  0.0139\n",
      "     34        \u001b[36m0.6624\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6682\u001b[0m  0.0160\n",
      "     35        \u001b[36m0.6608\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6669\u001b[0m  0.0160\n",
      "     36        \u001b[36m0.6592\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6656\u001b[0m  0.0254\n",
      "     37        \u001b[36m0.6575\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6642\u001b[0m  0.0185\n",
      "     38        \u001b[36m0.6558\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6629\u001b[0m  0.0147\n",
      "     39        \u001b[36m0.6541\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6615\u001b[0m  0.0217\n",
      "     40        \u001b[36m0.6524\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6601\u001b[0m  0.0165\n",
      "     41        \u001b[36m0.6506\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6586\u001b[0m  0.0194\n",
      "     42        \u001b[36m0.6488\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6572\u001b[0m  0.0250\n",
      "     43        \u001b[36m0.6469\u001b[0m       0.7031        \u001b[35m0.6557\u001b[0m  0.0142\n",
      "     44        \u001b[36m0.6450\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6541\u001b[0m  0.0138\n",
      "     45        \u001b[36m0.6430\u001b[0m       0.6875        \u001b[35m0.6525\u001b[0m  0.0187\n",
      "     46        \u001b[36m0.6410\u001b[0m       0.6875        \u001b[35m0.6509\u001b[0m  0.0164\n",
      "     47        \u001b[36m0.6388\u001b[0m       0.6875        \u001b[35m0.6492\u001b[0m  0.0159\n",
      "     48        \u001b[36m0.6367\u001b[0m       0.6875        \u001b[35m0.6475\u001b[0m  0.0164\n",
      "     49        \u001b[36m0.6345\u001b[0m       0.6875        \u001b[35m0.6458\u001b[0m  0.0328\n",
      "     50        \u001b[36m0.6322\u001b[0m       0.6875        \u001b[35m0.6440\u001b[0m  0.0149\n",
      "     51        \u001b[36m0.6298\u001b[0m       0.6797        \u001b[35m0.6421\u001b[0m  0.0136\n",
      "     52        \u001b[36m0.6274\u001b[0m       0.6797        \u001b[35m0.6402\u001b[0m  0.0222\n",
      "     53        \u001b[36m0.6249\u001b[0m       0.6797        \u001b[35m0.6382\u001b[0m  0.0163\n",
      "     54        \u001b[36m0.6223\u001b[0m       0.6875        \u001b[35m0.6362\u001b[0m  0.0159\n",
      "     55        \u001b[36m0.6196\u001b[0m       0.6875        \u001b[35m0.6341\u001b[0m  0.0149\n",
      "     56        \u001b[36m0.6168\u001b[0m       0.7031        \u001b[35m0.6320\u001b[0m  0.0139\n",
      "     57        \u001b[36m0.6140\u001b[0m       0.7031        \u001b[35m0.6299\u001b[0m  0.0188\n",
      "     58        \u001b[36m0.6111\u001b[0m       0.7031        \u001b[35m0.6277\u001b[0m  0.0159\n",
      "     59        \u001b[36m0.6082\u001b[0m       0.7031        \u001b[35m0.6254\u001b[0m  0.0172\n",
      "     60        \u001b[36m0.6051\u001b[0m       0.7109        \u001b[35m0.6231\u001b[0m  0.0138\n",
      "     61        \u001b[36m0.6021\u001b[0m       0.7109        \u001b[35m0.6208\u001b[0m  0.0140\n",
      "     62        \u001b[36m0.5989\u001b[0m       0.7109        \u001b[35m0.6184\u001b[0m  0.0147\n",
      "     63        \u001b[36m0.5957\u001b[0m       0.7109        \u001b[35m0.6160\u001b[0m  0.0134\n",
      "     64        \u001b[36m0.5925\u001b[0m       0.7109        \u001b[35m0.6135\u001b[0m  0.0224\n",
      "     65        \u001b[36m0.5892\u001b[0m       0.7031        \u001b[35m0.6111\u001b[0m  0.0199\n",
      "     66        \u001b[36m0.5858\u001b[0m       0.7031        \u001b[35m0.6086\u001b[0m  0.0176\n",
      "     67        \u001b[36m0.5825\u001b[0m       0.7031        \u001b[35m0.6060\u001b[0m  0.0180\n",
      "     68        \u001b[36m0.5791\u001b[0m       0.6953        \u001b[35m0.6035\u001b[0m  0.0170\n",
      "     69        \u001b[36m0.5757\u001b[0m       0.6875        \u001b[35m0.6010\u001b[0m  0.0213\n",
      "     70        \u001b[36m0.5722\u001b[0m       0.6953        \u001b[35m0.5985\u001b[0m  0.0228\n",
      "     71        \u001b[36m0.5688\u001b[0m       0.6953        \u001b[35m0.5960\u001b[0m  0.0259\n",
      "     72        \u001b[36m0.5653\u001b[0m       0.6953        \u001b[35m0.5935\u001b[0m  0.0240\n",
      "     73        \u001b[36m0.5618\u001b[0m       0.6953        \u001b[35m0.5910\u001b[0m  0.0214\n",
      "     74        \u001b[36m0.5584\u001b[0m       0.6953        \u001b[35m0.5886\u001b[0m  0.0189\n",
      "     75        \u001b[36m0.5550\u001b[0m       0.6953        \u001b[35m0.5862\u001b[0m  0.0150\n",
      "     76        \u001b[36m0.5516\u001b[0m       0.6953        \u001b[35m0.5839\u001b[0m  0.0158\n",
      "     77        \u001b[36m0.5482\u001b[0m       0.7031        \u001b[35m0.5816\u001b[0m  0.0175\n",
      "     78        \u001b[36m0.5448\u001b[0m       0.6953        \u001b[35m0.5793\u001b[0m  0.0172\n",
      "     79        \u001b[36m0.5415\u001b[0m       0.6953        \u001b[35m0.5772\u001b[0m  0.0227\n",
      "     80        \u001b[36m0.5382\u001b[0m       0.6953        \u001b[35m0.5751\u001b[0m  0.0141\n",
      "     81        \u001b[36m0.5350\u001b[0m       0.6953        \u001b[35m0.5730\u001b[0m  0.0140\n",
      "     82        \u001b[36m0.5318\u001b[0m       0.6953        \u001b[35m0.5710\u001b[0m  0.0188\n",
      "     83        \u001b[36m0.5286\u001b[0m       0.6953        \u001b[35m0.5691\u001b[0m  0.0151\n",
      "     84        \u001b[36m0.5255\u001b[0m       0.6953        \u001b[35m0.5672\u001b[0m  0.0181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     85        \u001b[36m0.5225\u001b[0m       0.6953        \u001b[35m0.5654\u001b[0m  0.0150\n",
      "     86        \u001b[36m0.5195\u001b[0m       0.6953        \u001b[35m0.5637\u001b[0m  0.0151\n",
      "     87        \u001b[36m0.5166\u001b[0m       0.6953        \u001b[35m0.5620\u001b[0m  0.0176\n",
      "     88        \u001b[36m0.5137\u001b[0m       0.7109        \u001b[35m0.5604\u001b[0m  0.0194\n",
      "     89        \u001b[36m0.5109\u001b[0m       0.7031        \u001b[35m0.5589\u001b[0m  0.0138\n",
      "     90        \u001b[36m0.5082\u001b[0m       0.7031        \u001b[35m0.5575\u001b[0m  0.0176\n",
      "     91        \u001b[36m0.5055\u001b[0m       0.7031        \u001b[35m0.5561\u001b[0m  0.0275\n",
      "     92        \u001b[36m0.5029\u001b[0m       0.7031        \u001b[35m0.5548\u001b[0m  0.0212\n",
      "     93        \u001b[36m0.5004\u001b[0m       0.7031        \u001b[35m0.5535\u001b[0m  0.0139\n",
      "     94        \u001b[36m0.4980\u001b[0m       0.7031        \u001b[35m0.5523\u001b[0m  0.0133\n",
      "     95        \u001b[36m0.4956\u001b[0m       0.7031        \u001b[35m0.5512\u001b[0m  0.0256\n",
      "     96        \u001b[36m0.4933\u001b[0m       0.7031        \u001b[35m0.5502\u001b[0m  0.0267\n",
      "     97        \u001b[36m0.4911\u001b[0m       0.7031        \u001b[35m0.5493\u001b[0m  0.0236\n",
      "     98        \u001b[36m0.4890\u001b[0m       0.7031        \u001b[35m0.5484\u001b[0m  0.0143\n",
      "     99        \u001b[36m0.4869\u001b[0m       0.7031        \u001b[35m0.5475\u001b[0m  0.0140\n",
      "    100        \u001b[36m0.4848\u001b[0m       0.7031        \u001b[35m0.5468\u001b[0m  0.0176\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7134\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6942\u001b[0m  0.0509\n",
      "      2        \u001b[36m0.6957\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6889\u001b[0m  0.0369\n",
      "      3        0.6969       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6820\u001b[0m  0.0428\n",
      "      4        \u001b[36m0.6893\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6728\u001b[0m  0.0369\n",
      "      5        \u001b[36m0.6800\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6619\u001b[0m  0.0428\n",
      "      6        \u001b[36m0.6695\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6509\u001b[0m  0.0415\n",
      "      7        \u001b[36m0.6686\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6384\u001b[0m  0.0388\n",
      "      8        \u001b[36m0.6560\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6253\u001b[0m  0.0427\n",
      "      9        \u001b[36m0.6494\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6103\u001b[0m  0.0368\n",
      "     10        \u001b[36m0.6251\u001b[0m       0.7266        \u001b[35m0.5978\u001b[0m  0.0509\n",
      "     11        \u001b[36m0.6163\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5832\u001b[0m  0.0369\n",
      "     12        0.6165       0.7266        \u001b[35m0.5713\u001b[0m  0.0353\n",
      "     13        \u001b[36m0.6068\u001b[0m       0.7266        \u001b[35m0.5592\u001b[0m  0.0375\n",
      "     14        \u001b[36m0.6048\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5474\u001b[0m  0.0371\n",
      "     15        \u001b[36m0.6002\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5401\u001b[0m  0.0506\n",
      "     16        \u001b[36m0.5861\u001b[0m       0.7578        \u001b[35m0.5296\u001b[0m  0.0609\n",
      "     17        0.5990       0.7578        \u001b[35m0.5288\u001b[0m  0.0370\n",
      "     18        \u001b[36m0.5817\u001b[0m       0.7578        \u001b[35m0.5198\u001b[0m  0.0376\n",
      "     19        \u001b[36m0.5749\u001b[0m       0.7578        \u001b[35m0.5142\u001b[0m  0.0425\n",
      "     20        \u001b[36m0.5719\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5038\u001b[0m  0.0376\n",
      "     21        \u001b[36m0.5583\u001b[0m       0.7578        \u001b[35m0.4962\u001b[0m  0.0370\n",
      "     22        0.5854       0.7656        0.4966  0.0396\n",
      "     23        \u001b[36m0.5548\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4903\u001b[0m  0.0420\n",
      "     24        0.5549       0.7734        \u001b[35m0.4844\u001b[0m  0.0368\n",
      "     25        0.5589       0.7734        \u001b[35m0.4834\u001b[0m  0.0371\n",
      "     26        \u001b[36m0.5545\u001b[0m       0.7734        \u001b[35m0.4831\u001b[0m  0.0389\n",
      "     27        \u001b[36m0.5453\u001b[0m       0.7734        \u001b[35m0.4804\u001b[0m  0.0425\n",
      "     28        0.5606       0.7734        \u001b[35m0.4789\u001b[0m  0.0383\n",
      "     29        0.5555       0.7734        \u001b[35m0.4741\u001b[0m  0.0371\n",
      "     30        \u001b[36m0.5425\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4725\u001b[0m  0.0382\n",
      "     31        0.5533       0.7812        \u001b[35m0.4687\u001b[0m  0.0387\n",
      "     32        0.5473       0.7812        0.4708  0.0386\n",
      "     33        0.5440       0.7812        \u001b[35m0.4682\u001b[0m  0.0447\n",
      "     34        0.5498       0.7812        \u001b[35m0.4667\u001b[0m  0.0370\n",
      "     35        0.5440       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4616\u001b[0m  0.0422\n",
      "     36        \u001b[36m0.5397\u001b[0m       0.7812        0.4626  0.0364\n",
      "     37        \u001b[36m0.5390\u001b[0m       0.7812        \u001b[35m0.4587\u001b[0m  0.0431\n",
      "     38        \u001b[36m0.5376\u001b[0m       0.7812        \u001b[35m0.4586\u001b[0m  0.0360\n",
      "     39        0.5492       0.7891        \u001b[35m0.4556\u001b[0m  0.0360\n",
      "     40        0.5429       0.7891        \u001b[35m0.4540\u001b[0m  0.0364\n",
      "     41        0.5386       0.7891        \u001b[35m0.4533\u001b[0m  0.0363\n",
      "     42        0.5395       0.7891        \u001b[35m0.4527\u001b[0m  0.0376\n",
      "     43        \u001b[36m0.5326\u001b[0m       0.7891        \u001b[35m0.4505\u001b[0m  0.0377\n",
      "     44        0.5440       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4486\u001b[0m  0.0387\n",
      "     45        \u001b[36m0.5139\u001b[0m       0.7969        \u001b[35m0.4457\u001b[0m  0.0391\n",
      "     46        0.5203       0.7969        \u001b[35m0.4432\u001b[0m  0.0391\n",
      "     47        0.5352       0.7969        \u001b[35m0.4431\u001b[0m  0.0376\n",
      "     48        0.5353       0.7891        0.4432  0.0377\n",
      "     49        0.5206       0.7891        \u001b[35m0.4406\u001b[0m  0.0382\n",
      "     50        0.5471       0.7891        0.4412  0.0374\n",
      "     51        0.5436       0.7891        0.4434  0.0375\n",
      "     52        0.5365       0.7891        \u001b[35m0.4403\u001b[0m  0.0374\n",
      "     53        \u001b[36m0.5107\u001b[0m       0.7891        \u001b[35m0.4382\u001b[0m  0.0374\n",
      "     54        0.5420       0.7812        \u001b[35m0.4373\u001b[0m  0.0368\n",
      "     55        0.5280       0.7812        \u001b[35m0.4371\u001b[0m  0.0366\n",
      "     56        0.5161       0.7812        \u001b[35m0.4339\u001b[0m  0.0362\n",
      "     57        0.5256       0.7812        0.4366  0.0364\n",
      "     58        \u001b[36m0.5040\u001b[0m       0.7891        \u001b[35m0.4330\u001b[0m  0.0362\n",
      "     59        0.5256       0.7812        \u001b[35m0.4299\u001b[0m  0.0359\n",
      "     60        0.5228       0.7812        \u001b[35m0.4290\u001b[0m  0.0362\n",
      "     61        0.5144       0.7812        \u001b[35m0.4269\u001b[0m  0.0362\n",
      "     62        0.5247       0.7812        0.4281  0.0362\n",
      "     63        0.5122       0.7891        0.4285  0.0383\n",
      "     64        0.5286       0.7891        \u001b[35m0.4259\u001b[0m  0.0369\n",
      "     65        0.5072       0.7891        \u001b[35m0.4249\u001b[0m  0.0360\n",
      "     66        0.5079       0.7812        \u001b[35m0.4217\u001b[0m  0.0379\n",
      "     67        0.5246       0.7891        \u001b[35m0.4214\u001b[0m  0.0384\n",
      "     68        0.5083       0.7891        \u001b[35m0.4187\u001b[0m  0.0355\n",
      "     69        0.5145       0.7891        0.4190  0.0363\n",
      "     70        0.5051       0.7891        \u001b[35m0.4177\u001b[0m  0.0356\n",
      "     71        \u001b[36m0.4859\u001b[0m       0.7812        \u001b[35m0.4136\u001b[0m  0.0366\n",
      "     72        0.5035       0.7812        \u001b[35m0.4122\u001b[0m  0.0361\n",
      "     73        \u001b[36m0.4859\u001b[0m       0.7812        \u001b[35m0.4114\u001b[0m  0.0392\n",
      "     74        0.5035       0.7812        0.4119  0.0367\n",
      "     75        0.5040       0.7734        \u001b[35m0.4103\u001b[0m  0.0374\n",
      "     76        0.4886       0.7734        \u001b[35m0.4095\u001b[0m  0.0403\n",
      "     77        0.5061       0.7812        0.4104  0.0360\n",
      "     78        0.5053       0.7812        \u001b[35m0.4093\u001b[0m  0.0375\n",
      "     79        0.5072       0.7734        0.4104  0.0364\n",
      "     80        0.5208       0.7734        0.4101  0.0364\n",
      "     81        0.4970       0.7812        0.4101  0.0376\n",
      "     82        0.5034       0.7812        0.4110  0.0368\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6978\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6811\u001b[0m  0.0336\n",
      "      2        \u001b[36m0.6895\u001b[0m       0.5078        \u001b[35m0.6727\u001b[0m  0.0468\n",
      "      3        \u001b[36m0.6810\u001b[0m       0.5078        \u001b[35m0.6647\u001b[0m  0.0410\n",
      "      4        \u001b[36m0.6785\u001b[0m       0.5703        \u001b[35m0.6560\u001b[0m  0.0408\n",
      "      5        \u001b[36m0.6633\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6457\u001b[0m  0.0362\n",
      "      6        \u001b[36m0.6533\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6346\u001b[0m  0.0410\n",
      "      7        \u001b[36m0.6521\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6238\u001b[0m  0.0373\n",
      "      8        \u001b[36m0.6342\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6126\u001b[0m  0.0413\n",
      "      9        \u001b[36m0.6325\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6039\u001b[0m  0.0358\n",
      "     10        \u001b[36m0.6074\u001b[0m       0.7188        \u001b[35m0.5953\u001b[0m  0.0401\n",
      "     11        \u001b[36m0.5964\u001b[0m       0.7188        \u001b[35m0.5869\u001b[0m  0.0479\n",
      "     12        \u001b[36m0.5844\u001b[0m       0.7266        \u001b[35m0.5792\u001b[0m  0.0358\n",
      "     13        0.6193       0.7109        \u001b[35m0.5764\u001b[0m  0.0396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     14        0.5870       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5747\u001b[0m  0.0421\n",
      "     15        0.5890       0.7266        \u001b[35m0.5724\u001b[0m  0.0345\n",
      "     16        \u001b[36m0.5616\u001b[0m       0.7266        \u001b[35m0.5691\u001b[0m  0.0405\n",
      "     17        0.5711       0.7266        \u001b[35m0.5681\u001b[0m  0.0363\n",
      "     18        0.5693       0.7188        \u001b[35m0.5666\u001b[0m  0.0381\n",
      "     19        0.5824       0.7188        \u001b[35m0.5657\u001b[0m  0.0406\n",
      "     20        0.5678       0.7188        \u001b[35m0.5645\u001b[0m  0.0361\n",
      "     21        \u001b[36m0.5586\u001b[0m       0.7188        \u001b[35m0.5632\u001b[0m  0.0381\n",
      "     22        \u001b[36m0.5495\u001b[0m       0.7188        0.5633  0.0412\n",
      "     23        \u001b[36m0.5388\u001b[0m       0.7188        \u001b[35m0.5613\u001b[0m  0.0359\n",
      "     24        0.5400       0.7188        \u001b[35m0.5597\u001b[0m  0.0378\n",
      "     25        0.5524       0.7188        \u001b[35m0.5583\u001b[0m  0.0422\n",
      "     26        0.5694       0.7109        \u001b[35m0.5559\u001b[0m  0.0376\n",
      "     27        0.5420       0.7188        \u001b[35m0.5549\u001b[0m  0.0359\n",
      "     28        0.5437       0.7031        0.5552  0.0382\n",
      "     29        0.5516       0.7266        \u001b[35m0.5533\u001b[0m  0.0404\n",
      "     30        0.5417       0.7266        \u001b[35m0.5530\u001b[0m  0.0357\n",
      "     31        0.5511       0.7266        \u001b[35m0.5521\u001b[0m  0.0361\n",
      "     32        0.5480       0.7266        0.5522  0.0378\n",
      "     33        0.5467       0.7266        \u001b[35m0.5495\u001b[0m  0.0410\n",
      "     34        \u001b[36m0.5379\u001b[0m       0.7344        \u001b[35m0.5490\u001b[0m  0.0360\n",
      "     35        \u001b[36m0.5345\u001b[0m       0.7266        \u001b[35m0.5467\u001b[0m  0.0362\n",
      "     36        \u001b[36m0.5146\u001b[0m       0.7266        0.5482  0.0387\n",
      "     37        0.5201       0.7344        0.5475  0.0360\n",
      "     38        \u001b[36m0.5074\u001b[0m       0.7266        0.5486  0.0383\n",
      "     39        0.5205       0.7266        \u001b[35m0.5466\u001b[0m  0.0396\n",
      "     40        0.5315       0.7266        \u001b[35m0.5447\u001b[0m  0.0391\n",
      "     41        0.5275       0.7344        \u001b[35m0.5433\u001b[0m  0.0416\n",
      "     42        0.5264       0.7344        \u001b[35m0.5428\u001b[0m  0.0358\n",
      "     43        \u001b[36m0.5039\u001b[0m       0.7344        \u001b[35m0.5419\u001b[0m  0.0410\n",
      "     44        0.5278       0.7344        \u001b[35m0.5398\u001b[0m  0.0367\n",
      "     45        0.5285       0.7344        \u001b[35m0.5385\u001b[0m  0.0359\n",
      "     46        0.5138       0.7344        0.5386  0.0369\n",
      "     47        0.5201       0.7344        \u001b[35m0.5383\u001b[0m  0.0376\n",
      "     48        0.5203       \u001b[32m0.7422\u001b[0m        0.5386  0.0361\n",
      "     49        0.5102       0.7422        0.5402  0.0364\n",
      "     50        0.5158       0.7422        0.5386  0.0383\n",
      "     51        0.5172       0.7422        \u001b[35m0.5380\u001b[0m  0.0364\n",
      "     52        0.5139       0.7422        0.5385  0.0383\n",
      "     53        0.5141       0.7422        \u001b[35m0.5373\u001b[0m  0.0369\n",
      "     54        \u001b[36m0.5034\u001b[0m       0.7422        0.5379  0.0381\n",
      "     55        0.5209       0.7422        \u001b[35m0.5367\u001b[0m  0.0361\n",
      "     56        0.5180       0.7422        \u001b[35m0.5365\u001b[0m  0.0461\n",
      "     57        0.5111       0.7422        \u001b[35m0.5352\u001b[0m  0.0357\n",
      "     58        \u001b[36m0.4920\u001b[0m       \u001b[32m0.7500\u001b[0m        0.5373  0.0374\n",
      "     59        0.5058       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5346\u001b[0m  0.0364\n",
      "     60        0.4992       0.7578        0.5354  0.0363\n",
      "     61        0.4992       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5337\u001b[0m  0.0365\n",
      "     62        \u001b[36m0.4838\u001b[0m       0.7578        0.5338  0.0358\n",
      "     63        0.5111       0.7578        \u001b[35m0.5313\u001b[0m  0.0373\n",
      "     64        0.5173       0.7500        \u001b[35m0.5293\u001b[0m  0.0364\n",
      "     65        0.5017       0.7578        0.5296  0.0366\n",
      "     66        0.5122       0.7578        \u001b[35m0.5293\u001b[0m  0.0358\n",
      "     67        0.4991       0.7500        \u001b[35m0.5288\u001b[0m  0.0363\n",
      "     68        0.4992       0.7500        0.5298  0.0361\n",
      "     69        0.4990       0.7578        0.5289  0.0368\n",
      "     70        0.4890       0.7656        \u001b[35m0.5286\u001b[0m  0.0362\n",
      "     71        0.4930       0.7656        0.5289  0.0359\n",
      "     72        0.5024       0.7656        \u001b[35m0.5261\u001b[0m  0.0359\n",
      "     73        0.4972       0.7656        0.5267  0.0364\n",
      "     74        0.4935       0.7656        0.5277  0.0363\n",
      "     75        0.5120       0.7656        \u001b[35m0.5260\u001b[0m  0.0364\n",
      "     76        0.4951       0.7656        \u001b[35m0.5259\u001b[0m  0.0365\n",
      "     77        0.4943       0.7578        0.5260  0.0389\n",
      "     78        \u001b[36m0.4833\u001b[0m       0.7578        0.5267  0.0358\n",
      "     79        0.5163       0.7578        \u001b[35m0.5230\u001b[0m  0.0372\n",
      "     80        0.4848       0.7578        0.5235  0.0358\n",
      "     81        0.5070       0.7578        \u001b[35m0.5219\u001b[0m  0.0361\n",
      "     82        0.4895       0.7656        0.5225  0.0367\n",
      "     83        0.5003       0.7578        0.5241  0.0365\n",
      "     84        \u001b[36m0.4815\u001b[0m       0.7578        0.5247  0.0368\n",
      "     85        \u001b[36m0.4803\u001b[0m       0.7656        0.5255  0.0358\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7079\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6939\u001b[0m  0.0339\n",
      "      2        \u001b[36m0.7047\u001b[0m       0.5234        \u001b[35m0.6890\u001b[0m  0.0431\n",
      "      3        \u001b[36m0.6975\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6836\u001b[0m  0.0404\n",
      "      4        \u001b[36m0.6899\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6768\u001b[0m  0.0358\n",
      "      5        \u001b[36m0.6836\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6684\u001b[0m  0.0415\n",
      "      6        \u001b[36m0.6730\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6577\u001b[0m  0.0361\n",
      "      7        \u001b[36m0.6633\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6445\u001b[0m  0.0415\n",
      "      8        \u001b[36m0.6556\u001b[0m       0.7031        \u001b[35m0.6301\u001b[0m  0.0542\n",
      "      9        \u001b[36m0.6447\u001b[0m       0.7266        \u001b[35m0.6169\u001b[0m  0.0366\n",
      "     10        \u001b[36m0.6135\u001b[0m       0.7266        \u001b[35m0.6009\u001b[0m  0.0362\n",
      "     11        \u001b[36m0.6135\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5875\u001b[0m  0.0409\n",
      "     12        \u001b[36m0.5956\u001b[0m       0.7344        \u001b[35m0.5761\u001b[0m  0.0362\n",
      "     13        \u001b[36m0.5859\u001b[0m       0.7422        \u001b[35m0.5668\u001b[0m  0.0405\n",
      "     14        \u001b[36m0.5717\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5575\u001b[0m  0.0364\n",
      "     15        \u001b[36m0.5703\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5507\u001b[0m  0.0384\n",
      "     16        \u001b[36m0.5668\u001b[0m       0.7578        \u001b[35m0.5465\u001b[0m  0.0415\n",
      "     17        \u001b[36m0.5505\u001b[0m       0.7500        \u001b[35m0.5394\u001b[0m  0.0358\n",
      "     18        0.5546       0.7500        \u001b[35m0.5384\u001b[0m  0.0388\n",
      "     19        \u001b[36m0.5397\u001b[0m       0.7422        \u001b[35m0.5355\u001b[0m  0.0437\n",
      "     20        \u001b[36m0.5308\u001b[0m       0.7578        \u001b[35m0.5311\u001b[0m  0.0426\n",
      "     21        0.5363       0.7422        0.5313  0.0396\n",
      "     22        0.5364       0.7422        \u001b[35m0.5281\u001b[0m  0.0364\n",
      "     23        0.5473       0.7422        \u001b[35m0.5265\u001b[0m  0.0399\n",
      "     24        \u001b[36m0.5243\u001b[0m       0.7500        \u001b[35m0.5249\u001b[0m  0.0425\n",
      "     25        0.5397       0.7578        \u001b[35m0.5231\u001b[0m  0.0423\n",
      "     26        0.5323       0.7578        \u001b[35m0.5227\u001b[0m  0.0418\n",
      "     27        0.5417       0.7500        \u001b[35m0.5213\u001b[0m  0.0422\n",
      "     28        \u001b[36m0.5225\u001b[0m       0.7422        \u001b[35m0.5197\u001b[0m  0.0361\n",
      "     29        0.5375       0.7500        \u001b[35m0.5184\u001b[0m  0.0371\n",
      "     30        0.5239       0.7500        \u001b[35m0.5168\u001b[0m  0.0439\n",
      "     31        0.5435       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5148\u001b[0m  0.0386\n",
      "     32        \u001b[36m0.5060\u001b[0m       0.7500        \u001b[35m0.5147\u001b[0m  0.0396\n",
      "     33        0.5159       0.7578        \u001b[35m0.5141\u001b[0m  0.0403\n",
      "     34        0.5192       0.7578        \u001b[35m0.5129\u001b[0m  0.0406\n",
      "     35        0.5188       0.7578        \u001b[35m0.5124\u001b[0m  0.0409\n",
      "     36        0.5127       0.7656        \u001b[35m0.5119\u001b[0m  0.0419\n",
      "     37        0.5160       0.7500        0.5131  0.0358\n",
      "     38        0.5292       0.7578        \u001b[35m0.5117\u001b[0m  0.0477\n",
      "     39        0.5350       0.7578        \u001b[35m0.5116\u001b[0m  0.0360\n",
      "     40        \u001b[36m0.4840\u001b[0m       0.7500        0.5129  0.0423\n",
      "     41        0.5105       0.7656        0.5157  0.0411\n",
      "     42        0.5140       0.7578        0.5144  0.0393\n",
      "     43        0.5230       0.7578        0.5137  0.0394\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6881\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6690\u001b[0m  0.0353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.6756\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6579\u001b[0m  0.0404\n",
      "      3        \u001b[36m0.6743\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6466\u001b[0m  0.0407\n",
      "      4        \u001b[36m0.6595\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6347\u001b[0m  0.0411\n",
      "      5        \u001b[36m0.6582\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6244\u001b[0m  0.0361\n",
      "      6        \u001b[36m0.6371\u001b[0m       0.7422        \u001b[35m0.6141\u001b[0m  0.0420\n",
      "      7        0.6387       0.7266        \u001b[35m0.6048\u001b[0m  0.0383\n",
      "      8        \u001b[36m0.6117\u001b[0m       0.7344        \u001b[35m0.5940\u001b[0m  0.0395\n",
      "      9        0.6213       0.7188        \u001b[35m0.5854\u001b[0m  0.0360\n",
      "     10        0.6164       0.7344        \u001b[35m0.5836\u001b[0m  0.0386\n",
      "     11        \u001b[36m0.6116\u001b[0m       0.7188        \u001b[35m0.5789\u001b[0m  0.0433\n",
      "     12        \u001b[36m0.6001\u001b[0m       0.7109        \u001b[35m0.5754\u001b[0m  0.0358\n",
      "     13        \u001b[36m0.5948\u001b[0m       0.7188        \u001b[35m0.5709\u001b[0m  0.0407\n",
      "     14        \u001b[36m0.5772\u001b[0m       0.7266        \u001b[35m0.5692\u001b[0m  0.0364\n",
      "     15        0.5814       0.7266        \u001b[35m0.5667\u001b[0m  0.0386\n",
      "     16        0.5875       0.7266        \u001b[35m0.5631\u001b[0m  0.0409\n",
      "     17        0.5812       0.7266        \u001b[35m0.5599\u001b[0m  0.0363\n",
      "     18        0.5789       0.7188        \u001b[35m0.5599\u001b[0m  0.0414\n",
      "     19        \u001b[36m0.5666\u001b[0m       0.7109        \u001b[35m0.5578\u001b[0m  0.0363\n",
      "     20        \u001b[36m0.5552\u001b[0m       0.7109        \u001b[35m0.5567\u001b[0m  0.0368\n",
      "     21        \u001b[36m0.5518\u001b[0m       0.7109        \u001b[35m0.5549\u001b[0m  0.0424\n",
      "     22        0.5530       0.7109        \u001b[35m0.5537\u001b[0m  0.0356\n",
      "     23        0.5733       0.7266        \u001b[35m0.5523\u001b[0m  0.0372\n",
      "     24        \u001b[36m0.5495\u001b[0m       0.7266        \u001b[35m0.5507\u001b[0m  0.0407\n",
      "     25        \u001b[36m0.5415\u001b[0m       0.7266        \u001b[35m0.5491\u001b[0m  0.0359\n",
      "     26        0.5425       0.7109        \u001b[35m0.5480\u001b[0m  0.0362\n",
      "     27        \u001b[36m0.5396\u001b[0m       0.7109        0.5484  0.0394\n",
      "     28        \u001b[36m0.5277\u001b[0m       0.7109        0.5500  0.0422\n",
      "     29        0.5366       0.7109        \u001b[35m0.5479\u001b[0m  0.0363\n",
      "     30        0.5330       0.7031        0.5485  0.0361\n",
      "     31        \u001b[36m0.5268\u001b[0m       0.6875        \u001b[35m0.5465\u001b[0m  0.0370\n",
      "     32        0.5441       0.6953        \u001b[35m0.5452\u001b[0m  0.0414\n",
      "     33        0.5472       0.6953        0.5475  0.0380\n",
      "     34        0.5358       0.6953        0.5471  0.0415\n",
      "     35        0.5619       0.6953        0.5458  0.0363\n",
      "     36        0.5300       0.6953        \u001b[35m0.5451\u001b[0m  0.0361\n",
      "     37        \u001b[36m0.5226\u001b[0m       0.6953        0.5455  0.0365\n",
      "     38        \u001b[36m0.5175\u001b[0m       0.6953        0.5455  0.0387\n",
      "     39        0.5367       0.6953        0.5458  0.0399\n",
      "     40        0.5316       0.6875        0.5469  0.0374\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7065\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6811\u001b[0m  0.0363\n",
      "      2        \u001b[36m0.6899\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6656\u001b[0m  0.0435\n",
      "      3        \u001b[36m0.6795\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6514\u001b[0m  0.0386\n",
      "      4        \u001b[36m0.6607\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6348\u001b[0m  0.0430\n",
      "      5        \u001b[36m0.6369\u001b[0m       0.6797        \u001b[35m0.6167\u001b[0m  0.0368\n",
      "      6        \u001b[36m0.6332\u001b[0m       0.7031        \u001b[35m0.6015\u001b[0m  0.0414\n",
      "      7        \u001b[36m0.6163\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5883\u001b[0m  0.0365\n",
      "      8        0.6261       0.7031        \u001b[35m0.5750\u001b[0m  0.0398\n",
      "      9        \u001b[36m0.5920\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5649\u001b[0m  0.0365\n",
      "     10        \u001b[36m0.5772\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5595\u001b[0m  0.0431\n",
      "     11        \u001b[36m0.5714\u001b[0m       0.7344        \u001b[35m0.5485\u001b[0m  0.0360\n",
      "     12        0.5770       0.7344        \u001b[35m0.5402\u001b[0m  0.0407\n",
      "     13        \u001b[36m0.5547\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5378\u001b[0m  0.0374\n",
      "     14        \u001b[36m0.5485\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5341\u001b[0m  0.0374\n",
      "     15        0.5677       0.7500        0.5351  0.0417\n",
      "     16        \u001b[36m0.5462\u001b[0m       0.7500        \u001b[35m0.5340\u001b[0m  0.0362\n",
      "     17        \u001b[36m0.5386\u001b[0m       0.7500        \u001b[35m0.5290\u001b[0m  0.0401\n",
      "     18        0.5430       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5242\u001b[0m  0.0359\n",
      "     19        0.5423       0.7500        0.5245  0.0373\n",
      "     20        \u001b[36m0.5277\u001b[0m       0.7500        0.5245  0.0414\n",
      "     21        0.5325       0.7500        \u001b[35m0.5238\u001b[0m  0.0361\n",
      "     22        0.5321       0.7500        \u001b[35m0.5233\u001b[0m  0.0383\n",
      "     23        0.5415       0.7422        0.5240  0.0445\n",
      "     24        \u001b[36m0.5254\u001b[0m       0.7422        \u001b[35m0.5232\u001b[0m  0.0362\n",
      "     25        \u001b[36m0.5233\u001b[0m       0.7422        \u001b[35m0.5232\u001b[0m  0.0361\n",
      "     26        \u001b[36m0.5124\u001b[0m       0.7344        0.5237  0.0384\n",
      "     27        0.5250       0.7422        \u001b[35m0.5231\u001b[0m  0.0409\n",
      "     28        0.5176       0.7344        0.5235  0.0359\n",
      "     29        0.5158       0.7422        0.5247  0.0364\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6834\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7770\u001b[0m  0.0209\n",
      "      2        0.7801       0.5000        \u001b[35m0.7090\u001b[0m  0.0222\n",
      "      3        0.7174       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6688\u001b[0m  0.0235\n",
      "      4        0.6861       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6355\u001b[0m  0.0446\n",
      "      5        \u001b[36m0.6761\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5924\u001b[0m  0.0382\n",
      "      6        \u001b[36m0.6122\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5417\u001b[0m  0.0397\n",
      "      7        0.6329       0.7266        \u001b[35m0.5211\u001b[0m  0.0295\n",
      "      8        0.6509       0.7344        \u001b[35m0.5161\u001b[0m  0.0367\n",
      "      9        0.6144       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4719\u001b[0m  0.0341\n",
      "     10        \u001b[36m0.5915\u001b[0m       0.7578        0.4913  0.0329\n",
      "     11        0.5958       0.7578        0.4855  0.0350\n",
      "     12        0.6212       0.7656        0.4728  0.0308\n",
      "     13        \u001b[36m0.5692\u001b[0m       0.7500        0.4837  0.0305\n",
      "     14        0.5847       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4590\u001b[0m  0.0271\n",
      "     15        \u001b[36m0.5607\u001b[0m       0.7578        0.4614  0.0309\n",
      "     16        0.5920       0.7578        0.4651  0.0257\n",
      "     17        0.5879       0.7500        0.4728  0.0312\n",
      "     18        0.5738       0.7812        \u001b[35m0.4464\u001b[0m  0.0267\n",
      "     19        \u001b[36m0.5552\u001b[0m       0.7656        0.4585  0.0316\n",
      "     20        0.5556       0.7656        0.4592  0.0265\n",
      "     21        0.5576       0.7656        0.4504  0.0297\n",
      "     22        0.5738       0.7578        0.4707  0.0265\n",
      "     23        0.5655       0.7656        \u001b[35m0.4411\u001b[0m  0.0270\n",
      "     24        \u001b[36m0.5427\u001b[0m       0.7656        0.4496  0.0273\n",
      "     25        0.5817       0.7656        0.4506  0.0266\n",
      "     26        0.5614       0.7734        0.4438  0.0266\n",
      "     27        0.5768       0.7656        0.4566  0.0269\n",
      "     28        0.5581       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4238\u001b[0m  0.0270\n",
      "     29        0.5516       0.7734        0.4384  0.0274\n",
      "     30        0.5651       0.7656        0.4539  0.0275\n",
      "     31        \u001b[36m0.5425\u001b[0m       0.7812        0.4341  0.0290\n",
      "     32        0.5657       0.7812        0.4422  0.0290\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6453\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8326\u001b[0m  0.0218\n",
      "      2        0.8145       0.5000        \u001b[35m0.7218\u001b[0m  0.0216\n",
      "      3        0.7214       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6934\u001b[0m  0.0242\n",
      "      4        0.6741       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6400\u001b[0m  0.0274\n",
      "      5        0.6575       0.6484        0.6513  0.0309\n",
      "      6        0.6539       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5852\u001b[0m  0.0270\n",
      "      7        \u001b[36m0.6111\u001b[0m       0.6875        \u001b[35m0.5839\u001b[0m  0.0271\n",
      "      8        0.6246       0.6875        0.5929  0.0260\n",
      "      9        \u001b[36m0.6043\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5638\u001b[0m  0.0249\n",
      "     10        \u001b[36m0.6008\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5637\u001b[0m  0.0230\n",
      "     11        \u001b[36m0.5918\u001b[0m       0.7109        0.5895  0.0268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12        0.6072       0.7031        0.5821  0.0273\n",
      "     13        \u001b[36m0.5831\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5590\u001b[0m  0.0279\n",
      "     14        \u001b[36m0.5640\u001b[0m       0.7344        0.5709  0.0247\n",
      "     15        0.5870       0.7266        \u001b[35m0.5526\u001b[0m  0.0262\n",
      "     16        0.5746       0.7188        0.5581  0.0300\n",
      "     17        0.5864       0.7422        \u001b[35m0.5388\u001b[0m  0.0314\n",
      "     18        \u001b[36m0.5605\u001b[0m       0.7266        0.5554  0.0290\n",
      "     19        0.5677       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5364\u001b[0m  0.0267\n",
      "     20        \u001b[36m0.5498\u001b[0m       0.7266        0.5487  0.0283\n",
      "     21        0.5693       0.7266        0.5500  0.0273\n",
      "     22        0.5538       0.7344        \u001b[35m0.5334\u001b[0m  0.0273\n",
      "     23        0.5587       0.7344        \u001b[35m0.5292\u001b[0m  0.0267\n",
      "     24        0.5629       0.7500        \u001b[35m0.5288\u001b[0m  0.0241\n",
      "     25        \u001b[36m0.5287\u001b[0m       0.7500        \u001b[35m0.5263\u001b[0m  0.0254\n",
      "     26        0.5332       0.7500        0.5293  0.0276\n",
      "     27        0.5374       0.7344        \u001b[35m0.5236\u001b[0m  0.0273\n",
      "     28        0.5403       0.7422        \u001b[35m0.5178\u001b[0m  0.0284\n",
      "     29        \u001b[36m0.5238\u001b[0m       0.7344        0.5226  0.0287\n",
      "     30        0.5396       0.7500        0.5204  0.0280\n",
      "     31        0.5268       0.7500        0.5240  0.0294\n",
      "     32        0.5385       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5129\u001b[0m  0.0283\n",
      "     33        \u001b[36m0.5187\u001b[0m       0.7422        0.5224  0.0280\n",
      "     34        \u001b[36m0.5123\u001b[0m       0.7500        0.5281  0.0278\n",
      "     35        0.5224       0.7500        0.5291  0.0343\n",
      "     36        0.5241       0.7578        0.5197  0.0258\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7193\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7031\u001b[0m  0.0203\n",
      "      2        0.7212       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6654\u001b[0m  0.0228\n",
      "      3        \u001b[36m0.6693\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6418\u001b[0m  0.0297\n",
      "      4        \u001b[36m0.6271\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6155\u001b[0m  0.0272\n",
      "      5        \u001b[36m0.6232\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6067\u001b[0m  0.0295\n",
      "      6        \u001b[36m0.5993\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5722\u001b[0m  0.0290\n",
      "      7        \u001b[36m0.5866\u001b[0m       \u001b[32m0.7578\u001b[0m        0.5754  0.0291\n",
      "      8        0.5870       0.7266        \u001b[35m0.5533\u001b[0m  0.0267\n",
      "      9        \u001b[36m0.5601\u001b[0m       0.7578        0.5596  0.0263\n",
      "     10        0.5667       0.7500        0.5565  0.0277\n",
      "     11        0.5604       0.7500        0.5549  0.0290\n",
      "     12        \u001b[36m0.5595\u001b[0m       0.7422        0.5643  0.0299\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6586\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6608\u001b[0m  0.0217\n",
      "      2        \u001b[36m0.6530\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6268\u001b[0m  0.0238\n",
      "      3        \u001b[36m0.5976\u001b[0m       0.7188        \u001b[35m0.5958\u001b[0m  0.0279\n",
      "      4        \u001b[36m0.5755\u001b[0m       0.7188        0.6057  0.0299\n",
      "      5        0.6022       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5838\u001b[0m  0.0288\n",
      "      6        0.5784       0.7031        \u001b[35m0.5718\u001b[0m  0.0271\n",
      "      7        \u001b[36m0.5502\u001b[0m       0.7188        \u001b[35m0.5699\u001b[0m  0.0259\n",
      "      8        \u001b[36m0.5449\u001b[0m       0.7266        \u001b[35m0.5639\u001b[0m  0.0286\n",
      "      9        \u001b[36m0.5300\u001b[0m       0.7188        \u001b[35m0.5608\u001b[0m  0.0286\n",
      "     10        0.5444       0.7109        0.5621  0.0285\n",
      "     11        0.5429       0.7109        0.5661  0.0273\n",
      "     12        \u001b[36m0.5293\u001b[0m       0.7031        0.5715  0.0294\n",
      "     13        \u001b[36m0.5167\u001b[0m       0.7188        0.5712  0.0259\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6904\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7400\u001b[0m  0.0221\n",
      "      2        0.7344       0.5000        \u001b[35m0.7076\u001b[0m  0.0320\n",
      "      3        \u001b[36m0.6691\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6897\u001b[0m  0.0289\n",
      "      4        \u001b[36m0.6325\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6594\u001b[0m  0.0282\n",
      "      5        \u001b[36m0.6096\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6333\u001b[0m  0.0280\n",
      "      6        \u001b[36m0.5809\u001b[0m       0.7500        \u001b[35m0.5894\u001b[0m  0.0289\n",
      "      7        \u001b[36m0.5361\u001b[0m       0.7578        0.5895  0.0276\n",
      "      8        0.5441       0.7578        \u001b[35m0.5859\u001b[0m  0.0280\n",
      "      9        \u001b[36m0.5287\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5754\u001b[0m  0.0282\n",
      "     10        0.5324       0.7500        \u001b[35m0.5734\u001b[0m  0.0277\n",
      "     11        0.5339       0.7656        0.5755  0.0280\n",
      "     12        0.5339       0.7500        \u001b[35m0.5621\u001b[0m  0.0276\n",
      "     13        0.5338       0.7500        \u001b[35m0.5521\u001b[0m  0.0300\n",
      "     14        \u001b[36m0.4912\u001b[0m       0.7578        0.5568  0.0252\n",
      "     15        0.5236       0.7578        \u001b[35m0.5505\u001b[0m  0.0276\n",
      "     16        0.5283       0.7500        0.5541  0.0284\n",
      "     17        0.5091       0.7422        0.5541  0.0280\n",
      "     18        0.5240       0.7656        \u001b[35m0.5446\u001b[0m  0.0286\n",
      "     19        0.5059       0.7578        0.5514  0.0288\n",
      "     20        0.5205       0.7500        \u001b[35m0.5421\u001b[0m  0.0306\n",
      "     21        0.5085       0.7500        0.5601  0.0275\n",
      "     22        0.5185       0.7578        0.5595  0.0294\n",
      "     23        0.5281       0.7422        0.5503  0.0295\n",
      "     24        0.5140       0.7578        0.5459  0.0284\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5890\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8123\u001b[0m  0.0412\n",
      "      2        0.6772       0.5000        0.8130  0.0385\n",
      "      3        0.6735       0.5000        \u001b[35m0.8120\u001b[0m  0.0428\n",
      "      4        0.6761       0.5000        \u001b[35m0.7909\u001b[0m  0.0381\n",
      "      5        0.6482       0.5000        \u001b[35m0.7567\u001b[0m  0.0477\n",
      "      6        0.6287       \u001b[32m0.5234\u001b[0m        \u001b[35m0.7048\u001b[0m  0.0360\n",
      "      7        0.6262       0.5156        0.7230  0.0406\n",
      "      8        0.6328       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6662\u001b[0m  0.0412\n",
      "      9        0.6220       0.5469        0.6782  0.0454\n",
      "     10        0.5922       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6364\u001b[0m  0.0374\n",
      "     11        0.5952       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5961\u001b[0m  0.0462\n",
      "     12        0.6150       0.6250        0.6376  0.0359\n",
      "     13        0.5904       0.6719        \u001b[35m0.5900\u001b[0m  0.0382\n",
      "     14        \u001b[36m0.5784\u001b[0m       0.6641        \u001b[35m0.5778\u001b[0m  0.0420\n",
      "     15        0.5862       0.6562        0.5873  0.0361\n",
      "     16        0.5950       0.6797        \u001b[35m0.5675\u001b[0m  0.0405\n",
      "     17        \u001b[36m0.5772\u001b[0m       0.6484        0.5875  0.0413\n",
      "     18        0.5808       0.6484        0.5918  0.0427\n",
      "     19        0.5799       0.6797        \u001b[35m0.5659\u001b[0m  0.0365\n",
      "     20        0.5839       0.6719        0.5902  0.0394\n",
      "     21        \u001b[36m0.5629\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5609\u001b[0m  0.0426\n",
      "     22        \u001b[36m0.5621\u001b[0m       \u001b[32m0.7109\u001b[0m        0.5634  0.0411\n",
      "     23        0.5696       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5480\u001b[0m  0.0361\n",
      "     24        0.5778       0.6875        0.5774  0.0386\n",
      "     25        \u001b[36m0.5496\u001b[0m       0.7109        \u001b[35m0.5443\u001b[0m  0.0368\n",
      "     26        0.5668       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5141\u001b[0m  0.0448\n",
      "     27        0.5625       0.7031        0.5563  0.0380\n",
      "     28        0.5763       0.7109        0.5511  0.0416\n",
      "     29        0.5733       0.7109        0.5501  0.0363\n",
      "     30        0.5745       0.7031        0.5539  0.0364\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5934\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8686\u001b[0m  0.0362\n",
      "      2        0.6867       0.5000        \u001b[35m0.8399\u001b[0m  0.0416\n",
      "      3        0.6761       0.5000        \u001b[35m0.8123\u001b[0m  0.0366\n",
      "      4        0.6573       0.5000        \u001b[35m0.7860\u001b[0m  0.0419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5        0.6529       0.5000        \u001b[35m0.7656\u001b[0m  0.0367\n",
      "      6        0.6270       0.5000        0.7774  0.0429\n",
      "      7        0.6328       0.5000        \u001b[35m0.7449\u001b[0m  0.0358\n",
      "      8        0.6065       \u001b[32m0.5156\u001b[0m        \u001b[35m0.7184\u001b[0m  0.0407\n",
      "      9        0.6130       0.5000        0.7448  0.0364\n",
      "     10        0.6053       0.5078        0.7257  0.0401\n",
      "     11        0.6058       \u001b[32m0.5625\u001b[0m        \u001b[35m0.7032\u001b[0m  0.0362\n",
      "     12        0.6040       0.5547        0.7148  0.0411\n",
      "     13        \u001b[36m0.5865\u001b[0m       \u001b[32m0.6250\u001b[0m        0.7081  0.0360\n",
      "     14        0.5892       0.5469        0.7183  0.0392\n",
      "     15        0.5893       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6674\u001b[0m  0.0406\n",
      "     16        0.5889       0.5625        0.7283  0.0361\n",
      "     17        \u001b[36m0.5831\u001b[0m       0.6094        0.7074  0.0414\n",
      "     18        0.6083       0.5625        0.7207  0.0377\n",
      "     19        0.5902       0.5859        0.7217  0.0360\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6537\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7984\u001b[0m  0.0342\n",
      "      2        0.7120       0.5000        \u001b[35m0.7735\u001b[0m  0.0405\n",
      "      3        0.6922       0.5000        \u001b[35m0.7463\u001b[0m  0.0412\n",
      "      4        \u001b[36m0.6429\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6969\u001b[0m  0.0364\n",
      "      5        0.6542       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6833\u001b[0m  0.0412\n",
      "      6        \u001b[36m0.6323\u001b[0m       0.5156        0.6906  0.0361\n",
      "      7        \u001b[36m0.6015\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6343\u001b[0m  0.0410\n",
      "      8        0.6070       0.6641        \u001b[35m0.6333\u001b[0m  0.0366\n",
      "      9        0.6099       0.6562        \u001b[35m0.6184\u001b[0m  0.0423\n",
      "     10        \u001b[36m0.5788\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5777\u001b[0m  0.0363\n",
      "     11        \u001b[36m0.5786\u001b[0m       0.6719        0.6271  0.0383\n",
      "     12        0.5937       0.6953        0.6044  0.0417\n",
      "     13        0.5874       0.6953        0.6075  0.0361\n",
      "     14        0.5972       0.6797        0.6167  0.0410\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6518\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7614\u001b[0m  0.0338\n",
      "      2        0.6692       \u001b[32m0.5078\u001b[0m        \u001b[35m0.7098\u001b[0m  0.0481\n",
      "      3        0.6531       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6812\u001b[0m  0.0357\n",
      "      4        \u001b[36m0.6124\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6380\u001b[0m  0.0417\n",
      "      5        \u001b[36m0.6049\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6264\u001b[0m  0.0359\n",
      "      6        0.6066       0.6641        0.6292  0.0436\n",
      "      7        0.6056       0.6484        0.6519  0.0362\n",
      "      8        \u001b[36m0.5778\u001b[0m       0.6641        \u001b[35m0.6019\u001b[0m  0.0406\n",
      "      9        0.5902       0.6484        0.6416  0.0452\n",
      "     10        0.6174       \u001b[32m0.6797\u001b[0m        0.6036  0.0434\n",
      "     11        0.5891       0.6797        \u001b[35m0.5867\u001b[0m  0.0370\n",
      "     12        \u001b[36m0.5768\u001b[0m       \u001b[32m0.6875\u001b[0m        0.5883  0.0406\n",
      "     13        0.5870       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5719\u001b[0m  0.0363\n",
      "     14        \u001b[36m0.5703\u001b[0m       0.6797        0.5752  0.0404\n",
      "     15        \u001b[36m0.5440\u001b[0m       0.6875        0.5811  0.0358\n",
      "     16        0.5624       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5572\u001b[0m  0.0382\n",
      "     17        0.5808       0.6797        0.5998  0.0416\n",
      "     18        0.5619       0.6953        0.5956  0.0361\n",
      "     19        0.5508       0.6875        0.5744  0.0388\n",
      "     20        0.5489       0.7031        0.5575  0.0409\n",
      "     21        \u001b[36m0.5294\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5399\u001b[0m  0.0363\n",
      "     22        0.5549       0.7109        0.5695  0.0394\n",
      "     23        0.5538       0.7109        0.5728  0.0411\n",
      "     24        0.5609       0.7031        0.5413  0.0358\n",
      "     25        0.5469       0.6953        0.5627  0.0371\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6111\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8229\u001b[0m  0.0343\n",
      "      2        0.6666       0.5000        \u001b[35m0.7825\u001b[0m  0.0440\n",
      "      3        0.6393       0.5000        \u001b[35m0.7492\u001b[0m  0.0389\n",
      "      4        0.6113       0.5000        0.7499  0.0433\n",
      "      5        0.6284       0.5000        0.7542  0.0371\n",
      "      6        \u001b[36m0.6089\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.7299\u001b[0m  0.0417\n",
      "      7        0.6136       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6869\u001b[0m  0.0370\n",
      "      8        0.6154       0.5469        0.7129  0.0426\n",
      "      9        \u001b[36m0.5765\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6512\u001b[0m  0.0366\n",
      "     10        \u001b[36m0.5528\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6200\u001b[0m  0.0404\n",
      "     11        0.5773       0.6562        0.6421  0.0365\n",
      "     12        0.5782       0.6641        \u001b[35m0.6125\u001b[0m  0.0402\n",
      "     13        0.5932       0.6562        0.6451  0.0360\n",
      "     14        0.5721       0.6641        0.6247  0.0388\n",
      "     15        \u001b[36m0.5520\u001b[0m       \u001b[32m0.6875\u001b[0m        0.6208  0.0414\n",
      "     16        0.5711       0.6797        \u001b[35m0.6088\u001b[0m  0.0362\n",
      "     17        0.5757       0.6875        \u001b[35m0.5986\u001b[0m  0.0412\n",
      "     18        0.5548       0.6875        0.5987  0.0390\n",
      "     19        0.5605       0.6875        0.6249  0.0425\n",
      "     20        \u001b[36m0.5414\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5784\u001b[0m  0.0368\n",
      "     21        0.5885       0.6875        0.5964  0.0400\n",
      "     22        0.5519       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5775\u001b[0m  0.0365\n",
      "     23        0.5620       0.6953        0.5781  0.0362\n",
      "     24        0.5503       0.6953        0.5909  0.0407\n",
      "     25        0.5691       0.6953        0.6006  0.0388\n",
      "     26        0.5606       0.6953        0.5907  0.0361\n",
      "     27        \u001b[36m0.5280\u001b[0m       0.7031        \u001b[35m0.5726\u001b[0m  0.0377\n",
      "     28        0.5659       0.6562        0.6587  0.0422\n",
      "     29        0.5543       0.7031        0.6133  0.0363\n",
      "     30        0.5515       0.6875        0.5903  0.0361\n",
      "     31        0.5389       0.6719        0.6202  0.0367\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6997\u001b[0m       \u001b[32m0.5125\u001b[0m        \u001b[35m0.6924\u001b[0m  0.0251\n",
      "      2        \u001b[36m0.6967\u001b[0m       \u001b[32m0.5188\u001b[0m        \u001b[35m0.6897\u001b[0m  0.0289\n",
      "      3        \u001b[36m0.6953\u001b[0m       \u001b[32m0.5437\u001b[0m        \u001b[35m0.6870\u001b[0m  0.0313\n",
      "      4        \u001b[36m0.6911\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6841\u001b[0m  0.0323\n",
      "      5        \u001b[36m0.6901\u001b[0m       \u001b[32m0.5875\u001b[0m        \u001b[35m0.6812\u001b[0m  0.0329\n",
      "      6        \u001b[36m0.6822\u001b[0m       \u001b[32m0.6500\u001b[0m        \u001b[35m0.6776\u001b[0m  0.0313\n",
      "      7        \u001b[36m0.6814\u001b[0m       \u001b[32m0.6813\u001b[0m        \u001b[35m0.6738\u001b[0m  0.0336\n",
      "      8        \u001b[36m0.6810\u001b[0m       0.6813        \u001b[35m0.6703\u001b[0m  0.0338\n",
      "      9        \u001b[36m0.6788\u001b[0m       \u001b[32m0.6937\u001b[0m        \u001b[35m0.6665\u001b[0m  0.0324\n",
      "     10        \u001b[36m0.6684\u001b[0m       \u001b[32m0.7063\u001b[0m        \u001b[35m0.6619\u001b[0m  0.0325\n",
      "     11        0.6721       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6576\u001b[0m  0.0327\n",
      "     12        \u001b[36m0.6629\u001b[0m       0.7188        \u001b[35m0.6522\u001b[0m  0.0328\n",
      "     13        0.6636       \u001b[32m0.7250\u001b[0m        \u001b[35m0.6476\u001b[0m  0.0315\n",
      "     14        \u001b[36m0.6576\u001b[0m       0.7250        \u001b[35m0.6424\u001b[0m  0.0309\n",
      "     15        \u001b[36m0.6554\u001b[0m       0.7188        \u001b[35m0.6371\u001b[0m  0.0339\n",
      "     16        \u001b[36m0.6487\u001b[0m       0.7250        \u001b[35m0.6311\u001b[0m  0.0347\n",
      "     17        \u001b[36m0.6379\u001b[0m       0.7250        \u001b[35m0.6246\u001b[0m  0.0326\n",
      "     18        \u001b[36m0.6275\u001b[0m       \u001b[32m0.7375\u001b[0m        \u001b[35m0.6175\u001b[0m  0.0316\n",
      "     19        0.6308       0.7375        \u001b[35m0.6108\u001b[0m  0.0335\n",
      "     20        \u001b[36m0.6265\u001b[0m       0.7375        \u001b[35m0.6044\u001b[0m  0.0282\n",
      "     21        \u001b[36m0.6263\u001b[0m       \u001b[32m0.7438\u001b[0m        \u001b[35m0.5989\u001b[0m  0.0321\n",
      "     22        \u001b[36m0.6214\u001b[0m       0.7438        \u001b[35m0.5930\u001b[0m  0.0333\n",
      "     23        \u001b[36m0.6203\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5878\u001b[0m  0.0330\n",
      "     24        \u001b[36m0.6028\u001b[0m       0.7500        \u001b[35m0.5814\u001b[0m  0.0310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25        0.6059       0.7375        \u001b[35m0.5758\u001b[0m  0.0336\n",
      "     26        0.6093       0.7375        \u001b[35m0.5709\u001b[0m  0.0322\n",
      "     27        \u001b[36m0.6002\u001b[0m       0.7375        \u001b[35m0.5661\u001b[0m  0.0334\n",
      "     28        \u001b[36m0.5921\u001b[0m       0.7438        \u001b[35m0.5614\u001b[0m  0.0303\n",
      "     29        \u001b[36m0.5874\u001b[0m       0.7438        \u001b[35m0.5565\u001b[0m  0.0286\n",
      "     30        \u001b[36m0.5804\u001b[0m       0.7438        \u001b[35m0.5523\u001b[0m  0.0316\n",
      "     31        0.5834       0.7438        \u001b[35m0.5488\u001b[0m  0.0318\n",
      "     32        \u001b[36m0.5756\u001b[0m       0.7375        \u001b[35m0.5449\u001b[0m  0.0318\n",
      "     33        0.5801       0.7375        \u001b[35m0.5415\u001b[0m  0.0312\n",
      "     34        \u001b[36m0.5745\u001b[0m       0.7375        \u001b[35m0.5387\u001b[0m  0.0310\n",
      "     35        \u001b[36m0.5698\u001b[0m       0.7375        \u001b[35m0.5356\u001b[0m  0.0328\n",
      "     36        0.5760       0.7375        \u001b[35m0.5332\u001b[0m  0.0313\n",
      "     37        0.5734       0.7375        \u001b[35m0.5311\u001b[0m  0.0295\n",
      "     38        \u001b[36m0.5639\u001b[0m       0.7375        \u001b[35m0.5288\u001b[0m  0.0318\n",
      "     39        \u001b[36m0.5621\u001b[0m       0.7375        \u001b[35m0.5270\u001b[0m  0.0321\n",
      "     40        \u001b[36m0.5610\u001b[0m       0.7312        \u001b[35m0.5248\u001b[0m  0.0302\n",
      "     41        \u001b[36m0.5575\u001b[0m       0.7375        \u001b[35m0.5228\u001b[0m  0.0323\n",
      "     42        0.5780       0.7375        \u001b[35m0.5216\u001b[0m  0.0331\n",
      "     43        0.5624       0.7438        \u001b[35m0.5204\u001b[0m  0.0301\n",
      "     44        \u001b[36m0.5562\u001b[0m       0.7438        \u001b[35m0.5184\u001b[0m  0.0318\n",
      "     45        \u001b[36m0.5493\u001b[0m       0.7438        \u001b[35m0.5169\u001b[0m  0.0320\n",
      "     46        0.5493       0.7500        \u001b[35m0.5159\u001b[0m  0.0332\n",
      "     47        0.5530       0.7438        \u001b[35m0.5147\u001b[0m  0.0333\n",
      "     48        0.5540       0.7438        \u001b[35m0.5139\u001b[0m  0.0301\n",
      "     49        \u001b[36m0.5478\u001b[0m       0.7438        \u001b[35m0.5128\u001b[0m  0.0317\n",
      "     50        0.5523       0.7438        \u001b[35m0.5123\u001b[0m  0.0321\n",
      "     51        \u001b[36m0.5384\u001b[0m       0.7438        \u001b[35m0.5111\u001b[0m  0.0281\n",
      "     52        0.5670       0.7438        \u001b[35m0.5104\u001b[0m  0.0324\n",
      "     53        0.5551       0.7438        \u001b[35m0.5103\u001b[0m  0.0300\n",
      "     54        0.5576       0.7438        \u001b[35m0.5103\u001b[0m  0.0375\n",
      "     55        0.5532       0.7438        \u001b[35m0.5097\u001b[0m  0.0289\n",
      "     56        \u001b[36m0.5373\u001b[0m       0.7438        \u001b[35m0.5088\u001b[0m  0.0325\n",
      "     57        0.5462       0.7438        \u001b[35m0.5083\u001b[0m  0.0305\n",
      "     58        0.5387       0.7438        0.5086  0.0285\n",
      "     59        \u001b[36m0.5252\u001b[0m       0.7438        \u001b[35m0.5077\u001b[0m  0.0316\n",
      "     60        0.5510       0.7438        \u001b[35m0.5072\u001b[0m  0.0282\n",
      "     61        0.5391       0.7375        \u001b[35m0.5062\u001b[0m  0.0322\n",
      "     62        0.5386       0.7375        \u001b[35m0.5058\u001b[0m  0.0301\n",
      "     63        0.5398       0.7375        \u001b[35m0.5054\u001b[0m  0.0327\n",
      "     64        0.5367       0.7375        \u001b[35m0.5054\u001b[0m  0.0298\n",
      "     65        0.5394       0.7312        0.5054  0.0327\n",
      "     66        0.5316       0.7375        \u001b[35m0.5053\u001b[0m  0.0301\n",
      "     67        0.5399       0.7312        \u001b[35m0.5052\u001b[0m  0.0322\n",
      "     68        0.5342       0.7375        \u001b[35m0.5050\u001b[0m  0.0391\n",
      "     69        0.5311       0.7375        \u001b[35m0.5047\u001b[0m  0.0291\n",
      "     70        0.5475       0.7375        0.5050  0.0343\n",
      "     71        \u001b[36m0.5239\u001b[0m       0.7312        0.5049  0.0322\n",
      "     72        0.5398       0.7375        \u001b[35m0.5046\u001b[0m  0.0284\n",
      "     73        0.5399       0.7375        0.5047  0.0323\n",
      "     74        0.5253       0.7312        \u001b[35m0.5045\u001b[0m  0.0287\n",
      "     75        0.5290       0.7312        \u001b[35m0.5042\u001b[0m  0.0310\n",
      "     76        0.5451       0.7312        0.5046  0.0282\n",
      "     77        0.5322       0.7250        0.5043  0.0302\n",
      "     78        0.5427       0.7250        0.5045  0.0321\n",
      "     79        0.5413       0.7250        0.5045  0.0398\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best parameters found:\n",
      "\n",
      "{'optimizer__momentum': 0.3, 'module__num_unitsB': 6, 'module__num_unitsA': 12, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 32}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.740 (+/-0.064) for {'optimizer__momentum': 0.6, 'module__num_unitsB': 6, 'module__num_unitsA': 6, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 32}\n",
      "0.768 (+/-0.071) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 6, 'module__num_unitsA': 12, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 32}\n",
      "0.591 (+/-0.225) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 12, 'module__num_unitsA': 6, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 16}\n",
      "0.556 (+/-0.104) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 3, 'module__num_unitsA': 12, 'module__dropout': 0.0, 'lr': 1, 'batch_size': 16}\n",
      "0.655 (+/-0.134) for {'optimizer__momentum': 0.6, 'module__num_unitsB': 9, 'module__num_unitsA': 12, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 16}\n",
      "0.747 (+/-0.035) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 6, 'module__num_unitsA': 6, 'module__dropout': 0.5, 'lr': 0.01, 'batch_size': 16}\n",
      "0.739 (+/-0.050) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 9, 'module__num_unitsA': 12, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 64}\n",
      "0.761 (+/-0.069) for {'optimizer__momentum': 0.6, 'module__num_unitsB': 12, 'module__num_unitsA': 6, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 16}\n",
      "0.733 (+/-0.052) for {'optimizer__momentum': 0.6, 'module__num_unitsB': 9, 'module__num_unitsA': 12, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 32}\n",
      "0.670 (+/-0.054) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 9, 'module__num_unitsA': 6, 'module__dropout': 0.5, 'lr': 0.1, 'batch_size': 16}\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6593\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7258\u001b[0m  0.0219\n",
      "      2        0.7100       0.5000        0.7341  0.0228\n",
      "      3        0.7149       0.5000        0.7322  0.0326\n",
      "      4        0.7119       0.5000        0.7281  0.0314\n",
      "      5        0.7179       0.5000        \u001b[35m0.7217\u001b[0m  0.0278\n",
      "      6        0.7185       0.5000        \u001b[35m0.7205\u001b[0m  0.0276\n",
      "      7        0.7050       0.5000        \u001b[35m0.7195\u001b[0m  0.0302\n",
      "      8        0.7085       0.5000        \u001b[35m0.7087\u001b[0m  0.0308\n",
      "      9        0.7091       0.5000        \u001b[35m0.7017\u001b[0m  0.0388\n",
      "     10        0.6957       0.5000        \u001b[35m0.6904\u001b[0m  0.0439\n",
      "     11        0.7036       0.5000        \u001b[35m0.6891\u001b[0m  0.0314\n",
      "     12        0.6964       0.5000        \u001b[35m0.6788\u001b[0m  0.0398\n",
      "     13        0.7062       0.5000        \u001b[35m0.6728\u001b[0m  0.0377\n",
      "     14        0.7067       0.5000        0.6738  0.0310\n",
      "     15        0.6946       0.5000        \u001b[35m0.6667\u001b[0m  0.0293\n",
      "     16        0.6838       0.5000        \u001b[35m0.6565\u001b[0m  0.0296\n",
      "     17        0.6877       0.5000        \u001b[35m0.6465\u001b[0m  0.0267\n",
      "     18        0.6858       0.5000        \u001b[35m0.6403\u001b[0m  0.0276\n",
      "     19        0.6830       0.5000        \u001b[35m0.6362\u001b[0m  0.0282\n",
      "     20        0.7088       0.5000        0.6447  0.0277\n",
      "     21        0.6817       0.5000        0.6370  0.0286\n",
      "     22        0.6689       0.5000        \u001b[35m0.6282\u001b[0m  0.0274\n",
      "     23        0.6773       0.5000        \u001b[35m0.6267\u001b[0m  0.0269\n",
      "     24        0.6870       0.5000        \u001b[35m0.6260\u001b[0m  0.0270\n",
      "     25        0.6780       0.5000        \u001b[35m0.6214\u001b[0m  0.0294\n",
      "     26        0.6814       0.5000        0.6222  0.0280\n",
      "     27        0.6761       0.5000        \u001b[35m0.6165\u001b[0m  0.0263\n",
      "     28        0.6754       0.5000        \u001b[35m0.6133\u001b[0m  0.0253\n",
      "     29        0.6662       0.5000        \u001b[35m0.6083\u001b[0m  0.0244\n",
      "     30        0.6628       0.5000        \u001b[35m0.6035\u001b[0m  0.0246\n",
      "     31        0.6642       0.5000        \u001b[35m0.6006\u001b[0m  0.0298\n",
      "     32        0.6718       0.5000        \u001b[35m0.5977\u001b[0m  0.0255\n",
      "     33        0.6599       0.5000        \u001b[35m0.5940\u001b[0m  0.0271\n",
      "     34        0.6643       0.5000        \u001b[35m0.5938\u001b[0m  0.0300\n",
      "     35        \u001b[36m0.6541\u001b[0m       0.5000        \u001b[35m0.5825\u001b[0m  0.0294\n",
      "     36        \u001b[36m0.6325\u001b[0m       0.5000        \u001b[35m0.5725\u001b[0m  0.0259\n",
      "     37        0.6420       0.5000        \u001b[35m0.5724\u001b[0m  0.0277\n",
      "     38        0.6550       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5664\u001b[0m  0.0270\n",
      "     39        0.6539       0.7734        \u001b[35m0.5650\u001b[0m  0.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     40        0.6712       0.5000        0.5741  0.0363\n",
      "     41        0.6464       0.5000        0.5681  0.0271\n",
      "     42        0.6464       0.7500        0.5652  0.0270\n",
      "     43        0.6621       \u001b[32m0.7812\u001b[0m        0.5670  0.0286\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7065\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7386\u001b[0m  0.0211\n",
      "      2        \u001b[36m0.7038\u001b[0m       0.5000        0.7412  0.0254\n",
      "      3        0.7091       0.5000        \u001b[35m0.7221\u001b[0m  0.0227\n",
      "      4        \u001b[36m0.6806\u001b[0m       0.5000        \u001b[35m0.7055\u001b[0m  0.0257\n",
      "      5        \u001b[36m0.6702\u001b[0m       0.5000        \u001b[35m0.6861\u001b[0m  0.0285\n",
      "      6        0.6779       0.5000        \u001b[35m0.6795\u001b[0m  0.0246\n",
      "      7        0.6762       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6678\u001b[0m  0.0242\n",
      "      8        \u001b[36m0.6451\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6518\u001b[0m  0.0283\n",
      "      9        0.6687       0.5547        0.6533  0.0266\n",
      "     10        0.6624       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6503\u001b[0m  0.0251\n",
      "     11        \u001b[36m0.6328\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6373\u001b[0m  0.0274\n",
      "     12        0.6330       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6330\u001b[0m  0.0291\n",
      "     13        0.6509       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6235\u001b[0m  0.0271\n",
      "     14        0.6394       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6128\u001b[0m  0.0264\n",
      "     15        0.6652       0.6797        0.6172  0.0257\n",
      "     16        0.6476       0.7109        \u001b[35m0.6113\u001b[0m  0.0276\n",
      "     17        \u001b[36m0.6280\u001b[0m       0.7188        \u001b[35m0.6012\u001b[0m  0.0275\n",
      "     18        0.6314       0.7188        \u001b[35m0.5982\u001b[0m  0.0284\n",
      "     19        0.6357       0.6953        0.6067  0.0300\n",
      "     20        0.6391       0.6719        0.6127  0.0270\n",
      "     21        \u001b[36m0.6074\u001b[0m       0.7188        \u001b[35m0.5827\u001b[0m  0.0280\n",
      "     22        0.6295       0.7188        0.5879  0.0263\n",
      "     23        0.6187       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5716\u001b[0m  0.0260\n",
      "     24        0.6096       0.7188        0.5879  0.0261\n",
      "     25        0.6241       0.7188        0.5717  0.0274\n",
      "     26        0.6117       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5704\u001b[0m  0.0303\n",
      "     27        \u001b[36m0.6021\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5625\u001b[0m  0.0275\n",
      "     28        0.6232       0.7422        0.5655  0.0273\n",
      "     29        0.6053       0.7344        0.5730  0.0280\n",
      "     30        0.6238       0.7266        0.5766  0.0343\n",
      "     31        0.6215       0.7188        0.5746  0.0304\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7062\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6786\u001b[0m  0.0222\n",
      "      2        \u001b[36m0.6882\u001b[0m       0.5000        \u001b[35m0.6687\u001b[0m  0.0307\n",
      "      3        \u001b[36m0.6690\u001b[0m       0.5000        \u001b[35m0.6575\u001b[0m  0.0267\n",
      "      4        0.6717       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6483\u001b[0m  0.0287\n",
      "      5        \u001b[36m0.6528\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6408\u001b[0m  0.0297\n",
      "      6        \u001b[36m0.6505\u001b[0m       0.5781        \u001b[35m0.6355\u001b[0m  0.0273\n",
      "      7        0.6559       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6317\u001b[0m  0.0299\n",
      "      8        \u001b[36m0.6445\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6241\u001b[0m  0.0262\n",
      "      9        \u001b[36m0.6401\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6205\u001b[0m  0.0273\n",
      "     10        0.6485       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6106\u001b[0m  0.0297\n",
      "     11        \u001b[36m0.6286\u001b[0m       0.7031        0.6141  0.0288\n",
      "     12        0.6337       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6083\u001b[0m  0.0304\n",
      "     13        0.6395       \u001b[32m0.7422\u001b[0m        0.6097  0.0325\n",
      "     14        \u001b[36m0.6246\u001b[0m       0.7422        \u001b[35m0.6045\u001b[0m  0.0273\n",
      "     15        0.6316       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6035\u001b[0m  0.0283\n",
      "     16        \u001b[36m0.6145\u001b[0m       0.7500        \u001b[35m0.6026\u001b[0m  0.0279\n",
      "     17        0.6598       0.7344        0.6068  0.0270\n",
      "     18        0.6230       0.7422        0.6036  0.0308\n",
      "     19        0.6178       0.7109        0.6087  0.0245\n",
      "     20        \u001b[36m0.6101\u001b[0m       0.7188        \u001b[35m0.6010\u001b[0m  0.0279\n",
      "     21        \u001b[36m0.6081\u001b[0m       0.7188        0.6038  0.0269\n",
      "     22        0.6285       0.7109        \u001b[35m0.5977\u001b[0m  0.0273\n",
      "     23        0.6294       0.7188        0.5984  0.0278\n",
      "     24        \u001b[36m0.5956\u001b[0m       0.7109        \u001b[35m0.5924\u001b[0m  0.0288\n",
      "     25        0.6037       0.7031        0.5979  0.0286\n",
      "     26        0.6289       0.6953        0.6036  0.0277\n",
      "     27        \u001b[36m0.5912\u001b[0m       0.7109        0.6079  0.0272\n",
      "     28        0.6024       0.7109        0.6030  0.0272\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7214\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7193\u001b[0m  0.0268\n",
      "      2        \u001b[36m0.7159\u001b[0m       0.5000        \u001b[35m0.7146\u001b[0m  0.0280\n",
      "      3        \u001b[36m0.7146\u001b[0m       0.5000        \u001b[35m0.7128\u001b[0m  0.0265\n",
      "      4        \u001b[36m0.7064\u001b[0m       0.5000        0.7138  0.0291\n",
      "      5        0.7119       0.5000        0.7148  0.0265\n",
      "      6        0.7123       0.5000        \u001b[35m0.7070\u001b[0m  0.0284\n",
      "      7        \u001b[36m0.7051\u001b[0m       0.5000        0.7076  0.0281\n",
      "      8        \u001b[36m0.7023\u001b[0m       0.5000        \u001b[35m0.7033\u001b[0m  0.0280\n",
      "      9        \u001b[36m0.6979\u001b[0m       0.5000        \u001b[35m0.7001\u001b[0m  0.0269\n",
      "     10        \u001b[36m0.6937\u001b[0m       0.5000        \u001b[35m0.6944\u001b[0m  0.0282\n",
      "     11        \u001b[36m0.6882\u001b[0m       0.5000        \u001b[35m0.6834\u001b[0m  0.0275\n",
      "     12        \u001b[36m0.6794\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6677\u001b[0m  0.0276\n",
      "     13        \u001b[36m0.6789\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6599\u001b[0m  0.0286\n",
      "     14        \u001b[36m0.6601\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6370\u001b[0m  0.0276\n",
      "     15        \u001b[36m0.6401\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6199\u001b[0m  0.0274\n",
      "     16        0.6445       0.6797        0.6219  0.0289\n",
      "     17        0.6540       0.6797        \u001b[35m0.6190\u001b[0m  0.0249\n",
      "     18        0.6408       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6005\u001b[0m  0.0275\n",
      "     19        \u001b[36m0.6158\u001b[0m       0.7031        \u001b[35m0.5990\u001b[0m  0.0276\n",
      "     20        \u001b[36m0.6098\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5838\u001b[0m  0.0282\n",
      "     21        \u001b[36m0.6016\u001b[0m       0.7109        \u001b[35m0.5826\u001b[0m  0.0310\n",
      "     22        \u001b[36m0.5900\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5673\u001b[0m  0.0276\n",
      "     23        0.6564       0.6875        0.5963  0.0322\n",
      "     24        0.6169       0.7031        0.5823  0.0273\n",
      "     25        0.6020       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5618\u001b[0m  0.0282\n",
      "     26        0.5968       0.7422        \u001b[35m0.5528\u001b[0m  0.0273\n",
      "     27        \u001b[36m0.5837\u001b[0m       0.7500        \u001b[35m0.5524\u001b[0m  0.0286\n",
      "     28        0.6224       0.7266        0.5736  0.0290\n",
      "     29        0.6058       0.7266        0.5713  0.0296\n",
      "     30        0.6087       0.7344        0.5583  0.0277\n",
      "     31        0.5918       0.7344        0.5586  0.0284\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6863\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6987\u001b[0m  0.0279\n",
      "      2        0.6970       0.5000        0.7032  0.0278\n",
      "      3        0.6974       0.5000        \u001b[35m0.6980\u001b[0m  0.0294\n",
      "      4        0.7102       0.5000        \u001b[35m0.6931\u001b[0m  0.0290\n",
      "      5        0.6945       0.5000        \u001b[35m0.6854\u001b[0m  0.0245\n",
      "      6        \u001b[36m0.6773\u001b[0m       0.5000        \u001b[35m0.6780\u001b[0m  0.0312\n",
      "      7        0.6827       0.5000        \u001b[35m0.6713\u001b[0m  0.0282\n",
      "      8        \u001b[36m0.6772\u001b[0m       0.5000        \u001b[35m0.6623\u001b[0m  0.0277\n",
      "      9        \u001b[36m0.6555\u001b[0m       0.5000        \u001b[35m0.6473\u001b[0m  0.0281\n",
      "     10        \u001b[36m0.6402\u001b[0m       0.5000        \u001b[35m0.6398\u001b[0m  0.0316\n",
      "     11        0.6482       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6310\u001b[0m  0.0287\n",
      "     12        \u001b[36m0.6146\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6225\u001b[0m  0.0291\n",
      "     13        0.6226       0.7109        \u001b[35m0.6200\u001b[0m  0.0264\n",
      "     14        0.6455       \u001b[32m0.7422\u001b[0m        0.6256  0.0284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15        0.6220       0.7188        0.6245  0.0258\n",
      "     16        0.6460       0.7188        0.6264  0.0276\n",
      "     17        0.6266       0.6953        0.6218  0.0269\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7563\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6511\u001b[0m  0.0369\n",
      "      2        \u001b[36m0.6846\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5905\u001b[0m  0.0398\n",
      "      3        \u001b[36m0.6824\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5587\u001b[0m  0.0380\n",
      "      4        \u001b[36m0.6785\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5310\u001b[0m  0.0436\n",
      "      5        \u001b[36m0.6402\u001b[0m       0.7500        \u001b[35m0.5161\u001b[0m  0.0356\n",
      "      6        \u001b[36m0.6350\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4976\u001b[0m  0.0406\n",
      "      7        0.6488       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4968\u001b[0m  0.0360\n",
      "      8        0.6506       0.7656        \u001b[35m0.4882\u001b[0m  0.0414\n",
      "      9        0.6541       0.7656        0.4967  0.0361\n",
      "     10        0.6390       0.7656        \u001b[35m0.4769\u001b[0m  0.0411\n",
      "     11        \u001b[36m0.6168\u001b[0m       0.7656        \u001b[35m0.4732\u001b[0m  0.0359\n",
      "     12        \u001b[36m0.5985\u001b[0m       0.7578        0.4779  0.0404\n",
      "     13        0.6244       0.7656        0.4795  0.0368\n",
      "     14        0.6050       0.7578        \u001b[35m0.4663\u001b[0m  0.0385\n",
      "     15        \u001b[36m0.5948\u001b[0m       0.7578        0.4694  0.0409\n",
      "     16        0.6093       0.7578        0.4675  0.0372\n",
      "     17        0.6015       0.7656        0.4696  0.0402\n",
      "     18        0.6156       0.7656        \u001b[35m0.4590\u001b[0m  0.0360\n",
      "     19        \u001b[36m0.5929\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4563\u001b[0m  0.0372\n",
      "     20        0.6013       0.7812        0.4569  0.0444\n",
      "     21        0.6045       0.7734        0.4628  0.0357\n",
      "     22        0.6214       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4530\u001b[0m  0.0364\n",
      "     23        \u001b[36m0.5864\u001b[0m       0.7656        \u001b[35m0.4483\u001b[0m  0.0399\n",
      "     24        \u001b[36m0.5702\u001b[0m       0.7891        0.4486  0.0428\n",
      "     25        0.5808       0.7734        \u001b[35m0.4435\u001b[0m  0.0372\n",
      "     26        0.5762       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4432\u001b[0m  0.0404\n",
      "     27        0.6011       0.8047        0.4441  0.0362\n",
      "     28        0.6087       0.7812        0.4580  0.0422\n",
      "     29        0.6037       0.7812        0.4531  0.0369\n",
      "     30        0.5904       0.7734        0.4503  0.0357\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8044\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6985\u001b[0m  0.0351\n",
      "      2        0.8081       0.5000        \u001b[35m0.6923\u001b[0m  0.0395\n",
      "      3        \u001b[36m0.7760\u001b[0m       0.5000        \u001b[35m0.6845\u001b[0m  0.0363\n",
      "      4        \u001b[36m0.7579\u001b[0m       0.5000        \u001b[35m0.6751\u001b[0m  0.0412\n",
      "      5        \u001b[36m0.7567\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6619\u001b[0m  0.0393\n",
      "      6        \u001b[36m0.7338\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6383\u001b[0m  0.0412\n",
      "      7        \u001b[36m0.7203\u001b[0m       0.7422        \u001b[35m0.6072\u001b[0m  0.0362\n",
      "      8        \u001b[36m0.6899\u001b[0m       0.7344        \u001b[35m0.5757\u001b[0m  0.0405\n",
      "      9        \u001b[36m0.6485\u001b[0m       0.7422        \u001b[35m0.5548\u001b[0m  0.0361\n",
      "     10        \u001b[36m0.6308\u001b[0m       0.7344        \u001b[35m0.5305\u001b[0m  0.0409\n",
      "     11        \u001b[36m0.6041\u001b[0m       0.7422        \u001b[35m0.5208\u001b[0m  0.0361\n",
      "     12        \u001b[36m0.5842\u001b[0m       \u001b[32m0.7500\u001b[0m        0.5231  0.0404\n",
      "     13        0.5947       0.7500        0.5247  0.0361\n",
      "     14        0.5994       0.7500        \u001b[35m0.5168\u001b[0m  0.0389\n",
      "     15        \u001b[36m0.5677\u001b[0m       0.7500        \u001b[35m0.5142\u001b[0m  0.0415\n",
      "     16        0.5865       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5092\u001b[0m  0.0371\n",
      "     17        0.5853       0.7578        \u001b[35m0.5072\u001b[0m  0.0392\n",
      "     18        0.5682       0.7578        0.5074  0.0430\n",
      "     19        0.5749       0.7578        \u001b[35m0.5039\u001b[0m  0.0356\n",
      "     20        \u001b[36m0.5627\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4985\u001b[0m  0.0384\n",
      "     21        \u001b[36m0.5572\u001b[0m       0.7656        0.5024  0.0410\n",
      "     22        \u001b[36m0.5472\u001b[0m       0.7500        0.5022  0.0360\n",
      "     23        0.5551       0.7656        \u001b[35m0.4954\u001b[0m  0.0374\n",
      "     24        0.5512       0.7656        0.5013  0.0408\n",
      "     25        0.5549       0.7656        \u001b[35m0.4934\u001b[0m  0.0363\n",
      "     26        0.5760       \u001b[32m0.7734\u001b[0m        0.4974  0.0361\n",
      "     27        \u001b[36m0.5319\u001b[0m       0.7578        0.4962  0.0417\n",
      "     28        0.5648       0.7578        \u001b[35m0.4920\u001b[0m  0.0364\n",
      "     29        \u001b[36m0.5293\u001b[0m       0.7656        0.4949  0.0365\n",
      "     30        0.5668       0.7656        0.4944  0.0367\n",
      "     31        0.5467       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4904\u001b[0m  0.0392\n",
      "     32        0.5301       0.7656        0.5021  0.0411\n",
      "     33        0.5402       0.7656        0.4971  0.0361\n",
      "     34        0.5428       0.7734        0.5011  0.0383\n",
      "     35        0.5309       0.7734        0.4942  0.0360\n",
      "     36        0.5392       0.7656        \u001b[35m0.4891\u001b[0m  0.0376\n",
      "     37        0.5452       0.7734        \u001b[35m0.4847\u001b[0m  0.0393\n",
      "     38        0.5594       0.7812        \u001b[35m0.4844\u001b[0m  0.0418\n",
      "     39        0.5535       0.7734        0.4872  0.0363\n",
      "     40        0.5316       0.7812        0.4873  0.0359\n",
      "     41        \u001b[36m0.5202\u001b[0m       0.7812        0.4857  0.0362\n",
      "     42        0.5410       0.7812        0.4857  0.0362\n",
      "     43        0.5213       0.7812        \u001b[35m0.4806\u001b[0m  0.0363\n",
      "     44        0.5351       0.7812        0.4867  0.0373\n",
      "     45        0.5401       0.7812        0.4870  0.0371\n",
      "     46        0.5311       0.7734        0.4912  0.0390\n",
      "     47        0.5368       0.7734        0.4855  0.0388\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7440\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6909\u001b[0m  0.0324\n",
      "      2        \u001b[36m0.7424\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6839\u001b[0m  0.0358\n",
      "      3        \u001b[36m0.7239\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6709\u001b[0m  0.0415\n",
      "      4        \u001b[36m0.7073\u001b[0m       0.6719        \u001b[35m0.6467\u001b[0m  0.0356\n",
      "      5        \u001b[36m0.6960\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6118\u001b[0m  0.0413\n",
      "      6        \u001b[36m0.6658\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5815\u001b[0m  0.0357\n",
      "      7        \u001b[36m0.6433\u001b[0m       0.7109        \u001b[35m0.5569\u001b[0m  0.0409\n",
      "      8        \u001b[36m0.6272\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5473\u001b[0m  0.0359\n",
      "      9        \u001b[36m0.5913\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5360\u001b[0m  0.0402\n",
      "     10        \u001b[36m0.5784\u001b[0m       0.7422        \u001b[35m0.5334\u001b[0m  0.0362\n",
      "     11        \u001b[36m0.5748\u001b[0m       0.7422        \u001b[35m0.5306\u001b[0m  0.0402\n",
      "     12        0.5897       \u001b[32m0.7500\u001b[0m        0.5329  0.0362\n",
      "     13        \u001b[36m0.5696\u001b[0m       0.7188        \u001b[35m0.5282\u001b[0m  0.0391\n",
      "     14        0.5717       0.7266        0.5295  0.0419\n",
      "     15        0.5868       0.7109        0.5283  0.0410\n",
      "     16        0.5724       0.7109        0.5297  0.0368\n",
      "     17        \u001b[36m0.5577\u001b[0m       0.7031        \u001b[35m0.5258\u001b[0m  0.0417\n",
      "     18        0.5583       0.7188        \u001b[35m0.5236\u001b[0m  0.0361\n",
      "     19        \u001b[36m0.5478\u001b[0m       0.6953        0.5265  0.0398\n",
      "     20        \u001b[36m0.5374\u001b[0m       0.7109        0.5255  0.0413\n",
      "     21        0.5598       0.6953        0.5277  0.0394\n",
      "     22        0.5628       0.7031        0.5313  0.0368\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6986\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6483\u001b[0m  0.0358\n",
      "      2        \u001b[36m0.6680\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5813\u001b[0m  0.0415\n",
      "      3        \u001b[36m0.6306\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5502\u001b[0m  0.0412\n",
      "      4        \u001b[36m0.5762\u001b[0m       0.7344        \u001b[35m0.5271\u001b[0m  0.0436\n",
      "      5        0.6006       \u001b[32m0.7578\u001b[0m        0.5336  0.0368\n",
      "      6        0.5995       0.7422        0.5326  0.0406\n",
      "      7        0.5908       0.7422        \u001b[35m0.5267\u001b[0m  0.0361\n",
      "      8        0.5950       0.7344        \u001b[35m0.5243\u001b[0m  0.0437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9        0.5807       0.7344        \u001b[35m0.5212\u001b[0m  0.0359\n",
      "     10        \u001b[36m0.5760\u001b[0m       0.7422        \u001b[35m0.5159\u001b[0m  0.0396\n",
      "     11        \u001b[36m0.5565\u001b[0m       0.7422        \u001b[35m0.5110\u001b[0m  0.0415\n",
      "     12        0.5750       0.7500        0.5155  0.0369\n",
      "     13        \u001b[36m0.5462\u001b[0m       0.7500        0.5152  0.0415\n",
      "     14        0.5581       0.7422        0.5165  0.0372\n",
      "     15        0.5494       0.7188        0.5249  0.0389\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7496\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6951\u001b[0m  0.0345\n",
      "      2        0.7554       0.5000        0.6976  0.0408\n",
      "      3        0.7557       0.5000        \u001b[35m0.6925\u001b[0m  0.0417\n",
      "      4        \u001b[36m0.7389\u001b[0m       0.5000        \u001b[35m0.6895\u001b[0m  0.0356\n",
      "      5        \u001b[36m0.7332\u001b[0m       0.5000        \u001b[35m0.6799\u001b[0m  0.0400\n",
      "      6        \u001b[36m0.7160\u001b[0m       0.5000        \u001b[35m0.6597\u001b[0m  0.0358\n",
      "      7        \u001b[36m0.6912\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6295\u001b[0m  0.0427\n",
      "      8        \u001b[36m0.6566\u001b[0m       0.6719        \u001b[35m0.6141\u001b[0m  0.0385\n",
      "      9        \u001b[36m0.6485\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6013\u001b[0m  0.0384\n",
      "     10        \u001b[36m0.6199\u001b[0m       0.6875        \u001b[35m0.5928\u001b[0m  0.0412\n",
      "     11        0.6277       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5820\u001b[0m  0.0359\n",
      "     12        0.6250       0.7031        \u001b[35m0.5703\u001b[0m  0.0407\n",
      "     13        \u001b[36m0.5929\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5641\u001b[0m  0.0362\n",
      "     14        \u001b[36m0.5861\u001b[0m       0.7109        \u001b[35m0.5594\u001b[0m  0.0403\n",
      "     15        \u001b[36m0.5612\u001b[0m       0.7109        \u001b[35m0.5574\u001b[0m  0.0363\n",
      "     16        0.5679       0.6875        \u001b[35m0.5386\u001b[0m  0.0380\n",
      "     17        0.5653       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5307\u001b[0m  0.0405\n",
      "     18        \u001b[36m0.5274\u001b[0m       0.7188        0.5390  0.0363\n",
      "     19        0.5340       0.7188        0.5344  0.0420\n",
      "     20        \u001b[36m0.5258\u001b[0m       0.7188        \u001b[35m0.5285\u001b[0m  0.0364\n",
      "     21        0.5597       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5198\u001b[0m  0.0378\n",
      "     22        0.5370       0.7266        0.5249  0.0381\n",
      "     23        0.5305       \u001b[32m0.7344\u001b[0m        0.5318  0.0420\n",
      "     24        0.5464       0.7266        0.5242  0.0358\n",
      "     25        0.5468       \u001b[32m0.7422\u001b[0m        0.5278  0.0371\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.2997\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.9531\u001b[0m  0.0321\n",
      "      2        0.5517       0.5000        \u001b[35m1.8710\u001b[0m  0.0380\n",
      "      3        0.5317       0.5000        \u001b[35m1.8710\u001b[0m  0.0396\n",
      "      4        0.5317       0.5000        \u001b[35m1.8709\u001b[0m  0.0357\n",
      "      5        0.5317       0.5000        \u001b[35m1.8709\u001b[0m  0.0394\n",
      "      6        0.5317       0.5000        \u001b[35m1.8708\u001b[0m  0.0370\n",
      "      7        0.5317       0.5000        \u001b[35m1.8707\u001b[0m  0.0338\n",
      "      8        0.5316       0.5000        \u001b[35m1.8704\u001b[0m  0.0391\n",
      "      9        0.5263       0.5000        \u001b[35m1.8243\u001b[0m  0.0345\n",
      "     10        0.5007       \u001b[32m0.5156\u001b[0m        \u001b[35m1.5148\u001b[0m  0.0388\n",
      "     11        0.4700       \u001b[32m0.5391\u001b[0m        \u001b[35m1.4113\u001b[0m  0.0366\n",
      "     12        0.4740       \u001b[32m0.6094\u001b[0m        \u001b[35m1.2943\u001b[0m  0.0388\n",
      "     13        0.4683       0.5859        1.3026  0.0369\n",
      "     14        0.4668       0.5859        1.3047  0.0406\n",
      "     15        0.4618       0.6016        \u001b[35m1.2552\u001b[0m  0.0349\n",
      "     16        0.4532       \u001b[32m0.6406\u001b[0m        \u001b[35m1.1980\u001b[0m  0.0388\n",
      "     17        0.4708       0.6172        1.2546  0.0350\n",
      "     18        0.4724       0.6250        1.2548  0.0391\n",
      "     19        0.4578       0.6172        1.2660  0.0339\n",
      "     20        0.4500       \u001b[32m0.6797\u001b[0m        \u001b[35m1.1407\u001b[0m  0.0381\n",
      "     21        0.4482       0.6328        1.2249  0.0336\n",
      "     22        0.4423       0.6797        \u001b[35m1.1174\u001b[0m  0.0371\n",
      "     23        0.4674       0.6406        1.2317  0.0337\n",
      "     24        0.4398       0.6797        1.1573  0.0373\n",
      "     25        0.4655       0.6406        1.2131  0.0340\n",
      "     26        0.4413       0.6719        1.2077  0.0352\n",
      "     27        0.4456       \u001b[32m0.6875\u001b[0m        \u001b[35m1.0864\u001b[0m  0.0390\n",
      "     28        0.4375       0.6641        1.1185  0.0348\n",
      "     29        0.4270       0.6641        1.1149  0.0373\n",
      "     30        0.4346       0.6406        1.1754  0.0342\n",
      "     31        0.4214       \u001b[32m0.7109\u001b[0m        \u001b[35m0.9868\u001b[0m  0.0343\n",
      "     32        0.4407       0.6719        1.1827  0.0378\n",
      "     33        0.4360       0.6719        1.1439  0.0334\n",
      "     34        0.4381       0.6719        1.0580  0.0349\n",
      "     35        0.4224       0.7031        1.1234  0.0393\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.3646\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.6641\u001b[0m  0.0314\n",
      "      2        0.4395       0.5000        \u001b[35m1.8169\u001b[0m  0.0428\n",
      "      3        0.3755       0.5000        \u001b[35m1.7067\u001b[0m  0.0394\n",
      "      4        0.3884       0.5000        \u001b[35m1.6137\u001b[0m  0.0391\n",
      "      5        0.3887       \u001b[32m0.5547\u001b[0m        \u001b[35m1.5130\u001b[0m  0.0338\n",
      "      6        0.3853       0.5469        1.5490  0.0405\n",
      "      7        0.3796       0.5547        \u001b[35m1.4577\u001b[0m  0.0341\n",
      "      8        \u001b[36m0.3574\u001b[0m       0.5391        1.4817  0.0388\n",
      "      9        0.3590       0.5391        1.5644  0.0365\n",
      "     10        \u001b[36m0.3554\u001b[0m       0.5312        1.6688  0.0389\n",
      "     11        0.3636       0.5547        1.4703  0.0404\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5809\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.8264\u001b[0m  0.0351\n",
      "      2        0.7009       0.5000        2.2154  0.0350\n",
      "      3        0.7031       0.5000        1.8293  0.0380\n",
      "      4        0.7143       0.5000        1.8277  0.0442\n",
      "      5        0.7141       0.5000        1.8277  0.0355\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5292\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.6086\u001b[0m  0.0329\n",
      "      2        0.5387       0.5000        \u001b[35m1.4782\u001b[0m  0.0375\n",
      "      3        0.5292       0.5000        \u001b[35m1.4399\u001b[0m  0.0349\n",
      "      4        0.5431       0.5000        1.4783  0.0389\n",
      "      5        0.5653       0.5000        1.5777  0.0375\n",
      "      6        0.5856       \u001b[32m0.5703\u001b[0m        \u001b[35m1.3844\u001b[0m  0.0339\n",
      "      7        \u001b[36m0.5217\u001b[0m       0.5703        \u001b[35m1.2633\u001b[0m  0.0416\n",
      "      8        \u001b[36m0.5056\u001b[0m       0.5391        1.3919  0.0342\n",
      "      9        \u001b[36m0.4873\u001b[0m       0.5078        1.5454  0.0392\n",
      "     10        0.4915       0.5156        1.5770  0.0359\n",
      "     11        0.4910       0.5391        1.5809  0.0390\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.3937\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.5316\u001b[0m  0.0367\n",
      "      2        0.5193       0.5000        \u001b[35m1.7892\u001b[0m  0.0392\n",
      "      3        0.5980       0.5000        \u001b[35m1.7639\u001b[0m  0.0376\n",
      "      4        0.5512       0.5000        1.7962  0.0388\n",
      "      5        0.5441       0.5000        1.7684  0.0396\n",
      "      6        0.5110       0.5000        \u001b[35m1.7262\u001b[0m  0.0340\n",
      "      7        0.5051       0.5000        1.8089  0.0389\n",
      "      8        0.5057       0.5000        \u001b[35m1.7091\u001b[0m  0.0354\n",
      "      9        0.4658       0.5000        1.7914  0.0395\n",
      "     10        0.5025       0.5000        \u001b[35m1.6392\u001b[0m  0.0394\n",
      "     11        0.5004       0.5000        1.7335  0.0357\n",
      "     12        0.4585       0.5000        1.6737  0.0375\n",
      "     13        0.4452       \u001b[32m0.5156\u001b[0m        1.6694  0.0417\n",
      "     14        0.4410       0.5000        1.6691  0.0347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15        0.4359       \u001b[32m0.5469\u001b[0m        \u001b[35m1.5519\u001b[0m  0.0398\n",
      "     16        0.4381       0.5000        1.7014  0.0341\n",
      "     17        0.4203       0.5312        \u001b[35m1.5157\u001b[0m  0.0387\n",
      "     18        0.4145       0.5234        1.5504  0.0363\n",
      "     19        0.4373       0.5000        1.7478  0.0373\n",
      "     20        0.4766       0.5000        1.8152  0.0335\n",
      "     21        0.6232       0.5000        1.7880  0.0377\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5600\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.1488\u001b[0m  0.0125\n",
      "      2        0.7873       0.5000        \u001b[35m1.0848\u001b[0m  0.0136\n",
      "      3        0.7136       0.5000        \u001b[35m1.0291\u001b[0m  0.0170\n",
      "      4        0.6863       0.5000        \u001b[35m1.0274\u001b[0m  0.0211\n",
      "      5        0.6785       0.5000        \u001b[35m1.0182\u001b[0m  0.0262\n",
      "      6        0.6799       \u001b[32m0.5078\u001b[0m        \u001b[35m0.9610\u001b[0m  0.0217\n",
      "      7        0.6635       0.5078        \u001b[35m0.9596\u001b[0m  0.0148\n",
      "      8        0.6565       \u001b[32m0.5469\u001b[0m        \u001b[35m0.9001\u001b[0m  0.0254\n",
      "      9        0.6539       \u001b[32m0.6094\u001b[0m        \u001b[35m0.8112\u001b[0m  0.0149\n",
      "     10        0.6456       0.5391        0.9107  0.0236\n",
      "     11        0.6212       \u001b[32m0.6406\u001b[0m        0.8232  0.0228\n",
      "     12        0.6164       0.6406        \u001b[35m0.7648\u001b[0m  0.0150\n",
      "     13        0.6235       0.5703        0.8704  0.0199\n",
      "     14        0.6335       0.6250        0.8129  0.0165\n",
      "     15        0.6107       \u001b[32m0.6562\u001b[0m        \u001b[35m0.7254\u001b[0m  0.0293\n",
      "     16        0.5923       0.6484        0.7302  0.0218\n",
      "     17        0.5874       0.6172        0.8356  0.0147\n",
      "     18        0.6308       0.6484        0.7473  0.0202\n",
      "     19        0.6225       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6966\u001b[0m  0.0225\n",
      "     20        0.5970       0.6484        \u001b[35m0.6902\u001b[0m  0.0196\n",
      "     21        0.5869       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6612\u001b[0m  0.0177\n",
      "     22        0.5755       0.6484        0.7053  0.0207\n",
      "     23        0.6076       0.6641        \u001b[35m0.6537\u001b[0m  0.0144\n",
      "     24        0.5872       0.6562        0.6634  0.0194\n",
      "     25        0.5771       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6460\u001b[0m  0.0160\n",
      "     26        \u001b[36m0.5561\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6437\u001b[0m  0.0291\n",
      "     27        0.5833       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6197\u001b[0m  0.0298\n",
      "     28        0.5672       0.6953        0.6447  0.0150\n",
      "     29        0.5760       0.6875        0.6577  0.0272\n",
      "     30        0.5594       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6057\u001b[0m  0.0209\n",
      "     31        \u001b[36m0.5531\u001b[0m       0.7266        0.6117  0.0139\n",
      "     32        0.5802       0.7266        \u001b[35m0.6008\u001b[0m  0.0215\n",
      "     33        \u001b[36m0.5430\u001b[0m       0.7266        \u001b[35m0.5968\u001b[0m  0.0160\n",
      "     34        \u001b[36m0.5339\u001b[0m       0.7266        0.6006  0.0256\n",
      "     35        0.5631       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5826\u001b[0m  0.0191\n",
      "     36        0.5541       0.7266        0.6005  0.0240\n",
      "     37        0.5627       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5546\u001b[0m  0.0153\n",
      "     38        \u001b[36m0.5331\u001b[0m       0.7266        0.5665  0.0172\n",
      "     39        \u001b[36m0.5209\u001b[0m       0.7344        0.5782  0.0170\n",
      "     40        0.5353       0.7188        0.5986  0.0219\n",
      "     41        0.5410       0.7266        0.5834  0.0163\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4936\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.5921\u001b[0m  0.0156\n",
      "      2        0.7296       0.5000        \u001b[35m1.0608\u001b[0m  0.0165\n",
      "      3        0.5989       0.5000        \u001b[35m1.0103\u001b[0m  0.0250\n",
      "      4        0.6286       0.5000        \u001b[35m0.9890\u001b[0m  0.0186\n",
      "      5        0.6431       0.5000        1.0054  0.0205\n",
      "      6        0.6011       0.5000        0.9985  0.0173\n",
      "      7        0.6077       \u001b[32m0.5234\u001b[0m        \u001b[35m0.9693\u001b[0m  0.0184\n",
      "      8        0.5898       \u001b[32m0.5703\u001b[0m        \u001b[35m0.9581\u001b[0m  0.0212\n",
      "      9        0.5828       0.5703        \u001b[35m0.9344\u001b[0m  0.0231\n",
      "     10        0.5808       0.5703        \u001b[35m0.9123\u001b[0m  0.0163\n",
      "     11        0.6002       0.5703        0.9372  0.0224\n",
      "     12        0.6099       \u001b[32m0.5938\u001b[0m        \u001b[35m0.8670\u001b[0m  0.0158\n",
      "     13        0.5717       \u001b[32m0.6641\u001b[0m        \u001b[35m0.8030\u001b[0m  0.0206\n",
      "     14        0.5545       0.6562        0.8419  0.0155\n",
      "     15        0.5542       0.6484        0.8781  0.0250\n",
      "     16        0.5628       0.6562        0.8456  0.0156\n",
      "     17        0.5395       \u001b[32m0.6719\u001b[0m        \u001b[35m0.7711\u001b[0m  0.0201\n",
      "     18        0.5407       \u001b[32m0.6797\u001b[0m        \u001b[35m0.7692\u001b[0m  0.0315\n",
      "     19        0.5277       0.6797        0.8572  0.0164\n",
      "     20        0.5594       0.6172        0.9351  0.0160\n",
      "     21        0.5728       \u001b[32m0.6875\u001b[0m        0.8476  0.0276\n",
      "     22        0.5543       0.6797        0.7884  0.0170\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7666\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.1537\u001b[0m  0.0221\n",
      "      2        0.8031       0.5000        \u001b[35m1.0094\u001b[0m  0.0189\n",
      "      3        \u001b[36m0.7263\u001b[0m       0.5000        \u001b[35m0.9522\u001b[0m  0.0180\n",
      "      4        \u001b[36m0.6984\u001b[0m       0.5000        0.9742  0.0170\n",
      "      5        \u001b[36m0.6956\u001b[0m       0.5000        \u001b[35m0.9410\u001b[0m  0.0228\n",
      "      6        \u001b[36m0.6483\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.8718\u001b[0m  0.0202\n",
      "      7        \u001b[36m0.6260\u001b[0m       0.5000        0.9285  0.0254\n",
      "      8        0.6287       \u001b[32m0.5703\u001b[0m        0.8754  0.0187\n",
      "      9        \u001b[36m0.6082\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.8246\u001b[0m  0.0241\n",
      "     10        \u001b[36m0.5747\u001b[0m       \u001b[32m0.6250\u001b[0m        0.8387  0.0188\n",
      "     11        0.5849       \u001b[32m0.6406\u001b[0m        \u001b[35m0.7697\u001b[0m  0.0248\n",
      "     12        0.5809       0.6172        0.8028  0.0170\n",
      "     13        0.5775       0.6328        0.7782  0.0293\n",
      "     14        \u001b[36m0.5518\u001b[0m       0.5703        0.8853  0.0163\n",
      "     15        0.5971       0.6094        0.7847  0.0201\n",
      "     16        0.5587       \u001b[32m0.6719\u001b[0m        \u001b[35m0.7244\u001b[0m  0.0162\n",
      "     17        0.5751       0.6328        0.7519  0.0216\n",
      "     18        0.5940       0.6328        0.7572  0.0165\n",
      "     19        0.5524       0.6719        0.7369  0.0158\n",
      "     20        0.5600       0.6328        0.7670  0.0324\n",
      "     21        0.5673       0.6641        \u001b[35m0.7185\u001b[0m  0.0134\n",
      "     22        \u001b[36m0.5504\u001b[0m       0.6406        0.7358  0.0221\n",
      "     23        0.5580       0.6641        0.7387  0.0150\n",
      "     24        0.5694       0.6328        0.7315  0.0184\n",
      "     25        0.5558       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6912\u001b[0m  0.0231\n",
      "     26        \u001b[36m0.5321\u001b[0m       0.6719        0.7027  0.0355\n",
      "     27        0.5394       0.6562        0.7422  0.0161\n",
      "     28        0.5528       0.6328        0.7366  0.0293\n",
      "     29        0.5801       0.6562        0.7139  0.0154\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6728\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.9237\u001b[0m  0.0226\n",
      "      2        0.7637       0.5000        \u001b[35m0.9011\u001b[0m  0.0161\n",
      "      3        0.6897       0.5000        0.9069  0.0340\n",
      "      4        0.6887       \u001b[32m0.5156\u001b[0m        \u001b[35m0.8738\u001b[0m  0.0281\n",
      "      5        \u001b[36m0.6462\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.8215\u001b[0m  0.0285\n",
      "      6        \u001b[36m0.6437\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.7364\u001b[0m  0.0202\n",
      "      7        \u001b[36m0.6196\u001b[0m       0.5938        0.7948  0.0266\n",
      "      8        \u001b[36m0.6177\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6975\u001b[0m  0.0266\n",
      "      9        \u001b[36m0.5968\u001b[0m       0.6406        0.7589  0.0329\n",
      "     10        \u001b[36m0.5837\u001b[0m       0.6719        0.7061  0.0189\n",
      "     11        \u001b[36m0.5723\u001b[0m       0.6406        0.7075  0.0497\n",
      "     12        \u001b[36m0.5590\u001b[0m       \u001b[32m0.6875\u001b[0m        0.7098  0.0303\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5385\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.5689\u001b[0m  0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        0.8725       0.5000        \u001b[35m1.0333\u001b[0m  0.0141\n",
      "      3        0.7144       0.5000        \u001b[35m1.0113\u001b[0m  0.0164\n",
      "      4        0.6395       0.5000        1.0741  0.0349\n",
      "      5        0.6277       0.5000        \u001b[35m0.9933\u001b[0m  0.0201\n",
      "      6        0.5905       0.5000        \u001b[35m0.9284\u001b[0m  0.0148\n",
      "      7        0.5937       \u001b[32m0.5078\u001b[0m        1.0058  0.0186\n",
      "      8        0.5635       \u001b[32m0.5859\u001b[0m        0.9609  0.0168\n",
      "      9        0.5650       0.5547        0.9488  0.0311\n",
      "     10        0.5538       \u001b[32m0.6562\u001b[0m        \u001b[35m0.8836\u001b[0m  0.0192\n",
      "     11        \u001b[36m0.5282\u001b[0m       0.6484        \u001b[35m0.8806\u001b[0m  0.0145\n",
      "     12        0.5385       0.6406        \u001b[35m0.8488\u001b[0m  0.0205\n",
      "     13        0.5412       0.6484        \u001b[35m0.8480\u001b[0m  0.0143\n",
      "     14        0.5325       0.6406        0.8608  0.0272\n",
      "     15        0.5427       0.6484        \u001b[35m0.8159\u001b[0m  0.0181\n",
      "     16        0.5431       0.6484        0.8514  0.0159\n",
      "     17        0.5441       \u001b[32m0.6797\u001b[0m        \u001b[35m0.7840\u001b[0m  0.0158\n",
      "     18        0.5493       0.6406        0.8711  0.0247\n",
      "     19        \u001b[36m0.5229\u001b[0m       0.6797        \u001b[35m0.7546\u001b[0m  0.0207\n",
      "     20        0.5287       0.6406        0.8396  0.0143\n",
      "     21        0.5470       0.6406        0.7607  0.0283\n",
      "     22        0.5423       0.6641        0.7970  0.0194\n",
      "     23        0.5412       0.6797        0.7653  0.0165\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8329\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m7.3906\u001b[0m  0.0263\n",
      "      2        8.6644       0.5000        \u001b[35m3.4785\u001b[0m  0.0272\n",
      "      3        6.0493       0.5000        6.2169  0.0265\n",
      "      4        7.6848       0.5000        4.8307  0.0270\n",
      "      5        6.6470       0.5000        6.0977  0.0248\n",
      "      6        7.6453       0.5000        3.7292  0.0281\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9913\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m7.9277\u001b[0m  0.0203\n",
      "      2        7.9666       0.5000        7.9712  0.0210\n",
      "      3        7.9712       0.5000        7.9712  0.0230\n",
      "      4        7.9712       0.5000        7.9712  0.0330\n",
      "      5        7.9712       0.5000        7.9712  0.0271\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4900\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m4.0408\u001b[0m  0.0264\n",
      "      2        2.9256       0.5000        5.6332  0.0271\n",
      "      3        5.6684       0.5000        \u001b[35m2.5254\u001b[0m  0.0279\n",
      "      4        5.1189       0.5000        \u001b[35m1.9675\u001b[0m  0.0261\n",
      "      5        4.3066       0.5000        2.8320  0.0283\n",
      "      6        4.6904       0.5000        2.7036  0.0270\n",
      "      7        4.9021       0.5000        2.3541  0.0242\n",
      "      8        4.7851       0.5000        2.3723  0.0255\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.9209\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m7.9712\u001b[0m  0.0262\n",
      "      2        4.8941       0.5000        7.9712  0.0282\n",
      "      3        5.1176       0.5000        7.9712  0.0256\n",
      "      4        5.1297       0.5000        7.9712  0.0240\n",
      "      5        5.0781       0.5000        7.9712  0.0290\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5785\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.6772\u001b[0m  0.0214\n",
      "      2        2.2869       0.5000        7.5865  0.0211\n",
      "      3        7.9099       0.5000        7.9712  0.0310\n",
      "      4        7.9712       0.5000        7.9712  0.0307\n",
      "      5        7.9712       0.5000        7.9712  0.0273\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6569\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.1011\u001b[0m  0.0188\n",
      "      2        0.7661       0.5000        \u001b[35m1.0657\u001b[0m  0.0146\n",
      "      3        0.6830       0.5000        \u001b[35m1.0164\u001b[0m  0.0176\n",
      "      4        \u001b[36m0.6377\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.9699\u001b[0m  0.0188\n",
      "      5        \u001b[36m0.6214\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.9420\u001b[0m  0.0290\n",
      "      6        \u001b[36m0.6152\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.9157\u001b[0m  0.0159\n",
      "      7        \u001b[36m0.6073\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.8904\u001b[0m  0.0226\n",
      "      8        \u001b[36m0.6012\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.8701\u001b[0m  0.0161\n",
      "      9        \u001b[36m0.5946\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.8436\u001b[0m  0.0249\n",
      "     10        \u001b[36m0.5867\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.8183\u001b[0m  0.0199\n",
      "     11        \u001b[36m0.5785\u001b[0m       0.6250        \u001b[35m0.8007\u001b[0m  0.0237\n",
      "     12        \u001b[36m0.5672\u001b[0m       0.6250        \u001b[35m0.7921\u001b[0m  0.0178\n",
      "     13        \u001b[36m0.5629\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.7692\u001b[0m  0.0222\n",
      "     14        \u001b[36m0.5584\u001b[0m       0.6328        \u001b[35m0.7574\u001b[0m  0.0163\n",
      "     15        \u001b[36m0.5552\u001b[0m       0.6328        \u001b[35m0.7560\u001b[0m  0.0225\n",
      "     16        \u001b[36m0.5535\u001b[0m       \u001b[32m0.6484\u001b[0m        0.7585  0.0135\n",
      "     17        0.5543       0.6484        \u001b[35m0.7556\u001b[0m  0.0258\n",
      "     18        \u001b[36m0.5510\u001b[0m       0.6484        \u001b[35m0.7498\u001b[0m  0.0191\n",
      "     19        \u001b[36m0.5489\u001b[0m       0.6484        0.7535  0.0157\n",
      "     20        0.5489       \u001b[32m0.6562\u001b[0m        \u001b[35m0.7401\u001b[0m  0.0198\n",
      "     21        \u001b[36m0.5425\u001b[0m       0.6484        0.7448  0.0158\n",
      "     22        \u001b[36m0.5424\u001b[0m       0.6484        0.7439  0.0221\n",
      "     23        \u001b[36m0.5405\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.7350\u001b[0m  0.0170\n",
      "     24        \u001b[36m0.5382\u001b[0m       0.6641        0.7352  0.0156\n",
      "     25        \u001b[36m0.5360\u001b[0m       0.6641        0.7362  0.0285\n",
      "     26        \u001b[36m0.5323\u001b[0m       0.6641        0.7382  0.0149\n",
      "     27        \u001b[36m0.5313\u001b[0m       0.6641        \u001b[35m0.7337\u001b[0m  0.0252\n",
      "     28        \u001b[36m0.5280\u001b[0m       0.6641        0.7362  0.0140\n",
      "     29        0.5282       0.6641        0.7369  0.0241\n",
      "     30        \u001b[36m0.5256\u001b[0m       0.6562        0.7416  0.0164\n",
      "     31        0.5271       0.6641        \u001b[35m0.7318\u001b[0m  0.0308\n",
      "     32        \u001b[36m0.5227\u001b[0m       0.6641        0.7341  0.0148\n",
      "     33        \u001b[36m0.5200\u001b[0m       0.6641        0.7450  0.0208\n",
      "     34        \u001b[36m0.5189\u001b[0m       0.6641        0.7388  0.0202\n",
      "     35        \u001b[36m0.5157\u001b[0m       0.6641        0.7350  0.0172\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5644\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.0819\u001b[0m  0.0138\n",
      "      2        0.7015       0.5000        \u001b[35m1.0681\u001b[0m  0.0187\n",
      "      3        0.6087       0.5000        \u001b[35m1.0274\u001b[0m  0.0154\n",
      "      4        0.5671       0.5000        \u001b[35m0.9983\u001b[0m  0.0184\n",
      "      5        \u001b[36m0.5543\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.9899\u001b[0m  0.0210\n",
      "      6        \u001b[36m0.5542\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.9816\u001b[0m  0.0180\n",
      "      7        0.5645       \u001b[32m0.5547\u001b[0m        \u001b[35m0.9559\u001b[0m  0.0229\n",
      "      8        0.5699       \u001b[32m0.5625\u001b[0m        \u001b[35m0.9363\u001b[0m  0.0260\n",
      "      9        0.5730       \u001b[32m0.5703\u001b[0m        \u001b[35m0.9095\u001b[0m  0.0198\n",
      "     10        0.5734       \u001b[32m0.5781\u001b[0m        \u001b[35m0.8932\u001b[0m  0.0264\n",
      "     11        0.5618       \u001b[32m0.6016\u001b[0m        \u001b[35m0.8799\u001b[0m  0.0133\n",
      "     12        0.5592       \u001b[32m0.6094\u001b[0m        \u001b[35m0.8625\u001b[0m  0.0199\n",
      "     13        \u001b[36m0.5525\u001b[0m       0.6016        \u001b[35m0.8529\u001b[0m  0.0153\n",
      "     14        \u001b[36m0.5433\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.8395\u001b[0m  0.0215\n",
      "     15        \u001b[36m0.5426\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.8313\u001b[0m  0.0251\n",
      "     16        \u001b[36m0.5384\u001b[0m       0.6406        \u001b[35m0.8250\u001b[0m  0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17        \u001b[36m0.5320\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.8183\u001b[0m  0.0200\n",
      "     18        \u001b[36m0.5307\u001b[0m       0.6484        \u001b[35m0.8137\u001b[0m  0.0139\n",
      "     19        \u001b[36m0.5239\u001b[0m       0.6484        \u001b[35m0.8002\u001b[0m  0.0233\n",
      "     20        \u001b[36m0.5175\u001b[0m       0.6484        0.8030  0.0265\n",
      "     21        \u001b[36m0.5077\u001b[0m       0.6484        \u001b[35m0.7992\u001b[0m  0.0170\n",
      "     22        0.5086       \u001b[32m0.6641\u001b[0m        \u001b[35m0.7955\u001b[0m  0.0242\n",
      "     23        \u001b[36m0.5048\u001b[0m       0.6562        0.7972  0.0133\n",
      "     24        \u001b[36m0.5004\u001b[0m       0.6562        \u001b[35m0.7861\u001b[0m  0.0188\n",
      "     25        \u001b[36m0.4907\u001b[0m       0.6562        0.7875  0.0157\n",
      "     26        \u001b[36m0.4871\u001b[0m       0.6562        \u001b[35m0.7857\u001b[0m  0.0241\n",
      "     27        \u001b[36m0.4854\u001b[0m       0.6562        \u001b[35m0.7855\u001b[0m  0.0189\n",
      "     28        0.4857       0.6641        \u001b[35m0.7709\u001b[0m  0.0140\n",
      "     29        \u001b[36m0.4739\u001b[0m       \u001b[32m0.6719\u001b[0m        0.7750  0.0285\n",
      "     30        0.4752       0.6641        \u001b[35m0.7619\u001b[0m  0.0192\n",
      "     31        \u001b[36m0.4708\u001b[0m       0.6719        0.7637  0.0174\n",
      "     32        \u001b[36m0.4670\u001b[0m       0.6719        \u001b[35m0.7593\u001b[0m  0.0133\n",
      "     33        \u001b[36m0.4661\u001b[0m       0.6641        0.7606  0.0294\n",
      "     34        \u001b[36m0.4608\u001b[0m       0.6719        \u001b[35m0.7510\u001b[0m  0.0172\n",
      "     35        \u001b[36m0.4569\u001b[0m       0.6719        0.7567  0.0169\n",
      "     36        0.4648       0.6719        0.7586  0.0137\n",
      "     37        0.4603       0.6719        \u001b[35m0.7441\u001b[0m  0.0200\n",
      "     38        \u001b[36m0.4565\u001b[0m       0.6719        0.7456  0.0187\n",
      "     39        \u001b[36m0.4521\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.7410\u001b[0m  0.0142\n",
      "     40        0.4575       0.6797        0.7466  0.0197\n",
      "     41        0.4526       0.6797        \u001b[35m0.7354\u001b[0m  0.0140\n",
      "     42        \u001b[36m0.4465\u001b[0m       0.6797        0.7422  0.0203\n",
      "     43        \u001b[36m0.4414\u001b[0m       \u001b[32m0.6875\u001b[0m        0.7377  0.0138\n",
      "     44        0.4524       0.6797        0.7404  0.0208\n",
      "     45        \u001b[36m0.4399\u001b[0m       0.6875        0.7407  0.0132\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7496\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.9587\u001b[0m  0.0137\n",
      "      2        0.8237       0.5000        \u001b[35m0.9586\u001b[0m  0.0173\n",
      "      3        0.8233       0.5000        \u001b[35m0.9585\u001b[0m  0.0178\n",
      "      4        0.8152       0.5000        0.9689  0.0168\n",
      "      5        \u001b[36m0.7419\u001b[0m       0.5000        1.0089  0.0248\n",
      "      6        \u001b[36m0.6925\u001b[0m       0.5000        1.0256  0.0215\n",
      "      7        \u001b[36m0.6854\u001b[0m       0.5000        0.9838  0.0151\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6537\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.9180\u001b[0m  0.0128\n",
      "      2        0.7177       0.5000        \u001b[35m0.8807\u001b[0m  0.0211\n",
      "      3        0.6737       \u001b[32m0.5625\u001b[0m        \u001b[35m0.8071\u001b[0m  0.0186\n",
      "      4        \u001b[36m0.6433\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.7952\u001b[0m  0.0145\n",
      "      5        \u001b[36m0.6324\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.7776\u001b[0m  0.0225\n",
      "      6        \u001b[36m0.6240\u001b[0m       0.5938        \u001b[35m0.7628\u001b[0m  0.0213\n",
      "      7        \u001b[36m0.6080\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.7413\u001b[0m  0.0137\n",
      "      8        \u001b[36m0.5926\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.7304\u001b[0m  0.0174\n",
      "      9        \u001b[36m0.5896\u001b[0m       0.5938        0.7677  0.0232\n",
      "     10        \u001b[36m0.5828\u001b[0m       0.6328        0.7497  0.0171\n",
      "     11        \u001b[36m0.5721\u001b[0m       0.6562        0.7382  0.0214\n",
      "     12        \u001b[36m0.5596\u001b[0m       \u001b[32m0.6641\u001b[0m        0.7308  0.0164\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6102\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.0296\u001b[0m  0.0164\n",
      "      2        0.7563       0.5000        \u001b[35m1.0247\u001b[0m  0.0259\n",
      "      3        0.6704       0.5000        \u001b[35m0.9605\u001b[0m  0.0159\n",
      "      4        \u001b[36m0.5846\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.8843\u001b[0m  0.0205\n",
      "      5        \u001b[36m0.5482\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.8364\u001b[0m  0.0162\n",
      "      6        \u001b[36m0.5219\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.8180\u001b[0m  0.0184\n",
      "      7        \u001b[36m0.5105\u001b[0m       0.6406        \u001b[35m0.8031\u001b[0m  0.0161\n",
      "      8        \u001b[36m0.4995\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.7908\u001b[0m  0.0150\n",
      "      9        \u001b[36m0.4957\u001b[0m       0.6562        \u001b[35m0.7851\u001b[0m  0.0248\n",
      "     10        \u001b[36m0.4907\u001b[0m       0.6562        \u001b[35m0.7777\u001b[0m  0.0164\n",
      "     11        \u001b[36m0.4845\u001b[0m       0.6406        \u001b[35m0.7649\u001b[0m  0.0233\n",
      "     12        \u001b[36m0.4765\u001b[0m       0.6406        \u001b[35m0.7636\u001b[0m  0.0161\n",
      "     13        \u001b[36m0.4728\u001b[0m       0.6406        \u001b[35m0.7610\u001b[0m  0.0231\n",
      "     14        \u001b[36m0.4692\u001b[0m       0.6406        0.7660  0.0188\n",
      "     15        \u001b[36m0.4685\u001b[0m       0.6406        0.7644  0.0223\n",
      "     16        \u001b[36m0.4659\u001b[0m       0.6328        0.7656  0.0141\n",
      "     17        \u001b[36m0.4636\u001b[0m       0.6328        0.7687  0.0232\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5637\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8118\u001b[0m  0.0564\n",
      "      2        0.6289       0.5000        \u001b[35m0.7803\u001b[0m  0.0431\n",
      "      3        0.6357       0.5000        \u001b[35m0.7504\u001b[0m  0.0379\n",
      "      4        0.6267       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6974\u001b[0m  0.0436\n",
      "      5        0.5833       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6379\u001b[0m  0.0389\n",
      "      6        0.6022       0.6328        0.6531  0.0405\n",
      "      7        0.5820       0.6406        \u001b[35m0.6363\u001b[0m  0.0432\n",
      "      8        0.5993       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6163\u001b[0m  0.0424\n",
      "      9        0.5643       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5829\u001b[0m  0.0389\n",
      "     10        \u001b[36m0.5576\u001b[0m       0.6641        0.5961  0.0439\n",
      "     11        0.5601       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5708\u001b[0m  0.0381\n",
      "     12        \u001b[36m0.5316\u001b[0m       0.6953        \u001b[35m0.5672\u001b[0m  0.0400\n",
      "     13        0.5354       \u001b[32m0.7031\u001b[0m        0.5697  0.0426\n",
      "     14        0.5356       0.6953        \u001b[35m0.5627\u001b[0m  0.0369\n",
      "     15        0.5322       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5483\u001b[0m  0.0394\n",
      "     16        0.5389       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5297\u001b[0m  0.0437\n",
      "     17        \u001b[36m0.5189\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5213\u001b[0m  0.0370\n",
      "     18        \u001b[36m0.5186\u001b[0m       0.7422        \u001b[35m0.5111\u001b[0m  0.0382\n",
      "     19        0.5503       0.7266        0.5437  0.0408\n",
      "     20        0.5548       \u001b[32m0.7500\u001b[0m        0.5288  0.0427\n",
      "     21        0.5245       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5048\u001b[0m  0.0424\n",
      "     22        0.5447       0.7344        0.5367  0.0368\n",
      "     23        0.5288       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4879\u001b[0m  0.0388\n",
      "     24        \u001b[36m0.5131\u001b[0m       0.7578        0.4984  0.0442\n",
      "     25        0.5325       0.7578        0.5121  0.0402\n",
      "     26        0.5261       0.7578        0.5181  0.0428\n",
      "     27        \u001b[36m0.5035\u001b[0m       0.7578        0.5018  0.0428\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6100\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8007\u001b[0m  0.0379\n",
      "      2        0.6128       0.5000        \u001b[35m0.7587\u001b[0m  0.0423\n",
      "      3        0.6146       0.5000        \u001b[35m0.7313\u001b[0m  0.0403\n",
      "      4        \u001b[36m0.5685\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6901\u001b[0m  0.0419\n",
      "      5        0.5899       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6769\u001b[0m  0.0377\n",
      "      6        0.5710       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6723\u001b[0m  0.0427\n",
      "      7        0.5764       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6534\u001b[0m  0.0368\n",
      "      8        0.5686       0.6328        0.6567  0.0408\n",
      "      9        \u001b[36m0.5666\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6516\u001b[0m  0.0471\n",
      "     10        \u001b[36m0.5497\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6270\u001b[0m  0.0423\n",
      "     11        0.5723       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5907\u001b[0m  0.0373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12        \u001b[36m0.5376\u001b[0m       0.6953        \u001b[35m0.5866\u001b[0m  0.0412\n",
      "     13        \u001b[36m0.5249\u001b[0m       0.7031        0.6152  0.0412\n",
      "     14        0.5458       0.6953        0.6075  0.0414\n",
      "     15        0.5620       0.7031        0.5915  0.0403\n",
      "     16        0.5283       0.6953        \u001b[35m0.5861\u001b[0m  0.0365\n",
      "     17        \u001b[36m0.5221\u001b[0m       0.6875        0.5917  0.0373\n",
      "     18        0.5294       0.7031        \u001b[35m0.5833\u001b[0m  0.0419\n",
      "     19        \u001b[36m0.5083\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5718\u001b[0m  0.0364\n",
      "     20        \u001b[36m0.5046\u001b[0m       0.7031        0.5805  0.0383\n",
      "     21        0.5059       0.7109        \u001b[35m0.5692\u001b[0m  0.0468\n",
      "     22        \u001b[36m0.5026\u001b[0m       0.7109        0.5729  0.0367\n",
      "     23        \u001b[36m0.5005\u001b[0m       0.7109        0.5753  0.0422\n",
      "     24        0.5189       0.7109        \u001b[35m0.5678\u001b[0m  0.0371\n",
      "     25        0.5107       0.7188        0.5809  0.0374\n",
      "     26        0.5025       0.7109        \u001b[35m0.5600\u001b[0m  0.0414\n",
      "     27        0.5005       0.7109        0.5758  0.0369\n",
      "     28        \u001b[36m0.4934\u001b[0m       0.7031        0.5734  0.0384\n",
      "     29        0.5057       0.7109        \u001b[35m0.5524\u001b[0m  0.0374\n",
      "     30        0.4942       0.7109        0.5712  0.0376\n",
      "     31        0.5037       0.6875        \u001b[35m0.5497\u001b[0m  0.0416\n",
      "     32        0.5080       0.7109        0.5786  0.0375\n",
      "     33        0.4997       0.6875        0.5543  0.0365\n",
      "     34        0.4969       0.6875        \u001b[35m0.5487\u001b[0m  0.0369\n",
      "     35        \u001b[36m0.4898\u001b[0m       0.7109        0.5569  0.0377\n",
      "     36        0.5212       0.7031        0.5619  0.0389\n",
      "     37        0.4932       0.7188        0.5561  0.0421\n",
      "     38        0.4982       0.7109        0.5555  0.0362\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6487\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7246\u001b[0m  0.0356\n",
      "      2        0.6522       0.5000        \u001b[35m0.6947\u001b[0m  0.0415\n",
      "      3        \u001b[36m0.6248\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6833\u001b[0m  0.0423\n",
      "      4        \u001b[36m0.6149\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6469\u001b[0m  0.0374\n",
      "      5        \u001b[36m0.5938\u001b[0m       \u001b[32m0.6250\u001b[0m        0.6476  0.0364\n",
      "      6        0.6038       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6340\u001b[0m  0.0438\n",
      "      7        \u001b[36m0.5644\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6083\u001b[0m  0.0365\n",
      "      8        0.5855       0.6641        0.6284  0.0418\n",
      "      9        0.5801       0.7031        \u001b[35m0.5983\u001b[0m  0.0367\n",
      "     10        0.5676       0.6797        0.6217  0.0409\n",
      "     11        0.5647       0.6953        0.6087  0.0369\n",
      "     12        0.5661       0.6953        0.6068  0.0377\n",
      "     13        \u001b[36m0.5464\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5813\u001b[0m  0.0417\n",
      "     14        0.5730       0.6875        0.6027  0.0366\n",
      "     15        0.5565       0.7109        \u001b[35m0.5793\u001b[0m  0.0438\n",
      "     16        \u001b[36m0.5454\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5647\u001b[0m  0.0364\n",
      "     17        \u001b[36m0.5226\u001b[0m       0.7500        \u001b[35m0.5631\u001b[0m  0.0372\n",
      "     18        0.5427       0.7188        0.5887  0.0412\n",
      "     19        \u001b[36m0.5075\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5627\u001b[0m  0.0363\n",
      "     20        0.5282       0.7188        0.5807  0.0367\n",
      "     21        \u001b[36m0.5014\u001b[0m       0.7188        0.6090  0.0409\n",
      "     22        0.5483       0.7188        0.5852  0.0366\n",
      "     23        0.5353       0.7266        0.5733  0.0372\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6504\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7327\u001b[0m  0.0344\n",
      "      2        0.6629       0.5000        \u001b[35m0.7043\u001b[0m  0.0442\n",
      "      3        0.6534       0.5000        \u001b[35m0.6900\u001b[0m  0.0376\n",
      "      4        \u001b[36m0.6296\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6778\u001b[0m  0.0419\n",
      "      5        \u001b[36m0.5941\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6448\u001b[0m  0.0372\n",
      "      6        \u001b[36m0.5730\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6291\u001b[0m  0.0419\n",
      "      7        \u001b[36m0.5557\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6237\u001b[0m  0.0369\n",
      "      8        0.5902       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6080\u001b[0m  0.0423\n",
      "      9        0.5586       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5821\u001b[0m  0.0370\n",
      "     10        \u001b[36m0.5222\u001b[0m       0.6953        \u001b[35m0.5796\u001b[0m  0.0409\n",
      "     11        0.5389       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5768\u001b[0m  0.0368\n",
      "     12        0.5238       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5736\u001b[0m  0.0384\n",
      "     13        0.5376       0.7109        \u001b[35m0.5613\u001b[0m  0.0418\n",
      "     14        0.5231       0.7188        \u001b[35m0.5447\u001b[0m  0.0374\n",
      "     15        \u001b[36m0.5162\u001b[0m       0.7031        0.5509  0.0391\n",
      "     16        0.5199       0.6953        0.5721  0.0422\n",
      "     17        \u001b[36m0.4908\u001b[0m       0.6875        0.5705  0.0420\n",
      "     18        0.5237       0.6797        0.5671  0.0376\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5983\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7778\u001b[0m  0.0351\n",
      "      2        0.6286       0.5000        \u001b[35m0.7592\u001b[0m  0.0414\n",
      "      3        0.6006       0.5000        \u001b[35m0.7191\u001b[0m  0.0400\n",
      "      4        \u001b[36m0.5706\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.7001\u001b[0m  0.0426\n",
      "      5        \u001b[36m0.5511\u001b[0m       \u001b[32m0.6406\u001b[0m        0.7036  0.0414\n",
      "      6        0.5563       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6982\u001b[0m  0.0452\n",
      "      7        0.5560       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6539\u001b[0m  0.0409\n",
      "      8        \u001b[36m0.5322\u001b[0m       0.6953        0.6636  0.0417\n",
      "      9        \u001b[36m0.5161\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6297\u001b[0m  0.0382\n",
      "     10        0.5392       0.7344        \u001b[35m0.6185\u001b[0m  0.0443\n",
      "     11        0.5284       0.7344        0.6331  0.0373\n",
      "     12        0.5226       0.7266        \u001b[35m0.6170\u001b[0m  0.0435\n",
      "     13        0.5344       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5948\u001b[0m  0.0408\n",
      "     14        \u001b[36m0.5020\u001b[0m       0.7344        0.5987  0.0420\n",
      "     15        0.5058       \u001b[32m0.7578\u001b[0m        0.6098  0.0370\n",
      "     16        \u001b[36m0.4821\u001b[0m       0.7422        0.6062  0.0402\n",
      "     17        0.5321       0.7266        \u001b[35m0.5908\u001b[0m  0.0429\n",
      "     18        0.5228       0.7188        0.6022  0.0424\n",
      "     19        0.4969       0.7266        0.6002  0.0372\n",
      "     20        0.4926       0.7266        0.6030  0.0403\n",
      "     21        0.5155       0.7266        0.6029  0.0408\n",
      "     22        0.4990       0.7422        \u001b[35m0.5746\u001b[0m  0.0420\n",
      "     23        0.5078       0.7344        0.5821  0.0373\n",
      "     24        0.4829       0.7344        0.5980  0.0382\n",
      "     25        \u001b[36m0.4767\u001b[0m       0.7266        0.6100  0.0418\n",
      "     26        0.4976       0.7500        0.5802  0.0366\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7692\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6889\u001b[0m  0.0211\n",
      "      2        \u001b[36m0.7162\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6838\u001b[0m  0.0213\n",
      "      3        \u001b[36m0.7027\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6785\u001b[0m  0.0231\n",
      "      4        \u001b[36m0.7000\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.6719\u001b[0m  0.0251\n",
      "      5        \u001b[36m0.6981\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.6620\u001b[0m  0.0326\n",
      "      6        \u001b[36m0.6940\u001b[0m       \u001b[32m0.8438\u001b[0m        \u001b[35m0.6476\u001b[0m  0.0279\n",
      "      7        \u001b[36m0.6775\u001b[0m       0.8281        \u001b[35m0.6247\u001b[0m  0.0230\n",
      "      8        \u001b[36m0.6634\u001b[0m       0.8281        \u001b[35m0.5904\u001b[0m  0.0262\n",
      "      9        \u001b[36m0.6394\u001b[0m       0.8203        \u001b[35m0.5495\u001b[0m  0.0263\n",
      "     10        \u001b[36m0.6078\u001b[0m       0.8047        \u001b[35m0.5123\u001b[0m  0.0260\n",
      "     11        \u001b[36m0.6049\u001b[0m       0.7891        \u001b[35m0.4839\u001b[0m  0.0260\n",
      "     12        \u001b[36m0.5895\u001b[0m       0.8125        \u001b[35m0.4697\u001b[0m  0.0244\n",
      "     13        \u001b[36m0.5864\u001b[0m       0.8125        \u001b[35m0.4584\u001b[0m  0.0267\n",
      "     14        \u001b[36m0.5743\u001b[0m       0.8047        \u001b[35m0.4526\u001b[0m  0.0265\n",
      "     15        0.5942       0.8047        \u001b[35m0.4491\u001b[0m  0.0261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16        \u001b[36m0.5575\u001b[0m       0.7969        \u001b[35m0.4426\u001b[0m  0.0266\n",
      "     17        0.5918       0.7969        0.4435  0.0309\n",
      "     18        0.5895       0.8047        0.4446  0.0231\n",
      "     19        \u001b[36m0.5571\u001b[0m       0.8047        0.4445  0.0241\n",
      "     20        0.5591       0.8047        \u001b[35m0.4379\u001b[0m  0.0284\n",
      "     21        0.5666       0.8047        \u001b[35m0.4327\u001b[0m  0.0277\n",
      "     22        \u001b[36m0.5460\u001b[0m       0.8047        \u001b[35m0.4317\u001b[0m  0.0272\n",
      "     23        0.5587       0.7969        \u001b[35m0.4278\u001b[0m  0.0257\n",
      "     24        \u001b[36m0.5437\u001b[0m       0.7969        \u001b[35m0.4221\u001b[0m  0.0254\n",
      "     25        0.5490       0.8047        0.4253  0.0272\n",
      "     26        0.5474       0.8125        0.4236  0.0272\n",
      "     27        0.5459       0.8047        \u001b[35m0.4196\u001b[0m  0.0279\n",
      "     28        0.5570       0.8047        0.4200  0.0276\n",
      "     29        \u001b[36m0.5426\u001b[0m       0.8203        \u001b[35m0.4173\u001b[0m  0.0290\n",
      "     30        \u001b[36m0.5358\u001b[0m       0.8125        \u001b[35m0.4139\u001b[0m  0.0333\n",
      "     31        0.5394       0.8047        0.4146  0.0323\n",
      "     32        \u001b[36m0.5245\u001b[0m       0.8125        \u001b[35m0.4128\u001b[0m  0.0235\n",
      "     33        \u001b[36m0.5221\u001b[0m       0.8047        \u001b[35m0.4126\u001b[0m  0.0285\n",
      "     34        0.5472       0.8047        0.4179  0.0244\n",
      "     35        0.5333       0.8125        0.4183  0.0318\n",
      "     36        0.5248       0.8047        0.4155  0.0223\n",
      "     37        \u001b[36m0.5217\u001b[0m       0.8047        \u001b[35m0.4117\u001b[0m  0.0263\n",
      "     38        \u001b[36m0.5209\u001b[0m       0.8047        0.4133  0.0273\n",
      "     39        \u001b[36m0.5086\u001b[0m       0.8047        0.4143  0.0262\n",
      "     40        0.5509       0.7969        0.4143  0.0283\n",
      "     41        0.5188       0.7969        0.4121  0.0267\n",
      "     42        0.5165       0.7969        \u001b[35m0.4093\u001b[0m  0.0269\n",
      "     43        \u001b[36m0.5056\u001b[0m       0.8203        \u001b[35m0.4091\u001b[0m  0.0381\n",
      "     44        0.5148       0.7969        \u001b[35m0.4073\u001b[0m  0.0271\n",
      "     45        0.5269       0.8047        0.4095  0.0269\n",
      "     46        \u001b[36m0.5039\u001b[0m       0.8047        0.4074  0.0271\n",
      "     47        0.5152       0.8047        \u001b[35m0.4062\u001b[0m  0.0272\n",
      "     48        0.5251       0.8203        \u001b[35m0.4053\u001b[0m  0.0280\n",
      "     49        0.5150       0.8047        \u001b[35m0.4048\u001b[0m  0.0261\n",
      "     50        0.5263       0.8047        0.4088  0.0277\n",
      "     51        \u001b[36m0.4970\u001b[0m       0.8047        0.4076  0.0258\n",
      "     52        0.5265       0.8203        0.4052  0.0252\n",
      "     53        0.4994       0.8203        0.4050  0.0259\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7387\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6979\u001b[0m  0.0219\n",
      "      2        \u001b[36m0.6692\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6590\u001b[0m  0.0293\n",
      "      3        \u001b[36m0.6644\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6326\u001b[0m  0.0270\n",
      "      4        \u001b[36m0.6490\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6009\u001b[0m  0.0301\n",
      "      5        \u001b[36m0.6215\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5738\u001b[0m  0.0281\n",
      "      6        0.6237       0.7422        \u001b[35m0.5588\u001b[0m  0.0270\n",
      "      7        \u001b[36m0.5880\u001b[0m       0.7344        \u001b[35m0.5462\u001b[0m  0.0261\n",
      "      8        \u001b[36m0.5818\u001b[0m       0.7188        \u001b[35m0.5391\u001b[0m  0.0245\n",
      "      9        0.5894       0.7109        \u001b[35m0.5347\u001b[0m  0.0307\n",
      "     10        0.5853       0.7109        \u001b[35m0.5320\u001b[0m  0.0283\n",
      "     11        \u001b[36m0.5735\u001b[0m       0.7031        \u001b[35m0.5298\u001b[0m  0.0278\n",
      "     12        \u001b[36m0.5719\u001b[0m       0.6953        \u001b[35m0.5287\u001b[0m  0.0258\n",
      "     13        \u001b[36m0.5480\u001b[0m       0.6953        \u001b[35m0.5275\u001b[0m  0.0278\n",
      "     14        0.5617       0.6953        \u001b[35m0.5267\u001b[0m  0.0275\n",
      "     15        \u001b[36m0.5412\u001b[0m       0.7031        \u001b[35m0.5250\u001b[0m  0.0273\n",
      "     16        \u001b[36m0.5366\u001b[0m       0.7031        \u001b[35m0.5222\u001b[0m  0.0295\n",
      "     17        \u001b[36m0.5255\u001b[0m       0.7031        \u001b[35m0.5186\u001b[0m  0.0280\n",
      "     18        0.5425       0.6953        \u001b[35m0.5174\u001b[0m  0.0289\n",
      "     19        0.5442       0.6953        0.5193  0.0296\n",
      "     20        \u001b[36m0.5141\u001b[0m       0.6953        0.5218  0.0272\n",
      "     21        0.5552       0.6953        0.5182  0.0260\n",
      "     22        0.5330       0.6953        \u001b[35m0.5150\u001b[0m  0.0318\n",
      "     23        \u001b[36m0.5140\u001b[0m       0.7031        \u001b[35m0.5135\u001b[0m  0.0231\n",
      "     24        0.5203       0.7031        0.5138  0.0297\n",
      "     25        0.5210       0.7109        \u001b[35m0.5129\u001b[0m  0.0318\n",
      "     26        \u001b[36m0.5063\u001b[0m       0.7188        0.5147  0.0242\n",
      "     27        0.5148       0.7188        0.5148  0.0315\n",
      "     28        0.5107       0.7188        0.5146  0.0259\n",
      "     29        0.5163       0.7188        0.5133  0.0309\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7255\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7061\u001b[0m  0.0307\n",
      "      2        \u001b[36m0.6903\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6822\u001b[0m  0.0236\n",
      "      3        \u001b[36m0.6864\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6689\u001b[0m  0.0230\n",
      "      4        \u001b[36m0.6679\u001b[0m       0.6875        \u001b[35m0.6543\u001b[0m  0.0391\n",
      "      5        \u001b[36m0.6543\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6338\u001b[0m  0.0311\n",
      "      6        \u001b[36m0.6268\u001b[0m       0.6953        \u001b[35m0.6075\u001b[0m  0.0266\n",
      "      7        \u001b[36m0.6210\u001b[0m       0.6953        \u001b[35m0.5825\u001b[0m  0.0280\n",
      "      8        \u001b[36m0.6112\u001b[0m       0.6953        \u001b[35m0.5620\u001b[0m  0.0291\n",
      "      9        \u001b[36m0.5834\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5494\u001b[0m  0.0311\n",
      "     10        \u001b[36m0.5459\u001b[0m       0.7031        \u001b[35m0.5434\u001b[0m  0.0315\n",
      "     11        0.5789       0.7031        \u001b[35m0.5419\u001b[0m  0.0285\n",
      "     12        \u001b[36m0.5352\u001b[0m       0.7109        \u001b[35m0.5405\u001b[0m  0.0311\n",
      "     13        0.5680       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5400\u001b[0m  0.0280\n",
      "     14        \u001b[36m0.5206\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5395\u001b[0m  0.0290\n",
      "     15        0.5544       0.7266        \u001b[35m0.5394\u001b[0m  0.0282\n",
      "     16        0.5654       0.7188        0.5398  0.0295\n",
      "     17        0.5238       0.7188        \u001b[35m0.5391\u001b[0m  0.0238\n",
      "     18        0.5632       0.7188        \u001b[35m0.5388\u001b[0m  0.0263\n",
      "     19        0.5259       0.7188        0.5405  0.0269\n",
      "     20        0.5248       0.7109        0.5412  0.0267\n",
      "     21        0.5281       0.7109        \u001b[35m0.5388\u001b[0m  0.0262\n",
      "     22        \u001b[36m0.5098\u001b[0m       0.7109        0.5393  0.0282\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7293\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6959\u001b[0m  0.0239\n",
      "      2        \u001b[36m0.6928\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6873\u001b[0m  0.0235\n",
      "      3        \u001b[36m0.6769\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6721\u001b[0m  0.0365\n",
      "      4        \u001b[36m0.6642\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6508\u001b[0m  0.0312\n",
      "      5        \u001b[36m0.6586\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6322\u001b[0m  0.0309\n",
      "      6        \u001b[36m0.6341\u001b[0m       0.7188        \u001b[35m0.6131\u001b[0m  0.0269\n",
      "      7        \u001b[36m0.6102\u001b[0m       0.7188        \u001b[35m0.6000\u001b[0m  0.0265\n",
      "      8        0.6170       0.6953        \u001b[35m0.5951\u001b[0m  0.0263\n",
      "      9        \u001b[36m0.6095\u001b[0m       0.6953        \u001b[35m0.5907\u001b[0m  0.0275\n",
      "     10        \u001b[36m0.5982\u001b[0m       0.6797        \u001b[35m0.5882\u001b[0m  0.0258\n",
      "     11        \u001b[36m0.5878\u001b[0m       0.6953        \u001b[35m0.5881\u001b[0m  0.0300\n",
      "     12        0.5902       0.6953        \u001b[35m0.5873\u001b[0m  0.0262\n",
      "     13        0.5922       0.6797        \u001b[35m0.5851\u001b[0m  0.0263\n",
      "     14        \u001b[36m0.5751\u001b[0m       0.6875        \u001b[35m0.5837\u001b[0m  0.0268\n",
      "     15        0.5969       0.6953        \u001b[35m0.5828\u001b[0m  0.0263\n",
      "     16        0.5784       0.7109        \u001b[35m0.5821\u001b[0m  0.0282\n",
      "     17        0.5926       0.6953        \u001b[35m0.5811\u001b[0m  0.0316\n",
      "     18        0.5949       0.7109        \u001b[35m0.5807\u001b[0m  0.0264\n",
      "     19        \u001b[36m0.5702\u001b[0m       0.7109        \u001b[35m0.5786\u001b[0m  0.0246\n",
      "     20        \u001b[36m0.5649\u001b[0m       0.7031        \u001b[35m0.5762\u001b[0m  0.0258\n",
      "     21        \u001b[36m0.5637\u001b[0m       0.7031        \u001b[35m0.5732\u001b[0m  0.0260\n",
      "     22        \u001b[36m0.5631\u001b[0m       0.6953        \u001b[35m0.5718\u001b[0m  0.0255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     23        \u001b[36m0.5445\u001b[0m       0.6875        \u001b[35m0.5687\u001b[0m  0.0264\n",
      "     24        \u001b[36m0.5255\u001b[0m       0.7031        \u001b[35m0.5665\u001b[0m  0.0293\n",
      "     25        0.5649       0.6953        \u001b[35m0.5629\u001b[0m  0.0272\n",
      "     26        0.5440       0.7031        \u001b[35m0.5609\u001b[0m  0.0268\n",
      "     27        0.5385       0.7031        \u001b[35m0.5577\u001b[0m  0.0259\n",
      "     28        0.5267       0.7109        \u001b[35m0.5553\u001b[0m  0.0266\n",
      "     29        0.5574       0.7109        \u001b[35m0.5523\u001b[0m  0.0267\n",
      "     30        0.5631       0.7109        \u001b[35m0.5506\u001b[0m  0.0257\n",
      "     31        0.5270       0.6953        \u001b[35m0.5493\u001b[0m  0.0271\n",
      "     32        0.5321       0.6875        \u001b[35m0.5481\u001b[0m  0.0266\n",
      "     33        0.5325       0.6953        \u001b[35m0.5469\u001b[0m  0.0274\n",
      "     34        0.5351       0.6953        \u001b[35m0.5457\u001b[0m  0.0284\n",
      "     35        0.5352       0.6953        \u001b[35m0.5426\u001b[0m  0.0293\n",
      "     36        \u001b[36m0.5197\u001b[0m       0.6953        \u001b[35m0.5396\u001b[0m  0.0275\n",
      "     37        \u001b[36m0.5184\u001b[0m       0.6953        \u001b[35m0.5381\u001b[0m  0.0290\n",
      "     38        0.5325       0.6953        \u001b[35m0.5377\u001b[0m  0.0270\n",
      "     39        0.5324       0.6953        \u001b[35m0.5353\u001b[0m  0.0269\n",
      "     40        0.5218       0.7188        \u001b[35m0.5333\u001b[0m  0.0273\n",
      "     41        \u001b[36m0.4925\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5319\u001b[0m  0.0273\n",
      "     42        0.5291       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5294\u001b[0m  0.0273\n",
      "     43        0.5213       0.7031        0.5299  0.0268\n",
      "     44        0.5252       0.7422        0.5302  0.0271\n",
      "     45        0.5200       0.7422        0.5295  0.0271\n",
      "     46        0.5060       0.7344        0.5312  0.0274\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7907\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7502\u001b[0m  0.0232\n",
      "      2        \u001b[36m0.6938\u001b[0m       0.5000        \u001b[35m0.6893\u001b[0m  0.0286\n",
      "      3        \u001b[36m0.6698\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6720\u001b[0m  0.0279\n",
      "      4        0.6756       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6622\u001b[0m  0.0284\n",
      "      5        0.6708       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6499\u001b[0m  0.0267\n",
      "      6        \u001b[36m0.6575\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6363\u001b[0m  0.0244\n",
      "      7        \u001b[36m0.6480\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6225\u001b[0m  0.0263\n",
      "      8        \u001b[36m0.6263\u001b[0m       0.7266        \u001b[35m0.6112\u001b[0m  0.0305\n",
      "      9        \u001b[36m0.6188\u001b[0m       0.7109        \u001b[35m0.6039\u001b[0m  0.0277\n",
      "     10        \u001b[36m0.6120\u001b[0m       0.7188        \u001b[35m0.5969\u001b[0m  0.0275\n",
      "     11        \u001b[36m0.5999\u001b[0m       0.7188        \u001b[35m0.5897\u001b[0m  0.0262\n",
      "     12        \u001b[36m0.5683\u001b[0m       0.7266        \u001b[35m0.5836\u001b[0m  0.0274\n",
      "     13        \u001b[36m0.5522\u001b[0m       0.7266        \u001b[35m0.5804\u001b[0m  0.0285\n",
      "     14        0.5572       0.7109        \u001b[35m0.5774\u001b[0m  0.0276\n",
      "     15        \u001b[36m0.5418\u001b[0m       0.7031        0.5789  0.0269\n",
      "     16        \u001b[36m0.5319\u001b[0m       0.7109        0.5828  0.0288\n",
      "     17        0.5335       0.7031        0.5822  0.0253\n",
      "     18        0.5341       0.7109        0.5792  0.0272\n",
      "     19        0.5351       0.7109        \u001b[35m0.5739\u001b[0m  0.0290\n",
      "     20        \u001b[36m0.5233\u001b[0m       0.7109        \u001b[35m0.5727\u001b[0m  0.0275\n",
      "     21        \u001b[36m0.5181\u001b[0m       0.7109        \u001b[35m0.5706\u001b[0m  0.0282\n",
      "     22        0.5299       0.7109        \u001b[35m0.5665\u001b[0m  0.0302\n",
      "     23        0.5314       0.7109        \u001b[35m0.5634\u001b[0m  0.0285\n",
      "     24        \u001b[36m0.5017\u001b[0m       0.7031        0.5648  0.0289\n",
      "     25        0.5200       0.7031        0.5638  0.0287\n",
      "     26        \u001b[36m0.4840\u001b[0m       0.7031        0.5687  0.0286\n",
      "     27        0.5119       0.7109        0.5662  0.0266\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7063\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6982\u001b[0m  0.0199\n",
      "      2        \u001b[36m0.7015\u001b[0m       0.5000        \u001b[35m0.6940\u001b[0m  0.0158\n",
      "      3        \u001b[36m0.6979\u001b[0m       0.5000        \u001b[35m0.6904\u001b[0m  0.0190\n",
      "      4        \u001b[36m0.6947\u001b[0m       0.5000        \u001b[35m0.6871\u001b[0m  0.0151\n",
      "      5        \u001b[36m0.6918\u001b[0m       0.5000        \u001b[35m0.6840\u001b[0m  0.0214\n",
      "      6        \u001b[36m0.6892\u001b[0m       0.5000        \u001b[35m0.6813\u001b[0m  0.0194\n",
      "      7        \u001b[36m0.6868\u001b[0m       0.5000        \u001b[35m0.6787\u001b[0m  0.0233\n",
      "      8        \u001b[36m0.6845\u001b[0m       0.5000        \u001b[35m0.6763\u001b[0m  0.0189\n",
      "      9        \u001b[36m0.6825\u001b[0m       0.5000        \u001b[35m0.6740\u001b[0m  0.0255\n",
      "     10        \u001b[36m0.6805\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6719\u001b[0m  0.0177\n",
      "     11        \u001b[36m0.6786\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6698\u001b[0m  0.0222\n",
      "     12        \u001b[36m0.6768\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6678\u001b[0m  0.0194\n",
      "     13        \u001b[36m0.6751\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6658\u001b[0m  0.0273\n",
      "     14        \u001b[36m0.6734\u001b[0m       0.7109        \u001b[35m0.6638\u001b[0m  0.0165\n",
      "     15        \u001b[36m0.6718\u001b[0m       0.6953        \u001b[35m0.6619\u001b[0m  0.0227\n",
      "     16        \u001b[36m0.6701\u001b[0m       0.7031        \u001b[35m0.6600\u001b[0m  0.0179\n",
      "     17        \u001b[36m0.6685\u001b[0m       0.7188        \u001b[35m0.6581\u001b[0m  0.0228\n",
      "     18        \u001b[36m0.6668\u001b[0m       0.7188        \u001b[35m0.6562\u001b[0m  0.0153\n",
      "     19        \u001b[36m0.6652\u001b[0m       0.7188        \u001b[35m0.6543\u001b[0m  0.0165\n",
      "     20        \u001b[36m0.6635\u001b[0m       0.7188        \u001b[35m0.6524\u001b[0m  0.0205\n",
      "     21        \u001b[36m0.6619\u001b[0m       0.7031        \u001b[35m0.6504\u001b[0m  0.0194\n",
      "     22        \u001b[36m0.6602\u001b[0m       0.7031        \u001b[35m0.6484\u001b[0m  0.0153\n",
      "     23        \u001b[36m0.6585\u001b[0m       0.6953        \u001b[35m0.6464\u001b[0m  0.0194\n",
      "     24        \u001b[36m0.6568\u001b[0m       0.6953        \u001b[35m0.6444\u001b[0m  0.0152\n",
      "     25        \u001b[36m0.6550\u001b[0m       0.6953        \u001b[35m0.6423\u001b[0m  0.0174\n",
      "     26        \u001b[36m0.6532\u001b[0m       0.6953        \u001b[35m0.6403\u001b[0m  0.0222\n",
      "     27        \u001b[36m0.6514\u001b[0m       0.6953        \u001b[35m0.6382\u001b[0m  0.0165\n",
      "     28        \u001b[36m0.6496\u001b[0m       0.6953        \u001b[35m0.6360\u001b[0m  0.0225\n",
      "     29        \u001b[36m0.6477\u001b[0m       0.6953        \u001b[35m0.6338\u001b[0m  0.0174\n",
      "     30        \u001b[36m0.6458\u001b[0m       0.7031        \u001b[35m0.6316\u001b[0m  0.0212\n",
      "     31        \u001b[36m0.6439\u001b[0m       0.7031        \u001b[35m0.6294\u001b[0m  0.0151\n",
      "     32        \u001b[36m0.6420\u001b[0m       0.7031        \u001b[35m0.6272\u001b[0m  0.0165\n",
      "     33        \u001b[36m0.6400\u001b[0m       0.7109        \u001b[35m0.6249\u001b[0m  0.0195\n",
      "     34        \u001b[36m0.6380\u001b[0m       0.7109        \u001b[35m0.6226\u001b[0m  0.0176\n",
      "     35        \u001b[36m0.6360\u001b[0m       0.7109        \u001b[35m0.6203\u001b[0m  0.0151\n",
      "     36        \u001b[36m0.6340\u001b[0m       0.7109        \u001b[35m0.6179\u001b[0m  0.0204\n",
      "     37        \u001b[36m0.6319\u001b[0m       0.7109        \u001b[35m0.6156\u001b[0m  0.0159\n",
      "     38        \u001b[36m0.6299\u001b[0m       0.7109        \u001b[35m0.6132\u001b[0m  0.0157\n",
      "     39        \u001b[36m0.6278\u001b[0m       0.7109        \u001b[35m0.6108\u001b[0m  0.0239\n",
      "     40        \u001b[36m0.6257\u001b[0m       0.7109        \u001b[35m0.6084\u001b[0m  0.0156\n",
      "     41        \u001b[36m0.6235\u001b[0m       0.7188        \u001b[35m0.6059\u001b[0m  0.0220\n",
      "     42        \u001b[36m0.6214\u001b[0m       0.7188        \u001b[35m0.6035\u001b[0m  0.0272\n",
      "     43        \u001b[36m0.6193\u001b[0m       0.7188        \u001b[35m0.6011\u001b[0m  0.0181\n",
      "     44        \u001b[36m0.6172\u001b[0m       0.7188        \u001b[35m0.5986\u001b[0m  0.0198\n",
      "     45        \u001b[36m0.6151\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5962\u001b[0m  0.0157\n",
      "     46        \u001b[36m0.6130\u001b[0m       0.7266        \u001b[35m0.5938\u001b[0m  0.0147\n",
      "     47        \u001b[36m0.6109\u001b[0m       0.7266        \u001b[35m0.5914\u001b[0m  0.0230\n",
      "     48        \u001b[36m0.6088\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5891\u001b[0m  0.0158\n",
      "     49        \u001b[36m0.6067\u001b[0m       0.7344        \u001b[35m0.5867\u001b[0m  0.0177\n",
      "     50        \u001b[36m0.6046\u001b[0m       0.7344        \u001b[35m0.5843\u001b[0m  0.0168\n",
      "     51        \u001b[36m0.6025\u001b[0m       0.7344        \u001b[35m0.5819\u001b[0m  0.0209\n",
      "     52        \u001b[36m0.6005\u001b[0m       0.7344        \u001b[35m0.5795\u001b[0m  0.0156\n",
      "     53        \u001b[36m0.5984\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5771\u001b[0m  0.0199\n",
      "     54        \u001b[36m0.5964\u001b[0m       0.7422        \u001b[35m0.5748\u001b[0m  0.0185\n",
      "     55        \u001b[36m0.5944\u001b[0m       0.7422        \u001b[35m0.5725\u001b[0m  0.0156\n",
      "     56        \u001b[36m0.5925\u001b[0m       0.7422        \u001b[35m0.5702\u001b[0m  0.0165\n",
      "     57        \u001b[36m0.5906\u001b[0m       0.7422        \u001b[35m0.5679\u001b[0m  0.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     58        \u001b[36m0.5887\u001b[0m       0.7344        \u001b[35m0.5658\u001b[0m  0.0171\n",
      "     59        \u001b[36m0.5869\u001b[0m       0.7344        \u001b[35m0.5636\u001b[0m  0.0134\n",
      "     60        \u001b[36m0.5851\u001b[0m       0.7344        \u001b[35m0.5615\u001b[0m  0.0246\n",
      "     61        \u001b[36m0.5834\u001b[0m       0.7344        \u001b[35m0.5594\u001b[0m  0.0197\n",
      "     62        \u001b[36m0.5816\u001b[0m       0.7344        \u001b[35m0.5574\u001b[0m  0.0147\n",
      "     63        \u001b[36m0.5799\u001b[0m       0.7344        \u001b[35m0.5554\u001b[0m  0.0216\n",
      "     64        \u001b[36m0.5783\u001b[0m       0.7344        \u001b[35m0.5534\u001b[0m  0.0141\n",
      "     65        \u001b[36m0.5767\u001b[0m       0.7344        \u001b[35m0.5516\u001b[0m  0.0160\n",
      "     66        \u001b[36m0.5752\u001b[0m       0.7266        \u001b[35m0.5497\u001b[0m  0.0202\n",
      "     67        \u001b[36m0.5736\u001b[0m       0.7266        \u001b[35m0.5479\u001b[0m  0.0210\n",
      "     68        \u001b[36m0.5722\u001b[0m       0.7266        \u001b[35m0.5462\u001b[0m  0.0151\n",
      "     69        \u001b[36m0.5707\u001b[0m       0.7266        \u001b[35m0.5444\u001b[0m  0.0149\n",
      "     70        \u001b[36m0.5694\u001b[0m       0.7188        \u001b[35m0.5428\u001b[0m  0.0250\n",
      "     71        \u001b[36m0.5680\u001b[0m       0.7188        \u001b[35m0.5411\u001b[0m  0.0190\n",
      "     72        \u001b[36m0.5667\u001b[0m       0.7188        \u001b[35m0.5395\u001b[0m  0.0219\n",
      "     73        \u001b[36m0.5654\u001b[0m       0.7188        \u001b[35m0.5379\u001b[0m  0.0149\n",
      "     74        \u001b[36m0.5641\u001b[0m       0.7188        \u001b[35m0.5364\u001b[0m  0.0149\n",
      "     75        \u001b[36m0.5629\u001b[0m       0.7266        \u001b[35m0.5349\u001b[0m  0.0182\n",
      "     76        \u001b[36m0.5617\u001b[0m       0.7266        \u001b[35m0.5334\u001b[0m  0.0134\n",
      "     77        \u001b[36m0.5606\u001b[0m       0.7266        \u001b[35m0.5319\u001b[0m  0.0242\n",
      "     78        \u001b[36m0.5595\u001b[0m       0.7266        \u001b[35m0.5305\u001b[0m  0.0140\n",
      "     79        \u001b[36m0.5583\u001b[0m       0.7266        \u001b[35m0.5292\u001b[0m  0.0201\n",
      "     80        \u001b[36m0.5573\u001b[0m       0.7266        \u001b[35m0.5278\u001b[0m  0.0145\n",
      "     81        \u001b[36m0.5562\u001b[0m       0.7266        \u001b[35m0.5266\u001b[0m  0.0153\n",
      "     82        \u001b[36m0.5553\u001b[0m       0.7266        \u001b[35m0.5253\u001b[0m  0.0201\n",
      "     83        \u001b[36m0.5543\u001b[0m       0.7266        \u001b[35m0.5241\u001b[0m  0.0180\n",
      "     84        \u001b[36m0.5534\u001b[0m       0.7266        \u001b[35m0.5228\u001b[0m  0.0198\n",
      "     85        \u001b[36m0.5525\u001b[0m       0.7266        \u001b[35m0.5216\u001b[0m  0.0144\n",
      "     86        \u001b[36m0.5516\u001b[0m       0.7266        \u001b[35m0.5203\u001b[0m  0.0152\n",
      "     87        \u001b[36m0.5508\u001b[0m       0.7266        \u001b[35m0.5191\u001b[0m  0.0231\n",
      "     88        \u001b[36m0.5500\u001b[0m       0.7266        \u001b[35m0.5179\u001b[0m  0.0133\n",
      "     89        \u001b[36m0.5492\u001b[0m       0.7266        \u001b[35m0.5167\u001b[0m  0.0195\n",
      "     90        \u001b[36m0.5485\u001b[0m       0.7344        \u001b[35m0.5155\u001b[0m  0.0145\n",
      "     91        \u001b[36m0.5477\u001b[0m       0.7344        \u001b[35m0.5144\u001b[0m  0.0161\n",
      "     92        \u001b[36m0.5470\u001b[0m       0.7344        \u001b[35m0.5133\u001b[0m  0.0211\n",
      "     93        \u001b[36m0.5463\u001b[0m       0.7344        \u001b[35m0.5121\u001b[0m  0.0162\n",
      "     94        \u001b[36m0.5456\u001b[0m       0.7344        \u001b[35m0.5110\u001b[0m  0.0136\n",
      "     95        \u001b[36m0.5449\u001b[0m       0.7344        \u001b[35m0.5099\u001b[0m  0.0190\n",
      "     96        \u001b[36m0.5443\u001b[0m       0.7344        \u001b[35m0.5088\u001b[0m  0.0201\n",
      "     97        \u001b[36m0.5437\u001b[0m       0.7344        \u001b[35m0.5077\u001b[0m  0.0178\n",
      "     98        \u001b[36m0.5430\u001b[0m       0.7344        \u001b[35m0.5067\u001b[0m  0.0152\n",
      "     99        \u001b[36m0.5425\u001b[0m       0.7344        \u001b[35m0.5057\u001b[0m  0.0191\n",
      "    100        \u001b[36m0.5419\u001b[0m       0.7344        \u001b[35m0.5046\u001b[0m  0.0152\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6956\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6842\u001b[0m  0.0183\n",
      "      2        \u001b[36m0.6905\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6801\u001b[0m  0.0196\n",
      "      3        \u001b[36m0.6865\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6761\u001b[0m  0.0153\n",
      "      4        \u001b[36m0.6825\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6723\u001b[0m  0.0210\n",
      "      5        \u001b[36m0.6788\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6686\u001b[0m  0.0163\n",
      "      6        \u001b[36m0.6752\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6650\u001b[0m  0.0252\n",
      "      7        \u001b[36m0.6717\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6615\u001b[0m  0.0169\n",
      "      8        \u001b[36m0.6681\u001b[0m       0.7031        \u001b[35m0.6581\u001b[0m  0.0202\n",
      "      9        \u001b[36m0.6646\u001b[0m       0.7031        \u001b[35m0.6548\u001b[0m  0.0165\n",
      "     10        \u001b[36m0.6612\u001b[0m       0.7031        \u001b[35m0.6516\u001b[0m  0.0300\n",
      "     11        \u001b[36m0.6578\u001b[0m       0.7188        \u001b[35m0.6484\u001b[0m  0.0167\n",
      "     12        \u001b[36m0.6544\u001b[0m       0.7188        \u001b[35m0.6453\u001b[0m  0.0184\n",
      "     13        \u001b[36m0.6510\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6421\u001b[0m  0.0232\n",
      "     14        \u001b[36m0.6477\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6390\u001b[0m  0.0161\n",
      "     15        \u001b[36m0.6443\u001b[0m       0.7344        \u001b[35m0.6359\u001b[0m  0.0214\n",
      "     16        \u001b[36m0.6410\u001b[0m       0.7344        \u001b[35m0.6328\u001b[0m  0.0147\n",
      "     17        \u001b[36m0.6377\u001b[0m       0.7344        \u001b[35m0.6297\u001b[0m  0.0233\n",
      "     18        \u001b[36m0.6344\u001b[0m       0.7344        \u001b[35m0.6266\u001b[0m  0.0160\n",
      "     19        \u001b[36m0.6311\u001b[0m       0.7266        \u001b[35m0.6236\u001b[0m  0.0201\n",
      "     20        \u001b[36m0.6278\u001b[0m       0.7344        \u001b[35m0.6206\u001b[0m  0.0159\n",
      "     21        \u001b[36m0.6246\u001b[0m       0.7344        \u001b[35m0.6176\u001b[0m  0.0163\n",
      "     22        \u001b[36m0.6213\u001b[0m       0.7344        \u001b[35m0.6146\u001b[0m  0.0312\n",
      "     23        \u001b[36m0.6181\u001b[0m       0.7344        \u001b[35m0.6116\u001b[0m  0.0155\n",
      "     24        \u001b[36m0.6149\u001b[0m       0.7344        \u001b[35m0.6087\u001b[0m  0.0167\n",
      "     25        \u001b[36m0.6117\u001b[0m       0.7344        \u001b[35m0.6059\u001b[0m  0.0202\n",
      "     26        \u001b[36m0.6085\u001b[0m       0.7344        \u001b[35m0.6031\u001b[0m  0.0151\n",
      "     27        \u001b[36m0.6054\u001b[0m       0.7344        \u001b[35m0.6004\u001b[0m  0.0210\n",
      "     28        \u001b[36m0.6023\u001b[0m       0.7344        \u001b[35m0.5977\u001b[0m  0.0175\n",
      "     29        \u001b[36m0.5993\u001b[0m       0.7344        \u001b[35m0.5951\u001b[0m  0.0168\n",
      "     30        \u001b[36m0.5963\u001b[0m       0.7344        \u001b[35m0.5925\u001b[0m  0.0206\n",
      "     31        \u001b[36m0.5934\u001b[0m       0.7344        \u001b[35m0.5900\u001b[0m  0.0170\n",
      "     32        \u001b[36m0.5905\u001b[0m       0.7344        \u001b[35m0.5876\u001b[0m  0.0155\n",
      "     33        \u001b[36m0.5877\u001b[0m       0.7344        \u001b[35m0.5852\u001b[0m  0.0170\n",
      "     34        \u001b[36m0.5849\u001b[0m       0.7344        \u001b[35m0.5829\u001b[0m  0.0198\n",
      "     35        \u001b[36m0.5822\u001b[0m       0.7344        \u001b[35m0.5808\u001b[0m  0.0161\n",
      "     36        \u001b[36m0.5796\u001b[0m       0.7344        \u001b[35m0.5787\u001b[0m  0.0159\n",
      "     37        \u001b[36m0.5771\u001b[0m       0.7344        \u001b[35m0.5767\u001b[0m  0.0236\n",
      "     38        \u001b[36m0.5747\u001b[0m       0.7344        \u001b[35m0.5747\u001b[0m  0.0169\n",
      "     39        \u001b[36m0.5724\u001b[0m       0.7344        \u001b[35m0.5729\u001b[0m  0.0201\n",
      "     40        \u001b[36m0.5701\u001b[0m       0.7344        \u001b[35m0.5712\u001b[0m  0.0155\n",
      "     41        \u001b[36m0.5680\u001b[0m       0.7344        \u001b[35m0.5696\u001b[0m  0.0201\n",
      "     42        \u001b[36m0.5659\u001b[0m       0.7344        \u001b[35m0.5680\u001b[0m  0.0153\n",
      "     43        \u001b[36m0.5639\u001b[0m       0.7344        \u001b[35m0.5666\u001b[0m  0.0154\n",
      "     44        \u001b[36m0.5619\u001b[0m       0.7344        \u001b[35m0.5652\u001b[0m  0.0176\n",
      "     45        \u001b[36m0.5601\u001b[0m       0.7344        \u001b[35m0.5639\u001b[0m  0.0195\n",
      "     46        \u001b[36m0.5583\u001b[0m       0.7344        \u001b[35m0.5626\u001b[0m  0.0156\n",
      "     47        \u001b[36m0.5566\u001b[0m       0.7344        \u001b[35m0.5615\u001b[0m  0.0156\n",
      "     48        \u001b[36m0.5549\u001b[0m       0.7344        \u001b[35m0.5604\u001b[0m  0.0155\n",
      "     49        \u001b[36m0.5533\u001b[0m       0.7344        \u001b[35m0.5593\u001b[0m  0.0199\n",
      "     50        \u001b[36m0.5518\u001b[0m       0.7344        \u001b[35m0.5583\u001b[0m  0.0163\n",
      "     51        \u001b[36m0.5503\u001b[0m       0.7344        \u001b[35m0.5574\u001b[0m  0.0166\n",
      "     52        \u001b[36m0.5489\u001b[0m       0.7266        \u001b[35m0.5566\u001b[0m  0.0163\n",
      "     53        \u001b[36m0.5475\u001b[0m       0.7266        \u001b[35m0.5558\u001b[0m  0.0197\n",
      "     54        \u001b[36m0.5462\u001b[0m       0.7266        \u001b[35m0.5550\u001b[0m  0.0142\n",
      "     55        \u001b[36m0.5449\u001b[0m       0.7266        \u001b[35m0.5543\u001b[0m  0.0161\n",
      "     56        \u001b[36m0.5436\u001b[0m       0.7266        \u001b[35m0.5536\u001b[0m  0.0192\n",
      "     57        \u001b[36m0.5424\u001b[0m       0.7266        \u001b[35m0.5530\u001b[0m  0.0177\n",
      "     58        \u001b[36m0.5412\u001b[0m       0.7266        \u001b[35m0.5524\u001b[0m  0.0157\n",
      "     59        \u001b[36m0.5401\u001b[0m       0.7266        \u001b[35m0.5518\u001b[0m  0.0148\n",
      "     60        \u001b[36m0.5391\u001b[0m       0.7266        \u001b[35m0.5512\u001b[0m  0.0157\n",
      "     61        \u001b[36m0.5380\u001b[0m       0.7266        \u001b[35m0.5507\u001b[0m  0.0147\n",
      "     62        \u001b[36m0.5370\u001b[0m       0.7266        \u001b[35m0.5502\u001b[0m  0.0196\n",
      "     63        \u001b[36m0.5360\u001b[0m       0.7266        \u001b[35m0.5498\u001b[0m  0.0187\n",
      "     64        \u001b[36m0.5351\u001b[0m       0.7266        \u001b[35m0.5493\u001b[0m  0.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     65        \u001b[36m0.5341\u001b[0m       0.7266        \u001b[35m0.5489\u001b[0m  0.0161\n",
      "     66        \u001b[36m0.5332\u001b[0m       0.7266        \u001b[35m0.5485\u001b[0m  0.0153\n",
      "     67        \u001b[36m0.5324\u001b[0m       0.7266        \u001b[35m0.5481\u001b[0m  0.0146\n",
      "     68        \u001b[36m0.5315\u001b[0m       0.7266        \u001b[35m0.5478\u001b[0m  0.0220\n",
      "     69        \u001b[36m0.5307\u001b[0m       0.7266        \u001b[35m0.5475\u001b[0m  0.0146\n",
      "     70        \u001b[36m0.5299\u001b[0m       0.7266        \u001b[35m0.5471\u001b[0m  0.0156\n",
      "     71        \u001b[36m0.5291\u001b[0m       0.7266        \u001b[35m0.5468\u001b[0m  0.0268\n",
      "     72        \u001b[36m0.5283\u001b[0m       0.7344        \u001b[35m0.5466\u001b[0m  0.0179\n",
      "     73        \u001b[36m0.5276\u001b[0m       0.7344        \u001b[35m0.5463\u001b[0m  0.0187\n",
      "     74        \u001b[36m0.5269\u001b[0m       0.7344        \u001b[35m0.5460\u001b[0m  0.0179\n",
      "     75        \u001b[36m0.5262\u001b[0m       0.7344        \u001b[35m0.5458\u001b[0m  0.0156\n",
      "     76        \u001b[36m0.5255\u001b[0m       0.7344        \u001b[35m0.5455\u001b[0m  0.0196\n",
      "     77        \u001b[36m0.5248\u001b[0m       0.7344        \u001b[35m0.5453\u001b[0m  0.0148\n",
      "     78        \u001b[36m0.5242\u001b[0m       0.7344        \u001b[35m0.5451\u001b[0m  0.0199\n",
      "     79        \u001b[36m0.5236\u001b[0m       0.7344        \u001b[35m0.5449\u001b[0m  0.0155\n",
      "     80        \u001b[36m0.5229\u001b[0m       0.7344        \u001b[35m0.5447\u001b[0m  0.0142\n",
      "     81        \u001b[36m0.5223\u001b[0m       0.7344        \u001b[35m0.5445\u001b[0m  0.0203\n",
      "     82        \u001b[36m0.5217\u001b[0m       0.7344        \u001b[35m0.5443\u001b[0m  0.0136\n",
      "     83        \u001b[36m0.5211\u001b[0m       0.7266        \u001b[35m0.5441\u001b[0m  0.0194\n",
      "     84        \u001b[36m0.5205\u001b[0m       0.7266        \u001b[35m0.5439\u001b[0m  0.0151\n",
      "     85        \u001b[36m0.5199\u001b[0m       0.7266        \u001b[35m0.5437\u001b[0m  0.0150\n",
      "     86        \u001b[36m0.5193\u001b[0m       0.7266        \u001b[35m0.5434\u001b[0m  0.0194\n",
      "     87        \u001b[36m0.5188\u001b[0m       0.7188        \u001b[35m0.5431\u001b[0m  0.0152\n",
      "     88        \u001b[36m0.5182\u001b[0m       0.7188        \u001b[35m0.5428\u001b[0m  0.0202\n",
      "     89        \u001b[36m0.5177\u001b[0m       0.7188        \u001b[35m0.5426\u001b[0m  0.0152\n",
      "     90        \u001b[36m0.5172\u001b[0m       0.7109        \u001b[35m0.5422\u001b[0m  0.0152\n",
      "     91        \u001b[36m0.5167\u001b[0m       0.7109        \u001b[35m0.5420\u001b[0m  0.0209\n",
      "     92        \u001b[36m0.5162\u001b[0m       0.7109        \u001b[35m0.5416\u001b[0m  0.0154\n",
      "     93        \u001b[36m0.5157\u001b[0m       0.7109        \u001b[35m0.5413\u001b[0m  0.0131\n",
      "     94        \u001b[36m0.5152\u001b[0m       0.7109        \u001b[35m0.5409\u001b[0m  0.0222\n",
      "     95        \u001b[36m0.5147\u001b[0m       0.7109        \u001b[35m0.5406\u001b[0m  0.0156\n",
      "     96        \u001b[36m0.5142\u001b[0m       0.7109        \u001b[35m0.5403\u001b[0m  0.0145\n",
      "     97        \u001b[36m0.5137\u001b[0m       0.7109        \u001b[35m0.5400\u001b[0m  0.0223\n",
      "     98        \u001b[36m0.5132\u001b[0m       0.7109        \u001b[35m0.5397\u001b[0m  0.0151\n",
      "     99        \u001b[36m0.5128\u001b[0m       0.7109        \u001b[35m0.5394\u001b[0m  0.0147\n",
      "    100        \u001b[36m0.5123\u001b[0m       0.7109        \u001b[35m0.5391\u001b[0m  0.0192\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7624\u001b[0m       \u001b[32m0.3672\u001b[0m        \u001b[35m0.7555\u001b[0m  0.0204\n",
      "      2        \u001b[36m0.7544\u001b[0m       \u001b[32m0.3750\u001b[0m        \u001b[35m0.7492\u001b[0m  0.0143\n",
      "      3        \u001b[36m0.7485\u001b[0m       0.3750        \u001b[35m0.7436\u001b[0m  0.0185\n",
      "      4        \u001b[36m0.7432\u001b[0m       0.3750        \u001b[35m0.7386\u001b[0m  0.0198\n",
      "      5        \u001b[36m0.7384\u001b[0m       0.3750        \u001b[35m0.7340\u001b[0m  0.0196\n",
      "      6        \u001b[36m0.7340\u001b[0m       \u001b[32m0.3828\u001b[0m        \u001b[35m0.7298\u001b[0m  0.0213\n",
      "      7        \u001b[36m0.7299\u001b[0m       \u001b[32m0.3906\u001b[0m        \u001b[35m0.7259\u001b[0m  0.0239\n",
      "      8        \u001b[36m0.7262\u001b[0m       0.3906        \u001b[35m0.7224\u001b[0m  0.0168\n",
      "      9        \u001b[36m0.7228\u001b[0m       0.3828        \u001b[35m0.7190\u001b[0m  0.0245\n",
      "     10        \u001b[36m0.7195\u001b[0m       0.3906        \u001b[35m0.7159\u001b[0m  0.0173\n",
      "     11        \u001b[36m0.7165\u001b[0m       \u001b[32m0.3984\u001b[0m        \u001b[35m0.7130\u001b[0m  0.0235\n",
      "     12        \u001b[36m0.7137\u001b[0m       0.3906        \u001b[35m0.7103\u001b[0m  0.0233\n",
      "     13        \u001b[36m0.7110\u001b[0m       \u001b[32m0.4062\u001b[0m        \u001b[35m0.7077\u001b[0m  0.0224\n",
      "     14        \u001b[36m0.7084\u001b[0m       \u001b[32m0.4219\u001b[0m        \u001b[35m0.7052\u001b[0m  0.0161\n",
      "     15        \u001b[36m0.7059\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7029\u001b[0m  0.0232\n",
      "     16        \u001b[36m0.7035\u001b[0m       0.5000        \u001b[35m0.7006\u001b[0m  0.0150\n",
      "     17        \u001b[36m0.7012\u001b[0m       0.5000        \u001b[35m0.6984\u001b[0m  0.0166\n",
      "     18        \u001b[36m0.6990\u001b[0m       0.5000        \u001b[35m0.6962\u001b[0m  0.0220\n",
      "     19        \u001b[36m0.6969\u001b[0m       0.5000        \u001b[35m0.6941\u001b[0m  0.0183\n",
      "     20        \u001b[36m0.6948\u001b[0m       0.5000        \u001b[35m0.6921\u001b[0m  0.0205\n",
      "     21        \u001b[36m0.6927\u001b[0m       0.5000        \u001b[35m0.6901\u001b[0m  0.0170\n",
      "     22        \u001b[36m0.6907\u001b[0m       0.5000        \u001b[35m0.6881\u001b[0m  0.0157\n",
      "     23        \u001b[36m0.6886\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6861\u001b[0m  0.0266\n",
      "     24        \u001b[36m0.6866\u001b[0m       0.5078        \u001b[35m0.6841\u001b[0m  0.0156\n",
      "     25        \u001b[36m0.6846\u001b[0m       0.5078        \u001b[35m0.6820\u001b[0m  0.0222\n",
      "     26        \u001b[36m0.6825\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6800\u001b[0m  0.0254\n",
      "     27        \u001b[36m0.6805\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6780\u001b[0m  0.0154\n",
      "     28        \u001b[36m0.6784\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6760\u001b[0m  0.0218\n",
      "     29        \u001b[36m0.6763\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6740\u001b[0m  0.0157\n",
      "     30        \u001b[36m0.6742\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6719\u001b[0m  0.0134\n",
      "     31        \u001b[36m0.6720\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6698\u001b[0m  0.0197\n",
      "     32        \u001b[36m0.6698\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6677\u001b[0m  0.0165\n",
      "     33        \u001b[36m0.6676\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6656\u001b[0m  0.0153\n",
      "     34        \u001b[36m0.6653\u001b[0m       0.6641        \u001b[35m0.6634\u001b[0m  0.0263\n",
      "     35        \u001b[36m0.6629\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6612\u001b[0m  0.0217\n",
      "     36        \u001b[36m0.6605\u001b[0m       0.6719        \u001b[35m0.6589\u001b[0m  0.0152\n",
      "     37        \u001b[36m0.6581\u001b[0m       0.6641        \u001b[35m0.6565\u001b[0m  0.0170\n",
      "     38        \u001b[36m0.6556\u001b[0m       0.6797        \u001b[35m0.6540\u001b[0m  0.0199\n",
      "     39        \u001b[36m0.6530\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6516\u001b[0m  0.0162\n",
      "     40        \u001b[36m0.6504\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6490\u001b[0m  0.0145\n",
      "     41        \u001b[36m0.6478\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6464\u001b[0m  0.0227\n",
      "     42        \u001b[36m0.6451\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6438\u001b[0m  0.0167\n",
      "     43        \u001b[36m0.6424\u001b[0m       0.7188        \u001b[35m0.6411\u001b[0m  0.0143\n",
      "     44        \u001b[36m0.6396\u001b[0m       0.7031        \u001b[35m0.6384\u001b[0m  0.0144\n",
      "     45        \u001b[36m0.6368\u001b[0m       0.7109        \u001b[35m0.6356\u001b[0m  0.0185\n",
      "     46        \u001b[36m0.6340\u001b[0m       0.7109        \u001b[35m0.6327\u001b[0m  0.0176\n",
      "     47        \u001b[36m0.6311\u001b[0m       0.7109        \u001b[35m0.6298\u001b[0m  0.0158\n",
      "     48        \u001b[36m0.6283\u001b[0m       0.7109        \u001b[35m0.6269\u001b[0m  0.0156\n",
      "     49        \u001b[36m0.6254\u001b[0m       0.7188        \u001b[35m0.6240\u001b[0m  0.0156\n",
      "     50        \u001b[36m0.6224\u001b[0m       0.7188        \u001b[35m0.6210\u001b[0m  0.0207\n",
      "     51        \u001b[36m0.6195\u001b[0m       0.7266        \u001b[35m0.6181\u001b[0m  0.0163\n",
      "     52        \u001b[36m0.6165\u001b[0m       0.7188        \u001b[35m0.6151\u001b[0m  0.0170\n",
      "     53        \u001b[36m0.6135\u001b[0m       0.7188        \u001b[35m0.6121\u001b[0m  0.0158\n",
      "     54        \u001b[36m0.6105\u001b[0m       0.7266        \u001b[35m0.6091\u001b[0m  0.0157\n",
      "     55        \u001b[36m0.6076\u001b[0m       0.7266        \u001b[35m0.6061\u001b[0m  0.0198\n",
      "     56        \u001b[36m0.6046\u001b[0m       0.7266        \u001b[35m0.6031\u001b[0m  0.0163\n",
      "     57        \u001b[36m0.6017\u001b[0m       0.7266        \u001b[35m0.6002\u001b[0m  0.0157\n",
      "     58        \u001b[36m0.5987\u001b[0m       0.7266        \u001b[35m0.5972\u001b[0m  0.0175\n",
      "     59        \u001b[36m0.5959\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5943\u001b[0m  0.0137\n",
      "     60        \u001b[36m0.5930\u001b[0m       0.7344        \u001b[35m0.5914\u001b[0m  0.0164\n",
      "     61        \u001b[36m0.5902\u001b[0m       0.7344        \u001b[35m0.5886\u001b[0m  0.0157\n",
      "     62        \u001b[36m0.5874\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5858\u001b[0m  0.0250\n",
      "     63        \u001b[36m0.5847\u001b[0m       0.7422        \u001b[35m0.5831\u001b[0m  0.0230\n",
      "     64        \u001b[36m0.5820\u001b[0m       0.7422        \u001b[35m0.5804\u001b[0m  0.0150\n",
      "     65        \u001b[36m0.5794\u001b[0m       0.7422        \u001b[35m0.5778\u001b[0m  0.0155\n",
      "     66        \u001b[36m0.5768\u001b[0m       0.7422        \u001b[35m0.5753\u001b[0m  0.0151\n",
      "     67        \u001b[36m0.5742\u001b[0m       0.7422        \u001b[35m0.5728\u001b[0m  0.0155\n",
      "     68        \u001b[36m0.5717\u001b[0m       0.7422        \u001b[35m0.5703\u001b[0m  0.0206\n",
      "     69        \u001b[36m0.5692\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5680\u001b[0m  0.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     70        \u001b[36m0.5668\u001b[0m       0.7500        \u001b[35m0.5657\u001b[0m  0.0181\n",
      "     71        \u001b[36m0.5645\u001b[0m       0.7500        \u001b[35m0.5635\u001b[0m  0.0143\n",
      "     72        \u001b[36m0.5623\u001b[0m       0.7500        \u001b[35m0.5614\u001b[0m  0.0173\n",
      "     73        \u001b[36m0.5602\u001b[0m       0.7500        \u001b[35m0.5594\u001b[0m  0.0163\n",
      "     74        \u001b[36m0.5581\u001b[0m       0.7500        \u001b[35m0.5575\u001b[0m  0.0212\n",
      "     75        \u001b[36m0.5560\u001b[0m       0.7500        \u001b[35m0.5557\u001b[0m  0.0152\n",
      "     76        \u001b[36m0.5541\u001b[0m       0.7500        \u001b[35m0.5539\u001b[0m  0.0148\n",
      "     77        \u001b[36m0.5522\u001b[0m       0.7500        \u001b[35m0.5522\u001b[0m  0.0180\n",
      "     78        \u001b[36m0.5503\u001b[0m       0.7500        \u001b[35m0.5505\u001b[0m  0.0136\n",
      "     79        \u001b[36m0.5485\u001b[0m       0.7500        \u001b[35m0.5490\u001b[0m  0.0203\n",
      "     80        \u001b[36m0.5468\u001b[0m       0.7500        \u001b[35m0.5474\u001b[0m  0.0143\n",
      "     81        \u001b[36m0.5451\u001b[0m       0.7500        \u001b[35m0.5460\u001b[0m  0.0209\n",
      "     82        \u001b[36m0.5435\u001b[0m       0.7422        \u001b[35m0.5445\u001b[0m  0.0150\n",
      "     83        \u001b[36m0.5420\u001b[0m       0.7422        \u001b[35m0.5432\u001b[0m  0.0166\n",
      "     84        \u001b[36m0.5405\u001b[0m       0.7422        \u001b[35m0.5419\u001b[0m  0.0200\n",
      "     85        \u001b[36m0.5390\u001b[0m       0.7422        \u001b[35m0.5406\u001b[0m  0.0149\n",
      "     86        \u001b[36m0.5375\u001b[0m       0.7422        \u001b[35m0.5394\u001b[0m  0.0204\n",
      "     87        \u001b[36m0.5360\u001b[0m       0.7344        \u001b[35m0.5383\u001b[0m  0.0167\n",
      "     88        \u001b[36m0.5346\u001b[0m       0.7344        \u001b[35m0.5372\u001b[0m  0.0233\n",
      "     89        \u001b[36m0.5332\u001b[0m       0.7344        \u001b[35m0.5361\u001b[0m  0.0191\n",
      "     90        \u001b[36m0.5318\u001b[0m       0.7344        \u001b[35m0.5351\u001b[0m  0.0208\n",
      "     91        \u001b[36m0.5305\u001b[0m       0.7266        \u001b[35m0.5342\u001b[0m  0.0150\n",
      "     92        \u001b[36m0.5293\u001b[0m       0.7266        \u001b[35m0.5333\u001b[0m  0.0142\n",
      "     93        \u001b[36m0.5280\u001b[0m       0.7266        \u001b[35m0.5324\u001b[0m  0.0227\n",
      "     94        \u001b[36m0.5269\u001b[0m       0.7188        \u001b[35m0.5316\u001b[0m  0.0155\n",
      "     95        \u001b[36m0.5257\u001b[0m       0.7188        \u001b[35m0.5308\u001b[0m  0.0135\n",
      "     96        \u001b[36m0.5246\u001b[0m       0.7188        \u001b[35m0.5300\u001b[0m  0.0235\n",
      "     97        \u001b[36m0.5236\u001b[0m       0.7266        \u001b[35m0.5293\u001b[0m  0.0159\n",
      "     98        \u001b[36m0.5226\u001b[0m       0.7266        \u001b[35m0.5286\u001b[0m  0.0135\n",
      "     99        \u001b[36m0.5216\u001b[0m       0.7266        \u001b[35m0.5279\u001b[0m  0.0208\n",
      "    100        \u001b[36m0.5206\u001b[0m       0.7266        \u001b[35m0.5273\u001b[0m  0.0154\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7033\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6963\u001b[0m  0.0227\n",
      "      2        \u001b[36m0.7012\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6951\u001b[0m  0.0192\n",
      "      3        \u001b[36m0.6999\u001b[0m       0.5234        \u001b[35m0.6940\u001b[0m  0.0172\n",
      "      4        \u001b[36m0.6987\u001b[0m       0.5156        \u001b[35m0.6930\u001b[0m  0.0201\n",
      "      5        \u001b[36m0.6976\u001b[0m       0.5000        \u001b[35m0.6921\u001b[0m  0.0167\n",
      "      6        \u001b[36m0.6966\u001b[0m       0.4844        \u001b[35m0.6912\u001b[0m  0.0206\n",
      "      7        \u001b[36m0.6956\u001b[0m       0.4922        \u001b[35m0.6903\u001b[0m  0.0160\n",
      "      8        \u001b[36m0.6946\u001b[0m       0.5000        \u001b[35m0.6895\u001b[0m  0.0208\n",
      "      9        \u001b[36m0.6936\u001b[0m       0.5078        \u001b[35m0.6887\u001b[0m  0.0158\n",
      "     10        \u001b[36m0.6925\u001b[0m       0.5156        \u001b[35m0.6879\u001b[0m  0.0197\n",
      "     11        \u001b[36m0.6915\u001b[0m       0.5234        \u001b[35m0.6871\u001b[0m  0.0156\n",
      "     12        \u001b[36m0.6904\u001b[0m       0.5234        \u001b[35m0.6862\u001b[0m  0.0203\n",
      "     13        \u001b[36m0.6893\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6852\u001b[0m  0.0155\n",
      "     14        \u001b[36m0.6882\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6843\u001b[0m  0.0223\n",
      "     15        \u001b[36m0.6871\u001b[0m       0.5469        \u001b[35m0.6833\u001b[0m  0.0174\n",
      "     16        \u001b[36m0.6859\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6823\u001b[0m  0.0331\n",
      "     17        \u001b[36m0.6846\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6813\u001b[0m  0.0158\n",
      "     18        \u001b[36m0.6834\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6803\u001b[0m  0.0226\n",
      "     19        \u001b[36m0.6822\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6792\u001b[0m  0.0168\n",
      "     20        \u001b[36m0.6810\u001b[0m       0.5938        \u001b[35m0.6781\u001b[0m  0.0161\n",
      "     21        \u001b[36m0.6798\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6770\u001b[0m  0.0419\n",
      "     22        \u001b[36m0.6785\u001b[0m       0.6016        \u001b[35m0.6758\u001b[0m  0.0206\n",
      "     23        \u001b[36m0.6771\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6746\u001b[0m  0.0143\n",
      "     24        \u001b[36m0.6757\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6733\u001b[0m  0.0177\n",
      "     25        \u001b[36m0.6743\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6721\u001b[0m  0.0170\n",
      "     26        \u001b[36m0.6728\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6707\u001b[0m  0.0311\n",
      "     27        \u001b[36m0.6711\u001b[0m       0.6328        \u001b[35m0.6692\u001b[0m  0.0154\n",
      "     28        \u001b[36m0.6694\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6675\u001b[0m  0.0177\n",
      "     29        \u001b[36m0.6675\u001b[0m       0.6484        \u001b[35m0.6658\u001b[0m  0.0239\n",
      "     30        \u001b[36m0.6657\u001b[0m       0.6484        \u001b[35m0.6640\u001b[0m  0.0155\n",
      "     31        \u001b[36m0.6637\u001b[0m       0.6484        \u001b[35m0.6622\u001b[0m  0.0213\n",
      "     32        \u001b[36m0.6617\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6603\u001b[0m  0.0156\n",
      "     33        \u001b[36m0.6597\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6583\u001b[0m  0.0252\n",
      "     34        \u001b[36m0.6575\u001b[0m       0.6641        \u001b[35m0.6563\u001b[0m  0.0182\n",
      "     35        \u001b[36m0.6554\u001b[0m       0.6641        \u001b[35m0.6542\u001b[0m  0.0195\n",
      "     36        \u001b[36m0.6532\u001b[0m       0.6641        \u001b[35m0.6521\u001b[0m  0.0171\n",
      "     37        \u001b[36m0.6509\u001b[0m       0.6641        \u001b[35m0.6500\u001b[0m  0.0164\n",
      "     38        \u001b[36m0.6487\u001b[0m       0.6641        \u001b[35m0.6478\u001b[0m  0.0218\n",
      "     39        \u001b[36m0.6464\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6455\u001b[0m  0.0235\n",
      "     40        \u001b[36m0.6441\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6432\u001b[0m  0.0194\n",
      "     41        \u001b[36m0.6418\u001b[0m       0.6953        \u001b[35m0.6409\u001b[0m  0.0220\n",
      "     42        \u001b[36m0.6395\u001b[0m       0.6953        \u001b[35m0.6384\u001b[0m  0.0168\n",
      "     43        \u001b[36m0.6371\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6360\u001b[0m  0.0176\n",
      "     44        \u001b[36m0.6346\u001b[0m       0.7031        \u001b[35m0.6335\u001b[0m  0.0186\n",
      "     45        \u001b[36m0.6321\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6310\u001b[0m  0.0172\n",
      "     46        \u001b[36m0.6295\u001b[0m       0.7109        \u001b[35m0.6285\u001b[0m  0.0140\n",
      "     47        \u001b[36m0.6270\u001b[0m       0.7109        \u001b[35m0.6260\u001b[0m  0.0162\n",
      "     48        \u001b[36m0.6244\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6235\u001b[0m  0.0192\n",
      "     49        \u001b[36m0.6218\u001b[0m       0.7188        \u001b[35m0.6210\u001b[0m  0.0245\n",
      "     50        \u001b[36m0.6192\u001b[0m       0.7188        \u001b[35m0.6185\u001b[0m  0.0242\n",
      "     51        \u001b[36m0.6167\u001b[0m       0.7188        \u001b[35m0.6161\u001b[0m  0.0155\n",
      "     52        \u001b[36m0.6141\u001b[0m       0.7188        \u001b[35m0.6138\u001b[0m  0.0198\n",
      "     53        \u001b[36m0.6115\u001b[0m       0.7188        \u001b[35m0.6114\u001b[0m  0.0391\n",
      "     54        \u001b[36m0.6090\u001b[0m       0.7188        \u001b[35m0.6090\u001b[0m  0.0177\n",
      "     55        \u001b[36m0.6064\u001b[0m       0.7188        \u001b[35m0.6067\u001b[0m  0.0201\n",
      "     56        \u001b[36m0.6039\u001b[0m       0.7188        \u001b[35m0.6045\u001b[0m  0.0165\n",
      "     57        \u001b[36m0.6014\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6022\u001b[0m  0.0144\n",
      "     58        \u001b[36m0.5990\u001b[0m       0.7266        \u001b[35m0.6001\u001b[0m  0.0160\n",
      "     59        \u001b[36m0.5965\u001b[0m       0.7266        \u001b[35m0.5979\u001b[0m  0.0214\n",
      "     60        \u001b[36m0.5942\u001b[0m       0.7266        \u001b[35m0.5959\u001b[0m  0.0193\n",
      "     61        \u001b[36m0.5919\u001b[0m       0.7266        \u001b[35m0.5939\u001b[0m  0.0150\n",
      "     62        \u001b[36m0.5897\u001b[0m       0.7266        \u001b[35m0.5919\u001b[0m  0.0200\n",
      "     63        \u001b[36m0.5875\u001b[0m       0.7266        \u001b[35m0.5900\u001b[0m  0.0185\n",
      "     64        \u001b[36m0.5853\u001b[0m       0.7266        \u001b[35m0.5881\u001b[0m  0.0164\n",
      "     65        \u001b[36m0.5832\u001b[0m       0.7266        \u001b[35m0.5862\u001b[0m  0.0152\n",
      "     66        \u001b[36m0.5810\u001b[0m       0.7266        \u001b[35m0.5844\u001b[0m  0.0193\n",
      "     67        \u001b[36m0.5788\u001b[0m       0.7266        \u001b[35m0.5825\u001b[0m  0.0194\n",
      "     68        \u001b[36m0.5767\u001b[0m       0.7266        \u001b[35m0.5807\u001b[0m  0.0151\n",
      "     69        \u001b[36m0.5747\u001b[0m       0.7266        \u001b[35m0.5789\u001b[0m  0.0160\n",
      "     70        \u001b[36m0.5728\u001b[0m       0.7266        \u001b[35m0.5772\u001b[0m  0.0183\n",
      "     71        \u001b[36m0.5708\u001b[0m       0.7266        \u001b[35m0.5755\u001b[0m  0.0166\n",
      "     72        \u001b[36m0.5690\u001b[0m       0.7266        \u001b[35m0.5738\u001b[0m  0.0207\n",
      "     73        \u001b[36m0.5671\u001b[0m       0.7266        \u001b[35m0.5722\u001b[0m  0.0198\n",
      "     74        \u001b[36m0.5653\u001b[0m       0.7266        \u001b[35m0.5707\u001b[0m  0.0192\n",
      "     75        \u001b[36m0.5635\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5692\u001b[0m  0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     76        \u001b[36m0.5618\u001b[0m       0.7344        \u001b[35m0.5677\u001b[0m  0.0206\n",
      "     77        \u001b[36m0.5601\u001b[0m       0.7266        \u001b[35m0.5663\u001b[0m  0.0248\n",
      "     78        \u001b[36m0.5585\u001b[0m       0.7266        \u001b[35m0.5649\u001b[0m  0.0224\n",
      "     79        \u001b[36m0.5569\u001b[0m       0.7344        \u001b[35m0.5636\u001b[0m  0.0168\n",
      "     80        \u001b[36m0.5554\u001b[0m       0.7344        \u001b[35m0.5622\u001b[0m  0.0229\n",
      "     81        \u001b[36m0.5538\u001b[0m       0.7344        \u001b[35m0.5610\u001b[0m  0.0147\n",
      "     82        \u001b[36m0.5524\u001b[0m       0.7344        \u001b[35m0.5597\u001b[0m  0.0154\n",
      "     83        \u001b[36m0.5509\u001b[0m       0.7344        \u001b[35m0.5585\u001b[0m  0.0204\n",
      "     84        \u001b[36m0.5495\u001b[0m       0.7344        \u001b[35m0.5573\u001b[0m  0.0159\n",
      "     85        \u001b[36m0.5481\u001b[0m       0.7344        \u001b[35m0.5562\u001b[0m  0.0210\n",
      "     86        \u001b[36m0.5467\u001b[0m       0.7344        \u001b[35m0.5552\u001b[0m  0.0146\n",
      "     87        \u001b[36m0.5454\u001b[0m       0.7344        \u001b[35m0.5542\u001b[0m  0.0136\n",
      "     88        \u001b[36m0.5442\u001b[0m       0.7344        \u001b[35m0.5532\u001b[0m  0.0178\n",
      "     89        \u001b[36m0.5429\u001b[0m       0.7344        \u001b[35m0.5522\u001b[0m  0.0134\n",
      "     90        \u001b[36m0.5417\u001b[0m       0.7344        \u001b[35m0.5513\u001b[0m  0.0188\n",
      "     91        \u001b[36m0.5404\u001b[0m       0.7344        \u001b[35m0.5504\u001b[0m  0.0146\n",
      "     92        \u001b[36m0.5392\u001b[0m       0.7344        \u001b[35m0.5495\u001b[0m  0.0191\n",
      "     93        \u001b[36m0.5380\u001b[0m       0.7344        \u001b[35m0.5486\u001b[0m  0.0147\n",
      "     94        \u001b[36m0.5368\u001b[0m       0.7344        \u001b[35m0.5477\u001b[0m  0.0159\n",
      "     95        \u001b[36m0.5356\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5468\u001b[0m  0.0207\n",
      "     96        \u001b[36m0.5345\u001b[0m       0.7422        \u001b[35m0.5460\u001b[0m  0.0167\n",
      "     97        \u001b[36m0.5334\u001b[0m       0.7422        \u001b[35m0.5452\u001b[0m  0.0168\n",
      "     98        \u001b[36m0.5323\u001b[0m       0.7422        \u001b[35m0.5445\u001b[0m  0.0185\n",
      "     99        \u001b[36m0.5313\u001b[0m       0.7422        \u001b[35m0.5437\u001b[0m  0.0167\n",
      "    100        \u001b[36m0.5303\u001b[0m       0.7422        \u001b[35m0.5430\u001b[0m  0.0145\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7057\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7045\u001b[0m  0.0171\n",
      "      2        \u001b[36m0.7023\u001b[0m       0.5000        \u001b[35m0.7020\u001b[0m  0.0155\n",
      "      3        \u001b[36m0.7000\u001b[0m       0.5000        \u001b[35m0.6998\u001b[0m  0.0158\n",
      "      4        \u001b[36m0.6978\u001b[0m       0.5000        \u001b[35m0.6977\u001b[0m  0.0240\n",
      "      5        \u001b[36m0.6958\u001b[0m       0.5000        \u001b[35m0.6957\u001b[0m  0.0229\n",
      "      6        \u001b[36m0.6939\u001b[0m       0.5000        \u001b[35m0.6938\u001b[0m  0.0157\n",
      "      7        \u001b[36m0.6920\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6919\u001b[0m  0.0191\n",
      "      8        \u001b[36m0.6902\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6900\u001b[0m  0.0155\n",
      "      9        \u001b[36m0.6883\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6882\u001b[0m  0.0204\n",
      "     10        \u001b[36m0.6865\u001b[0m       0.5547        \u001b[35m0.6863\u001b[0m  0.0201\n",
      "     11        \u001b[36m0.6846\u001b[0m       0.5781        \u001b[35m0.6844\u001b[0m  0.0225\n",
      "     12        \u001b[36m0.6827\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6825\u001b[0m  0.0173\n",
      "     13        \u001b[36m0.6807\u001b[0m       0.6094        \u001b[35m0.6805\u001b[0m  0.0184\n",
      "     14        \u001b[36m0.6787\u001b[0m       0.6094        \u001b[35m0.6785\u001b[0m  0.0206\n",
      "     15        \u001b[36m0.6765\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6763\u001b[0m  0.0155\n",
      "     16        \u001b[36m0.6743\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6742\u001b[0m  0.0168\n",
      "     17        \u001b[36m0.6720\u001b[0m       0.6328        \u001b[35m0.6719\u001b[0m  0.0244\n",
      "     18        \u001b[36m0.6695\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6696\u001b[0m  0.0199\n",
      "     19        \u001b[36m0.6670\u001b[0m       0.6406        \u001b[35m0.6671\u001b[0m  0.0232\n",
      "     20        \u001b[36m0.6643\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6646\u001b[0m  0.0185\n",
      "     21        \u001b[36m0.6615\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6619\u001b[0m  0.0205\n",
      "     22        \u001b[36m0.6586\u001b[0m       0.6641        \u001b[35m0.6592\u001b[0m  0.0197\n",
      "     23        \u001b[36m0.6555\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6562\u001b[0m  0.0221\n",
      "     24        \u001b[36m0.6524\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6532\u001b[0m  0.0154\n",
      "     25        \u001b[36m0.6490\u001b[0m       0.6797        \u001b[35m0.6500\u001b[0m  0.0218\n",
      "     26        \u001b[36m0.6456\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6468\u001b[0m  0.0161\n",
      "     27        \u001b[36m0.6422\u001b[0m       0.6875        \u001b[35m0.6434\u001b[0m  0.0226\n",
      "     28        \u001b[36m0.6386\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6400\u001b[0m  0.0157\n",
      "     29        \u001b[36m0.6349\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6364\u001b[0m  0.0221\n",
      "     30        \u001b[36m0.6310\u001b[0m       0.7188        \u001b[35m0.6328\u001b[0m  0.0181\n",
      "     31        \u001b[36m0.6271\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6291\u001b[0m  0.0229\n",
      "     32        \u001b[36m0.6230\u001b[0m       0.7266        \u001b[35m0.6253\u001b[0m  0.0187\n",
      "     33        \u001b[36m0.6189\u001b[0m       0.7266        \u001b[35m0.6216\u001b[0m  0.0260\n",
      "     34        \u001b[36m0.6146\u001b[0m       0.7266        \u001b[35m0.6178\u001b[0m  0.0238\n",
      "     35        \u001b[36m0.6103\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6140\u001b[0m  0.0187\n",
      "     36        \u001b[36m0.6059\u001b[0m       0.7344        \u001b[35m0.6101\u001b[0m  0.0210\n",
      "     37        \u001b[36m0.6014\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6062\u001b[0m  0.0147\n",
      "     38        \u001b[36m0.5968\u001b[0m       0.7344        \u001b[35m0.6023\u001b[0m  0.0233\n",
      "     39        \u001b[36m0.5922\u001b[0m       0.7422        \u001b[35m0.5985\u001b[0m  0.0211\n",
      "     40        \u001b[36m0.5877\u001b[0m       0.7344        \u001b[35m0.5947\u001b[0m  0.0165\n",
      "     41        \u001b[36m0.5831\u001b[0m       0.7344        \u001b[35m0.5909\u001b[0m  0.0197\n",
      "     42        \u001b[36m0.5785\u001b[0m       0.7344        \u001b[35m0.5871\u001b[0m  0.0172\n",
      "     43        \u001b[36m0.5740\u001b[0m       0.7344        \u001b[35m0.5835\u001b[0m  0.0199\n",
      "     44        \u001b[36m0.5695\u001b[0m       0.7344        \u001b[35m0.5799\u001b[0m  0.0155\n",
      "     45        \u001b[36m0.5650\u001b[0m       0.7344        \u001b[35m0.5765\u001b[0m  0.0136\n",
      "     46        \u001b[36m0.5606\u001b[0m       0.7344        \u001b[35m0.5731\u001b[0m  0.0235\n",
      "     47        \u001b[36m0.5562\u001b[0m       0.7188        \u001b[35m0.5698\u001b[0m  0.0147\n",
      "     48        \u001b[36m0.5520\u001b[0m       0.7188        \u001b[35m0.5667\u001b[0m  0.0206\n",
      "     49        \u001b[36m0.5478\u001b[0m       0.7188        \u001b[35m0.5637\u001b[0m  0.0213\n",
      "     50        \u001b[36m0.5436\u001b[0m       0.7188        \u001b[35m0.5608\u001b[0m  0.0146\n",
      "     51        \u001b[36m0.5396\u001b[0m       0.7188        \u001b[35m0.5580\u001b[0m  0.0236\n",
      "     52        \u001b[36m0.5357\u001b[0m       0.7188        \u001b[35m0.5554\u001b[0m  0.0154\n",
      "     53        \u001b[36m0.5319\u001b[0m       0.7188        \u001b[35m0.5529\u001b[0m  0.0172\n",
      "     54        \u001b[36m0.5283\u001b[0m       0.7188        \u001b[35m0.5506\u001b[0m  0.0137\n",
      "     55        \u001b[36m0.5249\u001b[0m       0.7188        \u001b[35m0.5484\u001b[0m  0.0205\n",
      "     56        \u001b[36m0.5216\u001b[0m       0.7266        \u001b[35m0.5463\u001b[0m  0.0165\n",
      "     57        \u001b[36m0.5183\u001b[0m       0.7188        \u001b[35m0.5444\u001b[0m  0.0160\n",
      "     58        \u001b[36m0.5153\u001b[0m       0.7188        \u001b[35m0.5426\u001b[0m  0.0218\n",
      "     59        \u001b[36m0.5123\u001b[0m       0.7188        \u001b[35m0.5409\u001b[0m  0.0156\n",
      "     60        \u001b[36m0.5095\u001b[0m       0.7109        \u001b[35m0.5393\u001b[0m  0.0138\n",
      "     61        \u001b[36m0.5069\u001b[0m       0.7109        \u001b[35m0.5379\u001b[0m  0.0136\n",
      "     62        \u001b[36m0.5044\u001b[0m       0.7031        \u001b[35m0.5365\u001b[0m  0.0150\n",
      "     63        \u001b[36m0.5020\u001b[0m       0.7031        \u001b[35m0.5353\u001b[0m  0.0152\n",
      "     64        \u001b[36m0.4997\u001b[0m       0.7109        \u001b[35m0.5342\u001b[0m  0.0234\n",
      "     65        \u001b[36m0.4975\u001b[0m       0.7031        \u001b[35m0.5331\u001b[0m  0.0208\n",
      "     66        \u001b[36m0.4954\u001b[0m       0.7031        \u001b[35m0.5321\u001b[0m  0.0157\n",
      "     67        \u001b[36m0.4934\u001b[0m       0.7031        \u001b[35m0.5312\u001b[0m  0.0167\n",
      "     68        \u001b[36m0.4915\u001b[0m       0.7031        \u001b[35m0.5304\u001b[0m  0.0220\n",
      "     69        \u001b[36m0.4896\u001b[0m       0.7031        \u001b[35m0.5295\u001b[0m  0.0220\n",
      "     70        \u001b[36m0.4878\u001b[0m       0.7031        \u001b[35m0.5287\u001b[0m  0.0253\n",
      "     71        \u001b[36m0.4861\u001b[0m       0.7031        \u001b[35m0.5280\u001b[0m  0.0142\n",
      "     72        \u001b[36m0.4844\u001b[0m       0.7031        \u001b[35m0.5274\u001b[0m  0.0151\n",
      "     73        \u001b[36m0.4829\u001b[0m       0.7109        \u001b[35m0.5269\u001b[0m  0.0200\n",
      "     74        \u001b[36m0.4814\u001b[0m       0.7109        \u001b[35m0.5264\u001b[0m  0.0172\n",
      "     75        \u001b[36m0.4801\u001b[0m       0.7109        \u001b[35m0.5260\u001b[0m  0.0197\n",
      "     76        \u001b[36m0.4788\u001b[0m       0.7109        \u001b[35m0.5257\u001b[0m  0.0144\n",
      "     77        \u001b[36m0.4775\u001b[0m       0.7109        \u001b[35m0.5254\u001b[0m  0.0149\n",
      "     78        \u001b[36m0.4763\u001b[0m       0.7109        \u001b[35m0.5251\u001b[0m  0.0138\n",
      "     79        \u001b[36m0.4751\u001b[0m       0.7109        \u001b[35m0.5248\u001b[0m  0.0204\n",
      "     80        \u001b[36m0.4740\u001b[0m       0.7109        \u001b[35m0.5246\u001b[0m  0.0185\n",
      "     81        \u001b[36m0.4730\u001b[0m       0.7109        \u001b[35m0.5244\u001b[0m  0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     82        \u001b[36m0.4720\u001b[0m       0.7109        \u001b[35m0.5242\u001b[0m  0.0155\n",
      "     83        \u001b[36m0.4710\u001b[0m       0.7109        \u001b[35m0.5240\u001b[0m  0.0145\n",
      "     84        \u001b[36m0.4701\u001b[0m       0.7109        \u001b[35m0.5238\u001b[0m  0.0152\n",
      "     85        \u001b[36m0.4691\u001b[0m       0.7109        \u001b[35m0.5237\u001b[0m  0.0196\n",
      "     86        \u001b[36m0.4682\u001b[0m       0.7109        \u001b[35m0.5235\u001b[0m  0.0192\n",
      "     87        \u001b[36m0.4673\u001b[0m       0.7109        \u001b[35m0.5234\u001b[0m  0.0153\n",
      "     88        \u001b[36m0.4665\u001b[0m       0.7109        \u001b[35m0.5233\u001b[0m  0.0138\n",
      "     89        \u001b[36m0.4657\u001b[0m       0.7109        \u001b[35m0.5232\u001b[0m  0.0196\n",
      "     90        \u001b[36m0.4650\u001b[0m       0.7109        \u001b[35m0.5231\u001b[0m  0.0222\n",
      "     91        \u001b[36m0.4642\u001b[0m       0.7109        \u001b[35m0.5231\u001b[0m  0.0182\n",
      "     92        \u001b[36m0.4635\u001b[0m       0.7109        0.5231  0.0222\n",
      "     93        \u001b[36m0.4628\u001b[0m       0.7109        0.5231  0.0158\n",
      "     94        \u001b[36m0.4622\u001b[0m       0.7109        0.5232  0.0139\n",
      "     95        \u001b[36m0.4616\u001b[0m       0.7188        0.5232  0.0217\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8803\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6412\u001b[0m  0.0141\n",
      "      2        \u001b[36m0.6327\u001b[0m       0.5000        0.6720  0.0186\n",
      "      3        0.7680       \u001b[32m0.7656\u001b[0m        \u001b[35m0.4859\u001b[0m  0.0256\n",
      "      4        \u001b[36m0.5403\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4455\u001b[0m  0.0221\n",
      "      5        0.5883       0.7656        \u001b[35m0.4262\u001b[0m  0.0159\n",
      "      6        0.5712       0.7734        \u001b[35m0.4124\u001b[0m  0.0333\n",
      "      7        \u001b[36m0.5123\u001b[0m       0.7812        \u001b[35m0.4049\u001b[0m  0.0190\n",
      "      8        0.5489       0.7656        \u001b[35m0.4027\u001b[0m  0.0174\n",
      "      9        0.5298       0.7656        0.4053  0.0234\n",
      "     10        0.5225       0.7734        \u001b[35m0.4000\u001b[0m  0.0147\n",
      "     11        0.5286       0.7734        \u001b[35m0.3944\u001b[0m  0.0240\n",
      "     12        0.5206       \u001b[32m0.7969\u001b[0m        \u001b[35m0.3933\u001b[0m  0.0166\n",
      "     13        0.5202       0.7969        \u001b[35m0.3911\u001b[0m  0.0228\n",
      "     14        0.5177       \u001b[32m0.8047\u001b[0m        \u001b[35m0.3897\u001b[0m  0.0204\n",
      "     15        0.5147       0.8047        \u001b[35m0.3892\u001b[0m  0.0144\n",
      "     16        0.5150       0.8047        \u001b[35m0.3858\u001b[0m  0.0223\n",
      "     17        \u001b[36m0.5094\u001b[0m       0.7969        \u001b[35m0.3857\u001b[0m  0.0206\n",
      "     18        \u001b[36m0.5078\u001b[0m       0.7891        0.3860  0.0299\n",
      "     19        0.5082       0.8047        \u001b[35m0.3848\u001b[0m  0.0224\n",
      "     20        \u001b[36m0.5017\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.3795\u001b[0m  0.0216\n",
      "     21        \u001b[36m0.4981\u001b[0m       0.8047        \u001b[35m0.3712\u001b[0m  0.0505\n",
      "     22        \u001b[36m0.4934\u001b[0m       \u001b[32m0.8438\u001b[0m        \u001b[35m0.3650\u001b[0m  0.0309\n",
      "     23        \u001b[36m0.4903\u001b[0m       \u001b[32m0.8516\u001b[0m        \u001b[35m0.3579\u001b[0m  0.0256\n",
      "     24        \u001b[36m0.4837\u001b[0m       \u001b[32m0.8594\u001b[0m        \u001b[35m0.3547\u001b[0m  0.0274\n",
      "     25        \u001b[36m0.4809\u001b[0m       0.8594        0.3558  0.0192\n",
      "     26        0.4823       0.8594        \u001b[35m0.3545\u001b[0m  0.0218\n",
      "     27        \u001b[36m0.4786\u001b[0m       0.8594        \u001b[35m0.3529\u001b[0m  0.0229\n",
      "     28        \u001b[36m0.4763\u001b[0m       0.8594        \u001b[35m0.3506\u001b[0m  0.0254\n",
      "     29        \u001b[36m0.4755\u001b[0m       0.8594        \u001b[35m0.3491\u001b[0m  0.0249\n",
      "     30        \u001b[36m0.4744\u001b[0m       0.8594        \u001b[35m0.3483\u001b[0m  0.0185\n",
      "     31        \u001b[36m0.4708\u001b[0m       0.8516        0.3500  0.0164\n",
      "     32        \u001b[36m0.4680\u001b[0m       0.8594        0.3491  0.0158\n",
      "     33        \u001b[36m0.4670\u001b[0m       0.8594        0.3483  0.0229\n",
      "     34        \u001b[36m0.4635\u001b[0m       0.8594        0.3505  0.0154\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8262\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6560\u001b[0m  0.0123\n",
      "      2        \u001b[36m0.7078\u001b[0m       0.5000        0.6865  0.0184\n",
      "      3        0.7771       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5583\u001b[0m  0.0265\n",
      "      4        \u001b[36m0.5665\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5512\u001b[0m  0.0159\n",
      "      5        0.6095       0.7266        \u001b[35m0.5158\u001b[0m  0.0216\n",
      "      6        0.5676       \u001b[32m0.7422\u001b[0m        0.5164  0.0156\n",
      "      7        \u001b[36m0.5192\u001b[0m       0.7266        0.5202  0.0228\n",
      "      8        0.5423       0.7031        0.5353  0.0158\n",
      "      9        \u001b[36m0.5186\u001b[0m       0.7109        0.5308  0.0218\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8069\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6763\u001b[0m  0.0233\n",
      "      2        \u001b[36m0.6251\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6184\u001b[0m  0.0161\n",
      "      3        0.6438       0.7031        \u001b[35m0.5722\u001b[0m  0.0220\n",
      "      4        \u001b[36m0.5447\u001b[0m       0.7266        \u001b[35m0.5464\u001b[0m  0.0164\n",
      "      5        \u001b[36m0.5365\u001b[0m       0.7188        \u001b[35m0.5305\u001b[0m  0.0231\n",
      "      6        \u001b[36m0.5195\u001b[0m       0.7344        0.5312  0.0141\n",
      "      7        \u001b[36m0.5014\u001b[0m       0.7266        0.5328  0.0167\n",
      "      8        \u001b[36m0.4973\u001b[0m       0.7266        0.5309  0.0194\n",
      "      9        \u001b[36m0.4831\u001b[0m       \u001b[32m0.7422\u001b[0m        0.5327  0.0144\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8054\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6908\u001b[0m  0.0237\n",
      "      2        \u001b[36m0.6453\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6605\u001b[0m  0.0168\n",
      "      3        0.6593       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5523\u001b[0m  0.0257\n",
      "      4        \u001b[36m0.4816\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5519\u001b[0m  0.0163\n",
      "      5        0.5130       0.6875        \u001b[35m0.5483\u001b[0m  0.0232\n",
      "      6        \u001b[36m0.4675\u001b[0m       0.7109        \u001b[35m0.5457\u001b[0m  0.0148\n",
      "      7        \u001b[36m0.4663\u001b[0m       0.7344        \u001b[35m0.5436\u001b[0m  0.0199\n",
      "      8        \u001b[36m0.4463\u001b[0m       \u001b[32m0.7500\u001b[0m        0.5453  0.0154\n",
      "      9        \u001b[36m0.4422\u001b[0m       0.7500        0.5495  0.0261\n",
      "     10        \u001b[36m0.4348\u001b[0m       0.7344        0.5512  0.0157\n",
      "     11        \u001b[36m0.4317\u001b[0m       0.7344        0.5556  0.0206\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8474\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6739\u001b[0m  0.0182\n",
      "      2        \u001b[36m0.6246\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6497\u001b[0m  0.0232\n",
      "      3        0.6682       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5634\u001b[0m  0.0153\n",
      "      4        \u001b[36m0.4822\u001b[0m       \u001b[32m0.7422\u001b[0m        0.5745  0.0202\n",
      "      5        0.5308       0.6953        \u001b[35m0.5505\u001b[0m  0.0156\n",
      "      6        \u001b[36m0.4536\u001b[0m       0.6953        0.5531  0.0174\n",
      "      7        \u001b[36m0.4521\u001b[0m       0.7109        0.5728  0.0283\n",
      "      8        \u001b[36m0.4460\u001b[0m       0.7188        0.5681  0.0164\n",
      "      9        \u001b[36m0.4334\u001b[0m       0.7109        0.5696  0.0159\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7646\u001b[0m       \u001b[32m0.5188\u001b[0m        \u001b[35m0.6913\u001b[0m  0.0405\n",
      "      2        \u001b[36m0.7044\u001b[0m       \u001b[32m0.6312\u001b[0m        \u001b[35m0.6796\u001b[0m  0.0296\n",
      "      3        \u001b[36m0.6818\u001b[0m       \u001b[32m0.6813\u001b[0m        \u001b[35m0.6612\u001b[0m  0.0388\n",
      "      4        \u001b[36m0.6642\u001b[0m       \u001b[32m0.7250\u001b[0m        \u001b[35m0.6326\u001b[0m  0.0343\n",
      "      5        \u001b[36m0.6421\u001b[0m       0.7188        \u001b[35m0.5959\u001b[0m  0.0338\n",
      "      6        \u001b[36m0.6069\u001b[0m       \u001b[32m0.7312\u001b[0m        \u001b[35m0.5648\u001b[0m  0.0370\n",
      "      7        \u001b[36m0.5948\u001b[0m       0.7250        \u001b[35m0.5420\u001b[0m  0.0292\n",
      "      8        \u001b[36m0.5896\u001b[0m       \u001b[32m0.7375\u001b[0m        \u001b[35m0.5288\u001b[0m  0.0365\n",
      "      9        \u001b[36m0.5670\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5173\u001b[0m  0.0353\n",
      "     10        \u001b[36m0.5658\u001b[0m       \u001b[32m0.7562\u001b[0m        \u001b[35m0.5084\u001b[0m  0.0333\n",
      "     11        0.5703       \u001b[32m0.7750\u001b[0m        \u001b[35m0.5042\u001b[0m  0.0335\n",
      "     12        \u001b[36m0.5591\u001b[0m       0.7750        \u001b[35m0.4994\u001b[0m  0.0347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13        \u001b[36m0.5543\u001b[0m       \u001b[32m0.7875\u001b[0m        \u001b[35m0.4960\u001b[0m  0.0320\n",
      "     14        \u001b[36m0.5542\u001b[0m       0.7812        \u001b[35m0.4903\u001b[0m  0.0320\n",
      "     15        \u001b[36m0.5388\u001b[0m       0.7875        \u001b[35m0.4869\u001b[0m  0.0373\n",
      "     16        0.5423       0.7875        \u001b[35m0.4848\u001b[0m  0.0319\n",
      "     17        \u001b[36m0.5057\u001b[0m       \u001b[32m0.7937\u001b[0m        \u001b[35m0.4816\u001b[0m  0.0312\n",
      "     18        0.5189       0.7937        0.4823  0.0314\n",
      "     19        0.5388       0.7812        0.4838  0.0325\n",
      "     20        0.5284       0.7688        0.4854  0.0345\n",
      "     21        0.5116       0.7688        0.4839  0.0314\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best parameters found:\n",
      "\n",
      "{'optimizer__momentum': 0.9, 'module__num_unitsB': 3, 'module__num_unitsA': 12, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 32}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.647 (+/-0.168) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 9, 'module__num_unitsA': 3, 'module__dropout': 0.5, 'lr': 0.1, 'batch_size': 32}\n",
      "0.708 (+/-0.060) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 9, 'module__num_unitsA': 3, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 16}\n",
      "0.533 (+/-0.078) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 3, 'module__num_unitsA': 6, 'module__dropout': 0.0, 'lr': 1, 'batch_size': 16}\n",
      "0.593 (+/-0.042) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 9, 'module__num_unitsA': 9, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 64}\n",
      "0.500 (+/-0.000) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 3, 'module__num_unitsA': 3, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 32}\n",
      "0.571 (+/-0.078) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 3, 'module__num_unitsA': 12, 'module__dropout': 0.0, 'lr': 1, 'batch_size': 64}\n",
      "0.639 (+/-0.014) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 12, 'module__num_unitsA': 12, 'module__dropout': 0.5, 'lr': 0.1, 'batch_size': 16}\n",
      "0.759 (+/-0.071) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 3, 'module__num_unitsA': 12, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 32}\n",
      "0.706 (+/-0.045) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 12, 'module__num_unitsA': 3, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 64}\n",
      "0.743 (+/-0.032) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 12, 'module__num_unitsA': 9, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 64}\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7880\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6652\u001b[0m  0.0357\n",
      "      2        \u001b[36m0.7033\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6251\u001b[0m  0.0404\n",
      "      3        0.7050       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5672\u001b[0m  0.0375\n",
      "      4        \u001b[36m0.6721\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.5353\u001b[0m  0.0454\n",
      "      5        \u001b[36m0.6587\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.5131\u001b[0m  0.0370\n",
      "      6        \u001b[36m0.6562\u001b[0m       0.8047        \u001b[35m0.5017\u001b[0m  0.0423\n",
      "      7        \u001b[36m0.6515\u001b[0m       0.8047        \u001b[35m0.4920\u001b[0m  0.0366\n",
      "      8        \u001b[36m0.6366\u001b[0m       0.7891        0.4927  0.0398\n",
      "      9        0.6454       0.7891        \u001b[35m0.4855\u001b[0m  0.0436\n",
      "     10        \u001b[36m0.6266\u001b[0m       0.7891        \u001b[35m0.4727\u001b[0m  0.0375\n",
      "     11        \u001b[36m0.6155\u001b[0m       0.7812        \u001b[35m0.4654\u001b[0m  0.0412\n",
      "     12        0.6209       0.7969        0.4699  0.0381\n",
      "     13        \u001b[36m0.6080\u001b[0m       0.7812        \u001b[35m0.4591\u001b[0m  0.0381\n",
      "     14        \u001b[36m0.5791\u001b[0m       0.7891        \u001b[35m0.4511\u001b[0m  0.0427\n",
      "     15        0.5804       0.7891        \u001b[35m0.4469\u001b[0m  0.0420\n",
      "     16        0.5860       0.7891        0.4527  0.0376\n",
      "     17        0.6091       0.7891        0.4529  0.0400\n",
      "     18        0.5906       0.8047        \u001b[35m0.4465\u001b[0m  0.0420\n",
      "     19        0.6012       0.8047        \u001b[35m0.4371\u001b[0m  0.0383\n",
      "     20        \u001b[36m0.5776\u001b[0m       0.8047        \u001b[35m0.4333\u001b[0m  0.0371\n",
      "     21        0.5839       0.8047        \u001b[35m0.4259\u001b[0m  0.0415\n",
      "     22        \u001b[36m0.5622\u001b[0m       0.8047        \u001b[35m0.4159\u001b[0m  0.0366\n",
      "     23        0.5670       0.8125        \u001b[35m0.4115\u001b[0m  0.0372\n",
      "     24        0.5678       0.8203        0.4158  0.0401\n",
      "     25        0.5681       0.8125        0.4116  0.0412\n",
      "     26        \u001b[36m0.5486\u001b[0m       0.8125        \u001b[35m0.4069\u001b[0m  0.0381\n",
      "     27        0.5662       0.8125        0.4076  0.0372\n",
      "     28        0.5488       0.8047        \u001b[35m0.4065\u001b[0m  0.0391\n",
      "     29        0.5632       0.8125        \u001b[35m0.3992\u001b[0m  0.0415\n",
      "     30        \u001b[36m0.5415\u001b[0m       0.8125        0.4025  0.0370\n",
      "     31        \u001b[36m0.5293\u001b[0m       0.8047        \u001b[35m0.3947\u001b[0m  0.0368\n",
      "     32        0.5481       0.8125        0.3981  0.0365\n",
      "     33        0.5624       0.8047        \u001b[35m0.3943\u001b[0m  0.0375\n",
      "     34        0.5407       0.8047        \u001b[35m0.3937\u001b[0m  0.0410\n",
      "     35        0.5465       0.8047        0.3942  0.0366\n",
      "     36        0.5476       0.8047        \u001b[35m0.3896\u001b[0m  0.0419\n",
      "     37        0.5324       0.7969        \u001b[35m0.3827\u001b[0m  0.0376\n",
      "     38        \u001b[36m0.5158\u001b[0m       0.7969        \u001b[35m0.3777\u001b[0m  0.0367\n",
      "     39        0.5517       0.7969        0.3825  0.0372\n",
      "     40        0.5460       0.7969        0.3852  0.0364\n",
      "     41        0.5383       0.7969        0.3811  0.0379\n",
      "     42        0.5254       0.7969        0.3807  0.0378\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8396\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6737\u001b[0m  0.0363\n",
      "      2        \u001b[36m0.7412\u001b[0m       0.5625        \u001b[35m0.6671\u001b[0m  0.0420\n",
      "      3        0.7507       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6385\u001b[0m  0.0376\n",
      "      4        \u001b[36m0.7272\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5989\u001b[0m  0.0421\n",
      "      5        \u001b[36m0.6853\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5604\u001b[0m  0.0369\n",
      "      6        \u001b[36m0.6654\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5396\u001b[0m  0.0416\n",
      "      7        \u001b[36m0.6357\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5298\u001b[0m  0.0372\n",
      "      8        \u001b[36m0.6279\u001b[0m       0.7422        \u001b[35m0.5258\u001b[0m  0.0389\n",
      "      9        \u001b[36m0.6235\u001b[0m       0.7422        \u001b[35m0.5211\u001b[0m  0.0421\n",
      "     10        \u001b[36m0.5905\u001b[0m       \u001b[32m0.7578\u001b[0m        0.5256  0.0419\n",
      "     11        0.6351       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5147\u001b[0m  0.0395\n",
      "     12        \u001b[36m0.5787\u001b[0m       0.7500        0.5241  0.0420\n",
      "     13        0.5903       0.7344        0.5208  0.0369\n",
      "     14        0.5846       0.7422        0.5152  0.0419\n",
      "     15        \u001b[36m0.5786\u001b[0m       0.7500        0.5153  0.0367\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7906\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6776\u001b[0m  0.0345\n",
      "      2        \u001b[36m0.6967\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6472\u001b[0m  0.0463\n",
      "      3        \u001b[36m0.6661\u001b[0m       0.7266        \u001b[35m0.5855\u001b[0m  0.0424\n",
      "      4        \u001b[36m0.6215\u001b[0m       0.7109        \u001b[35m0.5423\u001b[0m  0.0387\n",
      "      5        \u001b[36m0.6013\u001b[0m       0.6875        \u001b[35m0.5345\u001b[0m  0.0462\n",
      "      6        \u001b[36m0.5798\u001b[0m       0.7031        \u001b[35m0.5315\u001b[0m  0.0439\n",
      "      7        \u001b[36m0.5640\u001b[0m       0.6953        0.5324  0.0424\n",
      "      8        \u001b[36m0.5591\u001b[0m       0.7031        \u001b[35m0.5287\u001b[0m  0.0386\n",
      "      9        0.5678       0.7031        \u001b[35m0.5266\u001b[0m  0.0422\n",
      "     10        \u001b[36m0.5560\u001b[0m       0.7031        0.5274  0.0369\n",
      "     11        \u001b[36m0.5552\u001b[0m       0.7188        \u001b[35m0.5247\u001b[0m  0.0419\n",
      "     12        \u001b[36m0.5292\u001b[0m       0.7188        0.5290  0.0428\n",
      "     13        0.5329       0.6953        0.5302  0.0440\n",
      "     14        0.5363       0.7188        0.5278  0.0372\n",
      "     15        0.5398       0.7109        \u001b[35m0.5237\u001b[0m  0.0414\n",
      "     16        \u001b[36m0.5238\u001b[0m       0.7266        0.5246  0.0372\n",
      "     17        \u001b[36m0.5195\u001b[0m       0.7266        \u001b[35m0.5229\u001b[0m  0.0381\n",
      "     18        0.5273       0.7344        0.5238  0.0421\n",
      "     19        \u001b[36m0.5006\u001b[0m       0.7422        \u001b[35m0.5224\u001b[0m  0.0369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     20        0.5291       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5200\u001b[0m  0.0374\n",
      "     21        \u001b[36m0.4941\u001b[0m       0.7500        0.5214  0.0413\n",
      "     22        0.5383       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5181\u001b[0m  0.0427\n",
      "     23        0.4996       0.7656        \u001b[35m0.5171\u001b[0m  0.0364\n",
      "     24        0.5233       \u001b[32m0.7734\u001b[0m        0.5172  0.0371\n",
      "     25        0.5206       0.7734        0.5183  0.0403\n",
      "     26        0.5149       0.7656        0.5228  0.0365\n",
      "     27        0.5168       0.7734        0.5181  0.0369\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7282\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6497\u001b[0m  0.0356\n",
      "      2        \u001b[36m0.6553\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5849\u001b[0m  0.0417\n",
      "      3        \u001b[36m0.5972\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5503\u001b[0m  0.0374\n",
      "      4        \u001b[36m0.5932\u001b[0m       0.7422        \u001b[35m0.5447\u001b[0m  0.0428\n",
      "      5        \u001b[36m0.5667\u001b[0m       0.7188        \u001b[35m0.5338\u001b[0m  0.0380\n",
      "      6        \u001b[36m0.5392\u001b[0m       0.7109        \u001b[35m0.5305\u001b[0m  0.0410\n",
      "      7        0.5449       0.7188        \u001b[35m0.5302\u001b[0m  0.0370\n",
      "      8        \u001b[36m0.5189\u001b[0m       0.7109        \u001b[35m0.5285\u001b[0m  0.0414\n",
      "      9        \u001b[36m0.4992\u001b[0m       0.7031        0.5342  0.0363\n",
      "     10        \u001b[36m0.4970\u001b[0m       0.6953        0.5340  0.0417\n",
      "     11        0.5023       0.7109        0.5362  0.0366\n",
      "     12        \u001b[36m0.4920\u001b[0m       0.7109        0.5354  0.0387\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7492\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6839\u001b[0m  0.0342\n",
      "      2        \u001b[36m0.7437\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6696\u001b[0m  0.0412\n",
      "      3        \u001b[36m0.7069\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6426\u001b[0m  0.0427\n",
      "      4        \u001b[36m0.6772\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6012\u001b[0m  0.0388\n",
      "      5        \u001b[36m0.6446\u001b[0m       0.7109        \u001b[35m0.5703\u001b[0m  0.0412\n",
      "      6        \u001b[36m0.6219\u001b[0m       0.6953        \u001b[35m0.5571\u001b[0m  0.0370\n",
      "      7        \u001b[36m0.5569\u001b[0m       0.7031        \u001b[35m0.5568\u001b[0m  0.0411\n",
      "      8        0.5588       0.6953        \u001b[35m0.5526\u001b[0m  0.0367\n",
      "      9        0.5603       0.6953        \u001b[35m0.5417\u001b[0m  0.0399\n",
      "     10        \u001b[36m0.5406\u001b[0m       0.7109        \u001b[35m0.5414\u001b[0m  0.0416\n",
      "     11        \u001b[36m0.5332\u001b[0m       0.7031        \u001b[35m0.5372\u001b[0m  0.0368\n",
      "     12        0.5400       0.7109        \u001b[35m0.5328\u001b[0m  0.0416\n",
      "     13        \u001b[36m0.5282\u001b[0m       0.7031        0.5329  0.0368\n",
      "     14        \u001b[36m0.5105\u001b[0m       0.7109        0.5328  0.0389\n",
      "     15        \u001b[36m0.5090\u001b[0m       0.7266        0.5350  0.0422\n",
      "     16        0.5168       0.6953        0.5336  0.0368\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5868\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7546\u001b[0m  0.0355\n",
      "      2        0.6141       0.5000        0.7874  0.0425\n",
      "      3        0.5962       0.5000        0.7614  0.0401\n",
      "      4        \u001b[36m0.5803\u001b[0m       0.5000        \u001b[35m0.7288\u001b[0m  0.0363\n",
      "      5        0.5821       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6803\u001b[0m  0.0407\n",
      "      6        \u001b[36m0.5521\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6790\u001b[0m  0.0363\n",
      "      7        0.5685       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6747\u001b[0m  0.0409\n",
      "      8        \u001b[36m0.5517\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6235\u001b[0m  0.0360\n",
      "      9        \u001b[36m0.5453\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6001\u001b[0m  0.0415\n",
      "     10        0.5510       \u001b[32m0.6641\u001b[0m        \u001b[35m0.5858\u001b[0m  0.0412\n",
      "     11        0.5595       0.6484        0.6065  0.0372\n",
      "     12        \u001b[36m0.5407\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5517\u001b[0m  0.0416\n",
      "     13        \u001b[36m0.5247\u001b[0m       0.6875        0.5702  0.0362\n",
      "     14        \u001b[36m0.5150\u001b[0m       0.7031        0.5573  0.0432\n",
      "     15        0.5540       0.6875        0.5865  0.0363\n",
      "     16        0.5540       0.6875        0.5575  0.0367\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6269\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8599\u001b[0m  0.0338\n",
      "      2        \u001b[36m0.6123\u001b[0m       0.5000        \u001b[35m0.8590\u001b[0m  0.0419\n",
      "      3        \u001b[36m0.5997\u001b[0m       0.5000        \u001b[35m0.8372\u001b[0m  0.0414\n",
      "      4        \u001b[36m0.5598\u001b[0m       0.5000        \u001b[35m0.8255\u001b[0m  0.0361\n",
      "      5        0.5676       \u001b[32m0.5391\u001b[0m        \u001b[35m0.8045\u001b[0m  0.0431\n",
      "      6        \u001b[36m0.5575\u001b[0m       0.5234        0.8132  0.0362\n",
      "      7        0.5579       \u001b[32m0.5938\u001b[0m        \u001b[35m0.7755\u001b[0m  0.0425\n",
      "      8        \u001b[36m0.5520\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.7541\u001b[0m  0.0362\n",
      "      9        \u001b[36m0.5472\u001b[0m       0.6797        \u001b[35m0.7421\u001b[0m  0.0406\n",
      "     10        \u001b[36m0.5204\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.7284\u001b[0m  0.0365\n",
      "     11        0.5413       0.6953        \u001b[35m0.7208\u001b[0m  0.0391\n",
      "     12        \u001b[36m0.5187\u001b[0m       \u001b[32m0.7266\u001b[0m        0.7216  0.0411\n",
      "     13        \u001b[36m0.5159\u001b[0m       0.7109        0.7243  0.0364\n",
      "     14        \u001b[36m0.5038\u001b[0m       0.7031        0.7446  0.0413\n",
      "     15        0.5260       0.7031        0.7463  0.0362\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6942\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7302\u001b[0m  0.0342\n",
      "      2        0.7023       0.5000        0.7320  0.0462\n",
      "      3        0.6954       0.5000        \u001b[35m0.7249\u001b[0m  0.0363\n",
      "      4        \u001b[36m0.6745\u001b[0m       0.5000        \u001b[35m0.7141\u001b[0m  0.0413\n",
      "      5        \u001b[36m0.6291\u001b[0m       0.5000        0.7235  0.0388\n",
      "      6        \u001b[36m0.6225\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6781\u001b[0m  0.0416\n",
      "      7        \u001b[36m0.6003\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6739\u001b[0m  0.0367\n",
      "      8        \u001b[36m0.5818\u001b[0m       0.6953        0.6879  0.0410\n",
      "      9        0.5885       0.6953        0.6819  0.0359\n",
      "     10        0.6101       \u001b[32m0.7109\u001b[0m        0.6750  0.0397\n",
      "     11        0.5978       0.7109        0.6791  0.0428\n",
      "     12        0.6020       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6728\u001b[0m  0.0439\n",
      "     13        0.5978       \u001b[32m0.7344\u001b[0m        0.6779  0.0364\n",
      "     14        \u001b[36m0.5786\u001b[0m       \u001b[32m0.7422\u001b[0m        0.6759  0.0431\n",
      "     15        \u001b[36m0.5625\u001b[0m       0.7344        0.6752  0.0359\n",
      "     16        \u001b[36m0.5405\u001b[0m       0.7266        0.6834  0.0412\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6636\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7188\u001b[0m  0.0457\n",
      "      2        0.6693       0.5000        0.7204  0.0395\n",
      "      3        \u001b[36m0.6285\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6831\u001b[0m  0.0463\n",
      "      4        \u001b[36m0.5938\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6494\u001b[0m  0.0386\n",
      "      5        \u001b[36m0.5551\u001b[0m       0.6484        \u001b[35m0.6398\u001b[0m  0.0422\n",
      "      6        \u001b[36m0.5289\u001b[0m       0.6484        \u001b[35m0.6334\u001b[0m  0.0360\n",
      "      7        0.5303       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6115\u001b[0m  0.0529\n",
      "      8        \u001b[36m0.5093\u001b[0m       0.6953        0.6268  0.0505\n",
      "      9        0.5294       \u001b[32m0.7109\u001b[0m        0.6127  0.0364\n",
      "     10        0.5135       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5952\u001b[0m  0.0394\n",
      "     11        0.5286       0.7578        \u001b[35m0.5910\u001b[0m  0.0468\n",
      "     12        0.5269       0.7578        0.6023  0.0441\n",
      "     13        \u001b[36m0.4920\u001b[0m       0.7500        0.6119  0.0385\n",
      "     14        0.5156       \u001b[32m0.7656\u001b[0m        0.6023  0.0365\n",
      "     15        0.5051       0.7656        \u001b[35m0.5836\u001b[0m  0.0410\n",
      "     16        \u001b[36m0.4865\u001b[0m       0.7500        \u001b[35m0.5821\u001b[0m  0.0369\n",
      "     17        0.5052       0.7422        0.5923  0.0389\n",
      "     18        0.5113       0.7344        0.6054  0.0447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19        0.4879       0.7344        0.6123  0.0362\n",
      "     20        0.4979       0.7578        0.5893  0.0364\n",
      "     21        0.5070       0.7500        \u001b[35m0.5805\u001b[0m  0.0406\n",
      "     22        \u001b[36m0.4834\u001b[0m       0.7266        0.5913  0.0363\n",
      "     23        0.5036       0.7500        0.5895  0.0376\n",
      "     24        0.4997       0.7188        0.5957  0.0434\n",
      "     25        0.5029       0.7109        0.5990  0.0356\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6558\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7829\u001b[0m  0.0383\n",
      "      2        0.6758       0.5000        \u001b[35m0.7682\u001b[0m  0.0490\n",
      "      3        \u001b[36m0.6314\u001b[0m       0.5000        \u001b[35m0.7379\u001b[0m  0.0366\n",
      "      4        \u001b[36m0.5723\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.7187\u001b[0m  0.0411\n",
      "      5        \u001b[36m0.5585\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6692\u001b[0m  0.0402\n",
      "      6        \u001b[36m0.5138\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6458\u001b[0m  0.0465\n",
      "      7        0.5322       \u001b[32m0.7031\u001b[0m        0.6539  0.0403\n",
      "      8        \u001b[36m0.5106\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6423\u001b[0m  0.0427\n",
      "      9        0.5106       \u001b[32m0.7188\u001b[0m        0.6429  0.0361\n",
      "     10        0.5143       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6246\u001b[0m  0.0414\n",
      "     11        0.5112       0.7344        \u001b[35m0.6181\u001b[0m  0.0378\n",
      "     12        \u001b[36m0.4855\u001b[0m       0.7344        0.6360  0.0435\n",
      "     13        0.5061       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6064\u001b[0m  0.0386\n",
      "     14        0.5055       0.7422        0.6191  0.0395\n",
      "     15        0.5016       0.7422        0.6144  0.0437\n",
      "     16        0.4950       0.7344        \u001b[35m0.6029\u001b[0m  0.0387\n",
      "     17        0.4901       0.7344        0.6114  0.0373\n",
      "     18        \u001b[36m0.4804\u001b[0m       0.7422        \u001b[35m0.5886\u001b[0m  0.0365\n",
      "     19        \u001b[36m0.4777\u001b[0m       0.7344        \u001b[35m0.5830\u001b[0m  0.0404\n",
      "     20        0.4896       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5742\u001b[0m  0.0366\n",
      "     21        0.4799       0.7500        0.5829  0.0554\n",
      "     22        0.4858       0.7422        0.5970  0.0370\n",
      "     23        \u001b[36m0.4699\u001b[0m       0.7422        0.5888  0.0448\n",
      "     24        0.4907       0.7422        0.5841  0.0522\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.3429\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.6735\u001b[0m  0.0368\n",
      "      2        0.5187       0.5000        \u001b[35m2.1271\u001b[0m  0.0442\n",
      "      3        0.5727       0.5000        \u001b[35m1.8621\u001b[0m  0.0383\n",
      "      4        0.5265       0.5000        \u001b[35m1.7843\u001b[0m  0.0415\n",
      "      5        0.5047       0.5000        1.8606  0.0372\n",
      "      6        0.5195       0.5000        1.8663  0.0460\n",
      "      7        0.5228       0.5000        \u001b[35m1.7224\u001b[0m  0.0491\n",
      "      8        0.5024       0.5000        1.9917  0.0376\n",
      "      9        0.5470       0.5000        1.8710  0.0372\n",
      "     10        0.5319       0.5000        1.8711  0.0451\n",
      "     11        0.5317       0.5000        1.8711  0.0409\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.3751\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.2956\u001b[0m  0.0407\n",
      "      2        0.4509       0.5000        \u001b[35m1.8273\u001b[0m  0.0460\n",
      "      3        0.4679       0.5000        2.2273  0.0389\n",
      "      4        0.5582       0.5000        1.8622  0.0412\n",
      "      5        0.4620       0.5000        1.8778  0.0378\n",
      "      6        0.4723       0.5000        \u001b[35m1.6541\u001b[0m  0.0420\n",
      "      7        0.4626       0.5000        1.8061  0.0389\n",
      "      8        0.4557       0.5000        1.9152  0.0413\n",
      "      9        0.4592       0.5000        1.8753  0.0371\n",
      "     10        0.4573       0.5000        1.7542  0.0391\n",
      "     11        0.4645       0.5000        \u001b[35m1.6534\u001b[0m  0.0427\n",
      "     12        0.5161       0.5000        1.8609  0.0368\n",
      "     13        0.4348       0.5000        1.7797  0.0417\n",
      "     14        0.5564       0.5000        1.8692  0.0363\n",
      "     15        0.4704       0.5000        1.8699  0.0386\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5859\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.8266\u001b[0m  0.0340\n",
      "      2        0.7120       0.5000        \u001b[35m1.8153\u001b[0m  0.0442\n",
      "      3        0.6624       0.5000        2.1205  0.0417\n",
      "      4        0.8419       0.5000        1.9154  0.0367\n",
      "      5        0.7274       0.5000        1.8277  0.0430\n",
      "      6        0.7141       0.5000        1.8280  0.0373\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5433\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.9888\u001b[0m  0.0337\n",
      "      2        0.6281       0.5000        \u001b[35m1.7707\u001b[0m  0.0497\n",
      "      3        0.7131       0.5000        \u001b[35m1.6955\u001b[0m  0.0423\n",
      "      4        0.6788       0.5000        \u001b[35m1.6383\u001b[0m  0.0411\n",
      "      5        0.6473       \u001b[32m0.5234\u001b[0m        \u001b[35m1.3052\u001b[0m  0.0365\n",
      "      6        0.5762       \u001b[32m0.6484\u001b[0m        \u001b[35m1.0809\u001b[0m  0.0417\n",
      "      7        0.5962       0.5859        1.2833  0.0388\n",
      "      8        0.6644       0.5000        1.5983  0.0437\n",
      "      9        0.6276       \u001b[32m0.6562\u001b[0m        1.0908  0.0386\n",
      "     10        0.6542       0.5469        1.4478  0.0364\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4748\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.8732\u001b[0m  0.0347\n",
      "      2        0.6034       0.5000        2.2611  0.0428\n",
      "      3        0.6442       0.5000        2.4580  0.0427\n",
      "      4        0.6236       0.5000        \u001b[35m1.7781\u001b[0m  0.0369\n",
      "      5        0.6276       0.5000        1.7861  0.0413\n",
      "      6        0.8021       0.5000        1.8221  0.0363\n",
      "      7        0.6267       0.5000        1.7880  0.0408\n",
      "      8        0.6209       0.5000        1.7880  0.0365\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6557\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.8846\u001b[0m  0.0118\n",
      "      2        1.5693       0.5000        \u001b[35m1.8397\u001b[0m  0.0129\n",
      "      3        1.5800       0.5000        \u001b[35m1.8068\u001b[0m  0.0155\n",
      "      4        1.5567       0.5000        1.8118  0.0171\n",
      "      5        1.5595       0.5000        1.8118  0.0226\n",
      "      6        1.5595       0.5000        1.8117  0.0179\n",
      "      7        1.5595       0.5000        1.8117  0.0211\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5241\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.9351\u001b[0m  0.0236\n",
      "      2        1.6482       0.5000        \u001b[35m1.7824\u001b[0m  0.0180\n",
      "      3        1.7221       0.5000        \u001b[35m1.7263\u001b[0m  0.0191\n",
      "      4        1.6812       0.5000        1.7371  0.0146\n",
      "      5        1.6876       0.5000        1.7359  0.0207\n",
      "      6        1.6870       0.5000        1.7359  0.0160\n",
      "      7        1.6870       0.5000        1.7359  0.0229\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7450\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.2148\u001b[0m  0.0233\n",
      "      2        0.9912       0.5000        1.2697  0.0274\n",
      "      3        1.0387       0.5000        1.2280  0.0167\n",
      "      4        1.0336       0.5000        1.2223  0.0261\n",
      "      5        1.0318       0.5000        1.2189  0.0156\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7223\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.1083\u001b[0m  0.0207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        0.9685       0.5000        1.1793  0.0155\n",
      "      3        0.9839       0.5000        1.1189  0.0227\n",
      "      4        0.9043       \u001b[32m0.5234\u001b[0m        \u001b[35m1.0597\u001b[0m  0.0236\n",
      "      5        0.8921       0.5000        1.0717  0.0187\n",
      "      6        0.8684       0.5000        1.1723  0.0135\n",
      "      7        0.9830       0.5234        1.1232  0.0305\n",
      "      8        0.9855       \u001b[32m0.5469\u001b[0m        1.1014  0.0201\n",
      "      9        0.9195       \u001b[32m0.5781\u001b[0m        \u001b[35m0.9685\u001b[0m  0.0149\n",
      "     10        0.8978       \u001b[32m0.6250\u001b[0m        \u001b[35m0.8665\u001b[0m  0.0192\n",
      "     11        0.8395       \u001b[32m0.6406\u001b[0m        \u001b[35m0.8366\u001b[0m  0.0157\n",
      "     12        0.8270       0.6406        0.8481  0.0282\n",
      "     13        0.8221       \u001b[32m0.6641\u001b[0m        \u001b[35m0.7679\u001b[0m  0.0224\n",
      "     14        0.8053       0.6016        0.8554  0.0233\n",
      "     15        0.7894       \u001b[32m0.6719\u001b[0m        \u001b[35m0.7482\u001b[0m  0.0206\n",
      "     16        0.7284       0.6484        0.7813  0.0149\n",
      "     17        0.7226       0.6250        0.8472  0.0233\n",
      "     18        0.7810       \u001b[32m0.6875\u001b[0m        \u001b[35m0.7386\u001b[0m  0.0137\n",
      "     19        0.7572       0.6328        0.8105  0.0277\n",
      "     20        0.7782       0.6875        0.7436  0.0179\n",
      "     21        0.7557       \u001b[32m0.6953\u001b[0m        \u001b[35m0.7244\u001b[0m  0.0166\n",
      "     22        \u001b[36m0.7158\u001b[0m       0.6641        0.7399  0.0164\n",
      "     23        \u001b[36m0.7130\u001b[0m       0.6641        0.7539  0.0319\n",
      "     24        0.7573       0.6797        0.7459  0.0186\n",
      "     25        0.7457       0.6484        0.7953  0.0155\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6166\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.8129\u001b[0m  0.0313\n",
      "      2        1.2652       0.5000        \u001b[35m1.6290\u001b[0m  0.0184\n",
      "      3        1.2878       0.5000        \u001b[35m1.5905\u001b[0m  0.0254\n",
      "      4        1.2685       0.5000        \u001b[35m1.5898\u001b[0m  0.0191\n",
      "      5        1.2673       0.5000        1.5904  0.0147\n",
      "      6        1.2677       0.5000        1.5902  0.0228\n",
      "      7        1.2676       0.5000        1.5903  0.0133\n",
      "      8        1.2676       0.5000        1.5901  0.0180\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7197\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7149\u001b[0m  0.0490\n",
      "      2        \u001b[36m0.7130\u001b[0m       0.4141        \u001b[35m0.7040\u001b[0m  0.0412\n",
      "      3        \u001b[36m0.7049\u001b[0m       0.4219        \u001b[35m0.6975\u001b[0m  0.0360\n",
      "      4        \u001b[36m0.6995\u001b[0m       0.5000        \u001b[35m0.6930\u001b[0m  0.0420\n",
      "      5        \u001b[36m0.6917\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6891\u001b[0m  0.0359\n",
      "      6        0.6956       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6846\u001b[0m  0.0410\n",
      "      7        \u001b[36m0.6888\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6800\u001b[0m  0.0364\n",
      "      8        \u001b[36m0.6823\u001b[0m       0.5781        \u001b[35m0.6750\u001b[0m  0.0417\n",
      "      9        \u001b[36m0.6787\u001b[0m       0.5859        \u001b[35m0.6690\u001b[0m  0.0359\n",
      "     10        \u001b[36m0.6711\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6615\u001b[0m  0.0404\n",
      "     11        0.6715       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6540\u001b[0m  0.0361\n",
      "     12        \u001b[36m0.6703\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6461\u001b[0m  0.0385\n",
      "     13        \u001b[36m0.6637\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6374\u001b[0m  0.0418\n",
      "     14        \u001b[36m0.6535\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6272\u001b[0m  0.0371\n",
      "     15        \u001b[36m0.6520\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6169\u001b[0m  0.0423\n",
      "     16        \u001b[36m0.6388\u001b[0m       0.7266        \u001b[35m0.6053\u001b[0m  0.0359\n",
      "     17        0.6435       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5945\u001b[0m  0.0389\n",
      "     18        \u001b[36m0.6268\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5835\u001b[0m  0.0421\n",
      "     19        0.6275       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5722\u001b[0m  0.0358\n",
      "     20        \u001b[36m0.6262\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.5616\u001b[0m  0.0383\n",
      "     21        \u001b[36m0.6184\u001b[0m       0.8125        \u001b[35m0.5515\u001b[0m  0.0411\n",
      "     22        \u001b[36m0.6127\u001b[0m       0.8047        \u001b[35m0.5427\u001b[0m  0.0364\n",
      "     23        \u001b[36m0.6015\u001b[0m       0.8125        \u001b[35m0.5333\u001b[0m  0.0370\n",
      "     24        \u001b[36m0.5968\u001b[0m       0.8125        \u001b[35m0.5230\u001b[0m  0.0432\n",
      "     25        \u001b[36m0.5881\u001b[0m       0.8125        \u001b[35m0.5145\u001b[0m  0.0361\n",
      "     26        \u001b[36m0.5852\u001b[0m       0.8047        \u001b[35m0.5077\u001b[0m  0.0359\n",
      "     27        \u001b[36m0.5783\u001b[0m       0.7969        \u001b[35m0.4995\u001b[0m  0.0383\n",
      "     28        \u001b[36m0.5647\u001b[0m       0.7891        \u001b[35m0.4926\u001b[0m  0.0410\n",
      "     29        0.5815       0.7891        \u001b[35m0.4884\u001b[0m  0.0389\n",
      "     30        \u001b[36m0.5639\u001b[0m       0.7891        \u001b[35m0.4827\u001b[0m  0.0412\n",
      "     31        0.5787       0.7891        \u001b[35m0.4795\u001b[0m  0.0369\n",
      "     32        0.5918       0.7891        \u001b[35m0.4769\u001b[0m  0.0365\n",
      "     33        \u001b[36m0.5574\u001b[0m       0.7891        \u001b[35m0.4728\u001b[0m  0.0390\n",
      "     34        0.5816       0.7891        \u001b[35m0.4705\u001b[0m  0.0398\n",
      "     35        0.5715       0.7891        \u001b[35m0.4676\u001b[0m  0.0421\n",
      "     36        0.5643       0.7969        \u001b[35m0.4651\u001b[0m  0.0364\n",
      "     37        0.5671       0.7969        \u001b[35m0.4641\u001b[0m  0.0371\n",
      "     38        \u001b[36m0.5454\u001b[0m       0.7969        \u001b[35m0.4606\u001b[0m  0.0364\n",
      "     39        0.5468       0.7734        \u001b[35m0.4574\u001b[0m  0.0364\n",
      "     40        \u001b[36m0.5432\u001b[0m       0.7891        \u001b[35m0.4542\u001b[0m  0.0379\n",
      "     41        \u001b[36m0.5313\u001b[0m       0.7969        \u001b[35m0.4503\u001b[0m  0.0385\n",
      "     42        0.5603       0.7891        \u001b[35m0.4488\u001b[0m  0.0397\n",
      "     43        0.5639       0.7891        0.4491  0.0392\n",
      "     44        0.5689       0.7969        \u001b[35m0.4481\u001b[0m  0.0401\n",
      "     45        0.5511       0.7891        \u001b[35m0.4479\u001b[0m  0.0418\n",
      "     46        0.5391       0.7969        \u001b[35m0.4440\u001b[0m  0.0368\n",
      "     47        0.5648       0.7891        \u001b[35m0.4434\u001b[0m  0.0369\n",
      "     48        0.5533       0.7891        \u001b[35m0.4422\u001b[0m  0.0374\n",
      "     49        0.5537       0.7969        \u001b[35m0.4412\u001b[0m  0.0374\n",
      "     50        0.5330       0.7969        \u001b[35m0.4407\u001b[0m  0.0382\n",
      "     51        0.5587       0.7969        \u001b[35m0.4402\u001b[0m  0.0369\n",
      "     52        0.5430       0.7969        \u001b[35m0.4390\u001b[0m  0.0374\n",
      "     53        0.5540       0.7969        \u001b[35m0.4385\u001b[0m  0.0371\n",
      "     54        0.5526       0.7969        0.4387  0.0371\n",
      "     55        0.5463       0.7969        \u001b[35m0.4381\u001b[0m  0.0368\n",
      "     56        0.5485       0.8047        \u001b[35m0.4373\u001b[0m  0.0367\n",
      "     57        0.5416       0.7969        \u001b[35m0.4360\u001b[0m  0.0373\n",
      "     58        0.5487       0.7969        0.4363  0.0362\n",
      "     59        0.5487       0.7969        0.4370  0.0360\n",
      "     60        0.5460       0.7969        \u001b[35m0.4356\u001b[0m  0.0365\n",
      "     61        0.5464       0.7969        0.4361  0.0365\n",
      "     62        0.5368       0.8047        \u001b[35m0.4347\u001b[0m  0.0362\n",
      "     63        0.5528       0.8047        0.4349  0.0384\n",
      "     64        0.5528       0.8047        0.4361  0.0365\n",
      "     65        0.5431       0.8047        0.4349  0.0387\n",
      "     66        0.5623       0.7969        0.4355  0.0366\n",
      "     67        0.5373       0.7969        \u001b[35m0.4345\u001b[0m  0.0363\n",
      "     68        0.5465       0.7969        0.4348  0.0366\n",
      "     69        0.5407       0.7969        \u001b[35m0.4345\u001b[0m  0.0361\n",
      "     70        0.5336       0.7969        \u001b[35m0.4329\u001b[0m  0.0360\n",
      "     71        0.5371       0.7969        \u001b[35m0.4327\u001b[0m  0.0361\n",
      "     72        0.5397       0.7969        \u001b[35m0.4323\u001b[0m  0.0378\n",
      "     73        0.5327       0.7969        \u001b[35m0.4322\u001b[0m  0.0362\n",
      "     74        \u001b[36m0.5263\u001b[0m       0.7969        \u001b[35m0.4318\u001b[0m  0.0372\n",
      "     75        0.5488       0.7969        0.4326  0.0366\n",
      "     76        0.5478       0.7969        0.4335  0.0379\n",
      "     77        0.5284       0.7891        0.4329  0.0365\n",
      "     78        0.5483       0.7891        0.4324  0.0360\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7123\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7060\u001b[0m  0.0334\n",
      "      2        \u001b[36m0.7035\u001b[0m       0.4922        \u001b[35m0.6984\u001b[0m  0.0357\n",
      "      3        \u001b[36m0.6968\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6947\u001b[0m  0.0435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        \u001b[36m0.6925\u001b[0m       0.5156        \u001b[35m0.6925\u001b[0m  0.0367\n",
      "      5        \u001b[36m0.6895\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6911\u001b[0m  0.0471\n",
      "      6        0.6904       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6902\u001b[0m  0.0409\n",
      "      7        \u001b[36m0.6888\u001b[0m       0.5391        \u001b[35m0.6891\u001b[0m  0.0369\n",
      "      8        \u001b[36m0.6870\u001b[0m       0.5234        \u001b[35m0.6881\u001b[0m  0.0432\n",
      "      9        \u001b[36m0.6842\u001b[0m       0.5000        \u001b[35m0.6869\u001b[0m  0.0357\n",
      "     10        0.6852       0.5156        \u001b[35m0.6854\u001b[0m  0.0402\n",
      "     11        0.6857       0.5156        \u001b[35m0.6840\u001b[0m  0.0364\n",
      "     12        \u001b[36m0.6790\u001b[0m       0.5156        \u001b[35m0.6820\u001b[0m  0.0391\n",
      "     13        \u001b[36m0.6783\u001b[0m       0.5312        \u001b[35m0.6801\u001b[0m  0.0413\n",
      "     14        0.6785       0.5312        \u001b[35m0.6773\u001b[0m  0.0357\n",
      "     15        \u001b[36m0.6722\u001b[0m       0.5391        \u001b[35m0.6744\u001b[0m  0.0404\n",
      "     16        \u001b[36m0.6660\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6708\u001b[0m  0.0367\n",
      "     17        \u001b[36m0.6643\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6666\u001b[0m  0.0376\n",
      "     18        \u001b[36m0.6607\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6621\u001b[0m  0.0415\n",
      "     19        \u001b[36m0.6584\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6575\u001b[0m  0.0368\n",
      "     20        0.6614       0.6562        \u001b[35m0.6529\u001b[0m  0.0388\n",
      "     21        \u001b[36m0.6489\u001b[0m       0.6562        \u001b[35m0.6484\u001b[0m  0.0409\n",
      "     22        \u001b[36m0.6414\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6431\u001b[0m  0.0364\n",
      "     23        \u001b[36m0.6379\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6374\u001b[0m  0.0371\n",
      "     24        0.6387       0.6797        \u001b[35m0.6318\u001b[0m  0.0414\n",
      "     25        \u001b[36m0.6314\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6264\u001b[0m  0.0361\n",
      "     26        \u001b[36m0.6156\u001b[0m       0.6875        \u001b[35m0.6199\u001b[0m  0.0362\n",
      "     27        \u001b[36m0.6099\u001b[0m       0.6875        \u001b[35m0.6136\u001b[0m  0.0423\n",
      "     28        0.6132       0.6875        \u001b[35m0.6079\u001b[0m  0.0361\n",
      "     29        \u001b[36m0.5989\u001b[0m       0.6875        \u001b[35m0.6017\u001b[0m  0.0418\n",
      "     30        \u001b[36m0.5952\u001b[0m       0.6797        \u001b[35m0.5963\u001b[0m  0.0368\n",
      "     31        0.6096       0.6797        \u001b[35m0.5926\u001b[0m  0.0361\n",
      "     32        \u001b[36m0.5921\u001b[0m       0.6797        \u001b[35m0.5888\u001b[0m  0.0381\n",
      "     33        \u001b[36m0.5872\u001b[0m       0.6797        \u001b[35m0.5852\u001b[0m  0.0413\n",
      "     34        0.5906       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5829\u001b[0m  0.0362\n",
      "     35        \u001b[36m0.5801\u001b[0m       0.6875        \u001b[35m0.5797\u001b[0m  0.0360\n",
      "     36        \u001b[36m0.5691\u001b[0m       0.6875        \u001b[35m0.5766\u001b[0m  0.0362\n",
      "     37        0.5878       0.6875        \u001b[35m0.5738\u001b[0m  0.0376\n",
      "     38        0.5767       0.6875        \u001b[35m0.5715\u001b[0m  0.0414\n",
      "     39        0.5873       0.6875        \u001b[35m0.5694\u001b[0m  0.0359\n",
      "     40        0.5727       0.6953        \u001b[35m0.5673\u001b[0m  0.0412\n",
      "     41        0.5697       0.6953        \u001b[35m0.5659\u001b[0m  0.0364\n",
      "     42        0.5897       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5647\u001b[0m  0.0357\n",
      "     43        0.5756       0.7031        \u001b[35m0.5628\u001b[0m  0.0365\n",
      "     44        0.5788       0.6953        \u001b[35m0.5610\u001b[0m  0.0363\n",
      "     45        0.5967       0.7031        \u001b[35m0.5602\u001b[0m  0.0366\n",
      "     46        0.5825       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5594\u001b[0m  0.0365\n",
      "     47        \u001b[36m0.5609\u001b[0m       0.7109        \u001b[35m0.5583\u001b[0m  0.0365\n",
      "     48        \u001b[36m0.5523\u001b[0m       0.7109        \u001b[35m0.5555\u001b[0m  0.0378\n",
      "     49        0.5856       \u001b[32m0.7188\u001b[0m        0.5557  0.0368\n",
      "     50        0.5887       0.7188        \u001b[35m0.5543\u001b[0m  0.0365\n",
      "     51        0.5611       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5530\u001b[0m  0.0361\n",
      "     52        \u001b[36m0.5459\u001b[0m       0.7266        \u001b[35m0.5514\u001b[0m  0.0364\n",
      "     53        0.5769       0.7266        \u001b[35m0.5501\u001b[0m  0.0365\n",
      "     54        0.5504       0.7266        \u001b[35m0.5491\u001b[0m  0.0361\n",
      "     55        0.5526       0.7188        0.5496  0.0364\n",
      "     56        0.5662       0.7188        \u001b[35m0.5486\u001b[0m  0.0365\n",
      "     57        0.5665       0.7188        \u001b[35m0.5481\u001b[0m  0.0357\n",
      "     58        0.5475       0.7188        \u001b[35m0.5465\u001b[0m  0.0363\n",
      "     59        0.5647       0.7188        \u001b[35m0.5465\u001b[0m  0.0360\n",
      "     60        0.5630       0.7266        \u001b[35m0.5446\u001b[0m  0.0363\n",
      "     61        0.5628       0.7266        \u001b[35m0.5443\u001b[0m  0.0362\n",
      "     62        \u001b[36m0.5403\u001b[0m       0.7266        \u001b[35m0.5428\u001b[0m  0.0359\n",
      "     63        0.5632       0.7266        \u001b[35m0.5427\u001b[0m  0.0405\n",
      "     64        0.5725       0.7266        \u001b[35m0.5426\u001b[0m  0.0363\n",
      "     65        0.5511       0.7266        \u001b[35m0.5423\u001b[0m  0.0370\n",
      "     66        0.5869       0.7266        0.5430  0.0358\n",
      "     67        0.5579       0.7266        0.5425  0.0385\n",
      "     68        0.5564       0.7266        \u001b[35m0.5411\u001b[0m  0.0396\n",
      "     69        0.5550       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5409\u001b[0m  0.0366\n",
      "     70        0.5506       0.7344        \u001b[35m0.5397\u001b[0m  0.0361\n",
      "     71        0.5748       0.7344        \u001b[35m0.5393\u001b[0m  0.0368\n",
      "     72        0.5521       0.7266        \u001b[35m0.5385\u001b[0m  0.0362\n",
      "     73        0.5491       0.7266        \u001b[35m0.5375\u001b[0m  0.0361\n",
      "     74        0.5562       0.7266        \u001b[35m0.5370\u001b[0m  0.0378\n",
      "     75        0.5450       0.7266        \u001b[35m0.5368\u001b[0m  0.0364\n",
      "     76        0.5441       0.7266        \u001b[35m0.5365\u001b[0m  0.0363\n",
      "     77        \u001b[36m0.5356\u001b[0m       0.7266        \u001b[35m0.5358\u001b[0m  0.0368\n",
      "     78        0.5639       0.7266        0.5363  0.0365\n",
      "     79        0.5488       0.7344        0.5362  0.0377\n",
      "     80        \u001b[36m0.5349\u001b[0m       0.7266        \u001b[35m0.5353\u001b[0m  0.0365\n",
      "     81        0.5562       0.7266        \u001b[35m0.5348\u001b[0m  0.0362\n",
      "     82        0.5602       0.7266        0.5352  0.0368\n",
      "     83        0.5414       0.7266        \u001b[35m0.5345\u001b[0m  0.0370\n",
      "     84        \u001b[36m0.5318\u001b[0m       0.7266        \u001b[35m0.5338\u001b[0m  0.0362\n",
      "     85        0.5370       0.7266        \u001b[35m0.5336\u001b[0m  0.0361\n",
      "     86        0.5422       0.7266        \u001b[35m0.5330\u001b[0m  0.0363\n",
      "     87        0.5540       0.7266        \u001b[35m0.5325\u001b[0m  0.0366\n",
      "     88        0.5560       0.7266        \u001b[35m0.5325\u001b[0m  0.0360\n",
      "     89        0.5421       0.7266        \u001b[35m0.5322\u001b[0m  0.0370\n",
      "     90        \u001b[36m0.5270\u001b[0m       0.7266        0.5327  0.0368\n",
      "     91        \u001b[36m0.5251\u001b[0m       0.7266        0.5326  0.0361\n",
      "     92        0.5454       0.7344        0.5323  0.0359\n",
      "     93        0.5450       0.7344        0.5323  0.0361\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7211\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7121\u001b[0m  0.0340\n",
      "      2        \u001b[36m0.7147\u001b[0m       0.5000        \u001b[35m0.7072\u001b[0m  0.0447\n",
      "      3        \u001b[36m0.7120\u001b[0m       0.5000        \u001b[35m0.7037\u001b[0m  0.0418\n",
      "      4        \u001b[36m0.7081\u001b[0m       0.5000        \u001b[35m0.7014\u001b[0m  0.0402\n",
      "      5        \u001b[36m0.7036\u001b[0m       0.4766        \u001b[35m0.6999\u001b[0m  0.0413\n",
      "      6        \u001b[36m0.7032\u001b[0m       0.4609        \u001b[35m0.6986\u001b[0m  0.0388\n",
      "      7        \u001b[36m0.6996\u001b[0m       0.4609        \u001b[35m0.6977\u001b[0m  0.0415\n",
      "      8        \u001b[36m0.6975\u001b[0m       0.4688        \u001b[35m0.6971\u001b[0m  0.0375\n",
      "      9        \u001b[36m0.6973\u001b[0m       0.4688        \u001b[35m0.6965\u001b[0m  0.0413\n",
      "     10        \u001b[36m0.6971\u001b[0m       0.4688        \u001b[35m0.6959\u001b[0m  0.0414\n",
      "     11        0.6990       0.4844        \u001b[35m0.6951\u001b[0m  0.0438\n",
      "     12        0.6986       0.4922        \u001b[35m0.6944\u001b[0m  0.0398\n",
      "     13        \u001b[36m0.6922\u001b[0m       0.5000        \u001b[35m0.6939\u001b[0m  0.0432\n",
      "     14        0.6963       0.5000        \u001b[35m0.6932\u001b[0m  0.0414\n",
      "     15        0.6932       0.5000        \u001b[35m0.6927\u001b[0m  0.0376\n",
      "     16        0.6924       0.5000        \u001b[35m0.6921\u001b[0m  0.0424\n",
      "     17        \u001b[36m0.6866\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6916\u001b[0m  0.0427\n",
      "     18        0.6898       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6909\u001b[0m  0.0428\n",
      "     19        \u001b[36m0.6855\u001b[0m       0.5078        \u001b[35m0.6902\u001b[0m  0.0365\n",
      "     20        0.6904       0.5156        \u001b[35m0.6894\u001b[0m  0.0399\n",
      "     21        0.6880       0.5156        \u001b[35m0.6886\u001b[0m  0.0416\n",
      "     22        \u001b[36m0.6840\u001b[0m       0.5000        \u001b[35m0.6875\u001b[0m  0.0428\n",
      "     23        0.6847       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6862\u001b[0m  0.0358\n",
      "     24        \u001b[36m0.6766\u001b[0m       0.5156        \u001b[35m0.6850\u001b[0m  0.0392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25        0.6789       0.5234        \u001b[35m0.6837\u001b[0m  0.0406\n",
      "     26        0.6774       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6821\u001b[0m  0.0399\n",
      "     27        \u001b[36m0.6734\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6805\u001b[0m  0.0457\n",
      "     28        0.6756       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6785\u001b[0m  0.0366\n",
      "     29        \u001b[36m0.6690\u001b[0m       0.5625        \u001b[35m0.6762\u001b[0m  0.0377\n",
      "     30        \u001b[36m0.6615\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6736\u001b[0m  0.0367\n",
      "     31        0.6677       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6713\u001b[0m  0.0402\n",
      "     32        0.6705       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6687\u001b[0m  0.0362\n",
      "     33        \u001b[36m0.6560\u001b[0m       0.6172        \u001b[35m0.6654\u001b[0m  0.0381\n",
      "     34        \u001b[36m0.6520\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6621\u001b[0m  0.0359\n",
      "     35        \u001b[36m0.6480\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6586\u001b[0m  0.0397\n",
      "     36        \u001b[36m0.6441\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6548\u001b[0m  0.0374\n",
      "     37        \u001b[36m0.6394\u001b[0m       0.6641        \u001b[35m0.6515\u001b[0m  0.0398\n",
      "     38        0.6435       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6480\u001b[0m  0.0359\n",
      "     39        0.6398       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6447\u001b[0m  0.0410\n",
      "     40        \u001b[36m0.6364\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6412\u001b[0m  0.0364\n",
      "     41        \u001b[36m0.6267\u001b[0m       0.7188        \u001b[35m0.6376\u001b[0m  0.0359\n",
      "     42        \u001b[36m0.5999\u001b[0m       0.7188        \u001b[35m0.6331\u001b[0m  0.0360\n",
      "     43        0.6066       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6296\u001b[0m  0.0371\n",
      "     44        0.6117       0.7188        \u001b[35m0.6259\u001b[0m  0.0373\n",
      "     45        0.6043       0.7266        \u001b[35m0.6220\u001b[0m  0.0378\n",
      "     46        0.6024       0.7266        \u001b[35m0.6188\u001b[0m  0.0391\n",
      "     47        0.6100       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6160\u001b[0m  0.0374\n",
      "     48        \u001b[36m0.5893\u001b[0m       0.7344        \u001b[35m0.6132\u001b[0m  0.0385\n",
      "     49        0.5998       0.7266        \u001b[35m0.6100\u001b[0m  0.0382\n",
      "     50        0.5899       0.7266        \u001b[35m0.6075\u001b[0m  0.0376\n",
      "     51        0.5928       0.7266        \u001b[35m0.6053\u001b[0m  0.0373\n",
      "     52        \u001b[36m0.5858\u001b[0m       0.7266        \u001b[35m0.6036\u001b[0m  0.0382\n",
      "     53        \u001b[36m0.5832\u001b[0m       0.7188        \u001b[35m0.6012\u001b[0m  0.0409\n",
      "     54        \u001b[36m0.5776\u001b[0m       0.7109        \u001b[35m0.6001\u001b[0m  0.0361\n",
      "     55        0.5788       0.7109        \u001b[35m0.5984\u001b[0m  0.0362\n",
      "     56        \u001b[36m0.5669\u001b[0m       0.7109        \u001b[35m0.5977\u001b[0m  0.0364\n",
      "     57        0.5750       0.6953        \u001b[35m0.5954\u001b[0m  0.0361\n",
      "     58        \u001b[36m0.5527\u001b[0m       0.6953        \u001b[35m0.5942\u001b[0m  0.0363\n",
      "     59        0.5625       0.7109        \u001b[35m0.5934\u001b[0m  0.0361\n",
      "     60        0.5800       0.6953        \u001b[35m0.5931\u001b[0m  0.0363\n",
      "     61        0.5807       0.6953        \u001b[35m0.5919\u001b[0m  0.0355\n",
      "     62        0.5712       0.6953        \u001b[35m0.5905\u001b[0m  0.0402\n",
      "     63        0.5612       0.6953        0.5907  0.0367\n",
      "     64        0.5816       0.6953        \u001b[35m0.5888\u001b[0m  0.0361\n",
      "     65        0.5708       0.6953        \u001b[35m0.5881\u001b[0m  0.0376\n",
      "     66        0.5845       0.6875        \u001b[35m0.5871\u001b[0m  0.0359\n",
      "     67        0.5551       0.6875        \u001b[35m0.5864\u001b[0m  0.0360\n",
      "     68        0.5636       0.6875        \u001b[35m0.5857\u001b[0m  0.0375\n",
      "     69        \u001b[36m0.5514\u001b[0m       0.6875        \u001b[35m0.5848\u001b[0m  0.0360\n",
      "     70        0.5621       0.6875        \u001b[35m0.5836\u001b[0m  0.0360\n",
      "     71        0.5683       0.6875        0.5841  0.0364\n",
      "     72        0.5634       0.6875        \u001b[35m0.5823\u001b[0m  0.0405\n",
      "     73        \u001b[36m0.5484\u001b[0m       0.6875        \u001b[35m0.5813\u001b[0m  0.0365\n",
      "     74        0.5498       0.6875        0.5817  0.0368\n",
      "     75        0.5542       0.6875        0.5815  0.0364\n",
      "     76        0.5684       0.6875        \u001b[35m0.5813\u001b[0m  0.0359\n",
      "     77        0.5692       0.6797        \u001b[35m0.5794\u001b[0m  0.0357\n",
      "     78        0.5513       0.6797        \u001b[35m0.5782\u001b[0m  0.0398\n",
      "     79        0.5496       0.6797        0.5789  0.0363\n",
      "     80        0.5537       0.6875        \u001b[35m0.5772\u001b[0m  0.0364\n",
      "     81        0.5581       0.7031        \u001b[35m0.5761\u001b[0m  0.0374\n",
      "     82        0.5635       0.7031        0.5762  0.0368\n",
      "     83        \u001b[36m0.5281\u001b[0m       0.6953        0.5763  0.0379\n",
      "     84        0.5511       0.6953        \u001b[35m0.5741\u001b[0m  0.0360\n",
      "     85        0.5565       0.6953        \u001b[35m0.5736\u001b[0m  0.0360\n",
      "     86        0.5420       0.6875        0.5738  0.0363\n",
      "     87        0.5529       0.6875        \u001b[35m0.5727\u001b[0m  0.0364\n",
      "     88        0.5615       0.6953        \u001b[35m0.5717\u001b[0m  0.0367\n",
      "     89        0.5599       0.7031        \u001b[35m0.5709\u001b[0m  0.0363\n",
      "     90        0.5541       0.7031        \u001b[35m0.5701\u001b[0m  0.0394\n",
      "     91        0.5559       0.6875        0.5705  0.0363\n",
      "     92        \u001b[36m0.5252\u001b[0m       0.6875        0.5705  0.0359\n",
      "     93        0.5443       0.6953        \u001b[35m0.5698\u001b[0m  0.0367\n",
      "     94        0.5286       0.6953        0.5702  0.0364\n",
      "     95        0.5468       0.6797        0.5699  0.0362\n",
      "     96        0.5574       0.6797        \u001b[35m0.5694\u001b[0m  0.0365\n",
      "     97        0.5699       0.6797        0.5696  0.0360\n",
      "     98        0.5491       0.6875        \u001b[35m0.5693\u001b[0m  0.0374\n",
      "     99        0.5333       0.6797        \u001b[35m0.5690\u001b[0m  0.0367\n",
      "    100        0.5331       0.6797        \u001b[35m0.5681\u001b[0m  0.0381\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6999\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6880\u001b[0m  0.0361\n",
      "      2        \u001b[36m0.6821\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6817\u001b[0m  0.0363\n",
      "      3        \u001b[36m0.6760\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6756\u001b[0m  0.0417\n",
      "      4        \u001b[36m0.6659\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6701\u001b[0m  0.0360\n",
      "      5        \u001b[36m0.6566\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6643\u001b[0m  0.0413\n",
      "      6        \u001b[36m0.6514\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6581\u001b[0m  0.0363\n",
      "      7        \u001b[36m0.6446\u001b[0m       0.6719        \u001b[35m0.6520\u001b[0m  0.0415\n",
      "      8        \u001b[36m0.6425\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6465\u001b[0m  0.0517\n",
      "      9        \u001b[36m0.6233\u001b[0m       0.6797        \u001b[35m0.6393\u001b[0m  0.0478\n",
      "     10        \u001b[36m0.6219\u001b[0m       0.6797        \u001b[35m0.6324\u001b[0m  0.0518\n",
      "     11        \u001b[36m0.6179\u001b[0m       0.6719        \u001b[35m0.6257\u001b[0m  0.0506\n",
      "     12        \u001b[36m0.6137\u001b[0m       0.6641        \u001b[35m0.6189\u001b[0m  0.0481\n",
      "     13        \u001b[36m0.6043\u001b[0m       0.6719        \u001b[35m0.6127\u001b[0m  0.0504\n",
      "     14        \u001b[36m0.5871\u001b[0m       0.6875        \u001b[35m0.6058\u001b[0m  0.0421\n",
      "     15        \u001b[36m0.5840\u001b[0m       0.6953        \u001b[35m0.6000\u001b[0m  0.0414\n",
      "     16        \u001b[36m0.5720\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5946\u001b[0m  0.0453\n",
      "     17        0.5745       0.6797        \u001b[35m0.5898\u001b[0m  0.0359\n",
      "     18        \u001b[36m0.5714\u001b[0m       0.6797        \u001b[35m0.5849\u001b[0m  0.0387\n",
      "     19        \u001b[36m0.5671\u001b[0m       0.6797        \u001b[35m0.5808\u001b[0m  0.0453\n",
      "     20        \u001b[36m0.5555\u001b[0m       0.6875        \u001b[35m0.5778\u001b[0m  0.0432\n",
      "     21        0.5640       0.6875        \u001b[35m0.5744\u001b[0m  0.0425\n",
      "     22        0.5597       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5717\u001b[0m  0.0430\n",
      "     23        \u001b[36m0.5550\u001b[0m       0.7109        \u001b[35m0.5687\u001b[0m  0.0442\n",
      "     24        \u001b[36m0.5472\u001b[0m       0.7031        \u001b[35m0.5668\u001b[0m  0.0437\n",
      "     25        0.5705       0.6953        \u001b[35m0.5654\u001b[0m  0.0435\n",
      "     26        \u001b[36m0.5335\u001b[0m       0.6953        \u001b[35m0.5641\u001b[0m  0.0436\n",
      "     27        \u001b[36m0.5322\u001b[0m       0.6875        \u001b[35m0.5630\u001b[0m  0.0421\n",
      "     28        \u001b[36m0.5280\u001b[0m       0.6875        \u001b[35m0.5624\u001b[0m  0.0415\n",
      "     29        0.5390       0.6797        \u001b[35m0.5613\u001b[0m  0.0471\n",
      "     30        \u001b[36m0.5259\u001b[0m       0.6875        \u001b[35m0.5602\u001b[0m  0.0494\n",
      "     31        0.5376       0.6875        \u001b[35m0.5594\u001b[0m  0.0378\n",
      "     32        0.5390       0.6875        \u001b[35m0.5588\u001b[0m  0.0378\n",
      "     33        0.5455       0.6875        \u001b[35m0.5582\u001b[0m  0.0397\n",
      "     34        0.5268       0.6953        \u001b[35m0.5569\u001b[0m  0.0401\n",
      "     35        \u001b[36m0.5255\u001b[0m       0.6953        \u001b[35m0.5564\u001b[0m  0.0408\n",
      "     36        \u001b[36m0.5208\u001b[0m       0.6953        \u001b[35m0.5559\u001b[0m  0.0400\n",
      "     37        0.5416       0.6953        \u001b[35m0.5548\u001b[0m  0.0408\n",
      "     38        0.5292       0.6953        \u001b[35m0.5547\u001b[0m  0.0413\n",
      "     39        0.5251       0.6953        \u001b[35m0.5545\u001b[0m  0.0410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     40        0.5226       0.6953        \u001b[35m0.5537\u001b[0m  0.0418\n",
      "     41        0.5367       0.6953        \u001b[35m0.5528\u001b[0m  0.0388\n",
      "     42        0.5317       0.6953        \u001b[35m0.5525\u001b[0m  0.0402\n",
      "     43        \u001b[36m0.5123\u001b[0m       0.6953        0.5531  0.0364\n",
      "     44        0.5233       0.6953        0.5526  0.0362\n",
      "     45        0.5201       0.6953        0.5526  0.0358\n",
      "     46        0.5170       0.6953        0.5531  0.0394\n",
      "     47        0.5242       0.6953        \u001b[35m0.5518\u001b[0m  0.0361\n",
      "     48        0.5381       0.6953        0.5529  0.0380\n",
      "     49        \u001b[36m0.5093\u001b[0m       0.6953        0.5528  0.0361\n",
      "     50        \u001b[36m0.5048\u001b[0m       0.6953        0.5523  0.0363\n",
      "     51        0.5353       0.6953        \u001b[35m0.5515\u001b[0m  0.0360\n",
      "     52        0.5241       0.6953        \u001b[35m0.5508\u001b[0m  0.0360\n",
      "     53        0.5132       0.6953        0.5509  0.0361\n",
      "     54        \u001b[36m0.5043\u001b[0m       0.6953        \u001b[35m0.5507\u001b[0m  0.0361\n",
      "     55        0.5177       0.6953        \u001b[35m0.5496\u001b[0m  0.0362\n",
      "     56        0.5193       0.6953        0.5503  0.0361\n",
      "     57        0.5195       0.6953        0.5504  0.0358\n",
      "     58        0.5406       0.6953        \u001b[35m0.5495\u001b[0m  0.0368\n",
      "     59        0.5258       0.6953        0.5508  0.0358\n",
      "     60        0.5142       0.6875        0.5499  0.0383\n",
      "     61        0.5189       0.6875        0.5505  0.0358\n",
      "     62        0.5076       0.6953        0.5499  0.0392\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7108\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7076\u001b[0m  0.0322\n",
      "      2        \u001b[36m0.7096\u001b[0m       0.5000        \u001b[35m0.7042\u001b[0m  0.0364\n",
      "      3        \u001b[36m0.7046\u001b[0m       0.5000        \u001b[35m0.7014\u001b[0m  0.0425\n",
      "      4        \u001b[36m0.7034\u001b[0m       0.5000        \u001b[35m0.6991\u001b[0m  0.0381\n",
      "      5        \u001b[36m0.6998\u001b[0m       0.5000        \u001b[35m0.6974\u001b[0m  0.0467\n",
      "      6        \u001b[36m0.6983\u001b[0m       0.5000        \u001b[35m0.6956\u001b[0m  0.0362\n",
      "      7        0.6994       0.5000        \u001b[35m0.6945\u001b[0m  0.0422\n",
      "      8        \u001b[36m0.6965\u001b[0m       0.5000        \u001b[35m0.6933\u001b[0m  0.0381\n",
      "      9        \u001b[36m0.6931\u001b[0m       0.5000        \u001b[35m0.6919\u001b[0m  0.0386\n",
      "     10        \u001b[36m0.6884\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6906\u001b[0m  0.0420\n",
      "     11        0.6887       0.5078        \u001b[35m0.6893\u001b[0m  0.0358\n",
      "     12        0.6928       0.4922        \u001b[35m0.6882\u001b[0m  0.0411\n",
      "     13        \u001b[36m0.6827\u001b[0m       0.4922        \u001b[35m0.6865\u001b[0m  0.0362\n",
      "     14        \u001b[36m0.6823\u001b[0m       0.4922        \u001b[35m0.6847\u001b[0m  0.0410\n",
      "     15        0.6826       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6828\u001b[0m  0.0360\n",
      "     16        \u001b[36m0.6806\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6808\u001b[0m  0.0378\n",
      "     17        \u001b[36m0.6743\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6780\u001b[0m  0.0440\n",
      "     18        0.6791       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6754\u001b[0m  0.0359\n",
      "     19        \u001b[36m0.6703\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6719\u001b[0m  0.0378\n",
      "     20        \u001b[36m0.6643\u001b[0m       0.6562        \u001b[35m0.6676\u001b[0m  0.0432\n",
      "     21        \u001b[36m0.6596\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6629\u001b[0m  0.0360\n",
      "     22        0.6632       0.6719        \u001b[35m0.6587\u001b[0m  0.0369\n",
      "     23        \u001b[36m0.6568\u001b[0m       0.6562        \u001b[35m0.6539\u001b[0m  0.0406\n",
      "     24        \u001b[36m0.6498\u001b[0m       0.6562        \u001b[35m0.6484\u001b[0m  0.0364\n",
      "     25        \u001b[36m0.6404\u001b[0m       0.6641        \u001b[35m0.6422\u001b[0m  0.0363\n",
      "     26        \u001b[36m0.6309\u001b[0m       0.6641        \u001b[35m0.6354\u001b[0m  0.0406\n",
      "     27        \u001b[36m0.6300\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6285\u001b[0m  0.0363\n",
      "     28        \u001b[36m0.6272\u001b[0m       0.6953        \u001b[35m0.6217\u001b[0m  0.0383\n",
      "     29        \u001b[36m0.6072\u001b[0m       0.6953        \u001b[35m0.6136\u001b[0m  0.0365\n",
      "     30        0.6109       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6064\u001b[0m  0.0430\n",
      "     31        0.6158       0.7109        \u001b[35m0.6008\u001b[0m  0.0363\n",
      "     32        \u001b[36m0.5929\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5938\u001b[0m  0.0411\n",
      "     33        0.5957       0.7188        \u001b[35m0.5879\u001b[0m  0.0360\n",
      "     34        0.5961       0.7188        \u001b[35m0.5826\u001b[0m  0.0362\n",
      "     35        \u001b[36m0.5850\u001b[0m       0.7188        \u001b[35m0.5777\u001b[0m  0.0370\n",
      "     36        \u001b[36m0.5777\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5720\u001b[0m  0.0405\n",
      "     37        \u001b[36m0.5773\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5673\u001b[0m  0.0357\n",
      "     38        \u001b[36m0.5617\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5622\u001b[0m  0.0422\n",
      "     39        0.5619       0.7500        \u001b[35m0.5592\u001b[0m  0.0364\n",
      "     40        0.5623       0.7422        \u001b[35m0.5560\u001b[0m  0.0357\n",
      "     41        0.5759       0.7422        \u001b[35m0.5532\u001b[0m  0.0379\n",
      "     42        0.5640       0.7344        \u001b[35m0.5503\u001b[0m  0.0359\n",
      "     43        \u001b[36m0.5500\u001b[0m       0.7422        \u001b[35m0.5479\u001b[0m  0.0364\n",
      "     44        0.5598       0.7344        \u001b[35m0.5462\u001b[0m  0.0372\n",
      "     45        \u001b[36m0.5381\u001b[0m       0.7422        \u001b[35m0.5445\u001b[0m  0.0389\n",
      "     46        0.5458       0.7266        \u001b[35m0.5418\u001b[0m  0.0388\n",
      "     47        \u001b[36m0.5301\u001b[0m       0.7422        \u001b[35m0.5398\u001b[0m  0.0381\n",
      "     48        0.5358       0.7266        \u001b[35m0.5382\u001b[0m  0.0396\n",
      "     49        0.5366       0.7266        \u001b[35m0.5372\u001b[0m  0.0375\n",
      "     50        \u001b[36m0.5234\u001b[0m       0.7422        \u001b[35m0.5359\u001b[0m  0.0372\n",
      "     51        0.5357       0.7500        \u001b[35m0.5348\u001b[0m  0.0374\n",
      "     52        0.5392       0.7500        \u001b[35m0.5342\u001b[0m  0.0365\n",
      "     53        0.5239       0.7500        \u001b[35m0.5333\u001b[0m  0.0372\n",
      "     54        0.5318       0.7500        \u001b[35m0.5326\u001b[0m  0.0367\n",
      "     55        \u001b[36m0.5223\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5317\u001b[0m  0.0364\n",
      "     56        0.5230       0.7578        \u001b[35m0.5311\u001b[0m  0.0364\n",
      "     57        0.5272       0.7578        \u001b[35m0.5308\u001b[0m  0.0359\n",
      "     58        \u001b[36m0.5205\u001b[0m       0.7578        \u001b[35m0.5307\u001b[0m  0.0367\n",
      "     59        \u001b[36m0.5068\u001b[0m       0.7500        \u001b[35m0.5303\u001b[0m  0.0360\n",
      "     60        0.5072       0.7578        \u001b[35m0.5294\u001b[0m  0.0366\n",
      "     61        0.5347       0.7500        0.5294  0.0373\n",
      "     62        0.5165       0.7500        \u001b[35m0.5294\u001b[0m  0.0384\n",
      "     63        0.5196       0.7500        0.5297  0.0366\n",
      "     64        0.5129       0.7500        0.5298  0.0362\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0484\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m3.0332\u001b[0m  0.0118\n",
      "      2        3.9103       0.5000        \u001b[35m0.7186\u001b[0m  0.0129\n",
      "      3        1.1135       0.5000        1.7938  0.0142\n",
      "      4        2.6902       0.5000        1.1967  0.0155\n",
      "      5        2.2691       0.5000        1.1548  0.0236\n",
      "      6        2.0605       0.5000        1.4764  0.0269\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.1258\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.8716\u001b[0m  0.0142\n",
      "      2        4.0825       0.5000        \u001b[35m0.8472\u001b[0m  0.0213\n",
      "      3        1.2881       0.5000        1.6558  0.0150\n",
      "      4        2.9664       0.5000        \u001b[35m0.8343\u001b[0m  0.0167\n",
      "      5        2.2064       0.5000        1.0982  0.0203\n",
      "      6        2.4090       0.5000        1.1209  0.0161\n",
      "      7        2.5149       0.5000        0.9865  0.0180\n",
      "      8        2.3108       0.5000        1.1454  0.0206\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6888\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.6395\u001b[0m  0.0180\n",
      "      2        1.6913       0.5000        \u001b[35m0.9827\u001b[0m  0.0170\n",
      "      3        1.9141       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6970\u001b[0m  0.0176\n",
      "      4        1.2596       0.5000        0.7812  0.0198\n",
      "      5        1.3374       0.5000        0.8154  0.0158\n",
      "      6        1.5414       0.5000        0.7047  0.0171\n",
      "      7        1.3586       0.5000        0.8189  0.0187\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8187\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.8060\u001b[0m  0.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        1.8367       0.5000        \u001b[35m1.4348\u001b[0m  0.0178\n",
      "      3        1.7626       0.5000        \u001b[35m0.8155\u001b[0m  0.0187\n",
      "      4        1.0082       0.5000        1.2513  0.0231\n",
      "      5        1.3211       0.5000        1.4866  0.0160\n",
      "      6        1.5933       0.5000        1.1791  0.0216\n",
      "      7        1.3700       0.5000        1.1902  0.0153\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8779\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.6027\u001b[0m  0.0160\n",
      "      2        3.2231       0.5000        \u001b[35m0.7173\u001b[0m  0.0149\n",
      "      3        1.1349       0.5000        1.5391  0.0173\n",
      "      4        1.6864       0.5000        1.6103  0.0181\n",
      "      5        2.3750       0.5000        0.8237  0.0280\n",
      "      6        1.4967       0.5000        1.2762  0.0199\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6972\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6876\u001b[0m  0.0417\n",
      "      2        \u001b[36m0.6895\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6864\u001b[0m  0.0404\n",
      "      3        0.6950       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6861\u001b[0m  0.0359\n",
      "      4        0.6906       0.7266        \u001b[35m0.6852\u001b[0m  0.0417\n",
      "      5        \u001b[36m0.6875\u001b[0m       0.7266        \u001b[35m0.6841\u001b[0m  0.0360\n",
      "      6        \u001b[36m0.6814\u001b[0m       0.7188        \u001b[35m0.6823\u001b[0m  0.0461\n",
      "      7        0.6838       0.7109        \u001b[35m0.6807\u001b[0m  0.0357\n",
      "      8        0.6826       0.7109        \u001b[35m0.6793\u001b[0m  0.0386\n",
      "      9        0.6885       0.6875        \u001b[35m0.6780\u001b[0m  0.0413\n",
      "     10        0.6856       0.6875        \u001b[35m0.6769\u001b[0m  0.0362\n",
      "     11        0.6912       0.6484        \u001b[35m0.6763\u001b[0m  0.0448\n",
      "     12        0.6832       0.6641        \u001b[35m0.6747\u001b[0m  0.0357\n",
      "     13        0.6873       0.6641        \u001b[35m0.6736\u001b[0m  0.0404\n",
      "     14        0.6831       0.6797        \u001b[35m0.6718\u001b[0m  0.0359\n",
      "     15        \u001b[36m0.6805\u001b[0m       0.6875        \u001b[35m0.6697\u001b[0m  0.0375\n",
      "     16        0.6855       0.6875        \u001b[35m0.6684\u001b[0m  0.0404\n",
      "     17        0.6808       0.7188        \u001b[35m0.6662\u001b[0m  0.0358\n",
      "     18        \u001b[36m0.6773\u001b[0m       0.7344        \u001b[35m0.6637\u001b[0m  0.0405\n",
      "     19        0.6812       0.7422        \u001b[35m0.6618\u001b[0m  0.0358\n",
      "     20        0.6777       0.7266        \u001b[35m0.6598\u001b[0m  0.0369\n",
      "     21        \u001b[36m0.6772\u001b[0m       0.7266        \u001b[35m0.6578\u001b[0m  0.0441\n",
      "     22        \u001b[36m0.6728\u001b[0m       0.7422        \u001b[35m0.6545\u001b[0m  0.0357\n",
      "     23        0.6783       0.7500        \u001b[35m0.6525\u001b[0m  0.0365\n",
      "     24        \u001b[36m0.6625\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6485\u001b[0m  0.0406\n",
      "     25        0.6715       0.7578        \u001b[35m0.6462\u001b[0m  0.0360\n",
      "     26        \u001b[36m0.6574\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.6417\u001b[0m  0.0363\n",
      "     27        0.6714       \u001b[32m0.7734\u001b[0m        \u001b[35m0.6388\u001b[0m  0.0417\n",
      "     28        0.6658       0.7734        \u001b[35m0.6364\u001b[0m  0.0359\n",
      "     29        0.6678       0.7656        \u001b[35m0.6338\u001b[0m  0.0377\n",
      "     30        0.6585       0.7734        \u001b[35m0.6302\u001b[0m  0.0361\n",
      "     31        \u001b[36m0.6559\u001b[0m       0.7734        \u001b[35m0.6260\u001b[0m  0.0388\n",
      "     32        \u001b[36m0.6518\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.6211\u001b[0m  0.0400\n",
      "     33        0.6625       0.7812        \u001b[35m0.6194\u001b[0m  0.0358\n",
      "     34        0.6622       0.7734        \u001b[35m0.6168\u001b[0m  0.0361\n",
      "     35        \u001b[36m0.6483\u001b[0m       0.7969        \u001b[35m0.6122\u001b[0m  0.0362\n",
      "     36        0.6565       0.7891        \u001b[35m0.6099\u001b[0m  0.0380\n",
      "     37        0.6563       0.7969        \u001b[35m0.6072\u001b[0m  0.0403\n",
      "     38        0.6515       0.7969        \u001b[35m0.6047\u001b[0m  0.0364\n",
      "     39        0.6575       0.7969        \u001b[35m0.6029\u001b[0m  0.0366\n",
      "     40        0.6693       0.7969        0.6043  0.0360\n",
      "     41        0.6542       0.7969        0.6030  0.0360\n",
      "     42        0.6535       \u001b[32m0.8047\u001b[0m        \u001b[35m0.6002\u001b[0m  0.0379\n",
      "     43        0.6498       0.8047        \u001b[35m0.5978\u001b[0m  0.0372\n",
      "     44        0.6525       0.8047        \u001b[35m0.5962\u001b[0m  0.0371\n",
      "     45        0.6522       0.8047        \u001b[35m0.5951\u001b[0m  0.0377\n",
      "     46        \u001b[36m0.6374\u001b[0m       0.8047        \u001b[35m0.5928\u001b[0m  0.0398\n",
      "     47        0.6466       0.8047        \u001b[35m0.5906\u001b[0m  0.0360\n",
      "     48        0.6545       0.8047        \u001b[35m0.5885\u001b[0m  0.0406\n",
      "     49        0.6463       0.8047        \u001b[35m0.5878\u001b[0m  0.0361\n",
      "     50        0.6478       0.8047        \u001b[35m0.5872\u001b[0m  0.0383\n",
      "     51        0.6485       0.8047        \u001b[35m0.5867\u001b[0m  0.0383\n",
      "     52        0.6506       0.8047        0.5876  0.0372\n",
      "     53        0.6414       0.8047        \u001b[35m0.5859\u001b[0m  0.0366\n",
      "     54        0.6597       0.7969        0.5870  0.0362\n",
      "     55        0.6426       0.7969        \u001b[35m0.5845\u001b[0m  0.0360\n",
      "     56        0.6676       0.7969        0.5885  0.0360\n",
      "     57        0.6475       0.7969        0.5886  0.0361\n",
      "     58        \u001b[36m0.6062\u001b[0m       0.7969        \u001b[35m0.5809\u001b[0m  0.0362\n",
      "     59        0.6449       0.7969        \u001b[35m0.5793\u001b[0m  0.0363\n",
      "     60        0.6454       0.7969        \u001b[35m0.5780\u001b[0m  0.0362\n",
      "     61        0.6414       0.8047        \u001b[35m0.5764\u001b[0m  0.0360\n",
      "     62        0.6470       0.8047        0.5779  0.0381\n",
      "     63        0.6368       0.8047        \u001b[35m0.5758\u001b[0m  0.0358\n",
      "     64        0.6361       0.8047        \u001b[35m0.5745\u001b[0m  0.0373\n",
      "     65        0.6501       0.7969        0.5759  0.0361\n",
      "     66        0.6429       0.7969        0.5746  0.0359\n",
      "     67        0.6575       0.8047        0.5764  0.0358\n",
      "     68        0.6493       0.7969        0.5750  0.0364\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7155\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6972\u001b[0m  0.0324\n",
      "      2        \u001b[36m0.6972\u001b[0m       0.5000        \u001b[35m0.6920\u001b[0m  0.0358\n",
      "      3        \u001b[36m0.6883\u001b[0m       0.5000        \u001b[35m0.6891\u001b[0m  0.0411\n",
      "      4        0.6953       0.5000        \u001b[35m0.6870\u001b[0m  0.0419\n",
      "      5        \u001b[36m0.6874\u001b[0m       0.5000        \u001b[35m0.6845\u001b[0m  0.0358\n",
      "      6        0.6895       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6830\u001b[0m  0.0407\n",
      "      7        \u001b[36m0.6843\u001b[0m       0.6406        \u001b[35m0.6811\u001b[0m  0.0370\n",
      "      8        0.6881       0.6562        \u001b[35m0.6801\u001b[0m  0.0403\n",
      "      9        0.6843       0.6484        \u001b[35m0.6784\u001b[0m  0.0361\n",
      "     10        \u001b[36m0.6838\u001b[0m       0.6484        \u001b[35m0.6775\u001b[0m  0.0401\n",
      "     11        \u001b[36m0.6777\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6761\u001b[0m  0.0360\n",
      "     12        \u001b[36m0.6767\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6742\u001b[0m  0.0391\n",
      "     13        0.6806       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6730\u001b[0m  0.0449\n",
      "     14        \u001b[36m0.6747\u001b[0m       0.6875        \u001b[35m0.6712\u001b[0m  0.0413\n",
      "     15        \u001b[36m0.6731\u001b[0m       0.6875        \u001b[35m0.6697\u001b[0m  0.0374\n",
      "     16        0.6787       0.6953        \u001b[35m0.6683\u001b[0m  0.0414\n",
      "     17        \u001b[36m0.6688\u001b[0m       0.6953        \u001b[35m0.6655\u001b[0m  0.0360\n",
      "     18        0.6796       0.6875        0.6658  0.0379\n",
      "     19        0.6719       0.7031        \u001b[35m0.6633\u001b[0m  0.0416\n",
      "     20        \u001b[36m0.6662\u001b[0m       0.7031        \u001b[35m0.6610\u001b[0m  0.0362\n",
      "     21        \u001b[36m0.6584\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6586\u001b[0m  0.0379\n",
      "     22        0.6604       0.7188        \u001b[35m0.6572\u001b[0m  0.0411\n",
      "     23        0.6687       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6560\u001b[0m  0.0378\n",
      "     24        0.6669       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6539\u001b[0m  0.0364\n",
      "     25        0.6752       0.7344        \u001b[35m0.6534\u001b[0m  0.0397\n",
      "     26        0.6627       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6515\u001b[0m  0.0412\n",
      "     27        0.6629       0.7344        \u001b[35m0.6487\u001b[0m  0.0416\n",
      "     28        0.6636       0.7422        \u001b[35m0.6475\u001b[0m  0.0359\n",
      "     29        0.6724       0.7188        0.6489  0.0370\n",
      "     30        \u001b[36m0.6453\u001b[0m       0.7188        \u001b[35m0.6464\u001b[0m  0.0397\n",
      "     31        0.6694       0.7266        0.6469  0.0410\n",
      "     32        0.6675       0.7266        \u001b[35m0.6463\u001b[0m  0.0415\n",
      "     33        \u001b[36m0.6423\u001b[0m       0.7266        \u001b[35m0.6434\u001b[0m  0.0365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34        0.6563       0.7422        \u001b[35m0.6406\u001b[0m  0.0358\n",
      "     35        0.6589       0.7422        0.6408  0.0383\n",
      "     36        0.6676       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6390\u001b[0m  0.0394\n",
      "     37        0.6572       0.7422        \u001b[35m0.6375\u001b[0m  0.0405\n",
      "     38        0.6569       0.7344        \u001b[35m0.6374\u001b[0m  0.0387\n",
      "     39        0.6553       0.7344        \u001b[35m0.6348\u001b[0m  0.0414\n",
      "     40        0.6625       0.7422        0.6368  0.0363\n",
      "     41        0.6584       0.7344        0.6365  0.0366\n",
      "     42        0.6705       0.7344        0.6356  0.0488\n",
      "     43        0.6599       0.7344        \u001b[35m0.6341\u001b[0m  0.0375\n",
      "     44        0.6536       0.7344        \u001b[35m0.6321\u001b[0m  0.0394\n",
      "     45        0.6428       0.7422        \u001b[35m0.6278\u001b[0m  0.0370\n",
      "     46        0.6520       0.7422        0.6280  0.0385\n",
      "     47        0.6523       0.7422        \u001b[35m0.6278\u001b[0m  0.0377\n",
      "     48        0.6650       0.7422        \u001b[35m0.6278\u001b[0m  0.0377\n",
      "     49        0.6547       0.7344        0.6281  0.0373\n",
      "     50        0.6546       0.7500        \u001b[35m0.6254\u001b[0m  0.0418\n",
      "     51        0.6589       0.7500        \u001b[35m0.6247\u001b[0m  0.0372\n",
      "     52        0.6542       0.7422        \u001b[35m0.6246\u001b[0m  0.0410\n",
      "     53        0.6457       0.7422        \u001b[35m0.6203\u001b[0m  0.0362\n",
      "     54        0.6452       0.7500        \u001b[35m0.6183\u001b[0m  0.0383\n",
      "     55        \u001b[36m0.6419\u001b[0m       0.7500        \u001b[35m0.6152\u001b[0m  0.0374\n",
      "     56        0.6513       0.7500        \u001b[35m0.6119\u001b[0m  0.0371\n",
      "     57        0.6477       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6112\u001b[0m  0.0385\n",
      "     58        \u001b[36m0.6373\u001b[0m       0.7500        \u001b[35m0.6085\u001b[0m  0.0362\n",
      "     59        0.6471       0.7500        \u001b[35m0.6077\u001b[0m  0.0368\n",
      "     60        0.6575       0.7500        0.6081  0.0361\n",
      "     61        \u001b[36m0.6363\u001b[0m       0.7500        \u001b[35m0.6063\u001b[0m  0.0359\n",
      "     62        \u001b[36m0.6308\u001b[0m       0.7500        \u001b[35m0.6053\u001b[0m  0.0363\n",
      "     63        0.6496       0.7578        0.6057  0.0417\n",
      "     64        0.6632       0.7422        \u001b[35m0.6040\u001b[0m  0.0374\n",
      "     65        \u001b[36m0.6306\u001b[0m       0.7500        \u001b[35m0.6010\u001b[0m  0.0363\n",
      "     66        \u001b[36m0.6289\u001b[0m       0.7422        \u001b[35m0.5982\u001b[0m  0.0365\n",
      "     67        \u001b[36m0.6281\u001b[0m       0.7500        \u001b[35m0.5968\u001b[0m  0.0355\n",
      "     68        0.6385       0.7500        \u001b[35m0.5955\u001b[0m  0.0362\n",
      "     69        0.6334       0.7500        \u001b[35m0.5932\u001b[0m  0.0376\n",
      "     70        \u001b[36m0.6091\u001b[0m       0.7500        \u001b[35m0.5894\u001b[0m  0.0361\n",
      "     71        0.6420       0.7500        \u001b[35m0.5886\u001b[0m  0.0370\n",
      "     72        0.6487       0.7422        \u001b[35m0.5875\u001b[0m  0.0370\n",
      "     73        0.6150       0.7578        0.5879  0.0362\n",
      "     74        0.6315       0.7578        \u001b[35m0.5872\u001b[0m  0.0361\n",
      "     75        0.6374       0.7578        \u001b[35m0.5868\u001b[0m  0.0374\n",
      "     76        0.6399       0.7422        \u001b[35m0.5848\u001b[0m  0.0357\n",
      "     77        0.6359       0.7422        \u001b[35m0.5841\u001b[0m  0.0360\n",
      "     78        0.6179       0.7422        \u001b[35m0.5821\u001b[0m  0.0369\n",
      "     79        0.6159       0.7422        \u001b[35m0.5821\u001b[0m  0.0358\n",
      "     80        0.6268       0.7422        \u001b[35m0.5814\u001b[0m  0.0365\n",
      "     81        0.6122       0.7422        \u001b[35m0.5796\u001b[0m  0.0405\n",
      "     82        0.6201       0.7422        \u001b[35m0.5790\u001b[0m  0.0358\n",
      "     83        0.6304       0.7422        \u001b[35m0.5782\u001b[0m  0.0368\n",
      "     84        0.6295       0.7422        \u001b[35m0.5773\u001b[0m  0.0364\n",
      "     85        0.6263       0.7500        \u001b[35m0.5767\u001b[0m  0.0361\n",
      "     86        0.6280       0.7422        \u001b[35m0.5753\u001b[0m  0.0371\n",
      "     87        0.6112       0.7422        \u001b[35m0.5722\u001b[0m  0.0372\n",
      "     88        0.6330       0.7500        0.5735  0.0363\n",
      "     89        \u001b[36m0.6036\u001b[0m       0.7500        \u001b[35m0.5707\u001b[0m  0.0364\n",
      "     90        0.6129       0.7500        \u001b[35m0.5705\u001b[0m  0.0380\n",
      "     91        \u001b[36m0.6004\u001b[0m       0.7500        \u001b[35m0.5675\u001b[0m  0.0365\n",
      "     92        0.6262       0.7500        0.5679  0.0374\n",
      "     93        0.6131       0.7500        \u001b[35m0.5661\u001b[0m  0.0364\n",
      "     94        0.6320       0.7578        \u001b[35m0.5661\u001b[0m  0.0361\n",
      "     95        \u001b[36m0.6003\u001b[0m       0.7500        \u001b[35m0.5641\u001b[0m  0.0363\n",
      "     96        0.6085       0.7578        \u001b[35m0.5633\u001b[0m  0.0360\n",
      "     97        0.6222       0.7500        0.5633  0.0360\n",
      "     98        0.6183       0.7500        \u001b[35m0.5625\u001b[0m  0.0433\n",
      "     99        0.6105       0.7500        \u001b[35m0.5599\u001b[0m  0.0361\n",
      "    100        0.6131       0.7500        0.5600  0.0370\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7447\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.7424\u001b[0m  0.0353\n",
      "      2        \u001b[36m0.7260\u001b[0m       0.4922        \u001b[35m0.7289\u001b[0m  0.0366\n",
      "      3        \u001b[36m0.7186\u001b[0m       0.4844        \u001b[35m0.7189\u001b[0m  0.0415\n",
      "      4        \u001b[36m0.7159\u001b[0m       0.4922        \u001b[35m0.7107\u001b[0m  0.0373\n",
      "      5        \u001b[36m0.6968\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.7037\u001b[0m  0.0416\n",
      "      6        \u001b[36m0.6906\u001b[0m       0.5078        \u001b[35m0.6981\u001b[0m  0.0365\n",
      "      7        \u001b[36m0.6899\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6934\u001b[0m  0.0417\n",
      "      8        0.6934       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6897\u001b[0m  0.0359\n",
      "      9        0.6964       0.5391        \u001b[35m0.6868\u001b[0m  0.0426\n",
      "     10        \u001b[36m0.6860\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6841\u001b[0m  0.0419\n",
      "     11        \u001b[36m0.6795\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6812\u001b[0m  0.0421\n",
      "     12        \u001b[36m0.6757\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6781\u001b[0m  0.0383\n",
      "     13        \u001b[36m0.6736\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6746\u001b[0m  0.0424\n",
      "     14        0.6769       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6727\u001b[0m  0.0363\n",
      "     15        \u001b[36m0.6695\u001b[0m       0.6328        \u001b[35m0.6700\u001b[0m  0.0388\n",
      "     16        0.6778       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6686\u001b[0m  0.0424\n",
      "     17        0.6785       0.6406        \u001b[35m0.6680\u001b[0m  0.0409\n",
      "     18        \u001b[36m0.6650\u001b[0m       0.6406        \u001b[35m0.6648\u001b[0m  0.0375\n",
      "     19        0.6701       0.6484        \u001b[35m0.6638\u001b[0m  0.0411\n",
      "     20        0.6750       0.6484        \u001b[35m0.6619\u001b[0m  0.0384\n",
      "     21        0.6715       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6601\u001b[0m  0.0361\n",
      "     22        \u001b[36m0.6598\u001b[0m       0.6641        \u001b[35m0.6583\u001b[0m  0.0412\n",
      "     23        0.6620       0.6484        \u001b[35m0.6547\u001b[0m  0.0407\n",
      "     24        \u001b[36m0.6579\u001b[0m       0.6406        \u001b[35m0.6527\u001b[0m  0.0417\n",
      "     25        0.6689       0.6719        \u001b[35m0.6523\u001b[0m  0.0361\n",
      "     26        0.6708       0.6484        \u001b[35m0.6507\u001b[0m  0.0381\n",
      "     27        0.6612       0.6484        \u001b[35m0.6489\u001b[0m  0.0432\n",
      "     28        0.6676       0.6562        \u001b[35m0.6472\u001b[0m  0.0401\n",
      "     29        0.6633       0.6719        \u001b[35m0.6468\u001b[0m  0.0416\n",
      "     30        \u001b[36m0.6577\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6448\u001b[0m  0.0367\n",
      "     31        0.6659       0.6641        0.6451  0.0361\n",
      "     32        \u001b[36m0.6576\u001b[0m       0.6797        \u001b[35m0.6421\u001b[0m  0.0377\n",
      "     33        0.6645       0.6797        \u001b[35m0.6410\u001b[0m  0.0410\n",
      "     34        0.6711       0.6797        0.6418  0.0402\n",
      "     35        0.6644       \u001b[32m0.6875\u001b[0m        0.6412  0.0404\n",
      "     36        0.6583       0.6797        \u001b[35m0.6376\u001b[0m  0.0404\n",
      "     37        0.6597       0.6797        \u001b[35m0.6362\u001b[0m  0.0407\n",
      "     38        0.6625       0.6797        0.6363  0.0415\n",
      "     39        \u001b[36m0.6513\u001b[0m       0.6875        \u001b[35m0.6348\u001b[0m  0.0402\n",
      "     40        \u001b[36m0.6454\u001b[0m       0.6875        \u001b[35m0.6320\u001b[0m  0.0407\n",
      "     41        \u001b[36m0.6429\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6294\u001b[0m  0.0409\n",
      "     42        0.6701       0.6875        0.6309  0.0465\n",
      "     43        0.6507       0.6875        0.6296  0.0415\n",
      "     44        0.6573       0.7031        0.6296  0.0424\n",
      "     45        0.6646       0.6953        \u001b[35m0.6292\u001b[0m  0.0411\n",
      "     46        \u001b[36m0.6414\u001b[0m       0.6953        \u001b[35m0.6259\u001b[0m  0.0432\n",
      "     47        0.6751       0.6953        0.6282  0.0360\n",
      "     48        0.6524       0.7031        0.6265  0.0366\n",
      "     49        0.6494       0.7031        0.6275  0.0366\n",
      "     50        0.6611       0.7031        0.6273  0.0379\n",
      "     51        0.6537       0.7031        \u001b[35m0.6257\u001b[0m  0.0366\n",
      "     52        0.6523       0.7031        \u001b[35m0.6241\u001b[0m  0.0361\n",
      "     53        0.6509       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6224\u001b[0m  0.0379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     54        0.6617       0.7031        0.6241  0.0369\n",
      "     55        \u001b[36m0.6401\u001b[0m       0.7109        \u001b[35m0.6188\u001b[0m  0.0361\n",
      "     56        0.6657       \u001b[32m0.7344\u001b[0m        0.6193  0.0413\n",
      "     57        0.6539       0.7344        0.6189  0.0360\n",
      "     58        0.6478       0.7344        \u001b[35m0.6155\u001b[0m  0.0361\n",
      "     59        \u001b[36m0.6394\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6148\u001b[0m  0.0362\n",
      "     60        0.6607       0.7344        0.6152  0.0391\n",
      "     61        0.6453       0.7344        \u001b[35m0.6140\u001b[0m  0.0363\n",
      "     62        0.6506       0.7344        \u001b[35m0.6139\u001b[0m  0.0362\n",
      "     63        0.6516       0.7344        \u001b[35m0.6124\u001b[0m  0.0362\n",
      "     64        0.6397       0.7344        \u001b[35m0.6113\u001b[0m  0.0364\n",
      "     65        0.6494       0.7422        \u001b[35m0.6107\u001b[0m  0.0359\n",
      "     66        0.6495       0.7422        \u001b[35m0.6101\u001b[0m  0.0358\n",
      "     67        0.6426       0.7344        \u001b[35m0.6081\u001b[0m  0.0374\n",
      "     68        0.6442       0.7422        \u001b[35m0.6076\u001b[0m  0.0358\n",
      "     69        0.6441       0.7422        \u001b[35m0.6071\u001b[0m  0.0360\n",
      "     70        0.6453       0.7344        0.6075  0.0365\n",
      "     71        \u001b[36m0.6393\u001b[0m       0.7344        0.6090  0.0374\n",
      "     72        0.6474       0.7344        0.6098  0.0379\n",
      "     73        \u001b[36m0.6251\u001b[0m       0.7422        \u001b[35m0.6052\u001b[0m  0.0358\n",
      "     74        0.6394       0.7422        \u001b[35m0.6031\u001b[0m  0.0361\n",
      "     75        0.6507       0.7344        \u001b[35m0.6023\u001b[0m  0.0364\n",
      "     76        0.6309       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6001\u001b[0m  0.0359\n",
      "     77        0.6409       0.7422        0.6011  0.0388\n",
      "     78        0.6307       0.7422        \u001b[35m0.5994\u001b[0m  0.0370\n",
      "     79        0.6345       0.7344        0.6001  0.0358\n",
      "     80        \u001b[36m0.6237\u001b[0m       0.7422        \u001b[35m0.5975\u001b[0m  0.0362\n",
      "     81        0.6467       0.7422        \u001b[35m0.5974\u001b[0m  0.0361\n",
      "     82        \u001b[36m0.6210\u001b[0m       0.7422        \u001b[35m0.5955\u001b[0m  0.0364\n",
      "     83        0.6422       0.7344        0.5972  0.0362\n",
      "     84        0.6386       0.7344        0.5963  0.0360\n",
      "     85        0.6294       0.7500        \u001b[35m0.5925\u001b[0m  0.0360\n",
      "     86        0.6216       0.7500        \u001b[35m0.5912\u001b[0m  0.0358\n",
      "     87        0.6377       0.7500        \u001b[35m0.5904\u001b[0m  0.0362\n",
      "     88        \u001b[36m0.6189\u001b[0m       0.7500        \u001b[35m0.5872\u001b[0m  0.0365\n",
      "     89        0.6505       0.7500        0.5895  0.0362\n",
      "     90        0.6402       0.7500        0.5913  0.0358\n",
      "     91        0.6412       0.7344        0.5925  0.0362\n",
      "     92        0.6497       0.7344        0.5951  0.0357\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7038\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.6918\u001b[0m  0.0335\n",
      "      2        \u001b[36m0.7014\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6903\u001b[0m  0.0366\n",
      "      3        0.7042       0.4766        \u001b[35m0.6898\u001b[0m  0.0377\n",
      "      4        \u001b[36m0.6931\u001b[0m       0.4766        \u001b[35m0.6892\u001b[0m  0.0437\n",
      "      5        \u001b[36m0.6893\u001b[0m       0.5000        \u001b[35m0.6884\u001b[0m  0.0365\n",
      "      6        0.6896       0.5312        \u001b[35m0.6880\u001b[0m  0.0415\n",
      "      7        0.6945       0.5234        \u001b[35m0.6878\u001b[0m  0.0361\n",
      "      8        0.6927       0.5234        \u001b[35m0.6876\u001b[0m  0.0415\n",
      "      9        0.6953       0.5078        \u001b[35m0.6875\u001b[0m  0.0361\n",
      "     10        0.6916       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6870\u001b[0m  0.0405\n",
      "     11        0.6907       0.5469        \u001b[35m0.6865\u001b[0m  0.0371\n",
      "     12        \u001b[36m0.6871\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6856\u001b[0m  0.0387\n",
      "     13        0.6902       0.5547        \u001b[35m0.6852\u001b[0m  0.0410\n",
      "     14        0.6944       0.5312        \u001b[35m0.6851\u001b[0m  0.0364\n",
      "     15        \u001b[36m0.6832\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6840\u001b[0m  0.0409\n",
      "     16        0.6874       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6833\u001b[0m  0.0360\n",
      "     17        0.6885       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6825\u001b[0m  0.0396\n",
      "     18        \u001b[36m0.6815\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6809\u001b[0m  0.0374\n",
      "     19        0.6824       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6796\u001b[0m  0.0370\n",
      "     20        0.6832       0.6328        \u001b[35m0.6784\u001b[0m  0.0415\n",
      "     21        0.6857       0.6250        \u001b[35m0.6775\u001b[0m  0.0359\n",
      "     22        0.6817       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6763\u001b[0m  0.0363\n",
      "     23        \u001b[36m0.6769\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6746\u001b[0m  0.0406\n",
      "     24        0.6792       0.6484        \u001b[35m0.6731\u001b[0m  0.0358\n",
      "     25        0.6864       0.6562        \u001b[35m0.6727\u001b[0m  0.0365\n",
      "     26        \u001b[36m0.6699\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6702\u001b[0m  0.0426\n",
      "     27        0.6788       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6690\u001b[0m  0.0360\n",
      "     28        0.6755       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6675\u001b[0m  0.0412\n",
      "     29        \u001b[36m0.6697\u001b[0m       0.7031        \u001b[35m0.6654\u001b[0m  0.0362\n",
      "     30        0.6742       0.7031        \u001b[35m0.6641\u001b[0m  0.0369\n",
      "     31        0.6715       0.6953        \u001b[35m0.6626\u001b[0m  0.0393\n",
      "     32        \u001b[36m0.6646\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6599\u001b[0m  0.0360\n",
      "     33        0.6698       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6580\u001b[0m  0.0361\n",
      "     34        0.6764       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6567\u001b[0m  0.0370\n",
      "     35        \u001b[36m0.6573\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6543\u001b[0m  0.0383\n",
      "     36        0.6717       0.7109        0.6544  0.0414\n",
      "     37        \u001b[36m0.6497\u001b[0m       0.7188        \u001b[35m0.6506\u001b[0m  0.0380\n",
      "     38        0.6545       0.7266        \u001b[35m0.6480\u001b[0m  0.0360\n",
      "     39        0.6527       0.7266        \u001b[35m0.6458\u001b[0m  0.0362\n",
      "     40        0.6622       0.7344        \u001b[35m0.6442\u001b[0m  0.0387\n",
      "     41        0.6795       0.7344        0.6447  0.0364\n",
      "     42        0.6600       0.7344        \u001b[35m0.6433\u001b[0m  0.0374\n",
      "     43        0.6656       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6429\u001b[0m  0.0370\n",
      "     44        0.6622       0.7422        \u001b[35m0.6419\u001b[0m  0.0388\n",
      "     45        0.6617       0.7344        \u001b[35m0.6409\u001b[0m  0.0391\n",
      "     46        \u001b[36m0.6471\u001b[0m       0.7344        \u001b[35m0.6361\u001b[0m  0.0389\n",
      "     47        \u001b[36m0.6337\u001b[0m       0.7422        \u001b[35m0.6327\u001b[0m  0.0392\n",
      "     48        0.6522       0.7422        \u001b[35m0.6301\u001b[0m  0.0377\n",
      "     49        0.6535       0.7422        \u001b[35m0.6287\u001b[0m  0.0384\n",
      "     50        0.6509       0.7344        \u001b[35m0.6281\u001b[0m  0.0517\n",
      "     51        0.6662       0.7266        0.6294  0.0361\n",
      "     52        0.6632       0.7266        0.6284  0.0394\n",
      "     53        0.6573       0.7266        \u001b[35m0.6281\u001b[0m  0.0381\n",
      "     54        0.6662       0.7266        0.6283  0.0368\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7056\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7041\u001b[0m  0.0322\n",
      "      2        \u001b[36m0.6922\u001b[0m       0.5000        \u001b[35m0.6943\u001b[0m  0.0362\n",
      "      3        \u001b[36m0.6875\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6870\u001b[0m  0.0380\n",
      "      4        0.6879       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6812\u001b[0m  0.0411\n",
      "      5        \u001b[36m0.6796\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6768\u001b[0m  0.0375\n",
      "      6        \u001b[36m0.6760\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6728\u001b[0m  0.0417\n",
      "      7        0.6769       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6697\u001b[0m  0.0408\n",
      "      8        0.6772       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6674\u001b[0m  0.0406\n",
      "      9        0.6763       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6648\u001b[0m  0.0434\n",
      "     10        \u001b[36m0.6714\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6629\u001b[0m  0.0429\n",
      "     11        \u001b[36m0.6664\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6597\u001b[0m  0.0372\n",
      "     12        0.6737       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6574\u001b[0m  0.0418\n",
      "     13        0.6665       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6540\u001b[0m  0.0360\n",
      "     14        0.6817       0.7109        0.6552  0.0438\n",
      "     15        \u001b[36m0.6547\u001b[0m       0.7188        \u001b[35m0.6521\u001b[0m  0.0401\n",
      "     16        0.6682       0.6875        \u001b[35m0.6514\u001b[0m  0.0432\n",
      "     17        \u001b[36m0.6476\u001b[0m       0.7109        \u001b[35m0.6483\u001b[0m  0.0359\n",
      "     18        0.6502       0.7188        \u001b[35m0.6456\u001b[0m  0.0396\n",
      "     19        0.6622       0.7188        \u001b[35m0.6443\u001b[0m  0.0418\n",
      "     20        0.6564       0.7188        \u001b[35m0.6421\u001b[0m  0.0416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     21        0.6527       0.7109        \u001b[35m0.6405\u001b[0m  0.0364\n",
      "     22        0.6618       0.7031        \u001b[35m0.6391\u001b[0m  0.0397\n",
      "     23        0.6497       0.7031        \u001b[35m0.6363\u001b[0m  0.0357\n",
      "     24        0.6515       0.7031        \u001b[35m0.6342\u001b[0m  0.0361\n",
      "     25        0.6643       0.6953        \u001b[35m0.6332\u001b[0m  0.0422\n",
      "     26        0.6526       0.7031        \u001b[35m0.6306\u001b[0m  0.0355\n",
      "     27        \u001b[36m0.6361\u001b[0m       0.7031        \u001b[35m0.6276\u001b[0m  0.0363\n",
      "     28        0.6562       0.6953        \u001b[35m0.6267\u001b[0m  0.0379\n",
      "     29        0.6514       0.6797        \u001b[35m0.6256\u001b[0m  0.0408\n",
      "     30        0.6412       0.7031        \u001b[35m0.6238\u001b[0m  0.0358\n",
      "     31        0.6614       0.6719        0.6243  0.0359\n",
      "     32        \u001b[36m0.6334\u001b[0m       0.6797        \u001b[35m0.6219\u001b[0m  0.0376\n",
      "     33        0.6494       0.6641        \u001b[35m0.6212\u001b[0m  0.0407\n",
      "     34        0.6629       0.6641        0.6219  0.0363\n",
      "     35        0.6506       0.6641        \u001b[35m0.6211\u001b[0m  0.0363\n",
      "     36        0.6545       0.6641        \u001b[35m0.6207\u001b[0m  0.0400\n",
      "     37        0.6365       0.6797        \u001b[35m0.6190\u001b[0m  0.0361\n",
      "     38        0.6468       0.6875        \u001b[35m0.6184\u001b[0m  0.0390\n",
      "     39        0.6496       0.6797        \u001b[35m0.6183\u001b[0m  0.0381\n",
      "     40        0.6461       0.6875        \u001b[35m0.6173\u001b[0m  0.0409\n",
      "     41        0.6339       0.6875        \u001b[35m0.6163\u001b[0m  0.0361\n",
      "     42        0.6360       0.6875        \u001b[35m0.6156\u001b[0m  0.0415\n",
      "     43        \u001b[36m0.6155\u001b[0m       0.6875        \u001b[35m0.6142\u001b[0m  0.0360\n",
      "     44        0.6438       0.6797        0.6147  0.0410\n",
      "     45        0.6338       0.6797        \u001b[35m0.6137\u001b[0m  0.0358\n",
      "     46        0.6244       0.6797        \u001b[35m0.6130\u001b[0m  0.0373\n",
      "     47        0.6352       0.6875        \u001b[35m0.6124\u001b[0m  0.0358\n",
      "     48        0.6260       0.6797        \u001b[35m0.6114\u001b[0m  0.0360\n",
      "     49        0.6514       0.6797        0.6115  0.0373\n",
      "     50        0.6172       0.6797        \u001b[35m0.6094\u001b[0m  0.0358\n",
      "     51        0.6431       0.6797        \u001b[35m0.6090\u001b[0m  0.0362\n",
      "     52        \u001b[36m0.6145\u001b[0m       0.6875        \u001b[35m0.6071\u001b[0m  0.0359\n",
      "     53        0.6263       0.6797        \u001b[35m0.6062\u001b[0m  0.0359\n",
      "     54        0.6311       0.6797        0.6063  0.0359\n",
      "     55        0.6237       0.6797        \u001b[35m0.6052\u001b[0m  0.0361\n",
      "     56        0.6475       0.6797        0.6055  0.0538\n",
      "     57        \u001b[36m0.5987\u001b[0m       0.6797        \u001b[35m0.6034\u001b[0m  0.0357\n",
      "     58        0.6041       0.6797        \u001b[35m0.6023\u001b[0m  0.0365\n",
      "     59        0.6230       0.6797        \u001b[35m0.6022\u001b[0m  0.0373\n",
      "     60        0.6233       0.6797        \u001b[35m0.6015\u001b[0m  0.0363\n",
      "     61        0.6243       0.6797        \u001b[35m0.6010\u001b[0m  0.0365\n",
      "     62        0.6091       0.6797        \u001b[35m0.6002\u001b[0m  0.0359\n",
      "     63        0.6236       0.6797        \u001b[35m0.5997\u001b[0m  0.0370\n",
      "     64        0.6066       0.6797        \u001b[35m0.5994\u001b[0m  0.0362\n",
      "     65        0.6262       0.6797        0.5997  0.0359\n",
      "     66        0.6111       0.6797        \u001b[35m0.5992\u001b[0m  0.0360\n",
      "     67        0.6070       0.6797        \u001b[35m0.5986\u001b[0m  0.0359\n",
      "     68        0.6362       0.6719        \u001b[35m0.5984\u001b[0m  0.0357\n",
      "     69        0.6295       0.6797        0.5986  0.0374\n",
      "     70        0.6374       0.6797        \u001b[35m0.5984\u001b[0m  0.0367\n",
      "     71        0.6075       0.6797        \u001b[35m0.5974\u001b[0m  0.0448\n",
      "     72        0.6200       0.6797        \u001b[35m0.5968\u001b[0m  0.0366\n",
      "     73        0.6086       0.6875        \u001b[35m0.5965\u001b[0m  0.0359\n",
      "     74        \u001b[36m0.5930\u001b[0m       0.6797        0.5972  0.0360\n",
      "     75        0.6086       0.6797        0.5970  0.0362\n",
      "     76        0.6053       0.6797        0.5969  0.0362\n",
      "     77        0.6200       0.6875        0.5975  0.0371\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7950\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6618\u001b[0m  0.0121\n",
      "      2        \u001b[36m0.7095\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6465\u001b[0m  0.0137\n",
      "      3        \u001b[36m0.7029\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6155\u001b[0m  0.0164\n",
      "      4        \u001b[36m0.6854\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5813\u001b[0m  0.0185\n",
      "      5        \u001b[36m0.6492\u001b[0m       0.7656        \u001b[35m0.5477\u001b[0m  0.0227\n",
      "      6        \u001b[36m0.6329\u001b[0m       0.7578        \u001b[35m0.5186\u001b[0m  0.0171\n",
      "      7        \u001b[36m0.6309\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4960\u001b[0m  0.0226\n",
      "      8        \u001b[36m0.6009\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4845\u001b[0m  0.0174\n",
      "      9        \u001b[36m0.5811\u001b[0m       0.7969        \u001b[35m0.4691\u001b[0m  0.0231\n",
      "     10        0.5983       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4612\u001b[0m  0.0203\n",
      "     11        0.5896       0.8047        \u001b[35m0.4584\u001b[0m  0.0250\n",
      "     12        0.5988       0.8047        \u001b[35m0.4541\u001b[0m  0.0180\n",
      "     13        \u001b[36m0.5759\u001b[0m       0.7969        \u001b[35m0.4499\u001b[0m  0.0209\n",
      "     14        0.5826       0.7969        \u001b[35m0.4418\u001b[0m  0.0155\n",
      "     15        \u001b[36m0.5668\u001b[0m       0.8047        \u001b[35m0.4322\u001b[0m  0.0163\n",
      "     16        0.5737       0.8047        \u001b[35m0.4312\u001b[0m  0.0217\n",
      "     17        0.5668       0.7969        0.4322  0.0184\n",
      "     18        0.5686       0.7969        \u001b[35m0.4259\u001b[0m  0.0257\n",
      "     19        \u001b[36m0.5516\u001b[0m       0.8047        \u001b[35m0.4208\u001b[0m  0.0197\n",
      "     20        \u001b[36m0.5417\u001b[0m       0.8047        \u001b[35m0.4160\u001b[0m  0.0195\n",
      "     21        0.5545       0.8047        \u001b[35m0.4141\u001b[0m  0.0147\n",
      "     22        0.5572       0.8047        \u001b[35m0.4105\u001b[0m  0.0247\n",
      "     23        0.5689       0.8047        0.4123  0.0166\n",
      "     24        \u001b[36m0.5360\u001b[0m       0.8047        \u001b[35m0.4056\u001b[0m  0.0166\n",
      "     25        0.5424       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4013\u001b[0m  0.0237\n",
      "     26        0.5566       0.8125        \u001b[35m0.3995\u001b[0m  0.0155\n",
      "     27        0.5382       \u001b[32m0.8203\u001b[0m        \u001b[35m0.3957\u001b[0m  0.0156\n",
      "     28        0.5427       0.8047        0.3970  0.0246\n",
      "     29        0.5376       0.8125        0.3962  0.0246\n",
      "     30        \u001b[36m0.5196\u001b[0m       0.8203        \u001b[35m0.3908\u001b[0m  0.0172\n",
      "     31        0.5353       0.8203        \u001b[35m0.3897\u001b[0m  0.0160\n",
      "     32        0.5369       0.7969        0.3910  0.0234\n",
      "     33        0.5213       0.8125        \u001b[35m0.3886\u001b[0m  0.0252\n",
      "     34        0.5222       0.8047        \u001b[35m0.3809\u001b[0m  0.0159\n",
      "     35        \u001b[36m0.5110\u001b[0m       0.8047        0.3864  0.0233\n",
      "     36        0.5334       0.8125        0.3847  0.0256\n",
      "     37        0.5163       0.8203        0.3863  0.0156\n",
      "     38        0.5163       0.8047        \u001b[35m0.3800\u001b[0m  0.0228\n",
      "     39        \u001b[36m0.5051\u001b[0m       0.8125        0.3834  0.0237\n",
      "     40        0.5165       0.8047        0.3844  0.0164\n",
      "     41        0.5157       0.8047        0.3820  0.0205\n",
      "     42        0.5308       0.8047        0.3826  0.0173\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7452\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6672\u001b[0m  0.0230\n",
      "      2        \u001b[36m0.7069\u001b[0m       0.6641        \u001b[35m0.6510\u001b[0m  0.0207\n",
      "      3        \u001b[36m0.7010\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6187\u001b[0m  0.0158\n",
      "      4        \u001b[36m0.6641\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5884\u001b[0m  0.0206\n",
      "      5        \u001b[36m0.6478\u001b[0m       0.7266        \u001b[35m0.5651\u001b[0m  0.0168\n",
      "      6        \u001b[36m0.6399\u001b[0m       0.7266        \u001b[35m0.5538\u001b[0m  0.0160\n",
      "      7        \u001b[36m0.6142\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5493\u001b[0m  0.0198\n",
      "      8        \u001b[36m0.6094\u001b[0m       0.7344        \u001b[35m0.5410\u001b[0m  0.0198\n",
      "      9        \u001b[36m0.5807\u001b[0m       0.7422        \u001b[35m0.5375\u001b[0m  0.0181\n",
      "     10        0.6076       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5296\u001b[0m  0.0218\n",
      "     11        0.5822       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5264\u001b[0m  0.0161\n",
      "     12        \u001b[36m0.5644\u001b[0m       0.7656        \u001b[35m0.5251\u001b[0m  0.0161\n",
      "     13        0.5723       0.7578        \u001b[35m0.5219\u001b[0m  0.0183\n",
      "     14        0.5703       0.7656        0.5233  0.0229\n",
      "     15        0.5741       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5210\u001b[0m  0.0174\n",
      "     16        0.5704       0.7578        \u001b[35m0.5184\u001b[0m  0.0226\n",
      "     17        \u001b[36m0.5423\u001b[0m       0.7734        \u001b[35m0.5182\u001b[0m  0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        0.5705       0.7734        \u001b[35m0.5146\u001b[0m  0.0163\n",
      "     19        0.5554       0.7734        \u001b[35m0.5144\u001b[0m  0.0169\n",
      "     20        0.5626       0.7422        \u001b[35m0.5116\u001b[0m  0.0221\n",
      "     21        \u001b[36m0.5214\u001b[0m       0.7422        0.5136  0.0192\n",
      "     22        0.5311       0.7500        0.5135  0.0247\n",
      "     23        0.5280       0.7656        0.5121  0.0172\n",
      "     24        0.5435       0.7422        \u001b[35m0.5094\u001b[0m  0.0230\n",
      "     25        0.5226       0.7500        \u001b[35m0.5089\u001b[0m  0.0196\n",
      "     26        0.5243       0.7500        \u001b[35m0.5077\u001b[0m  0.0153\n",
      "     27        0.5261       0.7422        0.5119  0.0238\n",
      "     28        0.5489       0.7422        \u001b[35m0.5064\u001b[0m  0.0200\n",
      "     29        0.5225       0.7422        \u001b[35m0.5061\u001b[0m  0.0154\n",
      "     30        0.5235       0.7422        0.5101  0.0198\n",
      "     31        0.5367       0.7422        0.5074  0.0161\n",
      "     32        0.5236       0.7578        0.5072  0.0239\n",
      "     33        0.5359       0.7500        0.5094  0.0223\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7215\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6814\u001b[0m  0.0125\n",
      "      2        \u001b[36m0.6941\u001b[0m       0.5391        \u001b[35m0.6677\u001b[0m  0.0155\n",
      "      3        \u001b[36m0.6880\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6422\u001b[0m  0.0160\n",
      "      4        \u001b[36m0.6542\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6054\u001b[0m  0.0212\n",
      "      5        \u001b[36m0.6328\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5786\u001b[0m  0.0189\n",
      "      6        \u001b[36m0.6085\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.5649\u001b[0m  0.0163\n",
      "      7        \u001b[36m0.5744\u001b[0m       0.7734        \u001b[35m0.5537\u001b[0m  0.0255\n",
      "      8        0.6117       0.7500        \u001b[35m0.5463\u001b[0m  0.0218\n",
      "      9        \u001b[36m0.5708\u001b[0m       0.7500        \u001b[35m0.5443\u001b[0m  0.0147\n",
      "     10        \u001b[36m0.5587\u001b[0m       0.7422        \u001b[35m0.5421\u001b[0m  0.0213\n",
      "     11        \u001b[36m0.5552\u001b[0m       0.7344        \u001b[35m0.5379\u001b[0m  0.0165\n",
      "     12        \u001b[36m0.5523\u001b[0m       0.7422        \u001b[35m0.5375\u001b[0m  0.0233\n",
      "     13        \u001b[36m0.5340\u001b[0m       0.7344        \u001b[35m0.5353\u001b[0m  0.0222\n",
      "     14        \u001b[36m0.5325\u001b[0m       0.7344        \u001b[35m0.5330\u001b[0m  0.0234\n",
      "     15        0.5443       0.7422        \u001b[35m0.5298\u001b[0m  0.0212\n",
      "     16        0.5365       0.7500        \u001b[35m0.5289\u001b[0m  0.0145\n",
      "     17        \u001b[36m0.4991\u001b[0m       0.7500        0.5306  0.0219\n",
      "     18        0.5193       0.7422        \u001b[35m0.5283\u001b[0m  0.0151\n",
      "     19        0.5279       0.7422        \u001b[35m0.5272\u001b[0m  0.0213\n",
      "     20        0.5224       0.7500        \u001b[35m0.5270\u001b[0m  0.0143\n",
      "     21        \u001b[36m0.4989\u001b[0m       0.7422        \u001b[35m0.5264\u001b[0m  0.0225\n",
      "     22        0.5171       0.7422        0.5268  0.0139\n",
      "     23        0.4999       0.7422        0.5271  0.0218\n",
      "     24        0.5048       0.7344        \u001b[35m0.5259\u001b[0m  0.0149\n",
      "     25        0.5003       0.7422        \u001b[35m0.5258\u001b[0m  0.0231\n",
      "     26        0.5093       0.7422        \u001b[35m0.5232\u001b[0m  0.0145\n",
      "     27        0.4991       0.7344        0.5249  0.0214\n",
      "     28        0.5133       0.7422        0.5233  0.0145\n",
      "     29        \u001b[36m0.4810\u001b[0m       0.7578        \u001b[35m0.5230\u001b[0m  0.0225\n",
      "     30        \u001b[36m0.4710\u001b[0m       0.7500        0.5249  0.0144\n",
      "     31        0.4883       0.7578        \u001b[35m0.5228\u001b[0m  0.0220\n",
      "     32        0.5021       0.7578        \u001b[35m0.5204\u001b[0m  0.0142\n",
      "     33        0.4961       0.7578        \u001b[35m0.5196\u001b[0m  0.0203\n",
      "     34        0.4956       0.7422        0.5233  0.0149\n",
      "     35        0.4856       0.7344        0.5235  0.0212\n",
      "     36        0.4857       0.7500        0.5213  0.0139\n",
      "     37        0.4819       0.7422        0.5235  0.0213\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7424\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6829\u001b[0m  0.0137\n",
      "      2        \u001b[36m0.6849\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6684\u001b[0m  0.0219\n",
      "      3        \u001b[36m0.6709\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6408\u001b[0m  0.0164\n",
      "      4        \u001b[36m0.6321\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5999\u001b[0m  0.0229\n",
      "      5        \u001b[36m0.5933\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5721\u001b[0m  0.0193\n",
      "      6        \u001b[36m0.5762\u001b[0m       0.7266        \u001b[35m0.5558\u001b[0m  0.0233\n",
      "      7        \u001b[36m0.5659\u001b[0m       0.7109        \u001b[35m0.5445\u001b[0m  0.0206\n",
      "      8        0.5801       0.7109        \u001b[35m0.5359\u001b[0m  0.0235\n",
      "      9        \u001b[36m0.5362\u001b[0m       0.7188        \u001b[35m0.5302\u001b[0m  0.0198\n",
      "     10        0.5426       0.7109        \u001b[35m0.5286\u001b[0m  0.0239\n",
      "     11        0.5474       0.7266        \u001b[35m0.5234\u001b[0m  0.0177\n",
      "     12        0.5394       0.7344        \u001b[35m0.5190\u001b[0m  0.0234\n",
      "     13        \u001b[36m0.5041\u001b[0m       0.7344        \u001b[35m0.5142\u001b[0m  0.0178\n",
      "     14        0.5294       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5125\u001b[0m  0.0240\n",
      "     15        0.5124       0.7422        \u001b[35m0.5094\u001b[0m  0.0181\n",
      "     16        0.5077       0.7188        0.5132  0.0293\n",
      "     17        \u001b[36m0.4979\u001b[0m       0.7422        0.5115  0.0166\n",
      "     18        0.4990       0.7422        0.5124  0.0232\n",
      "     19        0.5067       0.7422        0.5112  0.0201\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7477\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6901\u001b[0m  0.0297\n",
      "      2        \u001b[36m0.7250\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6752\u001b[0m  0.0157\n",
      "      3        \u001b[36m0.7110\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6496\u001b[0m  0.0232\n",
      "      4        \u001b[36m0.6828\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6205\u001b[0m  0.0176\n",
      "      5        \u001b[36m0.6471\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.5892\u001b[0m  0.0257\n",
      "      6        \u001b[36m0.6183\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5657\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.5940\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5446\u001b[0m  0.0216\n",
      "      8        \u001b[36m0.5880\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5366\u001b[0m  0.0155\n",
      "      9        \u001b[36m0.5705\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5313\u001b[0m  0.0209\n",
      "     10        \u001b[36m0.5455\u001b[0m       0.7344        \u001b[35m0.5268\u001b[0m  0.0159\n",
      "     11        \u001b[36m0.5446\u001b[0m       0.7422        0.5303  0.0205\n",
      "     12        0.5511       \u001b[32m0.7500\u001b[0m        0.5344  0.0158\n",
      "     13        \u001b[36m0.5391\u001b[0m       0.7188        0.5301  0.0186\n",
      "     14        \u001b[36m0.5362\u001b[0m       0.7188        0.5349  0.0240\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.3321\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.4170\u001b[0m  0.0532\n",
      "      2        0.4976       0.5000        \u001b[35m1.8709\u001b[0m  0.0518\n",
      "      3        0.5308       0.5000        \u001b[35m1.8688\u001b[0m  0.0555\n",
      "      4        0.5298       0.5000        1.8710  0.0554\n",
      "      5        0.5316       0.5000        1.8699  0.0544\n",
      "      6        0.4956       0.5000        2.8860  0.0494\n",
      "      7        0.5438       0.5000        1.8710  0.0440\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.3325\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m3.3792\u001b[0m  0.0400\n",
      "      2        0.5005       0.5000        \u001b[35m2.6414\u001b[0m  0.0341\n",
      "      3        0.4205       0.5000        \u001b[35m1.6365\u001b[0m  0.0396\n",
      "      4        0.3891       0.5000        1.6781  0.0360\n",
      "      5        0.3740       \u001b[32m0.5312\u001b[0m        \u001b[35m1.6354\u001b[0m  0.0396\n",
      "      6        0.3631       0.5000        \u001b[35m1.6250\u001b[0m  0.0371\n",
      "      7        0.3840       \u001b[32m0.5391\u001b[0m        1.6409  0.0410\n",
      "      8        0.3837       0.5234        1.7108  0.0370\n",
      "      9        0.3685       \u001b[32m0.5547\u001b[0m        \u001b[35m1.5509\u001b[0m  0.0394\n",
      "     10        0.3544       0.5547        1.5668  0.0361\n",
      "     11        0.3518       0.5156        1.6214  0.0425\n",
      "     12        0.3646       0.5234        1.7386  0.0346\n",
      "     13        0.3783       \u001b[32m0.5625\u001b[0m        1.5650  0.0397\n",
      "     14        0.3795       \u001b[32m0.5859\u001b[0m        \u001b[35m1.5234\u001b[0m  0.0347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15        0.3593       \u001b[32m0.6094\u001b[0m        \u001b[35m1.3938\u001b[0m  0.0393\n",
      "     16        0.3621       0.6016        1.4033  0.0377\n",
      "     17        0.3698       0.5859        1.4138  0.0345\n",
      "     18        0.3681       0.5859        1.4329  0.0344\n",
      "     19        0.3659       0.5859        1.4369  0.0395\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5385\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.2728\u001b[0m  0.0322\n",
      "      2        0.7059       0.5000        \u001b[35m1.8271\u001b[0m  0.0355\n",
      "      3        0.7171       0.5000        1.8283  0.0396\n",
      "      4        0.7137       0.5000        \u001b[35m1.8262\u001b[0m  0.0359\n",
      "      5        0.6914       0.5000        3.2077  0.0412\n",
      "      6        0.7520       0.5000        1.8274  0.0355\n",
      "      7        0.7139       0.5000        1.8265  0.0404\n",
      "      8        0.7128       0.5000        \u001b[35m1.8207\u001b[0m  0.0378\n",
      "      9        0.6560       0.5000        2.4060  0.0404\n",
      "     10        0.6884       0.5000        1.8277  0.0360\n",
      "     11        0.7141       0.5000        1.8277  0.0395\n",
      "     12        0.7141       0.5000        1.8277  0.0361\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4772\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.6860\u001b[0m  0.0313\n",
      "      2        0.6033       0.5000        \u001b[35m1.5342\u001b[0m  0.0366\n",
      "      3        0.5519       \u001b[32m0.6016\u001b[0m        \u001b[35m1.2819\u001b[0m  0.0385\n",
      "      4        0.5464       0.5859        \u001b[35m1.2151\u001b[0m  0.0344\n",
      "      5        0.5397       0.5859        1.2451  0.0393\n",
      "      6        0.5266       0.5547        1.3155  0.0361\n",
      "      7        0.4938       0.5547        1.3293  0.0414\n",
      "      8        0.5564       0.5391        1.4515  0.0357\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4013\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.9503\u001b[0m  0.0312\n",
      "      2        0.5312       0.5000        \u001b[35m1.8015\u001b[0m  0.0357\n",
      "      3        0.5484       0.5000        \u001b[35m1.7645\u001b[0m  0.0394\n",
      "      4        0.5450       0.5000        1.7722  0.0347\n",
      "      5        0.5170       0.5000        \u001b[35m1.7099\u001b[0m  0.0403\n",
      "      6        0.4946       0.5000        1.8256  0.0358\n",
      "      7        0.5684       0.5000        1.7776  0.0401\n",
      "      8        0.5013       0.5000        1.8841  0.0380\n",
      "      9        0.5968       0.5000        1.7851  0.0345\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5891\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.3443\u001b[0m  0.0121\n",
      "      2        0.9594       0.5000        \u001b[35m1.2853\u001b[0m  0.0134\n",
      "      3        0.9377       0.5000        \u001b[35m1.2710\u001b[0m  0.0160\n",
      "      4        0.9428       0.5000        1.2732  0.0215\n",
      "      5        0.9215       0.5000        \u001b[35m1.2304\u001b[0m  0.0157\n",
      "      6        0.9137       0.5000        1.2468  0.0208\n",
      "      7        0.9177       0.5000        1.2425  0.0154\n",
      "      8        0.8906       0.5000        \u001b[35m1.1817\u001b[0m  0.0342\n",
      "      9        0.9051       0.5000        1.2760  0.0188\n",
      "     10        0.9029       0.5000        1.2309  0.0252\n",
      "     11        0.9096       0.5000        1.2814  0.0194\n",
      "     12        0.9149       0.5000        1.2560  0.0252\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5417\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.8547\u001b[0m  0.0194\n",
      "      2        0.9307       0.5000        \u001b[35m1.2674\u001b[0m  0.0174\n",
      "      3        0.9388       0.5000        1.3033  0.0157\n",
      "      4        0.8596       0.5000        1.2993  0.0233\n",
      "      5        0.8153       \u001b[32m0.5156\u001b[0m        \u001b[35m1.1510\u001b[0m  0.0206\n",
      "      6        0.8110       0.5000        1.2565  0.0162\n",
      "      7        0.8218       \u001b[32m0.5234\u001b[0m        1.1788  0.0190\n",
      "      8        0.7969       \u001b[32m0.5938\u001b[0m        \u001b[35m0.9433\u001b[0m  0.0316\n",
      "      9        0.7747       0.5625        1.0539  0.0160\n",
      "     10        0.7944       0.5547        1.0492  0.0211\n",
      "     11        0.7906       \u001b[32m0.6328\u001b[0m        \u001b[35m0.8937\u001b[0m  0.0145\n",
      "     12        0.7690       0.6016        0.9878  0.0270\n",
      "     13        0.8237       0.6094        0.9811  0.0160\n",
      "     14        0.7985       0.6094        0.9543  0.0154\n",
      "     15        0.7595       0.5938        1.0304  0.0273\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7737\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.0884\u001b[0m  0.0199\n",
      "      2        0.8464       0.5000        1.1171  0.0188\n",
      "      3        0.8277       0.5000        \u001b[35m1.0723\u001b[0m  0.0169\n",
      "      4        0.8229       0.5000        \u001b[35m1.0183\u001b[0m  0.0159\n",
      "      5        0.7829       0.5000        1.0518  0.0207\n",
      "      6        0.7995       0.5000        \u001b[35m1.0117\u001b[0m  0.0179\n",
      "      7        \u001b[36m0.7411\u001b[0m       0.5000        \u001b[35m0.9885\u001b[0m  0.0179\n",
      "      8        0.7414       0.5000        1.0229  0.0223\n",
      "      9        0.7774       0.5000        \u001b[35m0.9422\u001b[0m  0.0176\n",
      "     10        \u001b[36m0.6978\u001b[0m       \u001b[32m0.5156\u001b[0m        0.9616  0.0224\n",
      "     11        0.7474       \u001b[32m0.5312\u001b[0m        \u001b[35m0.8955\u001b[0m  0.0179\n",
      "     12        0.7520       0.5000        0.9955  0.0219\n",
      "     13        0.7612       0.5156        0.9463  0.0194\n",
      "     14        0.7571       \u001b[32m0.5703\u001b[0m        \u001b[35m0.8426\u001b[0m  0.0209\n",
      "     15        0.7189       0.5391        0.8926  0.0168\n",
      "     16        0.7203       0.5391        0.8653  0.0213\n",
      "     17        0.7039       0.5312        0.8870  0.0175\n",
      "     18        \u001b[36m0.6924\u001b[0m       \u001b[32m0.6094\u001b[0m        0.8841  0.0173\n",
      "     19        0.7079       0.6016        \u001b[35m0.7953\u001b[0m  0.0233\n",
      "     20        0.7003       0.5547        0.8691  0.0187\n",
      "     21        0.7105       0.5859        0.8400  0.0279\n",
      "     22        0.7041       0.5703        0.8645  0.0171\n",
      "     23        0.7404       \u001b[32m0.6250\u001b[0m        \u001b[35m0.7596\u001b[0m  0.0323\n",
      "     24        \u001b[36m0.6702\u001b[0m       0.6016        0.8257  0.0209\n",
      "     25        0.6956       0.6250        0.7834  0.0212\n",
      "     26        \u001b[36m0.6680\u001b[0m       0.6094        0.8256  0.0166\n",
      "     27        0.6948       0.6250        0.8209  0.0196\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7328\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.9634\u001b[0m  0.0132\n",
      "      2        0.8315       0.5000        \u001b[35m0.9394\u001b[0m  0.0162\n",
      "      3        0.8431       0.5000        0.9452  0.0237\n",
      "      4        0.7973       0.5000        \u001b[35m0.8933\u001b[0m  0.0278\n",
      "      5        0.7544       \u001b[32m0.5547\u001b[0m        \u001b[35m0.7997\u001b[0m  0.0170\n",
      "      6        \u001b[36m0.7256\u001b[0m       0.5469        0.8258  0.0248\n",
      "      7        \u001b[36m0.7196\u001b[0m       \u001b[32m0.5625\u001b[0m        0.8218  0.0165\n",
      "      8        \u001b[36m0.7174\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.7595\u001b[0m  0.0221\n",
      "      9        0.7182       0.5312        0.7976  0.0156\n",
      "     10        \u001b[36m0.6957\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6472\u001b[0m  0.0230\n",
      "     11        \u001b[36m0.6911\u001b[0m       0.5625        0.7885  0.0202\n",
      "     12        0.7106       0.6016        0.7630  0.0210\n",
      "     13        \u001b[36m0.6835\u001b[0m       0.6641        0.6530  0.0167\n",
      "     14        \u001b[36m0.6400\u001b[0m       0.6094        0.7659  0.0196\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6394\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.1830\u001b[0m  0.0136\n",
      "      2        0.8692       0.5000        \u001b[35m1.1725\u001b[0m  0.0277\n",
      "      3        0.8483       0.5000        \u001b[35m1.1675\u001b[0m  0.0246\n",
      "      4        0.8334       0.5000        \u001b[35m1.1518\u001b[0m  0.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5        0.7926       0.5000        \u001b[35m1.0468\u001b[0m  0.0150\n",
      "      6        0.7717       0.5000        1.2629  0.0198\n",
      "      7        0.8623       0.5000        1.0743  0.0191\n",
      "      8        0.7952       0.5000        1.0936  0.0208\n",
      "      9        0.8018       0.5000        \u001b[35m1.0110\u001b[0m  0.0154\n",
      "     10        0.8057       \u001b[32m0.5312\u001b[0m        \u001b[35m0.9225\u001b[0m  0.0322\n",
      "     11        0.7744       0.5000        1.0530  0.0230\n",
      "     12        0.7847       0.5078        1.0199  0.0158\n",
      "     13        0.8082       0.5000        1.1350  0.0271\n",
      "     14        0.8076       \u001b[32m0.6016\u001b[0m        \u001b[35m0.8491\u001b[0m  0.0160\n",
      "     15        0.7778       0.5703        0.9212  0.0178\n",
      "     16        0.7858       0.5781        0.9109  0.0210\n",
      "     17        0.7673       0.5859        0.9013  0.0204\n",
      "     18        0.7869       0.5000        1.0240  0.0140\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4549\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.7520\u001b[0m  0.0483\n",
      "      2        0.6466       0.5000        \u001b[35m1.8804\u001b[0m  0.0483\n",
      "      3        0.6003       0.5000        \u001b[35m1.8736\u001b[0m  0.0495\n",
      "      4        0.6021       0.5000        1.9158  0.0455\n",
      "      5        0.5903       0.5000        1.9052  0.0524\n",
      "      6        0.5985       0.5000        \u001b[35m1.8700\u001b[0m  0.0457\n",
      "      7        0.5694       0.5000        3.0382  0.0471\n",
      "      8        0.7016       0.5000        1.9291  0.0453\n",
      "      9        0.6042       0.5000        1.8710  0.0454\n",
      "     10        0.5962       0.5000        1.8710  0.0479\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best parameters found:\n",
      "\n",
      "{'optimizer__momentum': 0.3, 'module__num_unitsB': 9, 'module__num_unitsA': 12, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 16}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.853 (+/-0.093) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 12, 'module__num_unitsA': 9, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 16}\n",
      "0.955 (+/-0.046) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 3, 'module__num_unitsA': 9, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 16}\n",
      "1.000 (+/-0.000) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 9, 'module__num_unitsA': 12, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 16}\n",
      "1.000 (+/-0.000) for {'optimizer__momentum': 0.6, 'module__num_unitsB': 3, 'module__num_unitsA': 6, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 64}\n",
      "0.800 (+/-0.081) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 12, 'module__num_unitsA': 3, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 16}\n",
      "1.000 (+/-0.000) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 6, 'module__num_unitsA': 6, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 64}\n",
      "0.860 (+/-0.224) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 3, 'module__num_unitsA': 6, 'module__dropout': 0.5, 'lr': 0.01, 'batch_size': 16}\n",
      "0.870 (+/-0.077) for {'optimizer__momentum': 0.6, 'module__num_unitsB': 12, 'module__num_unitsA': 9, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 64}\n",
      "1.000 (+/-0.000) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 6, 'module__num_unitsA': 6, 'module__dropout': 0.0, 'lr': 1, 'batch_size': 16}\n",
      "0.997 (+/-0.010) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 9, 'module__num_unitsA': 6, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 64}\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6890\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6964\u001b[0m  0.0191\n",
      "      2        0.6938       0.5000        0.7081  0.0211\n",
      "      3        0.7042       0.5000        0.7122  0.0257\n",
      "      4        0.7074       0.5000        0.7131  0.0295\n",
      "      5        0.7069       0.5000        0.7145  0.0278\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6886\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6803\u001b[0m  0.0205\n",
      "      2        \u001b[36m0.6811\u001b[0m       0.5000        \u001b[35m0.6735\u001b[0m  0.0210\n",
      "      3        \u001b[36m0.6721\u001b[0m       0.5000        0.6752  0.0249\n",
      "      4        \u001b[36m0.6619\u001b[0m       0.5000        0.6760  0.0299\n",
      "      5        \u001b[36m0.6599\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6601\u001b[0m  0.0302\n",
      "      6        \u001b[36m0.6520\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6559\u001b[0m  0.0274\n",
      "      7        \u001b[36m0.6512\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6449\u001b[0m  0.0269\n",
      "      8        \u001b[36m0.6374\u001b[0m       \u001b[32m0.6719\u001b[0m        0.6464  0.0275\n",
      "      9        \u001b[36m0.6173\u001b[0m       0.6719        0.6474  0.0279\n",
      "     10        0.6225       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6383\u001b[0m  0.0282\n",
      "     11        \u001b[36m0.6141\u001b[0m       \u001b[32m0.7422\u001b[0m        0.6387  0.0293\n",
      "     12        0.6205       0.7422        \u001b[35m0.6356\u001b[0m  0.0276\n",
      "     13        \u001b[36m0.6063\u001b[0m       0.7422        \u001b[35m0.6305\u001b[0m  0.0284\n",
      "     14        0.6095       0.7422        \u001b[35m0.6233\u001b[0m  0.0240\n",
      "     15        0.6099       0.7422        \u001b[35m0.6219\u001b[0m  0.0277\n",
      "     16        \u001b[36m0.5887\u001b[0m       0.7422        \u001b[35m0.6198\u001b[0m  0.0275\n",
      "     17        \u001b[36m0.5781\u001b[0m       0.7422        \u001b[35m0.6066\u001b[0m  0.0292\n",
      "     18        0.5863       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5988\u001b[0m  0.0289\n",
      "     19        \u001b[36m0.5773\u001b[0m       0.7422        0.6021  0.0289\n",
      "     20        0.5892       0.7422        \u001b[35m0.5967\u001b[0m  0.0289\n",
      "     21        0.5861       0.7500        \u001b[35m0.5851\u001b[0m  0.0285\n",
      "     22        \u001b[36m0.5552\u001b[0m       0.7422        0.5882  0.0272\n",
      "     23        0.5713       0.7422        \u001b[35m0.5825\u001b[0m  0.0302\n",
      "     24        0.5613       0.7500        \u001b[35m0.5788\u001b[0m  0.0239\n",
      "     25        0.5965       0.7422        \u001b[35m0.5680\u001b[0m  0.0306\n",
      "     26        0.5671       0.7344        0.5723  0.0249\n",
      "     27        \u001b[36m0.5482\u001b[0m       0.7500        0.5778  0.0266\n",
      "     28        0.5669       0.7344        0.5746  0.0291\n",
      "     29        \u001b[36m0.5438\u001b[0m       0.7344        0.5783  0.0253\n",
      "     30        0.5678       0.7422        \u001b[35m0.5664\u001b[0m  0.0297\n",
      "     31        0.5777       0.7500        0.5678  0.0274\n",
      "     32        0.5544       0.7422        0.5758  0.0286\n",
      "     33        0.5699       0.7344        0.5766  0.0278\n",
      "     34        0.5697       0.7188        0.5775  0.0276\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7126\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7001\u001b[0m  0.0250\n",
      "      2        \u001b[36m0.7080\u001b[0m       0.5000        \u001b[35m0.6990\u001b[0m  0.0262\n",
      "      3        0.7082       0.5000        \u001b[35m0.6958\u001b[0m  0.0278\n",
      "      4        \u001b[36m0.6988\u001b[0m       0.5000        \u001b[35m0.6908\u001b[0m  0.0283\n",
      "      5        \u001b[36m0.6940\u001b[0m       0.5000        \u001b[35m0.6861\u001b[0m  0.0289\n",
      "      6        \u001b[36m0.6910\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6790\u001b[0m  0.0285\n",
      "      7        \u001b[36m0.6809\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6742\u001b[0m  0.0251\n",
      "      8        \u001b[36m0.6730\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6653\u001b[0m  0.0307\n",
      "      9        \u001b[36m0.6480\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6454\u001b[0m  0.0281\n",
      "     10        0.6517       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6352\u001b[0m  0.0276\n",
      "     11        \u001b[36m0.6391\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6230\u001b[0m  0.0292\n",
      "     12        \u001b[36m0.6100\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5975\u001b[0m  0.0285\n",
      "     13        0.6159       0.7188        \u001b[35m0.5916\u001b[0m  0.0308\n",
      "     14        \u001b[36m0.5901\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5805\u001b[0m  0.0312\n",
      "     15        0.6031       0.7422        0.5844  0.0272\n",
      "     16        0.6182       0.7266        \u001b[35m0.5775\u001b[0m  0.0279\n",
      "     17        0.6004       0.7422        0.5862  0.0252\n",
      "     18        \u001b[36m0.5728\u001b[0m       0.7266        \u001b[35m0.5746\u001b[0m  0.0258\n",
      "     19        0.5933       0.7266        \u001b[35m0.5693\u001b[0m  0.0271\n",
      "     20        0.6001       0.7109        0.5760  0.0271\n",
      "     21        0.5906       0.7188        0.5760  0.0273\n",
      "     22        0.5846       0.7109        0.5717  0.0273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     23        0.5793       0.7266        \u001b[35m0.5670\u001b[0m  0.0274\n",
      "     24        0.5744       0.7188        0.5684  0.0241\n",
      "     25        0.5746       0.7266        \u001b[35m0.5657\u001b[0m  0.0254\n",
      "     26        0.5774       0.7344        \u001b[35m0.5565\u001b[0m  0.0274\n",
      "     27        \u001b[36m0.5676\u001b[0m       0.7344        0.5567  0.0285\n",
      "     28        0.5871       0.7266        0.5601  0.0279\n",
      "     29        0.5803       0.7344        0.5656  0.0294\n",
      "     30        0.5696       0.7266        0.5610  0.0283\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7059\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7050\u001b[0m  0.0241\n",
      "      2        \u001b[36m0.6715\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6800\u001b[0m  0.0284\n",
      "      3        \u001b[36m0.6562\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6508\u001b[0m  0.0278\n",
      "      4        \u001b[36m0.6319\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6272\u001b[0m  0.0273\n",
      "      5        \u001b[36m0.6019\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6161\u001b[0m  0.0256\n",
      "      6        \u001b[36m0.5876\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6069\u001b[0m  0.0247\n",
      "      7        \u001b[36m0.5867\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5779\u001b[0m  0.0289\n",
      "      8        \u001b[36m0.5846\u001b[0m       0.6875        0.5974  0.0289\n",
      "      9        \u001b[36m0.5732\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5644\u001b[0m  0.0284\n",
      "     10        0.5818       0.7266        0.5741  0.0240\n",
      "     11        0.5858       0.7266        0.5690  0.0244\n",
      "     12        \u001b[36m0.5655\u001b[0m       0.7422        \u001b[35m0.5602\u001b[0m  0.0293\n",
      "     13        0.5728       0.7344        \u001b[35m0.5560\u001b[0m  0.0270\n",
      "     14        0.5867       0.7344        0.5747  0.0287\n",
      "     15        0.5902       0.7500        0.5565  0.0240\n",
      "     16        \u001b[36m0.5620\u001b[0m       0.7266        0.5588  0.0249\n",
      "     17        \u001b[36m0.5547\u001b[0m       0.7344        \u001b[35m0.5431\u001b[0m  0.0283\n",
      "     18        \u001b[36m0.5453\u001b[0m       0.7422        \u001b[35m0.5369\u001b[0m  0.0286\n",
      "     19        \u001b[36m0.5358\u001b[0m       0.7422        \u001b[35m0.5309\u001b[0m  0.0287\n",
      "     20        0.5651       0.7500        0.5319  0.0279\n",
      "     21        0.5461       0.7422        0.5358  0.0265\n",
      "     22        0.5406       0.7344        0.5378  0.0270\n",
      "     23        0.5561       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5277\u001b[0m  0.0258\n",
      "     24        0.5430       0.7500        0.5287  0.0269\n",
      "     25        \u001b[36m0.5265\u001b[0m       0.7422        0.5320  0.0279\n",
      "     26        0.5368       0.7344        0.5350  0.0283\n",
      "     27        0.5386       0.7578        \u001b[35m0.5249\u001b[0m  0.0280\n",
      "     28        0.5353       0.7656        \u001b[35m0.5192\u001b[0m  0.0280\n",
      "     29        0.5386       0.7656        0.5221  0.0273\n",
      "     30        0.5390       0.7422        0.5266  0.0287\n",
      "     31        0.5417       0.7344        0.5315  0.0288\n",
      "     32        0.5381       0.7422        0.5237  0.0283\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7416\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7222\u001b[0m  0.0270\n",
      "      2        \u001b[36m0.7067\u001b[0m       0.5000        \u001b[35m0.7025\u001b[0m  0.0274\n",
      "      3        \u001b[36m0.6842\u001b[0m       0.5000        \u001b[35m0.6883\u001b[0m  0.0278\n",
      "      4        \u001b[36m0.6680\u001b[0m       0.5000        \u001b[35m0.6708\u001b[0m  0.0269\n",
      "      5        0.6687       0.5000        \u001b[35m0.6526\u001b[0m  0.0263\n",
      "      6        \u001b[36m0.6465\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6377\u001b[0m  0.0273\n",
      "      7        \u001b[36m0.6193\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6277\u001b[0m  0.0281\n",
      "      8        0.6263       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6136\u001b[0m  0.0269\n",
      "      9        \u001b[36m0.5911\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6084\u001b[0m  0.0264\n",
      "     10        0.6106       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6047\u001b[0m  0.0266\n",
      "     11        \u001b[36m0.5884\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6042\u001b[0m  0.0272\n",
      "     12        0.5913       0.7500        \u001b[35m0.5981\u001b[0m  0.0286\n",
      "     13        \u001b[36m0.5742\u001b[0m       0.7500        0.6013  0.0284\n",
      "     14        \u001b[36m0.5727\u001b[0m       0.7422        0.6030  0.0255\n",
      "     15        0.5878       0.7578        0.5988  0.0308\n",
      "     16        0.6006       0.7344        0.5993  0.0268\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7647\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6862\u001b[0m  0.0154\n",
      "      2        \u001b[36m0.7218\u001b[0m       0.5000        \u001b[35m0.6756\u001b[0m  0.0149\n",
      "      3        \u001b[36m0.7195\u001b[0m       0.5000        \u001b[35m0.6589\u001b[0m  0.0163\n",
      "      4        0.7407       0.5312        \u001b[35m0.6473\u001b[0m  0.0154\n",
      "      5        0.7233       0.6016        \u001b[35m0.6342\u001b[0m  0.0248\n",
      "      6        \u001b[36m0.6995\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6089\u001b[0m  0.0150\n",
      "      7        \u001b[36m0.6907\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5827\u001b[0m  0.0291\n",
      "      8        0.6978       0.7734        \u001b[35m0.5642\u001b[0m  0.0147\n",
      "      9        \u001b[36m0.6677\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.5428\u001b[0m  0.0240\n",
      "     10        0.6873       0.7734        \u001b[35m0.5304\u001b[0m  0.0213\n",
      "     11        0.6877       0.7734        \u001b[35m0.5260\u001b[0m  0.0222\n",
      "     12        0.6704       0.7891        \u001b[35m0.5111\u001b[0m  0.0213\n",
      "     13        \u001b[36m0.6516\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4971\u001b[0m  0.0162\n",
      "     14        0.6521       0.7969        \u001b[35m0.4882\u001b[0m  0.0160\n",
      "     15        \u001b[36m0.6304\u001b[0m       0.7969        \u001b[35m0.4789\u001b[0m  0.0225\n",
      "     16        0.6611       0.7969        0.4792  0.0190\n",
      "     17        \u001b[36m0.5932\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4620\u001b[0m  0.0183\n",
      "     18        0.6348       \u001b[32m0.8125\u001b[0m        0.4633  0.0230\n",
      "     19        0.6369       0.8047        0.4627  0.0221\n",
      "     20        0.6092       0.7969        \u001b[35m0.4587\u001b[0m  0.0160\n",
      "     21        \u001b[36m0.5825\u001b[0m       0.7969        \u001b[35m0.4407\u001b[0m  0.0199\n",
      "     22        0.6085       0.8125        0.4479  0.0204\n",
      "     23        0.6018       0.8125        0.4420  0.0185\n",
      "     24        0.5936       0.8047        \u001b[35m0.4323\u001b[0m  0.0279\n",
      "     25        0.6033       0.8125        0.4335  0.0161\n",
      "     26        0.5846       0.8125        0.4327  0.0189\n",
      "     27        0.5865       0.8125        0.4328  0.0245\n",
      "     28        0.6022       0.8125        \u001b[35m0.4254\u001b[0m  0.0171\n",
      "     29        0.6013       \u001b[32m0.8203\u001b[0m        0.4288  0.0218\n",
      "     30        0.5865       0.8203        \u001b[35m0.4248\u001b[0m  0.0181\n",
      "     31        0.6092       0.8203        0.4263  0.0216\n",
      "     32        0.5850       \u001b[32m0.8281\u001b[0m        0.4269  0.0244\n",
      "     33        0.5923       0.8203        \u001b[35m0.4242\u001b[0m  0.0175\n",
      "     34        \u001b[36m0.5788\u001b[0m       0.8203        0.4253  0.0241\n",
      "     35        0.6073       0.8047        \u001b[35m0.4188\u001b[0m  0.0210\n",
      "     36        0.5990       0.7969        \u001b[35m0.4168\u001b[0m  0.0186\n",
      "     37        \u001b[36m0.5749\u001b[0m       0.8047        \u001b[35m0.4142\u001b[0m  0.0225\n",
      "     38        0.5835       0.8047        0.4166  0.0177\n",
      "     39        0.6022       0.8125        0.4257  0.0251\n",
      "     40        \u001b[36m0.5690\u001b[0m       0.8203        0.4217  0.0170\n",
      "     41        0.5821       0.8047        0.4175  0.0183\n",
      "     42        \u001b[36m0.5573\u001b[0m       0.7734        \u001b[35m0.4134\u001b[0m  0.0243\n",
      "     43        0.5645       0.8047        0.4158  0.0199\n",
      "     44        0.6023       0.8047        0.4225  0.0222\n",
      "     45        0.5818       0.8125        0.4215  0.0163\n",
      "     46        0.5734       0.8203        0.4235  0.0174\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7799\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6785\u001b[0m  0.0171\n",
      "      2        \u001b[36m0.7367\u001b[0m       0.5000        \u001b[35m0.6765\u001b[0m  0.0178\n",
      "      3        0.7475       0.5000        \u001b[35m0.6683\u001b[0m  0.0240\n",
      "      4        0.7418       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6618\u001b[0m  0.0175\n",
      "      5        \u001b[36m0.7242\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6509\u001b[0m  0.0194\n",
      "      6        \u001b[36m0.7120\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6332\u001b[0m  0.0142\n",
      "      7        0.7164       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6230\u001b[0m  0.0211\n",
      "      8        \u001b[36m0.6909\u001b[0m       0.7500        \u001b[35m0.6110\u001b[0m  0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9        0.7175       0.7500        \u001b[35m0.6006\u001b[0m  0.0186\n",
      "     10        0.7213       \u001b[32m0.7656\u001b[0m        0.6018  0.0238\n",
      "     11        \u001b[36m0.6667\u001b[0m       0.7422        \u001b[35m0.5873\u001b[0m  0.0172\n",
      "     12        0.6946       0.7344        \u001b[35m0.5872\u001b[0m  0.0221\n",
      "     13        \u001b[36m0.6614\u001b[0m       0.7344        \u001b[35m0.5734\u001b[0m  0.0153\n",
      "     14        0.6838       0.7344        \u001b[35m0.5699\u001b[0m  0.0256\n",
      "     15        0.6874       0.7500        0.5734  0.0209\n",
      "     16        \u001b[36m0.6534\u001b[0m       0.7500        \u001b[35m0.5660\u001b[0m  0.0147\n",
      "     17        0.6651       0.7422        \u001b[35m0.5615\u001b[0m  0.0189\n",
      "     18        \u001b[36m0.6323\u001b[0m       0.7500        \u001b[35m0.5543\u001b[0m  0.0218\n",
      "     19        0.6442       0.7422        0.5577  0.0284\n",
      "     20        0.6506       0.7422        0.5548  0.0178\n",
      "     21        \u001b[36m0.6306\u001b[0m       0.7422        \u001b[35m0.5469\u001b[0m  0.0189\n",
      "     22        0.6490       0.7500        0.5526  0.0173\n",
      "     23        0.6510       0.7500        \u001b[35m0.5459\u001b[0m  0.0190\n",
      "     24        0.6337       0.7422        \u001b[35m0.5418\u001b[0m  0.0182\n",
      "     25        \u001b[36m0.6285\u001b[0m       0.7500        \u001b[35m0.5373\u001b[0m  0.0156\n",
      "     26        \u001b[36m0.6016\u001b[0m       0.7500        \u001b[35m0.5295\u001b[0m  0.0254\n",
      "     27        0.6063       0.7422        \u001b[35m0.5282\u001b[0m  0.0189\n",
      "     28        0.6355       0.7422        \u001b[35m0.5281\u001b[0m  0.0155\n",
      "     29        0.6355       0.7500        0.5285  0.0184\n",
      "     30        0.6209       0.7500        0.5282  0.0293\n",
      "     31        0.6070       0.7578        0.5296  0.0191\n",
      "     32        \u001b[36m0.5860\u001b[0m       0.7578        \u001b[35m0.5270\u001b[0m  0.0163\n",
      "     33        0.6086       0.7500        \u001b[35m0.5203\u001b[0m  0.0363\n",
      "     34        0.6126       0.7578        0.5205  0.0135\n",
      "     35        0.5922       0.7578        \u001b[35m0.5189\u001b[0m  0.0232\n",
      "     36        \u001b[36m0.5809\u001b[0m       0.7578        \u001b[35m0.5183\u001b[0m  0.0147\n",
      "     37        0.6147       0.7500        0.5196  0.0161\n",
      "     38        0.5988       0.7500        0.5200  0.0317\n",
      "     39        0.6000       0.7422        0.5197  0.0198\n",
      "     40        \u001b[36m0.5720\u001b[0m       0.7500        0.5185  0.0159\n",
      "     41        0.5840       0.7422        \u001b[35m0.5176\u001b[0m  0.0171\n",
      "     42        \u001b[36m0.5600\u001b[0m       0.7344        0.5184  0.0271\n",
      "     43        0.5991       0.7500        0.5196  0.0235\n",
      "     44        0.5669       0.7422        0.5208  0.0194\n",
      "     45        0.6018       0.7422        0.5197  0.0154\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7201\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6590\u001b[0m  0.0236\n",
      "      2        \u001b[36m0.6915\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6377\u001b[0m  0.0174\n",
      "      3        0.6981       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6216\u001b[0m  0.0228\n",
      "      4        \u001b[36m0.6611\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6018\u001b[0m  0.0150\n",
      "      5        \u001b[36m0.6530\u001b[0m       0.7188        \u001b[35m0.5826\u001b[0m  0.0222\n",
      "      6        \u001b[36m0.6184\u001b[0m       0.7266        \u001b[35m0.5647\u001b[0m  0.0190\n",
      "      7        \u001b[36m0.6117\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5584\u001b[0m  0.0162\n",
      "      8        0.6142       0.7344        \u001b[35m0.5522\u001b[0m  0.0238\n",
      "      9        \u001b[36m0.6060\u001b[0m       0.7266        \u001b[35m0.5495\u001b[0m  0.0186\n",
      "     10        \u001b[36m0.6042\u001b[0m       0.7344        0.5515  0.0225\n",
      "     11        \u001b[36m0.5927\u001b[0m       0.7344        \u001b[35m0.5435\u001b[0m  0.0192\n",
      "     12        \u001b[36m0.5704\u001b[0m       0.7344        \u001b[35m0.5398\u001b[0m  0.0204\n",
      "     13        \u001b[36m0.5683\u001b[0m       0.7344        \u001b[35m0.5362\u001b[0m  0.0163\n",
      "     14        0.6032       0.7344        \u001b[35m0.5358\u001b[0m  0.0218\n",
      "     15        0.6084       0.7422        0.5392  0.0173\n",
      "     16        0.5734       0.7422        0.5367  0.0217\n",
      "     17        0.5992       0.7344        \u001b[35m0.5332\u001b[0m  0.0170\n",
      "     18        0.5747       0.7344        \u001b[35m0.5304\u001b[0m  0.0250\n",
      "     19        0.5747       0.7344        0.5332  0.0196\n",
      "     20        0.5872       0.7266        0.5344  0.0228\n",
      "     21        \u001b[36m0.5543\u001b[0m       0.7266        0.5316  0.0181\n",
      "     22        0.5689       0.7266        0.5367  0.0322\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7163\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6530\u001b[0m  0.0178\n",
      "      2        \u001b[36m0.6840\u001b[0m       0.7344        \u001b[35m0.6317\u001b[0m  0.0162\n",
      "      3        \u001b[36m0.6580\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6050\u001b[0m  0.0233\n",
      "      4        \u001b[36m0.6315\u001b[0m       0.7422        \u001b[35m0.5834\u001b[0m  0.0217\n",
      "      5        \u001b[36m0.6307\u001b[0m       0.7422        \u001b[35m0.5689\u001b[0m  0.0248\n",
      "      6        0.6531       0.7422        \u001b[35m0.5646\u001b[0m  0.0183\n",
      "      7        \u001b[36m0.5869\u001b[0m       0.7344        \u001b[35m0.5482\u001b[0m  0.0228\n",
      "      8        0.6275       0.7422        \u001b[35m0.5435\u001b[0m  0.0188\n",
      "      9        0.5895       0.7266        \u001b[35m0.5381\u001b[0m  0.0196\n",
      "     10        0.5923       0.7344        0.5407  0.0236\n",
      "     11        \u001b[36m0.5784\u001b[0m       0.7344        \u001b[35m0.5358\u001b[0m  0.0270\n",
      "     12        \u001b[36m0.5509\u001b[0m       0.7266        \u001b[35m0.5334\u001b[0m  0.0233\n",
      "     13        \u001b[36m0.5354\u001b[0m       0.7266        \u001b[35m0.5314\u001b[0m  0.0165\n",
      "     14        0.5704       0.7266        \u001b[35m0.5289\u001b[0m  0.0216\n",
      "     15        0.5629       0.7266        \u001b[35m0.5265\u001b[0m  0.0208\n",
      "     16        0.5470       0.7188        0.5271  0.0292\n",
      "     17        \u001b[36m0.5241\u001b[0m       0.7109        0.5294  0.0243\n",
      "     18        0.5293       0.7109        0.5316  0.0314\n",
      "     19        0.5364       0.7031        0.5290  0.0285\n",
      "     20        0.5458       0.7188        \u001b[35m0.5246\u001b[0m  0.0295\n",
      "     21        0.5413       0.7188        0.5281  0.0260\n",
      "     22        0.5567       0.7188        \u001b[35m0.5239\u001b[0m  0.0182\n",
      "     23        0.5637       0.7109        \u001b[35m0.5238\u001b[0m  0.0164\n",
      "     24        0.5304       0.6953        0.5289  0.0183\n",
      "     25        0.5521       0.6953        0.5289  0.0214\n",
      "     26        \u001b[36m0.5122\u001b[0m       0.7031        0.5286  0.0169\n",
      "     27        0.5191       0.7188        0.5292  0.0233\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7859\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6777\u001b[0m  0.0210\n",
      "      2        \u001b[36m0.7025\u001b[0m       0.5703        \u001b[35m0.6687\u001b[0m  0.0310\n",
      "      3        0.7029       0.5859        \u001b[35m0.6555\u001b[0m  0.0166\n",
      "      4        0.7036       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6402\u001b[0m  0.0228\n",
      "      5        \u001b[36m0.6952\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6295\u001b[0m  0.0234\n",
      "      6        \u001b[36m0.6753\u001b[0m       0.7266        \u001b[35m0.6161\u001b[0m  0.0220\n",
      "      7        \u001b[36m0.6668\u001b[0m       0.6953        \u001b[35m0.6042\u001b[0m  0.0185\n",
      "      8        \u001b[36m0.6557\u001b[0m       0.6797        \u001b[35m0.5993\u001b[0m  0.0193\n",
      "      9        \u001b[36m0.6244\u001b[0m       0.6797        \u001b[35m0.5947\u001b[0m  0.0261\n",
      "     10        0.6361       0.6797        \u001b[35m0.5850\u001b[0m  0.0171\n",
      "     11        \u001b[36m0.6229\u001b[0m       0.6797        \u001b[35m0.5826\u001b[0m  0.0177\n",
      "     12        \u001b[36m0.5864\u001b[0m       0.6797        0.5841  0.0205\n",
      "     13        \u001b[36m0.5829\u001b[0m       0.6797        0.5868  0.0199\n",
      "     14        0.6222       0.6875        \u001b[35m0.5753\u001b[0m  0.0319\n",
      "     15        \u001b[36m0.5822\u001b[0m       0.6875        \u001b[35m0.5717\u001b[0m  0.0224\n",
      "     16        0.6136       0.6875        \u001b[35m0.5643\u001b[0m  0.0191\n",
      "     17        0.6087       0.6875        \u001b[35m0.5556\u001b[0m  0.0190\n",
      "     18        0.5871       0.6953        \u001b[35m0.5496\u001b[0m  0.0206\n",
      "     19        \u001b[36m0.5783\u001b[0m       0.6875        \u001b[35m0.5461\u001b[0m  0.0208\n",
      "     20        \u001b[36m0.5375\u001b[0m       0.7031        0.5542  0.0171\n",
      "     21        0.5976       0.6875        \u001b[35m0.5404\u001b[0m  0.0174\n",
      "     22        0.5419       0.6875        0.5418  0.0162\n",
      "     23        0.5765       0.6875        0.5418  0.0226\n",
      "     24        0.5689       0.7188        \u001b[35m0.5358\u001b[0m  0.0168\n",
      "     25        0.5460       \u001b[32m0.7344\u001b[0m        0.5394  0.0166\n",
      "     26        0.5483       0.7344        \u001b[35m0.5352\u001b[0m  0.0164\n",
      "     27        0.5669       0.7109        \u001b[35m0.5340\u001b[0m  0.0260\n",
      "     28        0.5710       0.7031        0.5366  0.0208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     29        0.5796       0.7266        0.5363  0.0175\n",
      "     30        0.5714       0.7266        0.5362  0.0157\n",
      "     31        0.5844       0.7188        \u001b[35m0.5336\u001b[0m  0.0273\n",
      "     32        0.6041       0.7188        \u001b[35m0.5268\u001b[0m  0.0222\n",
      "     33        0.5416       \u001b[32m0.7422\u001b[0m        0.5349  0.0236\n",
      "     34        0.5467       0.7344        0.5356  0.0195\n",
      "     35        0.5414       0.7266        0.5366  0.0234\n",
      "     36        0.5386       0.7188        0.5425  0.0222\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5060\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m3.2395\u001b[0m  0.0282\n",
      "      2        1.0782       0.5000        \u001b[35m2.2616\u001b[0m  0.0281\n",
      "      3        0.9584       0.5000        \u001b[35m2.2362\u001b[0m  0.0250\n",
      "      4        0.9512       \u001b[32m0.5312\u001b[0m        \u001b[35m2.1236\u001b[0m  0.0249\n",
      "      5        0.9972       0.5000        2.6384  0.0306\n",
      "      6        1.1992       0.5000        2.4892  0.0280\n",
      "      7        1.3967       0.5000        2.5216  0.0267\n",
      "      8        1.1496       0.5000        3.3630  0.0296\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4234\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m3.2596\u001b[0m  0.0229\n",
      "      2        0.8789       \u001b[32m0.5078\u001b[0m        \u001b[35m2.9028\u001b[0m  0.0266\n",
      "      3        1.3382       0.5000        5.4862  0.0293\n",
      "      4        2.0146       0.5000        2.9955  0.0288\n",
      "      5        6.7677       0.5000        7.9126  0.0279\n",
      "      6        3.9163       \u001b[32m0.6953\u001b[0m        4.0850  0.0250\n",
      "      7        1.6704       0.6484        \u001b[35m2.0545\u001b[0m  0.0261\n",
      "      8        1.0849       0.5000        5.5390  0.0292\n",
      "      9        1.7112       0.5000        2.9534  0.0298\n",
      "     10        1.3296       0.5000        3.1279  0.0283\n",
      "     11        4.0878       0.4922        4.9566  0.0274\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7887\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m6.2035\u001b[0m  0.0221\n",
      "      2        1.8379       0.5000        \u001b[35m2.5090\u001b[0m  0.0247\n",
      "      3        1.2839       0.5000        2.5377  0.0273\n",
      "      4        1.1931       0.5000        \u001b[35m2.2842\u001b[0m  0.0284\n",
      "      5        1.2659       0.5000        2.5165  0.0281\n",
      "      6        1.2860       0.5000        2.5087  0.0287\n",
      "      7        1.2841       0.5000        2.5090  0.0290\n",
      "      8        1.2842       0.5000        2.5090  0.0286\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7211\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.5321\u001b[0m  0.0232\n",
      "      2        1.1170       0.5000        \u001b[35m1.6406\u001b[0m  0.0240\n",
      "      3        1.2091       0.5000        1.7021  0.0294\n",
      "      4        1.1681       0.5000        \u001b[35m1.6388\u001b[0m  0.0298\n",
      "      5        1.1466       0.5000        1.6414  0.0284\n",
      "      6        1.1469       0.5000        \u001b[35m1.6321\u001b[0m  0.0271\n",
      "      7        1.1354       0.5000        \u001b[35m1.5324\u001b[0m  0.0270\n",
      "      8        0.9028       \u001b[32m0.5156\u001b[0m        1.5806  0.0287\n",
      "      9        1.1011       0.5078        \u001b[35m1.4611\u001b[0m  0.0288\n",
      "     10        0.9851       \u001b[32m0.5391\u001b[0m        \u001b[35m1.3493\u001b[0m  0.0293\n",
      "     11        0.9949       \u001b[32m0.5781\u001b[0m        \u001b[35m1.2667\u001b[0m  0.0313\n",
      "     12        0.9675       0.5625        \u001b[35m1.2208\u001b[0m  0.0287\n",
      "     13        0.9857       \u001b[32m0.6641\u001b[0m        \u001b[35m0.9888\u001b[0m  0.0283\n",
      "     14        0.8954       0.5625        1.2990  0.0273\n",
      "     15        0.9273       0.6484        \u001b[35m0.9865\u001b[0m  0.0284\n",
      "     16        0.8311       0.5859        1.1715  0.0261\n",
      "     17        0.8927       0.6406        1.0313  0.0278\n",
      "     18        0.9681       0.5547        1.2942  0.0281\n",
      "     19        0.9409       0.6016        1.1233  0.0287\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5187\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m3.6634\u001b[0m  0.0240\n",
      "      2        0.8784       0.5000        \u001b[35m2.0457\u001b[0m  0.0240\n",
      "      3        0.9027       0.5000        \u001b[35m1.8399\u001b[0m  0.0312\n",
      "      4        0.8445       0.5000        1.8710  0.0254\n",
      "      5        0.8677       0.5000        \u001b[35m1.6574\u001b[0m  0.0279\n",
      "      6        0.7732       \u001b[32m0.5312\u001b[0m        \u001b[35m1.4936\u001b[0m  0.0283\n",
      "      7        0.7594       \u001b[32m0.5859\u001b[0m        \u001b[35m1.4071\u001b[0m  0.0292\n",
      "      8        0.7049       0.5000        1.7456  0.0284\n",
      "      9        0.7794       \u001b[32m0.5938\u001b[0m        1.7458  0.0289\n",
      "     10        0.7510       0.5000        2.1326  0.0264\n",
      "     11        0.8390       \u001b[32m0.6719\u001b[0m        1.4140  0.0276\n",
      "     12        0.7288       0.6250        \u001b[35m1.2474\u001b[0m  0.0317\n",
      "     13        0.6972       0.6328        \u001b[35m1.2011\u001b[0m  0.0281\n",
      "     14        0.7006       0.6016        1.3707  0.0280\n",
      "     15        0.7160       0.6719        1.3268  0.0292\n",
      "     16        0.6667       \u001b[32m0.6797\u001b[0m        1.3092  0.0295\n",
      "     17        0.6795       0.6406        1.3175  0.0291\n",
      "     18        0.7559       0.6641        \u001b[35m1.1501\u001b[0m  0.0294\n",
      "     19        0.7548       0.5391        1.5670  0.0271\n",
      "     20        0.7809       0.6562        1.2721  0.0314\n",
      "     21        0.7280       0.6641        1.2445  0.0233\n",
      "     22        0.6831       0.6406        1.2164  0.0283\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5811\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7605\u001b[0m  0.0351\n",
      "      2        \u001b[36m0.5698\u001b[0m       \u001b[32m0.5156\u001b[0m        0.7796  0.0399\n",
      "      3        \u001b[36m0.4958\u001b[0m       \u001b[32m0.5938\u001b[0m        0.7651  0.0396\n",
      "      4        \u001b[36m0.4711\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.7367\u001b[0m  0.0444\n",
      "      5        \u001b[36m0.4647\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.7002\u001b[0m  0.0347\n",
      "      6        \u001b[36m0.4609\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6696\u001b[0m  0.0399\n",
      "      7        \u001b[36m0.4581\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6491\u001b[0m  0.0356\n",
      "      8        \u001b[36m0.4562\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6327\u001b[0m  0.0414\n",
      "      9        \u001b[36m0.4545\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6181\u001b[0m  0.0354\n",
      "     10        \u001b[36m0.4516\u001b[0m       0.6875        \u001b[35m0.6104\u001b[0m  0.0402\n",
      "     11        \u001b[36m0.4484\u001b[0m       0.6875        \u001b[35m0.6077\u001b[0m  0.0354\n",
      "     12        \u001b[36m0.4454\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6035\u001b[0m  0.0405\n",
      "     13        \u001b[36m0.4426\u001b[0m       0.6953        \u001b[35m0.5996\u001b[0m  0.0353\n",
      "     14        \u001b[36m0.4393\u001b[0m       0.6953        \u001b[35m0.5972\u001b[0m  0.0398\n",
      "     15        \u001b[36m0.4372\u001b[0m       0.6875        \u001b[35m0.5969\u001b[0m  0.0351\n",
      "     16        \u001b[36m0.4351\u001b[0m       0.6953        \u001b[35m0.5946\u001b[0m  0.0394\n",
      "     17        \u001b[36m0.4351\u001b[0m       0.6953        \u001b[35m0.5918\u001b[0m  0.0346\n",
      "     18        \u001b[36m0.4337\u001b[0m       0.6953        \u001b[35m0.5906\u001b[0m  0.0380\n",
      "     19        \u001b[36m0.4324\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5891\u001b[0m  0.0408\n",
      "     20        \u001b[36m0.4294\u001b[0m       0.6953        0.5908  0.0400\n",
      "     21        \u001b[36m0.4293\u001b[0m       0.6953        0.5900  0.0371\n",
      "     22        \u001b[36m0.4279\u001b[0m       0.6953        \u001b[35m0.5875\u001b[0m  0.0399\n",
      "     23        \u001b[36m0.4256\u001b[0m       0.6953        0.5891  0.0351\n",
      "     24        \u001b[36m0.4244\u001b[0m       0.7031        \u001b[35m0.5863\u001b[0m  0.0366\n",
      "     25        \u001b[36m0.4222\u001b[0m       0.7031        \u001b[35m0.5833\u001b[0m  0.0405\n",
      "     26        \u001b[36m0.4208\u001b[0m       0.7031        0.5858  0.0357\n",
      "     27        \u001b[36m0.4190\u001b[0m       0.7031        0.5858  0.0353\n",
      "     28        \u001b[36m0.4182\u001b[0m       0.7031        0.5859  0.0387\n",
      "     29        \u001b[36m0.4173\u001b[0m       0.7031        0.5841  0.0349\n",
      "     30        \u001b[36m0.4164\u001b[0m       0.7031        \u001b[35m0.5833\u001b[0m  0.0352\n",
      "     31        \u001b[36m0.4158\u001b[0m       \u001b[32m0.7109\u001b[0m        0.5836  0.0382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     32        \u001b[36m0.4148\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5805\u001b[0m  0.0427\n",
      "     33        0.4157       0.7109        0.5807  0.0389\n",
      "     34        \u001b[36m0.4141\u001b[0m       0.7109        \u001b[35m0.5792\u001b[0m  0.0351\n",
      "     35        \u001b[36m0.4116\u001b[0m       0.7109        0.5806  0.0352\n",
      "     36        \u001b[36m0.4102\u001b[0m       0.7188        \u001b[35m0.5745\u001b[0m  0.0371\n",
      "     37        \u001b[36m0.4091\u001b[0m       0.7188        0.5764  0.0382\n",
      "     38        \u001b[36m0.4071\u001b[0m       0.7188        0.5751  0.0361\n",
      "     39        \u001b[36m0.4056\u001b[0m       0.7188        \u001b[35m0.5739\u001b[0m  0.0347\n",
      "     40        \u001b[36m0.4035\u001b[0m       0.7188        0.5748  0.0356\n",
      "     41        \u001b[36m0.4021\u001b[0m       0.7188        0.5792  0.0391\n",
      "     42        \u001b[36m0.4010\u001b[0m       0.7188        0.5801  0.0348\n",
      "     43        \u001b[36m0.3998\u001b[0m       0.7188        0.5778  0.0345\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6094\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8137\u001b[0m  0.0390\n",
      "      2        0.6120       0.5000        0.8778  0.0379\n",
      "      3        \u001b[36m0.5665\u001b[0m       0.5000        0.9166  0.0403\n",
      "      4        \u001b[36m0.5260\u001b[0m       \u001b[32m0.5156\u001b[0m        0.9375  0.0360\n",
      "      5        \u001b[36m0.5018\u001b[0m       \u001b[32m0.5859\u001b[0m        0.9485  0.0409\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6539\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7222\u001b[0m  0.0372\n",
      "      2        \u001b[36m0.6223\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.7140\u001b[0m  0.0356\n",
      "      3        \u001b[36m0.5320\u001b[0m       \u001b[32m0.5938\u001b[0m        0.7314  0.0403\n",
      "      4        \u001b[36m0.4963\u001b[0m       \u001b[32m0.6562\u001b[0m        0.7352  0.0369\n",
      "      5        \u001b[36m0.4887\u001b[0m       \u001b[32m0.6797\u001b[0m        0.7161  0.0402\n",
      "      6        \u001b[36m0.4837\u001b[0m       0.6719        \u001b[35m0.7034\u001b[0m  0.0372\n",
      "      7        \u001b[36m0.4792\u001b[0m       0.6797        \u001b[35m0.6941\u001b[0m  0.0390\n",
      "      8        \u001b[36m0.4744\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6836\u001b[0m  0.0384\n",
      "      9        \u001b[36m0.4699\u001b[0m       0.6875        \u001b[35m0.6724\u001b[0m  0.0347\n",
      "     10        \u001b[36m0.4656\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6658\u001b[0m  0.0392\n",
      "     11        \u001b[36m0.4621\u001b[0m       0.6953        \u001b[35m0.6635\u001b[0m  0.0508\n",
      "     12        \u001b[36m0.4588\u001b[0m       0.6875        \u001b[35m0.6595\u001b[0m  0.0363\n",
      "     13        \u001b[36m0.4559\u001b[0m       0.6953        \u001b[35m0.6579\u001b[0m  0.0442\n",
      "     14        \u001b[36m0.4540\u001b[0m       0.6953        \u001b[35m0.6534\u001b[0m  0.0346\n",
      "     15        \u001b[36m0.4524\u001b[0m       0.6875        \u001b[35m0.6512\u001b[0m  0.0366\n",
      "     16        \u001b[36m0.4503\u001b[0m       0.6953        \u001b[35m0.6494\u001b[0m  0.0397\n",
      "     17        \u001b[36m0.4476\u001b[0m       0.6953        \u001b[35m0.6473\u001b[0m  0.0349\n",
      "     18        \u001b[36m0.4442\u001b[0m       0.6953        0.6480  0.0408\n",
      "     19        \u001b[36m0.4416\u001b[0m       0.6875        \u001b[35m0.6468\u001b[0m  0.0343\n",
      "     20        \u001b[36m0.4387\u001b[0m       0.6875        \u001b[35m0.6442\u001b[0m  0.0400\n",
      "     21        \u001b[36m0.4362\u001b[0m       0.6953        \u001b[35m0.6426\u001b[0m  0.0352\n",
      "     22        \u001b[36m0.4326\u001b[0m       0.6953        0.6427  0.0350\n",
      "     23        \u001b[36m0.4300\u001b[0m       0.6953        \u001b[35m0.6422\u001b[0m  0.0394\n",
      "     24        \u001b[36m0.4279\u001b[0m       0.6953        \u001b[35m0.6406\u001b[0m  0.0348\n",
      "     25        \u001b[36m0.4256\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6397\u001b[0m  0.0373\n",
      "     26        \u001b[36m0.4235\u001b[0m       0.7031        0.6400  0.0398\n",
      "     27        \u001b[36m0.4223\u001b[0m       \u001b[32m0.7109\u001b[0m        0.6414  0.0346\n",
      "     28        \u001b[36m0.4210\u001b[0m       0.7109        0.6424  0.0361\n",
      "     29        \u001b[36m0.4202\u001b[0m       0.7031        0.6431  0.0395\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6445\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7386\u001b[0m  0.0320\n",
      "      2        \u001b[36m0.5878\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.7055\u001b[0m  0.0436\n",
      "      3        \u001b[36m0.5210\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.7015\u001b[0m  0.0397\n",
      "      4        \u001b[36m0.4971\u001b[0m       0.6406        \u001b[35m0.7014\u001b[0m  0.0390\n",
      "      5        \u001b[36m0.4852\u001b[0m       0.6406        \u001b[35m0.6957\u001b[0m  0.0349\n",
      "      6        \u001b[36m0.4753\u001b[0m       0.6406        \u001b[35m0.6861\u001b[0m  0.0398\n",
      "      7        \u001b[36m0.4674\u001b[0m       0.6562        \u001b[35m0.6798\u001b[0m  0.0349\n",
      "      8        \u001b[36m0.4613\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6751\u001b[0m  0.0399\n",
      "      9        \u001b[36m0.4581\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6663\u001b[0m  0.0367\n",
      "     10        \u001b[36m0.4539\u001b[0m       0.6953        \u001b[35m0.6610\u001b[0m  0.0396\n",
      "     11        \u001b[36m0.4501\u001b[0m       0.6953        \u001b[35m0.6575\u001b[0m  0.0361\n",
      "     12        \u001b[36m0.4484\u001b[0m       0.6953        \u001b[35m0.6534\u001b[0m  0.0397\n",
      "     13        \u001b[36m0.4463\u001b[0m       0.6875        \u001b[35m0.6502\u001b[0m  0.0350\n",
      "     14        \u001b[36m0.4447\u001b[0m       0.6875        \u001b[35m0.6491\u001b[0m  0.0424\n",
      "     15        \u001b[36m0.4425\u001b[0m       0.6875        \u001b[35m0.6480\u001b[0m  0.0351\n",
      "     16        \u001b[36m0.4402\u001b[0m       0.6875        0.6501  0.0392\n",
      "     17        \u001b[36m0.4391\u001b[0m       0.6875        0.6495  0.0350\n",
      "     18        \u001b[36m0.4375\u001b[0m       0.6875        0.6511  0.0380\n",
      "     19        \u001b[36m0.4359\u001b[0m       0.6719        0.6530  0.0417\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5966\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7285\u001b[0m  0.0320\n",
      "      2        \u001b[36m0.5638\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.7018\u001b[0m  0.0429\n",
      "      3        \u001b[36m0.5004\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6811\u001b[0m  0.0396\n",
      "      4        \u001b[36m0.4712\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6724\u001b[0m  0.0390\n",
      "      5        \u001b[36m0.4521\u001b[0m       0.6641        \u001b[35m0.6699\u001b[0m  0.0347\n",
      "      6        \u001b[36m0.4402\u001b[0m       0.6641        0.6707  0.0395\n",
      "      7        \u001b[36m0.4327\u001b[0m       0.6641        0.6735  0.0378\n",
      "      8        \u001b[36m0.4262\u001b[0m       \u001b[32m0.6797\u001b[0m        0.6740  0.0398\n",
      "      9        \u001b[36m0.4218\u001b[0m       \u001b[32m0.7031\u001b[0m        0.6709  0.0356\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4719\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.6751\u001b[0m  0.0186\n",
      "      2        0.6798       0.5000        \u001b[35m1.5620\u001b[0m  0.0206\n",
      "      3        0.6465       0.5000        2.0323  0.0288\n",
      "      4        0.8417       0.5000        1.6320  0.0285\n",
      "      5        0.6864       0.5000        \u001b[35m1.5119\u001b[0m  0.0259\n",
      "      6        0.6736       0.5000        1.5262  0.0298\n",
      "      7        0.7276       0.5000        \u001b[35m1.4723\u001b[0m  0.0315\n",
      "      8        0.6491       \u001b[32m0.5078\u001b[0m        \u001b[35m1.3565\u001b[0m  0.0257\n",
      "      9        0.6310       0.5000        1.5980  0.0300\n",
      "     10        0.6639       \u001b[32m0.5703\u001b[0m        \u001b[35m1.2599\u001b[0m  0.0262\n",
      "     11        0.6700       0.5625        \u001b[35m1.2573\u001b[0m  0.0295\n",
      "     12        0.6501       \u001b[32m0.6250\u001b[0m        \u001b[35m1.1076\u001b[0m  0.0274\n",
      "     13        0.6386       0.5625        1.2566  0.0286\n",
      "     14        0.6414       0.5781        1.2019  0.0286\n",
      "     15        0.6606       0.6094        1.1386  0.0281\n",
      "     16        0.6488       0.5625        1.2731  0.0260\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4267\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.8065\u001b[0m  0.0224\n",
      "      2        0.6225       0.5000        \u001b[35m1.5401\u001b[0m  0.0233\n",
      "      3        0.5857       0.5000        1.6170  0.0321\n",
      "      4        0.6110       0.5000        1.5436  0.0286\n",
      "      5        0.6069       0.5000        \u001b[35m1.4468\u001b[0m  0.0303\n",
      "      6        0.6166       0.5000        1.7059  0.0297\n",
      "      7        0.6272       0.5000        1.6130  0.0228\n",
      "      8        0.6258       0.5000        1.5715  0.0269\n",
      "      9        0.6028       0.5000        1.4717  0.0266\n",
      "     10        0.6164       0.5000        \u001b[35m1.3729\u001b[0m  0.0270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11        0.5596       0.5000        1.4299  0.0287\n",
      "     12        0.5809       0.5000        1.5556  0.0253\n",
      "     13        0.5426       \u001b[32m0.5391\u001b[0m        1.3990  0.0274\n",
      "     14        0.5599       \u001b[32m0.5547\u001b[0m        1.3917  0.0275\n",
      "     15        0.5756       \u001b[32m0.5781\u001b[0m        \u001b[35m1.2839\u001b[0m  0.0267\n",
      "     16        0.5712       0.5469        1.3295  0.0240\n",
      "     17        0.5883       \u001b[32m0.6016\u001b[0m        \u001b[35m1.1458\u001b[0m  0.0249\n",
      "     18        0.5719       0.5000        1.6900  0.0290\n",
      "     19        0.6181       0.5547        1.3375  0.0284\n",
      "     20        0.5846       0.5000        1.6502  0.0275\n",
      "     21        0.6304       \u001b[32m0.6250\u001b[0m        1.1588  0.0271\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7067\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.5351\u001b[0m  0.0267\n",
      "      2        0.8492       0.5000        1.5600  0.0287\n",
      "      3        0.8518       0.5000        \u001b[35m1.5020\u001b[0m  0.0269\n",
      "      4        0.7993       0.5000        \u001b[35m1.4367\u001b[0m  0.0320\n",
      "      5        0.7836       0.5000        \u001b[35m1.4329\u001b[0m  0.0248\n",
      "      6        0.7763       0.5000        \u001b[35m1.3819\u001b[0m  0.0272\n",
      "      7        0.7677       0.5000        1.4338  0.0285\n",
      "      8        0.7310       0.5000        1.4600  0.0263\n",
      "      9        0.7674       \u001b[32m0.5312\u001b[0m        \u001b[35m1.3534\u001b[0m  0.0309\n",
      "     10        0.7899       0.5000        1.4999  0.0252\n",
      "     11        0.8540       0.5000        1.4496  0.0249\n",
      "     12        0.8331       \u001b[32m0.5391\u001b[0m        \u001b[35m1.2532\u001b[0m  0.0281\n",
      "     13        0.7672       0.5234        \u001b[35m1.2473\u001b[0m  0.0275\n",
      "     14        0.8143       0.5000        1.3513  0.0257\n",
      "     15        0.8307       0.5000        1.4434  0.0304\n",
      "     16        0.8144       \u001b[32m0.5625\u001b[0m        1.2877  0.0261\n",
      "     17        0.7538       0.5391        1.2692  0.0278\n",
      "     18        0.7624       \u001b[32m0.5703\u001b[0m        \u001b[35m1.1841\u001b[0m  0.0275\n",
      "     19        0.7495       \u001b[32m0.5781\u001b[0m        \u001b[35m1.1718\u001b[0m  0.0286\n",
      "     20        0.7425       \u001b[32m0.6094\u001b[0m        \u001b[35m1.1114\u001b[0m  0.0281\n",
      "     21        0.7903       0.5469        1.1861  0.0291\n",
      "     22        0.8091       0.5000        1.4537  0.0287\n",
      "     23        0.8340       0.5000        1.4736  0.0272\n",
      "     24        0.8131       0.5781        1.1606  0.0251\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6253\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.5947\u001b[0m  0.0237\n",
      "      2        0.8131       0.5000        \u001b[35m1.2978\u001b[0m  0.0265\n",
      "      3        0.7765       0.5000        1.3060  0.0283\n",
      "      4        0.8092       0.5000        1.4331  0.0269\n",
      "      5        0.8235       0.5000        1.3185  0.0281\n",
      "      6        0.8426       0.5000        \u001b[35m1.2721\u001b[0m  0.0270\n",
      "      7        0.8341       0.5000        1.3397  0.0278\n",
      "      8        0.8142       0.5000        1.3292  0.0296\n",
      "      9        0.8366       0.5000        1.3145  0.0294\n",
      "     10        0.8141       0.5000        1.3267  0.0269\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5273\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.4533\u001b[0m  0.0217\n",
      "      2        0.6305       0.5000        1.5811  0.0226\n",
      "      3        0.6394       0.5000        \u001b[35m1.2859\u001b[0m  0.0306\n",
      "      4        0.5684       0.5000        1.4094  0.0266\n",
      "      5        0.5609       \u001b[32m0.5859\u001b[0m        \u001b[35m1.0003\u001b[0m  0.0256\n",
      "      6        0.6444       0.5000        1.3964  0.0294\n",
      "      7        0.6354       \u001b[32m0.5938\u001b[0m        1.0423  0.0274\n",
      "      8        0.6484       0.5547        1.1622  0.0256\n",
      "      9        0.6229       0.5000        1.2934  0.0278\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4710\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.5928\u001b[0m  0.0217\n",
      "      2        0.7043       0.5000        1.5967  0.0229\n",
      "      3        0.7054       0.5000        1.5971  0.0341\n",
      "      4        0.7052       0.5000        1.5970  0.0298\n",
      "      5        0.7049       0.5000        1.5965  0.0271\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4602\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.6291\u001b[0m  0.0218\n",
      "      2        0.6413       0.5000        \u001b[35m1.6126\u001b[0m  0.0217\n",
      "      3        0.6448       0.5000        \u001b[35m1.6125\u001b[0m  0.0314\n",
      "      4        0.6448       0.5000        \u001b[35m1.6121\u001b[0m  0.0293\n",
      "      5        0.6444       0.5000        \u001b[35m1.6081\u001b[0m  0.0269\n",
      "      6        0.6436       0.5000        1.6103  0.0258\n",
      "      7        0.6438       0.5000        \u001b[35m1.6052\u001b[0m  0.0272\n",
      "      8        0.6409       0.5000        1.6374  0.0275\n",
      "      9        0.6279       0.5000        1.6079  0.0261\n",
      "     10        0.6304       0.5000        1.6170  0.0260\n",
      "     11        0.6397       0.5000        \u001b[35m1.5793\u001b[0m  0.0271\n",
      "     12        0.6349       0.5000        \u001b[35m1.5763\u001b[0m  0.0275\n",
      "     13        0.6335       0.5000        1.5882  0.0273\n",
      "     14        0.6299       0.5000        1.5941  0.0304\n",
      "     15        0.6294       0.5000        1.7380  0.0250\n",
      "     16        0.6299       0.5000        1.6184  0.0250\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7126\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.5338\u001b[0m  0.0220\n",
      "      2        0.8802       0.5000        \u001b[35m1.5335\u001b[0m  0.0233\n",
      "      3        0.8802       0.5000        1.5335  0.0317\n",
      "      4        0.8802       0.5000        1.5335  0.0291\n",
      "      5        0.8802       0.5000        1.5335  0.0274\n",
      "      6        0.8802       0.5000        1.5335  0.0278\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6560\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.3326\u001b[0m  0.0214\n",
      "      2        0.8273       0.5000        1.3326  0.0216\n",
      "      3        0.8273       0.5000        \u001b[35m1.3325\u001b[0m  0.0224\n",
      "      4        0.8273       0.5000        1.3326  0.0385\n",
      "      5        0.8274       0.5000        \u001b[35m1.3325\u001b[0m  0.0297\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5359\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.5972\u001b[0m  0.0201\n",
      "      2        0.7188       0.5000        1.6069  0.0204\n",
      "      3        0.7182       0.5000        \u001b[35m1.4347\u001b[0m  0.0241\n",
      "      4        0.7142       0.5000        1.4585  0.0302\n",
      "      5        0.7242       0.5000        1.4718  0.0262\n",
      "      6        0.7249       0.5000        1.4550  0.0296\n",
      "      7        0.7267       0.5000        1.4996  0.0259\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7231\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6861\u001b[0m  0.0129\n",
      "      2        \u001b[36m0.7140\u001b[0m       0.5000        \u001b[35m0.6825\u001b[0m  0.0137\n",
      "      3        0.7149       0.5000        \u001b[35m0.6786\u001b[0m  0.0157\n",
      "      4        \u001b[36m0.7131\u001b[0m       0.5000        \u001b[35m0.6726\u001b[0m  0.0197\n",
      "      5        \u001b[36m0.7094\u001b[0m       0.5000        \u001b[35m0.6637\u001b[0m  0.0148\n",
      "      6        \u001b[36m0.7031\u001b[0m       0.5000        \u001b[35m0.6521\u001b[0m  0.0212\n",
      "      7        \u001b[36m0.6948\u001b[0m       0.5000        \u001b[35m0.6374\u001b[0m  0.0157\n",
      "      8        \u001b[36m0.6845\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6204\u001b[0m  0.0233\n",
      "      9        \u001b[36m0.6736\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6019\u001b[0m  0.0177\n",
      "     10        \u001b[36m0.6618\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5838\u001b[0m  0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11        \u001b[36m0.6510\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5671\u001b[0m  0.0151\n",
      "     12        \u001b[36m0.6411\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5530\u001b[0m  0.0222\n",
      "     13        \u001b[36m0.6330\u001b[0m       0.7500        \u001b[35m0.5407\u001b[0m  0.0155\n",
      "     14        \u001b[36m0.6266\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.5295\u001b[0m  0.0249\n",
      "     15        \u001b[36m0.6207\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.5202\u001b[0m  0.0135\n",
      "     16        \u001b[36m0.6148\u001b[0m       0.7891        \u001b[35m0.5125\u001b[0m  0.0272\n",
      "     17        \u001b[36m0.6108\u001b[0m       0.7891        \u001b[35m0.5054\u001b[0m  0.0172\n",
      "     18        \u001b[36m0.6065\u001b[0m       0.7812        \u001b[35m0.4993\u001b[0m  0.0175\n",
      "     19        \u001b[36m0.6036\u001b[0m       0.7812        \u001b[35m0.4933\u001b[0m  0.0157\n",
      "     20        \u001b[36m0.5998\u001b[0m       0.7812        \u001b[35m0.4878\u001b[0m  0.0211\n",
      "     21        \u001b[36m0.5960\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4824\u001b[0m  0.0176\n",
      "     22        \u001b[36m0.5923\u001b[0m       0.8125        \u001b[35m0.4773\u001b[0m  0.0168\n",
      "     23        \u001b[36m0.5876\u001b[0m       0.8125        \u001b[35m0.4730\u001b[0m  0.0196\n",
      "     24        \u001b[36m0.5839\u001b[0m       0.8047        \u001b[35m0.4684\u001b[0m  0.0184\n",
      "     25        \u001b[36m0.5801\u001b[0m       0.8047        \u001b[35m0.4644\u001b[0m  0.0207\n",
      "     26        \u001b[36m0.5762\u001b[0m       0.8047        \u001b[35m0.4609\u001b[0m  0.0207\n",
      "     27        \u001b[36m0.5733\u001b[0m       0.8125        \u001b[35m0.4575\u001b[0m  0.0169\n",
      "     28        \u001b[36m0.5701\u001b[0m       0.8125        \u001b[35m0.4530\u001b[0m  0.0208\n",
      "     29        \u001b[36m0.5661\u001b[0m       0.8047        \u001b[35m0.4492\u001b[0m  0.0155\n",
      "     30        \u001b[36m0.5630\u001b[0m       0.8047        \u001b[35m0.4459\u001b[0m  0.0208\n",
      "     31        \u001b[36m0.5602\u001b[0m       0.7969        \u001b[35m0.4434\u001b[0m  0.0211\n",
      "     32        \u001b[36m0.5575\u001b[0m       0.7891        \u001b[35m0.4409\u001b[0m  0.0204\n",
      "     33        \u001b[36m0.5552\u001b[0m       0.7891        \u001b[35m0.4388\u001b[0m  0.0144\n",
      "     34        \u001b[36m0.5526\u001b[0m       0.7891        \u001b[35m0.4367\u001b[0m  0.0215\n",
      "     35        \u001b[36m0.5506\u001b[0m       0.7891        \u001b[35m0.4351\u001b[0m  0.0142\n",
      "     36        \u001b[36m0.5489\u001b[0m       0.7969        \u001b[35m0.4334\u001b[0m  0.0223\n",
      "     37        \u001b[36m0.5467\u001b[0m       0.7891        \u001b[35m0.4315\u001b[0m  0.0144\n",
      "     38        \u001b[36m0.5447\u001b[0m       0.7891        \u001b[35m0.4299\u001b[0m  0.0206\n",
      "     39        \u001b[36m0.5430\u001b[0m       0.7891        \u001b[35m0.4281\u001b[0m  0.0130\n",
      "     40        \u001b[36m0.5412\u001b[0m       0.7891        \u001b[35m0.4262\u001b[0m  0.0233\n",
      "     41        \u001b[36m0.5399\u001b[0m       0.7891        \u001b[35m0.4244\u001b[0m  0.0295\n",
      "     42        \u001b[36m0.5381\u001b[0m       0.7891        \u001b[35m0.4224\u001b[0m  0.0245\n",
      "     43        \u001b[36m0.5365\u001b[0m       0.7891        \u001b[35m0.4206\u001b[0m  0.0679\n",
      "     44        \u001b[36m0.5351\u001b[0m       0.7891        \u001b[35m0.4191\u001b[0m  0.0559\n",
      "     45        \u001b[36m0.5337\u001b[0m       0.7891        \u001b[35m0.4178\u001b[0m  0.0503\n",
      "     46        \u001b[36m0.5322\u001b[0m       0.7969        \u001b[35m0.4164\u001b[0m  0.0354\n",
      "     47        \u001b[36m0.5307\u001b[0m       0.7969        \u001b[35m0.4151\u001b[0m  0.0344\n",
      "     48        \u001b[36m0.5295\u001b[0m       0.7969        \u001b[35m0.4135\u001b[0m  0.0206\n",
      "     49        \u001b[36m0.5278\u001b[0m       0.7969        \u001b[35m0.4125\u001b[0m  0.0234\n",
      "     50        \u001b[36m0.5267\u001b[0m       0.7969        \u001b[35m0.4115\u001b[0m  0.0556\n",
      "     51        \u001b[36m0.5253\u001b[0m       0.8047        \u001b[35m0.4107\u001b[0m  0.0305\n",
      "     52        \u001b[36m0.5238\u001b[0m       0.7891        \u001b[35m0.4098\u001b[0m  0.0634\n",
      "     53        \u001b[36m0.5229\u001b[0m       0.7891        \u001b[35m0.4093\u001b[0m  0.0376\n",
      "     54        \u001b[36m0.5214\u001b[0m       0.7969        \u001b[35m0.4082\u001b[0m  0.0423\n",
      "     55        \u001b[36m0.5204\u001b[0m       0.7969        \u001b[35m0.4076\u001b[0m  0.0283\n",
      "     56        \u001b[36m0.5192\u001b[0m       0.7891        \u001b[35m0.4068\u001b[0m  0.0252\n",
      "     57        \u001b[36m0.5176\u001b[0m       0.7891        \u001b[35m0.4058\u001b[0m  0.0189\n",
      "     58        \u001b[36m0.5161\u001b[0m       0.7891        \u001b[35m0.4052\u001b[0m  0.0283\n",
      "     59        \u001b[36m0.5150\u001b[0m       0.7891        \u001b[35m0.4049\u001b[0m  0.0277\n",
      "     60        \u001b[36m0.5138\u001b[0m       0.7891        \u001b[35m0.4045\u001b[0m  0.0293\n",
      "     61        \u001b[36m0.5127\u001b[0m       0.7891        0.4047  0.0464\n",
      "     62        \u001b[36m0.5116\u001b[0m       0.7812        0.4047  0.0401\n",
      "     63        \u001b[36m0.5100\u001b[0m       0.7812        \u001b[35m0.4042\u001b[0m  0.0340\n",
      "     64        \u001b[36m0.5083\u001b[0m       0.7812        \u001b[35m0.4041\u001b[0m  0.0474\n",
      "     65        \u001b[36m0.5073\u001b[0m       0.7812        \u001b[35m0.4039\u001b[0m  0.0764\n",
      "     66        \u001b[36m0.5062\u001b[0m       0.7812        \u001b[35m0.4027\u001b[0m  0.0193\n",
      "     67        \u001b[36m0.5045\u001b[0m       0.7812        \u001b[35m0.4025\u001b[0m  0.0328\n",
      "     68        \u001b[36m0.5037\u001b[0m       0.7891        \u001b[35m0.4016\u001b[0m  0.0279\n",
      "     69        \u001b[36m0.5020\u001b[0m       0.7812        \u001b[35m0.4009\u001b[0m  0.0156\n",
      "     70        \u001b[36m0.5009\u001b[0m       0.7891        \u001b[35m0.4000\u001b[0m  0.0143\n",
      "     71        \u001b[36m0.4992\u001b[0m       0.7891        \u001b[35m0.3989\u001b[0m  0.0147\n",
      "     72        \u001b[36m0.4976\u001b[0m       0.7891        \u001b[35m0.3978\u001b[0m  0.0149\n",
      "     73        \u001b[36m0.4965\u001b[0m       0.7969        \u001b[35m0.3964\u001b[0m  0.0194\n",
      "     74        \u001b[36m0.4947\u001b[0m       0.7969        \u001b[35m0.3954\u001b[0m  0.0175\n",
      "     75        \u001b[36m0.4933\u001b[0m       0.7969        \u001b[35m0.3945\u001b[0m  0.0182\n",
      "     76        \u001b[36m0.4920\u001b[0m       0.8047        \u001b[35m0.3936\u001b[0m  0.0241\n",
      "     77        \u001b[36m0.4904\u001b[0m       0.8047        \u001b[35m0.3927\u001b[0m  0.0305\n",
      "     78        \u001b[36m0.4892\u001b[0m       0.8047        \u001b[35m0.3910\u001b[0m  0.0333\n",
      "     79        \u001b[36m0.4881\u001b[0m       0.8125        \u001b[35m0.3894\u001b[0m  0.0320\n",
      "     80        \u001b[36m0.4857\u001b[0m       0.8125        \u001b[35m0.3885\u001b[0m  0.0192\n",
      "     81        \u001b[36m0.4842\u001b[0m       0.8125        \u001b[35m0.3870\u001b[0m  0.0248\n",
      "     82        \u001b[36m0.4820\u001b[0m       0.8125        \u001b[35m0.3866\u001b[0m  0.0281\n",
      "     83        \u001b[36m0.4803\u001b[0m       0.8047        \u001b[35m0.3848\u001b[0m  0.0260\n",
      "     84        \u001b[36m0.4764\u001b[0m       0.8047        \u001b[35m0.3846\u001b[0m  0.0261\n",
      "     85        \u001b[36m0.4756\u001b[0m       0.8125        \u001b[35m0.3833\u001b[0m  0.0293\n",
      "     86        \u001b[36m0.4732\u001b[0m       0.8125        \u001b[35m0.3827\u001b[0m  0.0367\n",
      "     87        \u001b[36m0.4716\u001b[0m       0.8125        \u001b[35m0.3809\u001b[0m  0.0291\n",
      "     88        \u001b[36m0.4690\u001b[0m       0.8125        \u001b[35m0.3801\u001b[0m  0.0212\n",
      "     89        \u001b[36m0.4673\u001b[0m       0.8125        \u001b[35m0.3794\u001b[0m  0.0151\n",
      "     90        \u001b[36m0.4656\u001b[0m       0.8125        \u001b[35m0.3790\u001b[0m  0.0157\n",
      "     91        \u001b[36m0.4641\u001b[0m       0.8047        \u001b[35m0.3780\u001b[0m  0.0178\n",
      "     92        \u001b[36m0.4625\u001b[0m       0.7891        \u001b[35m0.3773\u001b[0m  0.0169\n",
      "     93        \u001b[36m0.4610\u001b[0m       0.7891        \u001b[35m0.3762\u001b[0m  0.0178\n",
      "     94        \u001b[36m0.4588\u001b[0m       0.7891        \u001b[35m0.3756\u001b[0m  0.0176\n",
      "     95        \u001b[36m0.4570\u001b[0m       0.7969        \u001b[35m0.3747\u001b[0m  0.0209\n",
      "     96        \u001b[36m0.4558\u001b[0m       0.8047        \u001b[35m0.3739\u001b[0m  0.0171\n",
      "     97        \u001b[36m0.4542\u001b[0m       0.8047        \u001b[35m0.3734\u001b[0m  0.0436\n",
      "     98        \u001b[36m0.4523\u001b[0m       0.8047        \u001b[35m0.3724\u001b[0m  0.0358\n",
      "     99        \u001b[36m0.4505\u001b[0m       0.8047        \u001b[35m0.3716\u001b[0m  0.0412\n",
      "    100        \u001b[36m0.4486\u001b[0m       0.8125        \u001b[35m0.3716\u001b[0m  0.0454\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7305\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6775\u001b[0m  0.0198\n",
      "      2        \u001b[36m0.6986\u001b[0m       0.5000        \u001b[35m0.6694\u001b[0m  0.0373\n",
      "      3        \u001b[36m0.6963\u001b[0m       0.5000        \u001b[35m0.6651\u001b[0m  0.0199\n",
      "      4        \u001b[36m0.6900\u001b[0m       0.5000        \u001b[35m0.6587\u001b[0m  0.0154\n",
      "      5        \u001b[36m0.6797\u001b[0m       0.5859        \u001b[35m0.6515\u001b[0m  0.0147\n",
      "      6        \u001b[36m0.6680\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6450\u001b[0m  0.0249\n",
      "      7        \u001b[36m0.6560\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6400\u001b[0m  0.0257\n",
      "      8        \u001b[36m0.6452\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6362\u001b[0m  0.0154\n",
      "      9        \u001b[36m0.6358\u001b[0m       0.7266        \u001b[35m0.6338\u001b[0m  0.0166\n",
      "     10        \u001b[36m0.6280\u001b[0m       0.7188        \u001b[35m0.6323\u001b[0m  0.0227\n",
      "     11        \u001b[36m0.6214\u001b[0m       0.7031        \u001b[35m0.6310\u001b[0m  0.0168\n",
      "     12        \u001b[36m0.6154\u001b[0m       0.7031        \u001b[35m0.6295\u001b[0m  0.0179\n",
      "     13        \u001b[36m0.6099\u001b[0m       0.7031        \u001b[35m0.6281\u001b[0m  0.0264\n",
      "     14        \u001b[36m0.6051\u001b[0m       0.6953        \u001b[35m0.6263\u001b[0m  0.0163\n",
      "     15        \u001b[36m0.6009\u001b[0m       0.6953        \u001b[35m0.6241\u001b[0m  0.0196\n",
      "     16        \u001b[36m0.5964\u001b[0m       0.6953        \u001b[35m0.6226\u001b[0m  0.0158\n",
      "     17        \u001b[36m0.5935\u001b[0m       0.6875        \u001b[35m0.6209\u001b[0m  0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        \u001b[36m0.5904\u001b[0m       0.6875        \u001b[35m0.6197\u001b[0m  0.0140\n",
      "     19        \u001b[36m0.5879\u001b[0m       0.6875        \u001b[35m0.6186\u001b[0m  0.0221\n",
      "     20        \u001b[36m0.5857\u001b[0m       0.6797        \u001b[35m0.6172\u001b[0m  0.0258\n",
      "     21        \u001b[36m0.5838\u001b[0m       0.6797        \u001b[35m0.6160\u001b[0m  0.0194\n",
      "     22        \u001b[36m0.5824\u001b[0m       0.6797        \u001b[35m0.6146\u001b[0m  0.0161\n",
      "     23        \u001b[36m0.5804\u001b[0m       0.6797        \u001b[35m0.6133\u001b[0m  0.0183\n",
      "     24        \u001b[36m0.5790\u001b[0m       0.6797        \u001b[35m0.6118\u001b[0m  0.0320\n",
      "     25        \u001b[36m0.5776\u001b[0m       0.6875        \u001b[35m0.6101\u001b[0m  0.0527\n",
      "     26        \u001b[36m0.5759\u001b[0m       0.6953        \u001b[35m0.6084\u001b[0m  0.0386\n",
      "     27        \u001b[36m0.5744\u001b[0m       0.7031        \u001b[35m0.6062\u001b[0m  0.0580\n",
      "     28        \u001b[36m0.5731\u001b[0m       0.6953        \u001b[35m0.6040\u001b[0m  0.0403\n",
      "     29        \u001b[36m0.5714\u001b[0m       0.6953        \u001b[35m0.6018\u001b[0m  0.0458\n",
      "     30        \u001b[36m0.5698\u001b[0m       0.6953        \u001b[35m0.5995\u001b[0m  0.0325\n",
      "     31        \u001b[36m0.5681\u001b[0m       0.7109        \u001b[35m0.5969\u001b[0m  0.0571\n",
      "     32        \u001b[36m0.5666\u001b[0m       0.7188        \u001b[35m0.5942\u001b[0m  0.0345\n",
      "     33        \u001b[36m0.5648\u001b[0m       0.7188        \u001b[35m0.5917\u001b[0m  0.0241\n",
      "     34        \u001b[36m0.5631\u001b[0m       0.7188        \u001b[35m0.5893\u001b[0m  0.0296\n",
      "     35        \u001b[36m0.5618\u001b[0m       0.7266        \u001b[35m0.5867\u001b[0m  0.0248\n",
      "     36        \u001b[36m0.5595\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5842\u001b[0m  0.0157\n",
      "     37        \u001b[36m0.5582\u001b[0m       0.7344        \u001b[35m0.5816\u001b[0m  0.0212\n",
      "     38        \u001b[36m0.5564\u001b[0m       0.7344        \u001b[35m0.5793\u001b[0m  0.0320\n",
      "     39        \u001b[36m0.5546\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5767\u001b[0m  0.0174\n",
      "     40        \u001b[36m0.5531\u001b[0m       0.7422        \u001b[35m0.5742\u001b[0m  0.0286\n",
      "     41        \u001b[36m0.5510\u001b[0m       0.7422        \u001b[35m0.5718\u001b[0m  0.0182\n",
      "     42        \u001b[36m0.5497\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5694\u001b[0m  0.0157\n",
      "     43        \u001b[36m0.5480\u001b[0m       0.7500        \u001b[35m0.5671\u001b[0m  0.0520\n",
      "     44        \u001b[36m0.5457\u001b[0m       0.7500        \u001b[35m0.5650\u001b[0m  0.0877\n",
      "     45        \u001b[36m0.5442\u001b[0m       0.7500        \u001b[35m0.5627\u001b[0m  0.0452\n",
      "     46        \u001b[36m0.5426\u001b[0m       0.7500        \u001b[35m0.5604\u001b[0m  0.0212\n",
      "     47        \u001b[36m0.5406\u001b[0m       0.7422        \u001b[35m0.5587\u001b[0m  0.0600\n",
      "     48        \u001b[36m0.5392\u001b[0m       0.7422        \u001b[35m0.5568\u001b[0m  0.0293\n",
      "     49        \u001b[36m0.5374\u001b[0m       0.7422        \u001b[35m0.5547\u001b[0m  0.0293\n",
      "     50        \u001b[36m0.5360\u001b[0m       0.7422        \u001b[35m0.5529\u001b[0m  0.0248\n",
      "     51        \u001b[36m0.5348\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5513\u001b[0m  0.0398\n",
      "     52        \u001b[36m0.5327\u001b[0m       0.7578        \u001b[35m0.5499\u001b[0m  0.0350\n",
      "     53        \u001b[36m0.5308\u001b[0m       0.7578        \u001b[35m0.5487\u001b[0m  0.0275\n",
      "     54        \u001b[36m0.5294\u001b[0m       0.7578        \u001b[35m0.5474\u001b[0m  0.0293\n",
      "     55        \u001b[36m0.5275\u001b[0m       0.7578        \u001b[35m0.5464\u001b[0m  0.0429\n",
      "     56        \u001b[36m0.5255\u001b[0m       0.7500        \u001b[35m0.5452\u001b[0m  0.0236\n",
      "     57        \u001b[36m0.5240\u001b[0m       0.7500        \u001b[35m0.5438\u001b[0m  0.0272\n",
      "     58        \u001b[36m0.5227\u001b[0m       0.7500        \u001b[35m0.5427\u001b[0m  0.0211\n",
      "     59        \u001b[36m0.5208\u001b[0m       0.7500        \u001b[35m0.5417\u001b[0m  0.0342\n",
      "     60        \u001b[36m0.5199\u001b[0m       0.7500        \u001b[35m0.5413\u001b[0m  0.0263\n",
      "     61        \u001b[36m0.5183\u001b[0m       0.7500        \u001b[35m0.5408\u001b[0m  0.0242\n",
      "     62        \u001b[36m0.5163\u001b[0m       0.7578        \u001b[35m0.5405\u001b[0m  0.0237\n",
      "     63        \u001b[36m0.5146\u001b[0m       0.7500        0.5405  0.0234\n",
      "     64        \u001b[36m0.5131\u001b[0m       0.7500        0.5407  0.0265\n",
      "     65        \u001b[36m0.5118\u001b[0m       0.7500        0.5409  0.0230\n",
      "     66        \u001b[36m0.5103\u001b[0m       0.7422        0.5411  0.0344\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7067\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6695\u001b[0m  0.0512\n",
      "      2        \u001b[36m0.6921\u001b[0m       0.6328        \u001b[35m0.6626\u001b[0m  0.0255\n",
      "      3        \u001b[36m0.6811\u001b[0m       0.6875        \u001b[35m0.6526\u001b[0m  0.0146\n",
      "      4        \u001b[36m0.6623\u001b[0m       0.6797        \u001b[35m0.6403\u001b[0m  0.0276\n",
      "      5        \u001b[36m0.6398\u001b[0m       0.6953        \u001b[35m0.6281\u001b[0m  0.0431\n",
      "      6        \u001b[36m0.6160\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6186\u001b[0m  0.0172\n",
      "      7        \u001b[36m0.5946\u001b[0m       0.6953        \u001b[35m0.6130\u001b[0m  0.0151\n",
      "      8        \u001b[36m0.5776\u001b[0m       0.6797        \u001b[35m0.6099\u001b[0m  0.0199\n",
      "      9        \u001b[36m0.5646\u001b[0m       0.6562        \u001b[35m0.6088\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.5557\u001b[0m       0.6641        \u001b[35m0.6079\u001b[0m  0.0171\n",
      "     11        \u001b[36m0.5489\u001b[0m       0.6797        \u001b[35m0.6062\u001b[0m  0.0191\n",
      "     12        \u001b[36m0.5441\u001b[0m       0.6797        \u001b[35m0.6038\u001b[0m  0.0198\n",
      "     13        \u001b[36m0.5402\u001b[0m       0.6875        \u001b[35m0.6007\u001b[0m  0.0211\n",
      "     14        \u001b[36m0.5368\u001b[0m       0.6875        \u001b[35m0.5976\u001b[0m  0.0209\n",
      "     15        \u001b[36m0.5340\u001b[0m       0.6875        \u001b[35m0.5950\u001b[0m  0.0343\n",
      "     16        \u001b[36m0.5316\u001b[0m       0.6953        \u001b[35m0.5921\u001b[0m  0.0305\n",
      "     17        \u001b[36m0.5287\u001b[0m       0.7031        \u001b[35m0.5894\u001b[0m  0.0178\n",
      "     18        \u001b[36m0.5265\u001b[0m       0.7031        \u001b[35m0.5861\u001b[0m  0.0269\n",
      "     19        \u001b[36m0.5238\u001b[0m       0.7031        \u001b[35m0.5832\u001b[0m  0.0212\n",
      "     20        \u001b[36m0.5217\u001b[0m       0.7031        \u001b[35m0.5804\u001b[0m  0.0198\n",
      "     21        \u001b[36m0.5192\u001b[0m       0.6953        \u001b[35m0.5779\u001b[0m  0.0310\n",
      "     22        \u001b[36m0.5171\u001b[0m       0.6953        \u001b[35m0.5755\u001b[0m  0.0251\n",
      "     23        \u001b[36m0.5148\u001b[0m       0.7031        \u001b[35m0.5736\u001b[0m  0.0332\n",
      "     24        \u001b[36m0.5127\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5714\u001b[0m  0.0454\n",
      "     25        \u001b[36m0.5104\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5697\u001b[0m  0.0553\n",
      "     26        \u001b[36m0.5085\u001b[0m       0.7266        \u001b[35m0.5679\u001b[0m  0.0205\n",
      "     27        \u001b[36m0.5068\u001b[0m       0.7266        \u001b[35m0.5662\u001b[0m  0.0330\n",
      "     28        \u001b[36m0.5046\u001b[0m       0.7266        \u001b[35m0.5652\u001b[0m  0.0260\n",
      "     29        \u001b[36m0.5031\u001b[0m       0.7266        \u001b[35m0.5641\u001b[0m  0.0431\n",
      "     30        \u001b[36m0.5014\u001b[0m       0.7266        \u001b[35m0.5629\u001b[0m  0.0513\n",
      "     31        \u001b[36m0.4996\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5616\u001b[0m  0.0199\n",
      "     32        \u001b[36m0.4980\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5607\u001b[0m  0.0159\n",
      "     33        \u001b[36m0.4965\u001b[0m       0.7422        \u001b[35m0.5600\u001b[0m  0.0143\n",
      "     34        \u001b[36m0.4947\u001b[0m       0.7422        \u001b[35m0.5594\u001b[0m  0.0168\n",
      "     35        \u001b[36m0.4930\u001b[0m       0.7422        \u001b[35m0.5587\u001b[0m  0.0173\n",
      "     36        \u001b[36m0.4915\u001b[0m       0.7422        \u001b[35m0.5574\u001b[0m  0.0189\n",
      "     37        \u001b[36m0.4900\u001b[0m       0.7266        \u001b[35m0.5565\u001b[0m  0.0363\n",
      "     38        \u001b[36m0.4882\u001b[0m       0.7266        \u001b[35m0.5558\u001b[0m  0.0392\n",
      "     39        \u001b[36m0.4867\u001b[0m       0.7266        \u001b[35m0.5553\u001b[0m  0.0344\n",
      "     40        \u001b[36m0.4848\u001b[0m       0.7266        \u001b[35m0.5548\u001b[0m  0.0238\n",
      "     41        \u001b[36m0.4833\u001b[0m       0.7266        \u001b[35m0.5543\u001b[0m  0.0472\n",
      "     42        \u001b[36m0.4817\u001b[0m       0.7266        \u001b[35m0.5541\u001b[0m  0.0297\n",
      "     43        \u001b[36m0.4801\u001b[0m       0.7266        \u001b[35m0.5540\u001b[0m  0.0319\n",
      "     44        \u001b[36m0.4786\u001b[0m       0.7266        \u001b[35m0.5538\u001b[0m  0.0460\n",
      "     45        \u001b[36m0.4772\u001b[0m       0.7266        \u001b[35m0.5534\u001b[0m  0.0371\n",
      "     46        \u001b[36m0.4755\u001b[0m       0.7266        \u001b[35m0.5527\u001b[0m  0.0339\n",
      "     47        \u001b[36m0.4738\u001b[0m       0.7344        \u001b[35m0.5527\u001b[0m  0.0326\n",
      "     48        \u001b[36m0.4722\u001b[0m       0.7344        \u001b[35m0.5522\u001b[0m  0.0427\n",
      "     49        \u001b[36m0.4703\u001b[0m       0.7344        \u001b[35m0.5520\u001b[0m  0.0241\n",
      "     50        \u001b[36m0.4689\u001b[0m       0.7422        \u001b[35m0.5513\u001b[0m  0.0272\n",
      "     51        \u001b[36m0.4668\u001b[0m       0.7422        \u001b[35m0.5509\u001b[0m  0.0338\n",
      "     52        \u001b[36m0.4652\u001b[0m       0.7422        \u001b[35m0.5506\u001b[0m  0.0348\n",
      "     53        \u001b[36m0.4634\u001b[0m       0.7422        \u001b[35m0.5505\u001b[0m  0.0353\n",
      "     54        \u001b[36m0.4620\u001b[0m       0.7422        0.5507  0.0344\n",
      "     55        \u001b[36m0.4602\u001b[0m       0.7422        0.5506  0.0335\n",
      "     56        \u001b[36m0.4584\u001b[0m       0.7422        \u001b[35m0.5501\u001b[0m  0.0428\n",
      "     57        \u001b[36m0.4567\u001b[0m       0.7344        \u001b[35m0.5498\u001b[0m  0.0472\n",
      "     58        \u001b[36m0.4551\u001b[0m       0.7422        \u001b[35m0.5492\u001b[0m  0.0470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     59        \u001b[36m0.4539\u001b[0m       0.7422        \u001b[35m0.5490\u001b[0m  0.0462\n",
      "     60        \u001b[36m0.4522\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5482\u001b[0m  0.0179\n",
      "     61        \u001b[36m0.4504\u001b[0m       0.7500        0.5483  0.0382\n",
      "     62        \u001b[36m0.4493\u001b[0m       0.7500        \u001b[35m0.5475\u001b[0m  0.0331\n",
      "     63        \u001b[36m0.4479\u001b[0m       0.7500        \u001b[35m0.5470\u001b[0m  0.0321\n",
      "     64        \u001b[36m0.4468\u001b[0m       0.7500        \u001b[35m0.5466\u001b[0m  0.0202\n",
      "     65        \u001b[36m0.4454\u001b[0m       0.7500        \u001b[35m0.5461\u001b[0m  0.0176\n",
      "     66        \u001b[36m0.4444\u001b[0m       0.7500        \u001b[35m0.5455\u001b[0m  0.0212\n",
      "     67        \u001b[36m0.4429\u001b[0m       0.7500        0.5456  0.0190\n",
      "     68        \u001b[36m0.4419\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5455\u001b[0m  0.0348\n",
      "     69        \u001b[36m0.4409\u001b[0m       0.7578        0.5456  0.0284\n",
      "     70        \u001b[36m0.4395\u001b[0m       0.7578        0.5458  0.0283\n",
      "     71        \u001b[36m0.4384\u001b[0m       0.7422        \u001b[35m0.5455\u001b[0m  0.0298\n",
      "     72        \u001b[36m0.4376\u001b[0m       0.7500        0.5459  0.0185\n",
      "     73        \u001b[36m0.4367\u001b[0m       0.7500        0.5460  0.0237\n",
      "     74        \u001b[36m0.4355\u001b[0m       0.7500        0.5458  0.0377\n",
      "     75        \u001b[36m0.4347\u001b[0m       0.7500        0.5462  0.0297\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7192\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6903\u001b[0m  0.0317\n",
      "      2        \u001b[36m0.6999\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6829\u001b[0m  0.0441\n",
      "      3        \u001b[36m0.6968\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6778\u001b[0m  0.0289\n",
      "      4        \u001b[36m0.6918\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6707\u001b[0m  0.0400\n",
      "      5        \u001b[36m0.6826\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6593\u001b[0m  0.0308\n",
      "      6        \u001b[36m0.6683\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6421\u001b[0m  0.0346\n",
      "      7        \u001b[36m0.6471\u001b[0m       0.6875        \u001b[35m0.6188\u001b[0m  0.0626\n",
      "      8        \u001b[36m0.6205\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5925\u001b[0m  0.0417\n",
      "      9        \u001b[36m0.5930\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5685\u001b[0m  0.0493\n",
      "     10        \u001b[36m0.5689\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5505\u001b[0m  0.0357\n",
      "     11        \u001b[36m0.5515\u001b[0m       0.7422        \u001b[35m0.5377\u001b[0m  0.0235\n",
      "     12        \u001b[36m0.5397\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5293\u001b[0m  0.0227\n",
      "     13        \u001b[36m0.5316\u001b[0m       0.7500        \u001b[35m0.5238\u001b[0m  0.0203\n",
      "     14        \u001b[36m0.5250\u001b[0m       0.7422        \u001b[35m0.5201\u001b[0m  0.0244\n",
      "     15        \u001b[36m0.5197\u001b[0m       0.7422        \u001b[35m0.5170\u001b[0m  0.0414\n",
      "     16        \u001b[36m0.5149\u001b[0m       0.7422        \u001b[35m0.5148\u001b[0m  0.0243\n",
      "     17        \u001b[36m0.5114\u001b[0m       0.7344        \u001b[35m0.5131\u001b[0m  0.0350\n",
      "     18        \u001b[36m0.5071\u001b[0m       0.7344        \u001b[35m0.5122\u001b[0m  0.0478\n",
      "     19        \u001b[36m0.5038\u001b[0m       0.7266        \u001b[35m0.5112\u001b[0m  0.0317\n",
      "     20        \u001b[36m0.5007\u001b[0m       0.7266        \u001b[35m0.5105\u001b[0m  0.0472\n",
      "     21        \u001b[36m0.4970\u001b[0m       0.7422        \u001b[35m0.5097\u001b[0m  0.0842\n",
      "     22        \u001b[36m0.4938\u001b[0m       0.7422        \u001b[35m0.5089\u001b[0m  0.0289\n",
      "     23        \u001b[36m0.4904\u001b[0m       0.7344        \u001b[35m0.5082\u001b[0m  0.0357\n",
      "     24        \u001b[36m0.4877\u001b[0m       0.7344        \u001b[35m0.5075\u001b[0m  0.0453\n",
      "     25        \u001b[36m0.4850\u001b[0m       0.7344        \u001b[35m0.5070\u001b[0m  0.0298\n",
      "     26        \u001b[36m0.4823\u001b[0m       0.7344        \u001b[35m0.5069\u001b[0m  0.0294\n",
      "     27        \u001b[36m0.4798\u001b[0m       0.7344        0.5071  0.0341\n",
      "     28        \u001b[36m0.4774\u001b[0m       0.7344        0.5076  0.0263\n",
      "     29        \u001b[36m0.4750\u001b[0m       0.7422        0.5086  0.0203\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7306\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6874\u001b[0m  0.0199\n",
      "      2        \u001b[36m0.7010\u001b[0m       0.5000        \u001b[35m0.6790\u001b[0m  0.0270\n",
      "      3        \u001b[36m0.6968\u001b[0m       0.5000        \u001b[35m0.6751\u001b[0m  0.0333\n",
      "      4        \u001b[36m0.6890\u001b[0m       0.5000        \u001b[35m0.6700\u001b[0m  0.0234\n",
      "      5        \u001b[36m0.6751\u001b[0m       0.5234        \u001b[35m0.6617\u001b[0m  0.0230\n",
      "      6        \u001b[36m0.6565\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6491\u001b[0m  0.0435\n",
      "      7        \u001b[36m0.6318\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6340\u001b[0m  0.0340\n",
      "      8        \u001b[36m0.6026\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6197\u001b[0m  0.0211\n",
      "      9        \u001b[36m0.5727\u001b[0m       0.7188        \u001b[35m0.6096\u001b[0m  0.0449\n",
      "     10        \u001b[36m0.5474\u001b[0m       0.7109        \u001b[35m0.6046\u001b[0m  0.0391\n",
      "     11        \u001b[36m0.5283\u001b[0m       0.6953        \u001b[35m0.6034\u001b[0m  0.0371\n",
      "     12        \u001b[36m0.5153\u001b[0m       0.6875        0.6034  0.0705\n",
      "     13        \u001b[36m0.5066\u001b[0m       0.6953        \u001b[35m0.6025\u001b[0m  0.0283\n",
      "     14        \u001b[36m0.4997\u001b[0m       0.6953        \u001b[35m0.6011\u001b[0m  0.0216\n",
      "     15        \u001b[36m0.4939\u001b[0m       0.7031        \u001b[35m0.5993\u001b[0m  0.0166\n",
      "     16        \u001b[36m0.4895\u001b[0m       0.7031        \u001b[35m0.5974\u001b[0m  0.0268\n",
      "     17        \u001b[36m0.4860\u001b[0m       0.7031        \u001b[35m0.5950\u001b[0m  0.0190\n",
      "     18        \u001b[36m0.4823\u001b[0m       0.6953        \u001b[35m0.5932\u001b[0m  0.0309\n",
      "     19        \u001b[36m0.4798\u001b[0m       0.6875        \u001b[35m0.5915\u001b[0m  0.0515\n",
      "     20        \u001b[36m0.4772\u001b[0m       0.6953        \u001b[35m0.5899\u001b[0m  0.0238\n",
      "     21        \u001b[36m0.4746\u001b[0m       0.7031        \u001b[35m0.5885\u001b[0m  0.0316\n",
      "     22        \u001b[36m0.4724\u001b[0m       0.7031        \u001b[35m0.5870\u001b[0m  0.0281\n",
      "     23        \u001b[36m0.4702\u001b[0m       0.7109        \u001b[35m0.5855\u001b[0m  0.0459\n",
      "     24        \u001b[36m0.4685\u001b[0m       0.7109        \u001b[35m0.5840\u001b[0m  0.0417\n",
      "     25        \u001b[36m0.4668\u001b[0m       0.7109        \u001b[35m0.5827\u001b[0m  0.0279\n",
      "     26        \u001b[36m0.4647\u001b[0m       0.7109        \u001b[35m0.5815\u001b[0m  0.0315\n",
      "     27        \u001b[36m0.4632\u001b[0m       0.7109        \u001b[35m0.5805\u001b[0m  0.0208\n",
      "     28        \u001b[36m0.4619\u001b[0m       0.7109        \u001b[35m0.5798\u001b[0m  0.0452\n",
      "     29        \u001b[36m0.4606\u001b[0m       0.6953        \u001b[35m0.5792\u001b[0m  0.0498\n",
      "     30        \u001b[36m0.4594\u001b[0m       0.6953        \u001b[35m0.5787\u001b[0m  0.0578\n",
      "     31        \u001b[36m0.4584\u001b[0m       0.6953        \u001b[35m0.5783\u001b[0m  0.0296\n",
      "     32        \u001b[36m0.4575\u001b[0m       0.6953        \u001b[35m0.5782\u001b[0m  0.0307\n",
      "     33        \u001b[36m0.4567\u001b[0m       0.6953        \u001b[35m0.5780\u001b[0m  0.0465\n",
      "     34        \u001b[36m0.4556\u001b[0m       0.6953        \u001b[35m0.5779\u001b[0m  0.0300\n",
      "     35        \u001b[36m0.4551\u001b[0m       0.6953        \u001b[35m0.5775\u001b[0m  0.0320\n",
      "     36        \u001b[36m0.4539\u001b[0m       0.7031        \u001b[35m0.5774\u001b[0m  0.0318\n",
      "     37        \u001b[36m0.4530\u001b[0m       0.7031        \u001b[35m0.5771\u001b[0m  0.0291\n",
      "     38        \u001b[36m0.4521\u001b[0m       0.7031        \u001b[35m0.5769\u001b[0m  0.0494\n",
      "     39        \u001b[36m0.4509\u001b[0m       0.7109        \u001b[35m0.5769\u001b[0m  0.0444\n",
      "     40        \u001b[36m0.4505\u001b[0m       0.7188        \u001b[35m0.5765\u001b[0m  0.0255\n",
      "     41        \u001b[36m0.4491\u001b[0m       0.7188        \u001b[35m0.5763\u001b[0m  0.0193\n",
      "     42        \u001b[36m0.4483\u001b[0m       0.7188        \u001b[35m0.5763\u001b[0m  0.0382\n",
      "     43        \u001b[36m0.4476\u001b[0m       0.7188        \u001b[35m0.5762\u001b[0m  0.0338\n",
      "     44        \u001b[36m0.4467\u001b[0m       \u001b[32m0.7266\u001b[0m        0.5763  0.0309\n",
      "     45        \u001b[36m0.4460\u001b[0m       0.7266        0.5762  0.0312\n",
      "     46        \u001b[36m0.4450\u001b[0m       0.7188        0.5765  0.0293\n",
      "     47        \u001b[36m0.4445\u001b[0m       0.7188        0.5764  0.0344\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6749\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.5385\u001b[0m  0.0941\n",
      "      2        2.1134       0.5000        \u001b[35m2.2660\u001b[0m  0.1054\n",
      "      3        2.1409       0.5000        \u001b[35m2.1887\u001b[0m  0.1042\n",
      "      4        2.0749       0.5000        2.2135  0.0787\n",
      "      5        2.0880       0.5000        2.2110  0.0803\n",
      "      6        2.0875       0.5000        2.2107  0.0610\n",
      "      7        2.0872       0.5000        2.2108  0.0609\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6862\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.4079\u001b[0m  0.0809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        2.3016       0.5000        \u001b[35m2.0024\u001b[0m  0.0710\n",
      "      3        2.3173       0.5000        \u001b[35m1.9565\u001b[0m  0.0828\n",
      "      4        2.2503       0.5000        1.9857  0.1100\n",
      "      5        2.2686       0.5000        1.9797  0.1058\n",
      "      6        2.2661       0.5000        1.9802  0.0857\n",
      "      7        2.2661       0.5000        1.9803  0.1012\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8100\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.2478\u001b[0m  0.0654\n",
      "      2        1.0162       0.5000        1.4471  0.0922\n",
      "      3        1.1328       0.5000        1.3355  0.1051\n",
      "      4        1.0990       \u001b[32m0.5234\u001b[0m        1.2803  0.0979\n",
      "      5        1.1424       0.5000        2.1392  0.0960\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7233\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.9655\u001b[0m  0.1140\n",
      "      2        0.9268       0.5000        1.0801  0.0791\n",
      "      3        0.9983       0.5000        1.1484  0.0755\n",
      "      4        1.0240       0.5000        1.2464  0.1077\n",
      "      5        1.0581       0.5000        1.2998  0.0946\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6146\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.3053\u001b[0m  0.0976\n",
      "      2        1.3063       0.5000        \u001b[35m2.0364\u001b[0m  0.0654\n",
      "      3        1.5883       0.5000        \u001b[35m1.9387\u001b[0m  0.0689\n",
      "      4        1.5833       0.5000        \u001b[35m1.9008\u001b[0m  0.0835\n",
      "      5        1.5546       0.5000        \u001b[35m1.8858\u001b[0m  0.0744\n",
      "      6        1.5687       \u001b[32m0.5625\u001b[0m        \u001b[35m1.4470\u001b[0m  0.0761\n",
      "      7        1.5196       0.5000        2.0985  0.0632\n",
      "      8        1.5766       0.5000        1.8519  0.1025\n",
      "      9        1.6888       0.5469        1.7944  0.1180\n",
      "     10        1.5768       0.5000        1.8767  0.1091\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7529\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7224\u001b[0m  0.0321\n",
      "      2        \u001b[36m0.7342\u001b[0m       0.5000        \u001b[35m0.7118\u001b[0m  0.0288\n",
      "      3        \u001b[36m0.7249\u001b[0m       0.5000        \u001b[35m0.7046\u001b[0m  0.0257\n",
      "      4        \u001b[36m0.7181\u001b[0m       0.5000        \u001b[35m0.6983\u001b[0m  0.0395\n",
      "      5        \u001b[36m0.7115\u001b[0m       0.5000        \u001b[35m0.6909\u001b[0m  0.0327\n",
      "      6        \u001b[36m0.7036\u001b[0m       0.5000        \u001b[35m0.6817\u001b[0m  0.0290\n",
      "      7        \u001b[36m0.6935\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6697\u001b[0m  0.0247\n",
      "      8        \u001b[36m0.6809\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6544\u001b[0m  0.0532\n",
      "      9        \u001b[36m0.6662\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6365\u001b[0m  0.0323\n",
      "     10        \u001b[36m0.6495\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6160\u001b[0m  0.0321\n",
      "     11        \u001b[36m0.6305\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5945\u001b[0m  0.0337\n",
      "     12        \u001b[36m0.6116\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5721\u001b[0m  0.0384\n",
      "     13        \u001b[36m0.5936\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5525\u001b[0m  0.0521\n",
      "     14        \u001b[36m0.5799\u001b[0m       0.7500        \u001b[35m0.5360\u001b[0m  0.0240\n",
      "     15        \u001b[36m0.5688\u001b[0m       0.7500        \u001b[35m0.5237\u001b[0m  0.0210\n",
      "     16        \u001b[36m0.5623\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5134\u001b[0m  0.0629\n",
      "     17        \u001b[36m0.5569\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5056\u001b[0m  0.0210\n",
      "     18        \u001b[36m0.5533\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.4988\u001b[0m  0.0595\n",
      "     19        \u001b[36m0.5503\u001b[0m       0.7812        \u001b[35m0.4937\u001b[0m  0.0413\n",
      "     20        \u001b[36m0.5481\u001b[0m       0.7812        \u001b[35m0.4892\u001b[0m  0.0223\n",
      "     21        \u001b[36m0.5462\u001b[0m       0.7812        \u001b[35m0.4857\u001b[0m  0.0215\n",
      "     22        \u001b[36m0.5449\u001b[0m       0.7812        \u001b[35m0.4825\u001b[0m  0.0226\n",
      "     23        \u001b[36m0.5439\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4798\u001b[0m  0.0207\n",
      "     24        \u001b[36m0.5427\u001b[0m       0.7891        \u001b[35m0.4776\u001b[0m  0.0208\n",
      "     25        \u001b[36m0.5415\u001b[0m       0.7891        \u001b[35m0.4757\u001b[0m  0.0227\n",
      "     26        \u001b[36m0.5405\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4743\u001b[0m  0.0189\n",
      "     27        \u001b[36m0.5390\u001b[0m       0.7969        \u001b[35m0.4732\u001b[0m  0.0362\n",
      "     28        \u001b[36m0.5378\u001b[0m       0.7891        \u001b[35m0.4723\u001b[0m  0.0239\n",
      "     29        \u001b[36m0.5367\u001b[0m       0.7891        \u001b[35m0.4713\u001b[0m  0.0422\n",
      "     30        \u001b[36m0.5355\u001b[0m       0.7891        \u001b[35m0.4704\u001b[0m  0.0442\n",
      "     31        \u001b[36m0.5347\u001b[0m       0.7891        \u001b[35m0.4693\u001b[0m  0.0400\n",
      "     32        \u001b[36m0.5339\u001b[0m       0.7969        \u001b[35m0.4682\u001b[0m  0.0308\n",
      "     33        \u001b[36m0.5324\u001b[0m       0.7969        \u001b[35m0.4666\u001b[0m  0.0588\n",
      "     34        \u001b[36m0.5303\u001b[0m       0.7969        \u001b[35m0.4657\u001b[0m  0.0281\n",
      "     35        \u001b[36m0.5292\u001b[0m       0.7969        \u001b[35m0.4646\u001b[0m  0.0241\n",
      "     36        \u001b[36m0.5277\u001b[0m       0.7969        \u001b[35m0.4636\u001b[0m  0.0240\n",
      "     37        \u001b[36m0.5262\u001b[0m       0.7969        \u001b[35m0.4625\u001b[0m  0.0259\n",
      "     38        \u001b[36m0.5246\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4616\u001b[0m  0.0173\n",
      "     39        \u001b[36m0.5233\u001b[0m       0.8047        \u001b[35m0.4604\u001b[0m  0.0236\n",
      "     40        \u001b[36m0.5216\u001b[0m       0.7969        \u001b[35m0.4597\u001b[0m  0.0303\n",
      "     41        \u001b[36m0.5204\u001b[0m       0.7969        \u001b[35m0.4584\u001b[0m  0.0214\n",
      "     42        \u001b[36m0.5188\u001b[0m       0.7969        \u001b[35m0.4571\u001b[0m  0.0233\n",
      "     43        \u001b[36m0.5171\u001b[0m       0.7969        \u001b[35m0.4557\u001b[0m  0.0169\n",
      "     44        \u001b[36m0.5156\u001b[0m       0.7891        \u001b[35m0.4541\u001b[0m  0.0382\n",
      "     45        \u001b[36m0.5139\u001b[0m       0.7969        \u001b[35m0.4528\u001b[0m  0.0391\n",
      "     46        \u001b[36m0.5118\u001b[0m       0.7891        \u001b[35m0.4516\u001b[0m  0.0408\n",
      "     47        \u001b[36m0.5103\u001b[0m       0.7891        \u001b[35m0.4500\u001b[0m  0.0332\n",
      "     48        \u001b[36m0.5087\u001b[0m       0.7891        \u001b[35m0.4485\u001b[0m  0.0311\n",
      "     49        \u001b[36m0.5068\u001b[0m       0.7812        \u001b[35m0.4468\u001b[0m  0.0314\n",
      "     50        \u001b[36m0.5050\u001b[0m       0.7812        \u001b[35m0.4453\u001b[0m  0.0424\n",
      "     51        \u001b[36m0.5031\u001b[0m       0.7812        \u001b[35m0.4437\u001b[0m  0.0411\n",
      "     52        \u001b[36m0.5010\u001b[0m       0.7812        \u001b[35m0.4416\u001b[0m  0.0308\n",
      "     53        \u001b[36m0.4989\u001b[0m       0.7812        \u001b[35m0.4390\u001b[0m  0.0572\n",
      "     54        \u001b[36m0.4965\u001b[0m       0.7812        \u001b[35m0.4370\u001b[0m  0.0559\n",
      "     55        \u001b[36m0.4946\u001b[0m       0.7812        \u001b[35m0.4349\u001b[0m  0.0356\n",
      "     56        \u001b[36m0.4927\u001b[0m       0.7812        \u001b[35m0.4330\u001b[0m  0.0420\n",
      "     57        \u001b[36m0.4915\u001b[0m       0.7812        \u001b[35m0.4316\u001b[0m  0.0301\n",
      "     58        \u001b[36m0.4900\u001b[0m       0.7812        \u001b[35m0.4307\u001b[0m  0.0419\n",
      "     59        \u001b[36m0.4889\u001b[0m       0.7812        \u001b[35m0.4299\u001b[0m  0.0278\n",
      "     60        \u001b[36m0.4879\u001b[0m       0.7812        \u001b[35m0.4289\u001b[0m  0.0270\n",
      "     61        \u001b[36m0.4874\u001b[0m       0.7891        \u001b[35m0.4282\u001b[0m  0.0343\n",
      "     62        \u001b[36m0.4865\u001b[0m       0.7891        \u001b[35m0.4277\u001b[0m  0.0378\n",
      "     63        \u001b[36m0.4857\u001b[0m       0.7891        \u001b[35m0.4273\u001b[0m  0.0271\n",
      "     64        \u001b[36m0.4853\u001b[0m       0.7891        \u001b[35m0.4269\u001b[0m  0.0469\n",
      "     65        \u001b[36m0.4845\u001b[0m       0.7891        \u001b[35m0.4264\u001b[0m  0.0290\n",
      "     66        \u001b[36m0.4839\u001b[0m       0.7891        \u001b[35m0.4259\u001b[0m  0.0362\n",
      "     67        \u001b[36m0.4832\u001b[0m       0.7969        \u001b[35m0.4252\u001b[0m  0.0341\n",
      "     68        \u001b[36m0.4825\u001b[0m       0.7969        \u001b[35m0.4246\u001b[0m  0.0331\n",
      "     69        \u001b[36m0.4820\u001b[0m       0.7969        \u001b[35m0.4239\u001b[0m  0.0209\n",
      "     70        \u001b[36m0.4811\u001b[0m       0.7969        \u001b[35m0.4234\u001b[0m  0.0150\n",
      "     71        \u001b[36m0.4804\u001b[0m       0.7969        \u001b[35m0.4230\u001b[0m  0.0196\n",
      "     72        \u001b[36m0.4794\u001b[0m       0.7969        \u001b[35m0.4227\u001b[0m  0.0306\n",
      "     73        \u001b[36m0.4787\u001b[0m       0.7969        \u001b[35m0.4225\u001b[0m  0.0355\n",
      "     74        \u001b[36m0.4780\u001b[0m       0.7969        \u001b[35m0.4221\u001b[0m  0.0507\n",
      "     75        \u001b[36m0.4772\u001b[0m       0.8047        \u001b[35m0.4217\u001b[0m  0.0505\n",
      "     76        \u001b[36m0.4763\u001b[0m       0.7969        \u001b[35m0.4214\u001b[0m  0.0413\n",
      "     77        \u001b[36m0.4755\u001b[0m       0.8047        \u001b[35m0.4211\u001b[0m  0.0299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     78        \u001b[36m0.4745\u001b[0m       0.8047        \u001b[35m0.4207\u001b[0m  0.0316\n",
      "     79        \u001b[36m0.4736\u001b[0m       0.8047        \u001b[35m0.4200\u001b[0m  0.0384\n",
      "     80        \u001b[36m0.4727\u001b[0m       0.8047        0.4201  0.0571\n",
      "     81        \u001b[36m0.4719\u001b[0m       \u001b[32m0.8125\u001b[0m        0.4202  0.0406\n",
      "     82        \u001b[36m0.4713\u001b[0m       0.8125        0.4202  0.0230\n",
      "     83        \u001b[36m0.4705\u001b[0m       0.8125        0.4205  0.0334\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7077\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6909\u001b[0m  0.0280\n",
      "      2        \u001b[36m0.7043\u001b[0m       0.5000        \u001b[35m0.6894\u001b[0m  0.0459\n",
      "      3        \u001b[36m0.7013\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6870\u001b[0m  0.0274\n",
      "      4        \u001b[36m0.6962\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6825\u001b[0m  0.0386\n",
      "      5        \u001b[36m0.6878\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6747\u001b[0m  0.0320\n",
      "      6        \u001b[36m0.6751\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6629\u001b[0m  0.0328\n",
      "      7        \u001b[36m0.6574\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6468\u001b[0m  0.0278\n",
      "      8        \u001b[36m0.6351\u001b[0m       0.6953        \u001b[35m0.6267\u001b[0m  0.0395\n",
      "      9        \u001b[36m0.6089\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6061\u001b[0m  0.0276\n",
      "     10        \u001b[36m0.5835\u001b[0m       0.7266        \u001b[35m0.5876\u001b[0m  0.0570\n",
      "     11        \u001b[36m0.5616\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5738\u001b[0m  0.0424\n",
      "     12        \u001b[36m0.5454\u001b[0m       0.7266        \u001b[35m0.5641\u001b[0m  0.0294\n",
      "     13        \u001b[36m0.5333\u001b[0m       0.7344        \u001b[35m0.5580\u001b[0m  0.0276\n",
      "     14        \u001b[36m0.5244\u001b[0m       0.7344        \u001b[35m0.5543\u001b[0m  0.0487\n",
      "     15        \u001b[36m0.5183\u001b[0m       0.7344        \u001b[35m0.5520\u001b[0m  0.0527\n",
      "     16        \u001b[36m0.5135\u001b[0m       0.7344        \u001b[35m0.5501\u001b[0m  0.0302\n",
      "     17        \u001b[36m0.5100\u001b[0m       0.7422        \u001b[35m0.5481\u001b[0m  0.0325\n",
      "     18        \u001b[36m0.5069\u001b[0m       0.7422        \u001b[35m0.5458\u001b[0m  0.0309\n",
      "     19        \u001b[36m0.5043\u001b[0m       0.7422        \u001b[35m0.5439\u001b[0m  0.0216\n",
      "     20        \u001b[36m0.5020\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5428\u001b[0m  0.0342\n",
      "     21        \u001b[36m0.5002\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5415\u001b[0m  0.0494\n",
      "     22        \u001b[36m0.4981\u001b[0m       0.7578        \u001b[35m0.5398\u001b[0m  0.0340\n",
      "     23        \u001b[36m0.4965\u001b[0m       0.7578        \u001b[35m0.5380\u001b[0m  0.0299\n",
      "     24        \u001b[36m0.4950\u001b[0m       0.7578        \u001b[35m0.5366\u001b[0m  0.0383\n",
      "     25        \u001b[36m0.4934\u001b[0m       0.7578        \u001b[35m0.5350\u001b[0m  0.0348\n",
      "     26        \u001b[36m0.4916\u001b[0m       0.7500        \u001b[35m0.5339\u001b[0m  0.0299\n",
      "     27        \u001b[36m0.4901\u001b[0m       0.7500        \u001b[35m0.5335\u001b[0m  0.0497\n",
      "     28        \u001b[36m0.4889\u001b[0m       0.7500        \u001b[35m0.5333\u001b[0m  0.0262\n",
      "     29        \u001b[36m0.4875\u001b[0m       0.7500        \u001b[35m0.5327\u001b[0m  0.0243\n",
      "     30        \u001b[36m0.4860\u001b[0m       0.7500        \u001b[35m0.5323\u001b[0m  0.0374\n",
      "     31        \u001b[36m0.4849\u001b[0m       0.7500        \u001b[35m0.5322\u001b[0m  0.0300\n",
      "     32        \u001b[36m0.4838\u001b[0m       0.7500        \u001b[35m0.5319\u001b[0m  0.0242\n",
      "     33        \u001b[36m0.4834\u001b[0m       0.7500        \u001b[35m0.5316\u001b[0m  0.0301\n",
      "     34        \u001b[36m0.4828\u001b[0m       0.7500        \u001b[35m0.5312\u001b[0m  0.0229\n",
      "     35        \u001b[36m0.4820\u001b[0m       0.7500        \u001b[35m0.5309\u001b[0m  0.0273\n",
      "     36        \u001b[36m0.4815\u001b[0m       0.7500        \u001b[35m0.5306\u001b[0m  0.0234\n",
      "     37        \u001b[36m0.4810\u001b[0m       0.7500        \u001b[35m0.5302\u001b[0m  0.0278\n",
      "     38        \u001b[36m0.4805\u001b[0m       0.7500        \u001b[35m0.5300\u001b[0m  0.0537\n",
      "     39        \u001b[36m0.4800\u001b[0m       0.7500        \u001b[35m0.5298\u001b[0m  0.0397\n",
      "     40        \u001b[36m0.4796\u001b[0m       0.7422        \u001b[35m0.5297\u001b[0m  0.0589\n",
      "     41        \u001b[36m0.4791\u001b[0m       0.7422        \u001b[35m0.5296\u001b[0m  0.0356\n",
      "     42        \u001b[36m0.4790\u001b[0m       0.7422        \u001b[35m0.5296\u001b[0m  0.0302\n",
      "     43        \u001b[36m0.4787\u001b[0m       0.7500        \u001b[35m0.5295\u001b[0m  0.0823\n",
      "     44        \u001b[36m0.4782\u001b[0m       0.7500        0.5295  0.0623\n",
      "     45        \u001b[36m0.4776\u001b[0m       0.7500        \u001b[35m0.5294\u001b[0m  0.0181\n",
      "     46        \u001b[36m0.4772\u001b[0m       0.7500        \u001b[35m0.5294\u001b[0m  0.0219\n",
      "     47        \u001b[36m0.4769\u001b[0m       0.7500        \u001b[35m0.5294\u001b[0m  0.0248\n",
      "     48        \u001b[36m0.4763\u001b[0m       0.7500        \u001b[35m0.5291\u001b[0m  0.0236\n",
      "     49        \u001b[36m0.4759\u001b[0m       0.7500        \u001b[35m0.5285\u001b[0m  0.0353\n",
      "     50        \u001b[36m0.4753\u001b[0m       0.7500        \u001b[35m0.5279\u001b[0m  0.0255\n",
      "     51        \u001b[36m0.4752\u001b[0m       0.7500        \u001b[35m0.5274\u001b[0m  0.0549\n",
      "     52        \u001b[36m0.4746\u001b[0m       0.7500        \u001b[35m0.5269\u001b[0m  0.0256\n",
      "     53        \u001b[36m0.4745\u001b[0m       0.7500        \u001b[35m0.5264\u001b[0m  0.0351\n",
      "     54        \u001b[36m0.4738\u001b[0m       0.7500        \u001b[35m0.5261\u001b[0m  0.0292\n",
      "     55        \u001b[36m0.4734\u001b[0m       0.7578        \u001b[35m0.5256\u001b[0m  0.0440\n",
      "     56        \u001b[36m0.4731\u001b[0m       0.7578        \u001b[35m0.5251\u001b[0m  0.0851\n",
      "     57        \u001b[36m0.4729\u001b[0m       0.7578        \u001b[35m0.5250\u001b[0m  0.0469\n",
      "     58        \u001b[36m0.4728\u001b[0m       0.7578        \u001b[35m0.5249\u001b[0m  0.0586\n",
      "     59        \u001b[36m0.4722\u001b[0m       0.7578        \u001b[35m0.5247\u001b[0m  0.0307\n",
      "     60        0.4722       0.7578        0.5249  0.0195\n",
      "     61        \u001b[36m0.4719\u001b[0m       0.7578        0.5247  0.0488\n",
      "     62        \u001b[36m0.4714\u001b[0m       0.7578        0.5247  0.0383\n",
      "     63        0.4715       0.7578        \u001b[35m0.5247\u001b[0m  0.0371\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7156\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7025\u001b[0m  0.0321\n",
      "      2        0.7173       0.5000        \u001b[35m0.7007\u001b[0m  0.0208\n",
      "      3        \u001b[36m0.7127\u001b[0m       0.5000        \u001b[35m0.6953\u001b[0m  0.0342\n",
      "      4        \u001b[36m0.7042\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6872\u001b[0m  0.0242\n",
      "      5        \u001b[36m0.6921\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6757\u001b[0m  0.0294\n",
      "      6        \u001b[36m0.6765\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6602\u001b[0m  0.0309\n",
      "      7        \u001b[36m0.6574\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6422\u001b[0m  0.0236\n",
      "      8        \u001b[36m0.6367\u001b[0m       0.6641        \u001b[35m0.6243\u001b[0m  0.0214\n",
      "      9        \u001b[36m0.6169\u001b[0m       0.6562        \u001b[35m0.6080\u001b[0m  0.0317\n",
      "     10        \u001b[36m0.5994\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5938\u001b[0m  0.0285\n",
      "     11        \u001b[36m0.5846\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5825\u001b[0m  0.0431\n",
      "     12        \u001b[36m0.5732\u001b[0m       0.7031        \u001b[35m0.5738\u001b[0m  0.0193\n",
      "     13        \u001b[36m0.5646\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5673\u001b[0m  0.0422\n",
      "     14        \u001b[36m0.5583\u001b[0m       0.7188        \u001b[35m0.5627\u001b[0m  0.0255\n",
      "     15        \u001b[36m0.5535\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5589\u001b[0m  0.0226\n",
      "     16        \u001b[36m0.5495\u001b[0m       0.7266        \u001b[35m0.5563\u001b[0m  0.0305\n",
      "     17        \u001b[36m0.5463\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5544\u001b[0m  0.0440\n",
      "     18        \u001b[36m0.5437\u001b[0m       0.7344        \u001b[35m0.5531\u001b[0m  0.0404\n",
      "     19        \u001b[36m0.5419\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5517\u001b[0m  0.0352\n",
      "     20        \u001b[36m0.5402\u001b[0m       0.7422        \u001b[35m0.5506\u001b[0m  0.0352\n",
      "     21        \u001b[36m0.5388\u001b[0m       0.7422        \u001b[35m0.5499\u001b[0m  0.0437\n",
      "     22        \u001b[36m0.5375\u001b[0m       0.7422        \u001b[35m0.5496\u001b[0m  0.0363\n",
      "     23        \u001b[36m0.5361\u001b[0m       0.7422        0.5499  0.0277\n",
      "     24        \u001b[36m0.5343\u001b[0m       0.7422        0.5507  0.0276\n",
      "     25        \u001b[36m0.5330\u001b[0m       0.7422        0.5516  0.0555\n",
      "     26        \u001b[36m0.5319\u001b[0m       0.7422        0.5525  0.0345\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7544\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7122\u001b[0m  0.0438\n",
      "      2        \u001b[36m0.7261\u001b[0m       0.5000        \u001b[35m0.6972\u001b[0m  0.0311\n",
      "      3        \u001b[36m0.7138\u001b[0m       0.5000        \u001b[35m0.6880\u001b[0m  0.0211\n",
      "      4        \u001b[36m0.7056\u001b[0m       0.5000        \u001b[35m0.6806\u001b[0m  0.0242\n",
      "      5        \u001b[36m0.6987\u001b[0m       0.5000        \u001b[35m0.6733\u001b[0m  0.0320\n",
      "      6        \u001b[36m0.6917\u001b[0m       0.5000        \u001b[35m0.6653\u001b[0m  0.0296\n",
      "      7        \u001b[36m0.6841\u001b[0m       0.5000        \u001b[35m0.6560\u001b[0m  0.0212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        \u001b[36m0.6756\u001b[0m       0.5000        \u001b[35m0.6460\u001b[0m  0.0325\n",
      "      9        \u001b[36m0.6661\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6354\u001b[0m  0.0251\n",
      "     10        \u001b[36m0.6555\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6244\u001b[0m  0.0554\n",
      "     11        \u001b[36m0.6437\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6134\u001b[0m  0.0328\n",
      "     12        \u001b[36m0.6307\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6032\u001b[0m  0.0672\n",
      "     13        \u001b[36m0.6175\u001b[0m       0.7422        \u001b[35m0.5940\u001b[0m  0.0394\n",
      "     14        \u001b[36m0.6048\u001b[0m       0.7422        \u001b[35m0.5871\u001b[0m  0.0247\n",
      "     15        \u001b[36m0.5926\u001b[0m       0.7266        \u001b[35m0.5824\u001b[0m  0.0642\n",
      "     16        \u001b[36m0.5817\u001b[0m       0.7422        \u001b[35m0.5796\u001b[0m  0.0515\n",
      "     17        \u001b[36m0.5720\u001b[0m       0.7266        \u001b[35m0.5785\u001b[0m  0.0498\n",
      "     18        \u001b[36m0.5643\u001b[0m       0.7109        \u001b[35m0.5785\u001b[0m  0.0385\n",
      "     19        \u001b[36m0.5581\u001b[0m       0.7031        0.5794  0.0310\n",
      "     20        \u001b[36m0.5528\u001b[0m       0.6953        0.5811  0.0362\n",
      "     21        \u001b[36m0.5487\u001b[0m       0.6953        0.5822  0.0326\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6800\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6768\u001b[0m  0.0400\n",
      "      2        \u001b[36m0.6685\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6717\u001b[0m  0.0488\n",
      "      3        \u001b[36m0.6551\u001b[0m       0.5703        \u001b[35m0.6649\u001b[0m  0.0379\n",
      "      4        \u001b[36m0.6373\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6566\u001b[0m  0.0488\n",
      "      5        \u001b[36m0.6166\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6492\u001b[0m  0.0409\n",
      "      6        \u001b[36m0.5950\u001b[0m       0.6797        \u001b[35m0.6440\u001b[0m  0.0399\n",
      "      7        \u001b[36m0.5754\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6401\u001b[0m  0.0514\n",
      "      8        \u001b[36m0.5567\u001b[0m       0.6797        \u001b[35m0.6376\u001b[0m  0.0226\n",
      "      9        \u001b[36m0.5420\u001b[0m       0.6875        \u001b[35m0.6371\u001b[0m  0.0183\n",
      "     10        \u001b[36m0.5317\u001b[0m       \u001b[32m0.6953\u001b[0m        0.6371  0.0458\n",
      "     11        \u001b[36m0.5244\u001b[0m       0.6875        \u001b[35m0.6370\u001b[0m  0.0338\n",
      "     12        \u001b[36m0.5190\u001b[0m       0.6875        0.6374  0.0420\n",
      "     13        \u001b[36m0.5156\u001b[0m       0.6875        0.6375  0.0269\n",
      "     14        \u001b[36m0.5125\u001b[0m       0.6953        0.6372  0.0205\n",
      "     15        \u001b[36m0.5095\u001b[0m       0.6875        \u001b[35m0.6365\u001b[0m  0.0188\n",
      "     16        \u001b[36m0.5065\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6357\u001b[0m  0.0285\n",
      "     17        \u001b[36m0.5048\u001b[0m       0.7031        \u001b[35m0.6347\u001b[0m  0.0479\n",
      "     18        \u001b[36m0.5033\u001b[0m       0.7031        \u001b[35m0.6340\u001b[0m  0.0325\n",
      "     19        \u001b[36m0.5020\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6330\u001b[0m  0.0183\n",
      "     20        \u001b[36m0.5001\u001b[0m       0.7109        \u001b[35m0.6319\u001b[0m  0.0293\n",
      "     21        \u001b[36m0.4976\u001b[0m       0.7109        \u001b[35m0.6306\u001b[0m  0.0416\n",
      "     22        \u001b[36m0.4967\u001b[0m       0.7109        \u001b[35m0.6290\u001b[0m  0.0312\n",
      "     23        \u001b[36m0.4949\u001b[0m       0.7109        \u001b[35m0.6271\u001b[0m  0.0223\n",
      "     24        \u001b[36m0.4930\u001b[0m       0.7109        \u001b[35m0.6251\u001b[0m  0.0331\n",
      "     25        \u001b[36m0.4916\u001b[0m       0.7109        \u001b[35m0.6234\u001b[0m  0.0597\n",
      "     26        \u001b[36m0.4905\u001b[0m       0.7109        \u001b[35m0.6228\u001b[0m  0.0451\n",
      "     27        \u001b[36m0.4889\u001b[0m       0.7109        \u001b[35m0.6223\u001b[0m  0.0628\n",
      "     28        \u001b[36m0.4879\u001b[0m       0.7109        \u001b[35m0.6218\u001b[0m  0.0749\n",
      "     29        \u001b[36m0.4868\u001b[0m       0.7109        \u001b[35m0.6215\u001b[0m  0.0303\n",
      "     30        \u001b[36m0.4864\u001b[0m       0.7031        \u001b[35m0.6214\u001b[0m  0.0322\n",
      "     31        \u001b[36m0.4859\u001b[0m       0.7109        \u001b[35m0.6210\u001b[0m  0.0316\n",
      "     32        \u001b[36m0.4851\u001b[0m       0.7109        \u001b[35m0.6207\u001b[0m  0.0368\n",
      "     33        \u001b[36m0.4848\u001b[0m       0.7109        0.6208  0.0377\n",
      "     34        \u001b[36m0.4839\u001b[0m       0.7031        0.6214  0.0365\n",
      "     35        \u001b[36m0.4832\u001b[0m       0.7031        0.6219  0.0307\n",
      "     36        \u001b[36m0.4828\u001b[0m       0.7031        0.6221  0.0285\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6411\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7363\u001b[0m  0.0564\n",
      "      2        0.6756       0.5000        \u001b[35m0.6867\u001b[0m  0.0532\n",
      "      3        \u001b[36m0.6358\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6301\u001b[0m  0.0783\n",
      "      4        \u001b[36m0.5997\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.5837\u001b[0m  0.0754\n",
      "      5        \u001b[36m0.5730\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5512\u001b[0m  0.0692\n",
      "      6        \u001b[36m0.5712\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5387\u001b[0m  0.0518\n",
      "      7        0.5806       0.7344        \u001b[35m0.5350\u001b[0m  0.0497\n",
      "      8        \u001b[36m0.5659\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5197\u001b[0m  0.0575\n",
      "      9        \u001b[36m0.5578\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5046\u001b[0m  0.0552\n",
      "     10        0.5719       0.7656        \u001b[35m0.4985\u001b[0m  0.0472\n",
      "     11        \u001b[36m0.5532\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.4875\u001b[0m  0.0458\n",
      "     12        \u001b[36m0.5456\u001b[0m       0.7656        0.4914  0.0385\n",
      "     13        0.5735       0.7656        0.4956  0.0450\n",
      "     14        0.5666       0.7656        0.5020  0.0400\n",
      "     15        0.5546       0.7656        0.4888  0.0306\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7011\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7095\u001b[0m  0.0438\n",
      "      2        0.7084       0.5000        \u001b[35m0.6967\u001b[0m  0.0420\n",
      "      3        \u001b[36m0.6845\u001b[0m       0.5000        \u001b[35m0.6714\u001b[0m  0.0393\n",
      "      4        \u001b[36m0.6432\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6371\u001b[0m  0.0326\n",
      "      5        \u001b[36m0.5896\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6091\u001b[0m  0.0515\n",
      "      6        0.5956       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6016\u001b[0m  0.0559\n",
      "      7        \u001b[36m0.5884\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5999\u001b[0m  0.0629\n",
      "      8        \u001b[36m0.5693\u001b[0m       0.7422        \u001b[35m0.5740\u001b[0m  0.0407\n",
      "      9        \u001b[36m0.5549\u001b[0m       0.7422        0.5785  0.0348\n",
      "     10        \u001b[36m0.5505\u001b[0m       0.7344        \u001b[35m0.5635\u001b[0m  0.0588\n",
      "     11        \u001b[36m0.5331\u001b[0m       0.7422        0.5714  0.0424\n",
      "     12        0.5472       0.7344        0.5677  0.0416\n",
      "     13        0.5571       0.7344        \u001b[35m0.5606\u001b[0m  0.0346\n",
      "     14        \u001b[36m0.5276\u001b[0m       0.7344        0.5640  0.0367\n",
      "     15        0.5425       0.7422        \u001b[35m0.5427\u001b[0m  0.0328\n",
      "     16        0.5336       0.7500        0.5592  0.0611\n",
      "     17        0.5419       \u001b[32m0.7578\u001b[0m        0.5568  0.1004\n",
      "     18        0.5438       0.7500        0.5615  0.0434\n",
      "     19        \u001b[36m0.5269\u001b[0m       0.7500        0.5505  0.0391\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7183\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7073\u001b[0m  0.0408\n",
      "      2        0.7198       0.5000        \u001b[35m0.6997\u001b[0m  0.0732\n",
      "      3        \u001b[36m0.7097\u001b[0m       0.5000        \u001b[35m0.6893\u001b[0m  0.0416\n",
      "      4        \u001b[36m0.6939\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6665\u001b[0m  0.0396\n",
      "      5        \u001b[36m0.6652\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6377\u001b[0m  0.0557\n",
      "      6        \u001b[36m0.6337\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6080\u001b[0m  0.0639\n",
      "      7        \u001b[36m0.5993\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5858\u001b[0m  0.0536\n",
      "      8        0.6115       0.7188        \u001b[35m0.5766\u001b[0m  0.0731\n",
      "      9        \u001b[36m0.5895\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5595\u001b[0m  0.0364\n",
      "     10        \u001b[36m0.5582\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5550\u001b[0m  0.0563\n",
      "     11        0.5594       0.7422        \u001b[35m0.5548\u001b[0m  0.0549\n",
      "     12        0.5661       0.7578        \u001b[35m0.5466\u001b[0m  0.0410\n",
      "     13        \u001b[36m0.5457\u001b[0m       0.7578        \u001b[35m0.5464\u001b[0m  0.0487\n",
      "     14        \u001b[36m0.5257\u001b[0m       0.7500        0.5559  0.0432\n",
      "     15        0.5590       0.7422        0.5487  0.0618\n",
      "     16        0.5337       0.7266        0.5493  0.0672\n",
      "     17        0.5386       0.7344        0.5499  0.0574\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6801\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6967\u001b[0m  0.0451\n",
      "      2        0.6816       0.5000        \u001b[35m0.6752\u001b[0m  0.0502\n",
      "      3        \u001b[36m0.6536\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6327\u001b[0m  0.0489\n",
      "      4        \u001b[36m0.6056\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6065\u001b[0m  0.0572\n",
      "      5        \u001b[36m0.5693\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5843\u001b[0m  0.0815\n",
      "      6        \u001b[36m0.5579\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5665\u001b[0m  0.0770\n",
      "      7        \u001b[36m0.5414\u001b[0m       0.7344        0.5725  0.0613\n",
      "      8        \u001b[36m0.5386\u001b[0m       0.7422        0.5680  0.0471\n",
      "      9        \u001b[36m0.5287\u001b[0m       0.7266        0.5728  0.0578\n",
      "     10        0.5304       0.7422        \u001b[35m0.5645\u001b[0m  0.0971\n",
      "     11        \u001b[36m0.5257\u001b[0m       0.7266        \u001b[35m0.5623\u001b[0m  0.0672\n",
      "     12        0.5298       0.7344        \u001b[35m0.5539\u001b[0m  0.0357\n",
      "     13        \u001b[36m0.5119\u001b[0m       0.7188        0.5540  0.0642\n",
      "     14        0.5235       0.7344        \u001b[35m0.5447\u001b[0m  0.0687\n",
      "     15        \u001b[36m0.4768\u001b[0m       0.7422        0.5574  0.0864\n",
      "     16        0.5167       0.7344        0.5516  0.0466\n",
      "     17        0.4971       0.7188        0.5592  0.0686\n",
      "     18        0.5019       0.7188        0.5555  0.0428\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6781\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7086\u001b[0m  0.0461\n",
      "      2        0.6792       0.5000        \u001b[35m0.7062\u001b[0m  0.0316\n",
      "      3        \u001b[36m0.6572\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6902\u001b[0m  0.0422\n",
      "      4        \u001b[36m0.6093\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6752\u001b[0m  0.0653\n",
      "      5        \u001b[36m0.5625\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6745\u001b[0m  0.0614\n",
      "      6        \u001b[36m0.5358\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6601\u001b[0m  0.0877\n",
      "      7        0.5461       0.7188        \u001b[35m0.6411\u001b[0m  0.0962\n",
      "      8        0.5367       0.7109        \u001b[35m0.6215\u001b[0m  0.0933\n",
      "      9        \u001b[36m0.4931\u001b[0m       0.7188        0.6365  0.0460\n",
      "     10        0.5187       0.7266        \u001b[35m0.6168\u001b[0m  0.0505\n",
      "     11        0.5194       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6064\u001b[0m  0.0322\n",
      "     12        0.4995       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6019\u001b[0m  0.0536\n",
      "     13        0.5097       0.7422        \u001b[35m0.5810\u001b[0m  0.0387\n",
      "     14        0.5069       0.7422        \u001b[35m0.5694\u001b[0m  0.0467\n",
      "     15        \u001b[36m0.4711\u001b[0m       0.7344        0.5745  0.0424\n",
      "     16        0.4922       0.7266        \u001b[35m0.5682\u001b[0m  0.0416\n",
      "     17        0.4874       0.7422        0.5719  0.0836\n",
      "     18        \u001b[36m0.4455\u001b[0m       0.7344        0.5771  0.0477\n",
      "     19        0.4697       0.7344        0.5755  0.0385\n",
      "     20        0.4651       \u001b[32m0.7500\u001b[0m        0.5744  0.0449\n",
      "     21        0.4691       0.7422        \u001b[35m0.5670\u001b[0m  0.0478\n",
      "     22        0.4817       0.7422        \u001b[35m0.5605\u001b[0m  0.0347\n",
      "     23        0.4678       0.7422        \u001b[35m0.5589\u001b[0m  0.0433\n",
      "     24        0.4487       0.7422        0.5679  0.0571\n",
      "     25        0.4539       0.7422        0.5736  0.0375\n",
      "     26        0.4720       0.7344        \u001b[35m0.5529\u001b[0m  0.0420\n",
      "     27        0.4615       0.7344        0.5604  0.0321\n",
      "     28        0.4478       0.7500        0.5620  0.0387\n",
      "     29        0.4595       0.7500        0.5549  0.0373\n",
      "     30        0.4587       0.7344        0.5570  0.0469\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7248\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6915\u001b[0m  0.0478\n",
      "      2        \u001b[36m0.6843\u001b[0m       \u001b[32m0.6000\u001b[0m        \u001b[35m0.6413\u001b[0m  0.0468\n",
      "      3        \u001b[36m0.6344\u001b[0m       \u001b[32m0.7125\u001b[0m        \u001b[35m0.5925\u001b[0m  0.0367\n",
      "      4        \u001b[36m0.5898\u001b[0m       \u001b[32m0.7438\u001b[0m        \u001b[35m0.5589\u001b[0m  0.0396\n",
      "      5        \u001b[36m0.5625\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5427\u001b[0m  0.0326\n",
      "      6        \u001b[36m0.5486\u001b[0m       \u001b[32m0.7562\u001b[0m        \u001b[35m0.5360\u001b[0m  0.0305\n",
      "      7        \u001b[36m0.5407\u001b[0m       0.7562        \u001b[35m0.5333\u001b[0m  0.0287\n",
      "      8        \u001b[36m0.5348\u001b[0m       0.7562        \u001b[35m0.5325\u001b[0m  0.0345\n",
      "      9        \u001b[36m0.5298\u001b[0m       0.7500        0.5328  0.0383\n",
      "     10        \u001b[36m0.5255\u001b[0m       0.7500        0.5330  0.0482\n",
      "     11        \u001b[36m0.5216\u001b[0m       0.7500        0.5335  0.0397\n",
      "     12        \u001b[36m0.5164\u001b[0m       0.7500        0.5351  0.0277\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best parameters found:\n",
      "\n",
      "{'optimizer__momentum': 0.3, 'module__num_unitsB': 12, 'module__num_unitsA': 9, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 64}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.745 (+/-0.095) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 3, 'module__num_unitsA': 3, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 32}\n",
      "0.784 (+/-0.037) for {'optimizer__momentum': 0.6, 'module__num_unitsB': 12, 'module__num_unitsA': 12, 'module__dropout': 0.5, 'lr': 0.1, 'batch_size': 64}\n",
      "0.702 (+/-0.059) for {'optimizer__momentum': 0.6, 'module__num_unitsB': 12, 'module__num_unitsA': 9, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 32}\n",
      "0.752 (+/-0.029) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 12, 'module__num_unitsA': 9, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 16}\n",
      "0.708 (+/-0.049) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 9, 'module__num_unitsA': 6, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 32}\n",
      "0.667 (+/-0.000) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 3, 'module__num_unitsA': 3, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 32}\n",
      "0.796 (+/-0.053) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 12, 'module__num_unitsA': 9, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 64}\n",
      "0.667 (+/-0.000) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 3, 'module__num_unitsA': 6, 'module__dropout': 0.5, 'lr': 0.1, 'batch_size': 16}\n",
      "0.771 (+/-0.083) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 9, 'module__num_unitsA': 3, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 64}\n",
      "0.791 (+/-0.030) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 12, 'module__num_unitsA': 9, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 32}\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7103\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6919\u001b[0m  0.1288\n",
      "      2        \u001b[36m0.7046\u001b[0m       0.5234        \u001b[35m0.6885\u001b[0m  0.0880\n",
      "      3        \u001b[36m0.6880\u001b[0m       0.5312        \u001b[35m0.6859\u001b[0m  0.0896\n",
      "      4        0.6958       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6848\u001b[0m  0.0693\n",
      "      5        0.6941       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6838\u001b[0m  0.1427\n",
      "      6        0.6953       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6828\u001b[0m  0.0988\n",
      "      7        0.6951       0.6094        \u001b[35m0.6820\u001b[0m  0.1490\n",
      "      8        0.6907       0.6016        \u001b[35m0.6811\u001b[0m  0.1344\n",
      "      9        0.6902       0.6016        \u001b[35m0.6803\u001b[0m  0.0662\n",
      "     10        \u001b[36m0.6848\u001b[0m       0.6016        \u001b[35m0.6792\u001b[0m  0.1228\n",
      "     11        \u001b[36m0.6811\u001b[0m       0.6016        \u001b[35m0.6780\u001b[0m  0.1368\n",
      "     12        0.6915       0.6172        \u001b[35m0.6769\u001b[0m  0.1301\n",
      "     13        \u001b[36m0.6788\u001b[0m       0.6250        \u001b[35m0.6750\u001b[0m  0.1909\n",
      "     14        \u001b[36m0.6736\u001b[0m       0.6328        \u001b[35m0.6728\u001b[0m  0.1163\n",
      "     15        0.6854       0.6328        \u001b[35m0.6711\u001b[0m  0.1159\n",
      "     16        0.6843       0.6406        \u001b[35m0.6693\u001b[0m  0.0968\n",
      "     17        0.6846       0.6328        \u001b[35m0.6676\u001b[0m  0.0886\n",
      "     18        0.6757       0.6328        \u001b[35m0.6646\u001b[0m  0.0822\n",
      "     19        0.6786       0.6328        \u001b[35m0.6624\u001b[0m  0.0705\n",
      "     20        \u001b[36m0.6667\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6579\u001b[0m  0.0779\n",
      "     21        0.6699       0.6484        \u001b[35m0.6547\u001b[0m  0.0837\n",
      "     22        0.6723       0.6406        \u001b[35m0.6511\u001b[0m  0.1130\n",
      "     23        \u001b[36m0.6597\u001b[0m       0.6484        \u001b[35m0.6468\u001b[0m  0.0697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24        0.6713       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6426\u001b[0m  0.0990\n",
      "     25        \u001b[36m0.6581\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6366\u001b[0m  0.0844\n",
      "     26        \u001b[36m0.6541\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6305\u001b[0m  0.0418\n",
      "     27        \u001b[36m0.6522\u001b[0m       0.7188        \u001b[35m0.6237\u001b[0m  0.0432\n",
      "     28        \u001b[36m0.6492\u001b[0m       0.7188        \u001b[35m0.6187\u001b[0m  0.0509\n",
      "     29        0.6554       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6139\u001b[0m  0.0746\n",
      "     30        \u001b[36m0.6366\u001b[0m       0.7344        \u001b[35m0.6075\u001b[0m  0.1298\n",
      "     31        \u001b[36m0.6273\u001b[0m       0.7344        \u001b[35m0.6006\u001b[0m  0.1146\n",
      "     32        0.6413       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5934\u001b[0m  0.0948\n",
      "     33        \u001b[36m0.6257\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5870\u001b[0m  0.0529\n",
      "     34        0.6336       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5821\u001b[0m  0.0404\n",
      "     35        \u001b[36m0.6242\u001b[0m       0.7656        \u001b[35m0.5769\u001b[0m  0.0423\n",
      "     36        0.6409       0.7656        \u001b[35m0.5744\u001b[0m  0.0425\n",
      "     37        \u001b[36m0.6213\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5690\u001b[0m  0.0415\n",
      "     38        \u001b[36m0.6155\u001b[0m       0.7734        \u001b[35m0.5626\u001b[0m  0.0402\n",
      "     39        0.6236       0.7734        \u001b[35m0.5607\u001b[0m  0.0402\n",
      "     40        0.6296       0.7734        \u001b[35m0.5601\u001b[0m  0.0563\n",
      "     41        0.6412       0.7656        \u001b[35m0.5570\u001b[0m  0.0946\n",
      "     42        0.6163       0.7656        \u001b[35m0.5518\u001b[0m  0.0689\n",
      "     43        0.6428       0.7656        \u001b[35m0.5508\u001b[0m  0.0710\n",
      "     44        0.6185       0.7656        \u001b[35m0.5472\u001b[0m  0.0919\n",
      "     45        0.6328       0.7656        0.5480  0.0464\n",
      "     46        \u001b[36m0.5999\u001b[0m       0.7656        \u001b[35m0.5419\u001b[0m  0.0453\n",
      "     47        0.6159       0.7656        \u001b[35m0.5397\u001b[0m  0.0392\n",
      "     48        0.6238       0.7734        \u001b[35m0.5375\u001b[0m  0.0408\n",
      "     49        0.6049       0.7734        \u001b[35m0.5317\u001b[0m  0.0403\n",
      "     50        0.6143       0.7734        \u001b[35m0.5272\u001b[0m  0.0388\n",
      "     51        0.6135       0.7734        \u001b[35m0.5226\u001b[0m  0.0425\n",
      "     52        \u001b[36m0.5986\u001b[0m       0.7734        \u001b[35m0.5196\u001b[0m  0.0403\n",
      "     53        \u001b[36m0.5953\u001b[0m       0.7734        \u001b[35m0.5156\u001b[0m  0.0444\n",
      "     54        0.6074       0.7734        \u001b[35m0.5138\u001b[0m  0.0462\n",
      "     55        0.6263       0.7734        0.5182  0.0450\n",
      "     56        0.6027       0.7734        0.5145  0.0434\n",
      "     57        0.6028       0.7734        \u001b[35m0.5122\u001b[0m  0.0404\n",
      "     58        0.6010       0.7734        \u001b[35m0.5093\u001b[0m  0.0543\n",
      "     59        0.6034       0.7734        \u001b[35m0.5069\u001b[0m  0.0926\n",
      "     60        0.5990       0.7734        0.5077  0.0887\n",
      "     61        0.6126       0.7734        \u001b[35m0.5065\u001b[0m  0.0579\n",
      "     62        \u001b[36m0.5944\u001b[0m       0.7734        \u001b[35m0.5031\u001b[0m  0.0435\n",
      "     63        0.6028       0.7734        \u001b[35m0.5008\u001b[0m  0.0399\n",
      "     64        0.6181       0.7734        0.5023  0.0607\n",
      "     65        \u001b[36m0.5818\u001b[0m       0.7734        \u001b[35m0.4985\u001b[0m  0.1023\n",
      "     66        0.6093       0.7734        0.4990  0.0513\n",
      "     67        0.6160       0.7734        0.5004  0.0400\n",
      "     68        0.5932       0.7734        0.4985  0.0398\n",
      "     69        0.5860       0.7734        \u001b[35m0.4933\u001b[0m  0.0653\n",
      "     70        0.5822       0.7734        \u001b[35m0.4889\u001b[0m  0.0947\n",
      "     71        0.5941       0.7734        \u001b[35m0.4860\u001b[0m  0.0673\n",
      "     72        0.5824       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4836\u001b[0m  0.0394\n",
      "     73        0.6074       0.7734        0.4858  0.0387\n",
      "     74        0.5950       0.7734        0.4861  0.0388\n",
      "     75        0.6214       0.7734        0.4899  0.0501\n",
      "     76        0.5943       0.7734        0.4905  0.0920\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7003\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6983\u001b[0m  0.0388\n",
      "      2        \u001b[36m0.6892\u001b[0m       0.5000        \u001b[35m0.6910\u001b[0m  0.0441\n",
      "      3        \u001b[36m0.6851\u001b[0m       0.5000        \u001b[35m0.6847\u001b[0m  0.0492\n",
      "      4        \u001b[36m0.6788\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6790\u001b[0m  0.0452\n",
      "      5        \u001b[36m0.6633\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6720\u001b[0m  0.0471\n",
      "      6        0.6709       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6665\u001b[0m  0.0529\n",
      "      7        0.6635       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6604\u001b[0m  0.0398\n",
      "      8        0.6674       0.6562        \u001b[35m0.6563\u001b[0m  0.0560\n",
      "      9        \u001b[36m0.6549\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6510\u001b[0m  0.1162\n",
      "     10        0.6569       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6457\u001b[0m  0.0786\n",
      "     11        \u001b[36m0.6497\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6403\u001b[0m  0.0775\n",
      "     12        \u001b[36m0.6335\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6335\u001b[0m  0.0592\n",
      "     13        0.6469       0.7188        \u001b[35m0.6287\u001b[0m  0.0620\n",
      "     14        \u001b[36m0.6293\u001b[0m       0.7031        \u001b[35m0.6219\u001b[0m  0.0643\n",
      "     15        0.6394       0.7109        \u001b[35m0.6186\u001b[0m  0.0427\n",
      "     16        \u001b[36m0.6256\u001b[0m       0.7031        \u001b[35m0.6134\u001b[0m  0.0733\n",
      "     17        0.6326       0.7109        \u001b[35m0.6102\u001b[0m  0.0777\n",
      "     18        \u001b[36m0.6161\u001b[0m       0.7188        \u001b[35m0.6045\u001b[0m  0.0988\n",
      "     19        0.6222       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5996\u001b[0m  0.1586\n",
      "     20        0.6187       0.7266        \u001b[35m0.5981\u001b[0m  0.0571\n",
      "     21        \u001b[36m0.6116\u001b[0m       0.7266        \u001b[35m0.5923\u001b[0m  0.0421\n",
      "     22        \u001b[36m0.5991\u001b[0m       0.7266        \u001b[35m0.5875\u001b[0m  0.0425\n",
      "     23        0.6116       0.7266        \u001b[35m0.5863\u001b[0m  0.0419\n",
      "     24        0.6165       0.7266        \u001b[35m0.5822\u001b[0m  0.0428\n",
      "     25        \u001b[36m0.5923\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5790\u001b[0m  0.0424\n",
      "     26        0.6010       0.7266        \u001b[35m0.5771\u001b[0m  0.0431\n",
      "     27        0.5963       0.7344        \u001b[35m0.5736\u001b[0m  0.0416\n",
      "     28        0.6023       0.7344        \u001b[35m0.5726\u001b[0m  0.0412\n",
      "     29        \u001b[36m0.5907\u001b[0m       0.7344        \u001b[35m0.5699\u001b[0m  0.0420\n",
      "     30        0.5998       0.7344        \u001b[35m0.5685\u001b[0m  0.0434\n",
      "     31        0.6196       0.7344        0.5690  0.0403\n",
      "     32        0.5931       0.7266        \u001b[35m0.5654\u001b[0m  0.0431\n",
      "     33        \u001b[36m0.5811\u001b[0m       0.7344        \u001b[35m0.5634\u001b[0m  0.0405\n",
      "     34        \u001b[36m0.5715\u001b[0m       0.7266        \u001b[35m0.5628\u001b[0m  0.0918\n",
      "     35        0.6179       0.7266        \u001b[35m0.5625\u001b[0m  0.1012\n",
      "     36        0.5992       0.7344        0.5629  0.1110\n",
      "     37        0.6020       0.7344        \u001b[35m0.5616\u001b[0m  0.0519\n",
      "     38        0.5806       0.7344        \u001b[35m0.5575\u001b[0m  0.0405\n",
      "     39        0.5933       0.7344        0.5577  0.0516\n",
      "     40        0.5966       0.7344        \u001b[35m0.5557\u001b[0m  0.0407\n",
      "     41        0.6030       0.7344        \u001b[35m0.5542\u001b[0m  0.0407\n",
      "     42        0.5742       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5512\u001b[0m  0.0469\n",
      "     43        0.5808       0.7422        \u001b[35m0.5499\u001b[0m  0.0419\n",
      "     44        0.5841       0.7422        \u001b[35m0.5485\u001b[0m  0.0454\n",
      "     45        \u001b[36m0.5584\u001b[0m       0.7422        \u001b[35m0.5465\u001b[0m  0.0810\n",
      "     46        0.5721       0.7422        \u001b[35m0.5449\u001b[0m  0.0768\n",
      "     47        0.5636       0.7422        \u001b[35m0.5426\u001b[0m  0.0579\n",
      "     48        0.5768       0.7422        \u001b[35m0.5421\u001b[0m  0.0401\n",
      "     49        \u001b[36m0.5530\u001b[0m       0.7422        \u001b[35m0.5416\u001b[0m  0.0385\n",
      "     50        0.5827       0.7422        \u001b[35m0.5404\u001b[0m  0.0528\n",
      "     51        0.5801       0.7422        \u001b[35m0.5397\u001b[0m  0.0450\n",
      "     52        0.5721       0.7422        \u001b[35m0.5388\u001b[0m  0.0456\n",
      "     53        \u001b[36m0.5502\u001b[0m       0.7422        \u001b[35m0.5371\u001b[0m  0.0587\n",
      "     54        0.5736       0.7344        \u001b[35m0.5363\u001b[0m  0.0468\n",
      "     55        0.5703       0.7344        \u001b[35m0.5363\u001b[0m  0.0431\n",
      "     56        0.5909       0.7422        0.5364  0.0455\n",
      "     57        0.5895       0.7422        \u001b[35m0.5363\u001b[0m  0.0480\n",
      "     58        0.5779       0.7422        \u001b[35m0.5358\u001b[0m  0.0398\n",
      "     59        0.5721       0.7422        \u001b[35m0.5355\u001b[0m  0.0477\n",
      "     60        0.5654       0.7422        \u001b[35m0.5342\u001b[0m  0.0397\n",
      "     61        0.5659       0.7422        \u001b[35m0.5334\u001b[0m  0.0429\n",
      "     62        0.5978       0.7422        0.5342  0.0426\n",
      "     63        0.5626       0.7422        0.5337  0.0549\n",
      "     64        0.5746       0.7422        \u001b[35m0.5331\u001b[0m  0.0677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     65        \u001b[36m0.5447\u001b[0m       0.7422        \u001b[35m0.5321\u001b[0m  0.0560\n",
      "     66        0.5736       0.7422        \u001b[35m0.5318\u001b[0m  0.0610\n",
      "     67        0.5669       0.7422        \u001b[35m0.5307\u001b[0m  0.0458\n",
      "     68        \u001b[36m0.5418\u001b[0m       0.7422        \u001b[35m0.5298\u001b[0m  0.0463\n",
      "     69        0.5471       0.7422        \u001b[35m0.5290\u001b[0m  0.0472\n",
      "     70        0.5480       0.7422        \u001b[35m0.5276\u001b[0m  0.0446\n",
      "     71        0.5568       0.7422        \u001b[35m0.5273\u001b[0m  0.0431\n",
      "     72        0.5528       0.7422        \u001b[35m0.5269\u001b[0m  0.0396\n",
      "     73        0.5784       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5262\u001b[0m  0.0389\n",
      "     74        0.5642       0.7422        \u001b[35m0.5259\u001b[0m  0.0400\n",
      "     75        0.5666       0.7500        \u001b[35m0.5251\u001b[0m  0.0392\n",
      "     76        0.5800       0.7422        0.5253  0.0405\n",
      "     77        0.5510       0.7422        0.5252  0.0392\n",
      "     78        0.5466       0.7500        \u001b[35m0.5244\u001b[0m  0.0576\n",
      "     79        0.5724       0.7500        0.5246  0.0470\n",
      "     80        0.5541       0.7422        \u001b[35m0.5241\u001b[0m  0.0411\n",
      "     81        0.5566       0.7422        \u001b[35m0.5236\u001b[0m  0.1182\n",
      "     82        0.5603       0.7422        0.5240  0.0640\n",
      "     83        0.5736       0.7500        0.5239  0.0397\n",
      "     84        0.5522       0.7500        0.5237  0.0422\n",
      "     85        0.5574       0.7500        0.5238  0.0435\n",
      "     86        \u001b[36m0.5381\u001b[0m       0.7500        \u001b[35m0.5231\u001b[0m  0.0464\n",
      "     87        \u001b[36m0.5355\u001b[0m       0.7422        \u001b[35m0.5225\u001b[0m  0.0458\n",
      "     88        0.5773       0.7422        0.5226  0.0476\n",
      "     89        0.5501       0.7422        \u001b[35m0.5223\u001b[0m  0.0491\n",
      "     90        0.5398       0.7422        0.5229  0.0509\n",
      "     91        0.5677       0.7422        0.5231  0.0553\n",
      "     92        0.5542       0.7422        0.5226  0.0451\n",
      "     93        0.5561       \u001b[32m0.7578\u001b[0m        0.5227  0.0418\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7004\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6990\u001b[0m  0.0342\n",
      "      2        \u001b[36m0.6936\u001b[0m       0.5000        \u001b[35m0.6945\u001b[0m  0.0400\n",
      "      3        \u001b[36m0.6929\u001b[0m       0.5000        \u001b[35m0.6908\u001b[0m  0.0527\n",
      "      4        \u001b[36m0.6849\u001b[0m       0.5000        \u001b[35m0.6864\u001b[0m  0.0572\n",
      "      5        0.6899       0.5000        \u001b[35m0.6821\u001b[0m  0.1090\n",
      "      6        \u001b[36m0.6778\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6773\u001b[0m  0.1236\n",
      "      7        0.6842       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6736\u001b[0m  0.0593\n",
      "      8        \u001b[36m0.6770\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6697\u001b[0m  0.0563\n",
      "      9        \u001b[36m0.6733\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6645\u001b[0m  0.0393\n",
      "     10        \u001b[36m0.6665\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6606\u001b[0m  0.0402\n",
      "     11        0.6745       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6585\u001b[0m  0.0436\n",
      "     12        0.6692       0.7109        \u001b[35m0.6551\u001b[0m  0.0458\n",
      "     13        \u001b[36m0.6659\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6503\u001b[0m  0.1303\n",
      "     14        0.6659       0.7188        \u001b[35m0.6465\u001b[0m  0.0862\n",
      "     15        \u001b[36m0.6576\u001b[0m       0.7188        \u001b[35m0.6423\u001b[0m  0.0454\n",
      "     16        \u001b[36m0.6466\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6353\u001b[0m  0.0394\n",
      "     17        0.6500       0.7188        \u001b[35m0.6298\u001b[0m  0.0393\n",
      "     18        0.6477       0.7188        \u001b[35m0.6258\u001b[0m  0.0414\n",
      "     19        0.6522       0.7109        \u001b[35m0.6226\u001b[0m  0.0451\n",
      "     20        \u001b[36m0.6441\u001b[0m       0.7109        \u001b[35m0.6191\u001b[0m  0.0840\n",
      "     21        0.6593       0.7188        \u001b[35m0.6180\u001b[0m  0.0642\n",
      "     22        \u001b[36m0.6354\u001b[0m       0.7188        \u001b[35m0.6129\u001b[0m  0.0469\n",
      "     23        0.6412       0.7266        \u001b[35m0.6080\u001b[0m  0.0494\n",
      "     24        \u001b[36m0.6312\u001b[0m       0.7266        \u001b[35m0.6045\u001b[0m  0.0560\n",
      "     25        \u001b[36m0.6284\u001b[0m       0.7266        \u001b[35m0.5998\u001b[0m  0.0734\n",
      "     26        \u001b[36m0.6283\u001b[0m       0.7266        \u001b[35m0.5978\u001b[0m  0.1107\n",
      "     27        \u001b[36m0.6098\u001b[0m       0.7188        \u001b[35m0.5902\u001b[0m  0.0898\n",
      "     28        0.6251       0.7188        \u001b[35m0.5855\u001b[0m  0.0495\n",
      "     29        0.6110       0.7188        \u001b[35m0.5820\u001b[0m  0.0436\n",
      "     30        0.6248       0.7266        0.5832  0.0657\n",
      "     31        \u001b[36m0.6006\u001b[0m       0.7266        \u001b[35m0.5802\u001b[0m  0.0444\n",
      "     32        0.6191       0.7266        \u001b[35m0.5760\u001b[0m  0.0450\n",
      "     33        0.6162       0.7344        \u001b[35m0.5739\u001b[0m  0.0409\n",
      "     34        0.6116       0.7344        \u001b[35m0.5732\u001b[0m  0.0396\n",
      "     35        0.6390       0.7344        0.5768  0.0406\n",
      "     36        0.6116       0.7422        \u001b[35m0.5727\u001b[0m  0.0396\n",
      "     37        0.6076       0.7422        \u001b[35m0.5702\u001b[0m  0.0405\n",
      "     38        \u001b[36m0.5989\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5688\u001b[0m  0.0748\n",
      "     39        0.6122       0.7578        \u001b[35m0.5652\u001b[0m  0.0603\n",
      "     40        0.6235       0.7422        \u001b[35m0.5627\u001b[0m  0.0396\n",
      "     41        \u001b[36m0.5870\u001b[0m       0.7422        \u001b[35m0.5585\u001b[0m  0.0428\n",
      "     42        0.6078       0.7500        \u001b[35m0.5546\u001b[0m  0.0399\n",
      "     43        0.6067       0.7500        \u001b[35m0.5535\u001b[0m  0.0418\n",
      "     44        0.6039       0.7500        0.5545  0.0491\n",
      "     45        \u001b[36m0.5790\u001b[0m       0.7500        \u001b[35m0.5503\u001b[0m  0.0428\n",
      "     46        0.6053       0.7578        0.5507  0.0405\n",
      "     47        0.5917       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5495\u001b[0m  0.0380\n",
      "     48        \u001b[36m0.5580\u001b[0m       0.7656        \u001b[35m0.5459\u001b[0m  0.0397\n",
      "     49        0.5761       0.7500        \u001b[35m0.5454\u001b[0m  0.0388\n",
      "     50        0.5811       0.7656        \u001b[35m0.5444\u001b[0m  0.0448\n",
      "     51        0.5979       0.7578        0.5446  0.0387\n",
      "     52        0.6016       0.7500        0.5488  0.0577\n",
      "     53        0.5924       0.7578        0.5459  0.0817\n",
      "     54        0.6008       0.7578        0.5445  0.1028\n",
      "     55        0.5581       0.7578        \u001b[35m0.5424\u001b[0m  0.0647\n",
      "     56        0.5992       0.7656        \u001b[35m0.5419\u001b[0m  0.0461\n",
      "     57        0.5836       0.7500        0.5442  0.0396\n",
      "     58        0.5688       0.7578        \u001b[35m0.5392\u001b[0m  0.0413\n",
      "     59        0.5870       0.7500        0.5413  0.0396\n",
      "     60        0.5915       0.7500        \u001b[35m0.5383\u001b[0m  0.0453\n",
      "     61        0.5789       0.7500        0.5391  0.0830\n",
      "     62        0.5724       0.7500        0.5392  0.0942\n",
      "     63        0.5761       0.7500        0.5389  0.0548\n",
      "     64        0.5682       0.7500        \u001b[35m0.5383\u001b[0m  0.0406\n",
      "     65        0.5828       0.7500        \u001b[35m0.5362\u001b[0m  0.0395\n",
      "     66        0.5637       0.7500        \u001b[35m0.5337\u001b[0m  0.0407\n",
      "     67        0.5819       0.7500        \u001b[35m0.5322\u001b[0m  0.0401\n",
      "     68        \u001b[36m0.5461\u001b[0m       0.7500        \u001b[35m0.5293\u001b[0m  0.0448\n",
      "     69        0.5863       0.7500        0.5310  0.0398\n",
      "     70        0.5866       0.7500        0.5311  0.0417\n",
      "     71        0.5709       0.7500        0.5312  0.0612\n",
      "     72        0.5589       0.7500        0.5312  0.1221\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7338\u001b[0m       \u001b[32m0.3828\u001b[0m        \u001b[35m0.7111\u001b[0m  0.0347\n",
      "      2        \u001b[36m0.7133\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m0.7047\u001b[0m  0.1338\n",
      "      3        \u001b[36m0.7073\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m0.6997\u001b[0m  0.2150\n",
      "      4        \u001b[36m0.7030\u001b[0m       \u001b[32m0.4766\u001b[0m        \u001b[35m0.6956\u001b[0m  0.1656\n",
      "      5        \u001b[36m0.7019\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6912\u001b[0m  0.0590\n",
      "      6        \u001b[36m0.7003\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6873\u001b[0m  0.0551\n",
      "      7        \u001b[36m0.6907\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6843\u001b[0m  0.0701\n",
      "      8        \u001b[36m0.6871\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6807\u001b[0m  0.0602\n",
      "      9        0.6873       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6788\u001b[0m  0.0698\n",
      "     10        0.6939       0.5938        \u001b[35m0.6750\u001b[0m  0.1317\n",
      "     11        \u001b[36m0.6863\u001b[0m       0.6094        \u001b[35m0.6715\u001b[0m  0.1164\n",
      "     12        \u001b[36m0.6838\u001b[0m       0.6016        \u001b[35m0.6689\u001b[0m  0.1052\n",
      "     13        \u001b[36m0.6822\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6648\u001b[0m  0.0851\n",
      "     14        \u001b[36m0.6806\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6611\u001b[0m  0.1101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15        \u001b[36m0.6689\u001b[0m       0.6719        \u001b[35m0.6580\u001b[0m  0.1118\n",
      "     16        0.6732       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6558\u001b[0m  0.0962\n",
      "     17        \u001b[36m0.6643\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6521\u001b[0m  0.1239\n",
      "     18        \u001b[36m0.6637\u001b[0m       0.6953        \u001b[35m0.6490\u001b[0m  0.0744\n",
      "     19        0.6767       0.6953        \u001b[35m0.6482\u001b[0m  0.0518\n",
      "     20        \u001b[36m0.6538\u001b[0m       0.6953        \u001b[35m0.6440\u001b[0m  0.0486\n",
      "     21        0.6549       0.7031        \u001b[35m0.6405\u001b[0m  0.0820\n",
      "     22        0.6676       0.6875        \u001b[35m0.6398\u001b[0m  0.0886\n",
      "     23        0.6581       0.6953        \u001b[35m0.6374\u001b[0m  0.0984\n",
      "     24        \u001b[36m0.6521\u001b[0m       0.6953        \u001b[35m0.6349\u001b[0m  0.0755\n",
      "     25        0.6689       0.7031        \u001b[35m0.6340\u001b[0m  0.0500\n",
      "     26        \u001b[36m0.6443\u001b[0m       0.7031        \u001b[35m0.6313\u001b[0m  0.0386\n",
      "     27        \u001b[36m0.6160\u001b[0m       0.7031        \u001b[35m0.6273\u001b[0m  0.0474\n",
      "     28        \u001b[36m0.6139\u001b[0m       0.7109        \u001b[35m0.6237\u001b[0m  0.0396\n",
      "     29        0.6283       0.7109        \u001b[35m0.6222\u001b[0m  0.0446\n",
      "     30        0.6298       0.7109        \u001b[35m0.6204\u001b[0m  0.0419\n",
      "     31        0.6382       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6193\u001b[0m  0.0411\n",
      "     32        0.6561       0.7109        \u001b[35m0.6185\u001b[0m  0.0398\n",
      "     33        0.6394       0.7109        \u001b[35m0.6183\u001b[0m  0.0404\n",
      "     34        0.6299       0.7188        \u001b[35m0.6163\u001b[0m  0.0399\n",
      "     35        0.6544       0.7031        \u001b[35m0.6162\u001b[0m  0.0404\n",
      "     36        0.6290       0.7031        \u001b[35m0.6149\u001b[0m  0.0410\n",
      "     37        0.6353       0.7031        \u001b[35m0.6142\u001b[0m  0.0847\n",
      "     38        0.6264       0.7031        \u001b[35m0.6130\u001b[0m  0.1010\n",
      "     39        0.6392       0.7031        \u001b[35m0.6124\u001b[0m  0.0578\n",
      "     40        \u001b[36m0.6057\u001b[0m       0.7031        \u001b[35m0.6100\u001b[0m  0.0605\n",
      "     41        0.6113       0.7031        \u001b[35m0.6082\u001b[0m  0.0393\n",
      "     42        0.6315       0.7031        \u001b[35m0.6073\u001b[0m  0.0410\n",
      "     43        0.6170       0.7031        \u001b[35m0.6060\u001b[0m  0.0413\n",
      "     44        0.6194       0.7109        \u001b[35m0.6047\u001b[0m  0.0408\n",
      "     45        0.6059       0.7031        \u001b[35m0.6030\u001b[0m  0.0428\n",
      "     46        0.6213       0.7031        \u001b[35m0.6016\u001b[0m  0.0453\n",
      "     47        \u001b[36m0.5870\u001b[0m       0.6953        \u001b[35m0.6001\u001b[0m  0.0453\n",
      "     48        0.6039       0.6953        \u001b[35m0.5983\u001b[0m  0.0416\n",
      "     49        0.6014       0.6875        \u001b[35m0.5974\u001b[0m  0.0396\n",
      "     50        0.6030       0.6875        \u001b[35m0.5964\u001b[0m  0.0390\n",
      "     51        0.6150       0.6797        \u001b[35m0.5951\u001b[0m  0.0401\n",
      "     52        0.5949       0.6875        \u001b[35m0.5946\u001b[0m  0.0443\n",
      "     53        0.6081       0.6719        \u001b[35m0.5938\u001b[0m  0.0485\n",
      "     54        0.5890       0.6797        \u001b[35m0.5929\u001b[0m  0.0445\n",
      "     55        0.6244       0.6797        0.5933  0.0446\n",
      "     56        0.5991       0.6797        \u001b[35m0.5927\u001b[0m  0.0386\n",
      "     57        0.6016       0.6719        \u001b[35m0.5921\u001b[0m  0.0405\n",
      "     58        0.6085       0.6719        \u001b[35m0.5917\u001b[0m  0.0418\n",
      "     59        0.5943       0.6719        \u001b[35m0.5904\u001b[0m  0.0424\n",
      "     60        0.6042       0.6719        \u001b[35m0.5898\u001b[0m  0.0627\n",
      "     61        0.5907       0.6719        \u001b[35m0.5885\u001b[0m  0.0862\n",
      "     62        0.6038       0.6719        \u001b[35m0.5882\u001b[0m  0.0735\n",
      "     63        0.5936       0.6797        \u001b[35m0.5877\u001b[0m  0.0397\n",
      "     64        0.6167       0.6797        \u001b[35m0.5863\u001b[0m  0.0405\n",
      "     65        0.6119       0.6797        \u001b[35m0.5854\u001b[0m  0.0386\n",
      "     66        \u001b[36m0.5799\u001b[0m       0.6797        \u001b[35m0.5849\u001b[0m  0.0398\n",
      "     67        0.5820       0.6797        \u001b[35m0.5842\u001b[0m  0.0396\n",
      "     68        0.5806       0.6797        \u001b[35m0.5830\u001b[0m  0.0397\n",
      "     69        0.5836       0.6719        \u001b[35m0.5822\u001b[0m  0.0403\n",
      "     70        0.5888       0.6797        \u001b[35m0.5819\u001b[0m  0.0459\n",
      "     71        0.6144       0.6797        0.5828  0.0386\n",
      "     72        0.5888       0.6719        0.5828  0.0402\n",
      "     73        0.6120       0.6719        0.5824  0.0387\n",
      "     74        0.5835       0.6797        0.5827  0.0447\n",
      "     75        0.5923       0.6797        \u001b[35m0.5815\u001b[0m  0.0598\n",
      "     76        0.6143       0.6797        \u001b[35m0.5807\u001b[0m  0.1067\n",
      "     77        \u001b[36m0.5615\u001b[0m       0.6797        \u001b[35m0.5805\u001b[0m  0.1202\n",
      "     78        0.6000       0.6719        \u001b[35m0.5804\u001b[0m  0.0669\n",
      "     79        0.5857       0.6797        \u001b[35m0.5797\u001b[0m  0.0514\n",
      "     80        0.5802       0.6797        \u001b[35m0.5779\u001b[0m  0.0419\n",
      "     81        0.6105       0.6719        0.5782  0.0391\n",
      "     82        0.5785       0.6719        0.5779  0.0396\n",
      "     83        0.6055       0.6797        \u001b[35m0.5773\u001b[0m  0.0502\n",
      "     84        0.5905       0.6875        0.5777  0.0465\n",
      "     85        0.5893       0.6797        0.5775  0.0494\n",
      "     86        0.5997       0.6875        0.5783  0.0401\n",
      "     87        0.5892       0.6875        0.5791  0.0410\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7077\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.7058\u001b[0m  0.0403\n",
      "      2        \u001b[36m0.7026\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7011\u001b[0m  0.0500\n",
      "      3        \u001b[36m0.6940\u001b[0m       0.5000        \u001b[35m0.6976\u001b[0m  0.0399\n",
      "      4        0.6944       0.5000        \u001b[35m0.6942\u001b[0m  0.0472\n",
      "      5        \u001b[36m0.6914\u001b[0m       0.5000        \u001b[35m0.6907\u001b[0m  0.0526\n",
      "      6        0.6919       0.5000        \u001b[35m0.6880\u001b[0m  0.0450\n",
      "      7        \u001b[36m0.6838\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6833\u001b[0m  0.0476\n",
      "      8        0.6870       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6795\u001b[0m  0.0489\n",
      "      9        \u001b[36m0.6824\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6764\u001b[0m  0.0464\n",
      "     10        0.6852       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6736\u001b[0m  0.0458\n",
      "     11        \u001b[36m0.6762\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6688\u001b[0m  0.0526\n",
      "     12        \u001b[36m0.6743\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6640\u001b[0m  0.0480\n",
      "     13        0.6807       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6603\u001b[0m  0.0552\n",
      "     14        \u001b[36m0.6611\u001b[0m       0.6406        \u001b[35m0.6556\u001b[0m  0.0514\n",
      "     15        \u001b[36m0.6548\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6490\u001b[0m  0.0395\n",
      "     16        0.6603       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6439\u001b[0m  0.0413\n",
      "     17        0.6570       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6387\u001b[0m  0.0438\n",
      "     18        \u001b[36m0.6443\u001b[0m       0.6719        \u001b[35m0.6325\u001b[0m  0.0465\n",
      "     19        0.6467       0.6719        \u001b[35m0.6272\u001b[0m  0.0426\n",
      "     20        0.6455       0.6719        \u001b[35m0.6216\u001b[0m  0.0429\n",
      "     21        \u001b[36m0.6268\u001b[0m       0.6719        \u001b[35m0.6148\u001b[0m  0.0428\n",
      "     22        0.6491       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6114\u001b[0m  0.0425\n",
      "     23        0.6448       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6079\u001b[0m  0.0504\n",
      "     24        0.6375       0.7109        \u001b[35m0.6031\u001b[0m  0.0475\n",
      "     25        0.6315       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5982\u001b[0m  0.0500\n",
      "     26        0.6427       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5946\u001b[0m  0.0444\n",
      "     27        0.6289       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5887\u001b[0m  0.0438\n",
      "     28        0.6269       0.7422        \u001b[35m0.5858\u001b[0m  0.0508\n",
      "     29        0.6344       0.7422        \u001b[35m0.5843\u001b[0m  0.0424\n",
      "     30        \u001b[36m0.6230\u001b[0m       0.7422        \u001b[35m0.5805\u001b[0m  0.0414\n",
      "     31        0.6576       0.7422        0.5822  0.0410\n",
      "     32        \u001b[36m0.5981\u001b[0m       0.7422        \u001b[35m0.5755\u001b[0m  0.0438\n",
      "     33        0.6213       0.7422        \u001b[35m0.5729\u001b[0m  0.0417\n",
      "     34        0.6134       0.7422        \u001b[35m0.5718\u001b[0m  0.0498\n",
      "     35        0.6206       0.7422        \u001b[35m0.5696\u001b[0m  0.0410\n",
      "     36        \u001b[36m0.5916\u001b[0m       0.7422        \u001b[35m0.5640\u001b[0m  0.0407\n",
      "     37        0.6104       0.7422        \u001b[35m0.5621\u001b[0m  0.0402\n",
      "     38        0.6010       0.7344        \u001b[35m0.5581\u001b[0m  0.0501\n",
      "     39        0.6111       0.7344        \u001b[35m0.5558\u001b[0m  0.0422\n",
      "     40        0.6153       0.7344        \u001b[35m0.5557\u001b[0m  0.0404\n",
      "     41        \u001b[36m0.5848\u001b[0m       0.7344        \u001b[35m0.5532\u001b[0m  0.0412\n",
      "     42        0.5991       0.7344        \u001b[35m0.5512\u001b[0m  0.0470\n",
      "     43        0.6046       0.7422        \u001b[35m0.5505\u001b[0m  0.0424\n",
      "     44        0.5907       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5467\u001b[0m  0.0627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     45        0.5990       0.7422        0.5477  0.0396\n",
      "     46        \u001b[36m0.5848\u001b[0m       0.7422        \u001b[35m0.5462\u001b[0m  0.0435\n",
      "     47        \u001b[36m0.5845\u001b[0m       0.7422        \u001b[35m0.5458\u001b[0m  0.0415\n",
      "     48        \u001b[36m0.5835\u001b[0m       0.7422        \u001b[35m0.5441\u001b[0m  0.0402\n",
      "     49        \u001b[36m0.5818\u001b[0m       0.7422        \u001b[35m0.5426\u001b[0m  0.0389\n",
      "     50        \u001b[36m0.5661\u001b[0m       0.7422        \u001b[35m0.5407\u001b[0m  0.0419\n",
      "     51        0.5805       0.7422        0.5407  0.0395\n",
      "     52        \u001b[36m0.5651\u001b[0m       0.7422        \u001b[35m0.5376\u001b[0m  0.0396\n",
      "     53        0.5690       0.7422        \u001b[35m0.5354\u001b[0m  0.0392\n",
      "     54        0.5991       0.7422        0.5370  0.0402\n",
      "     55        0.5765       0.7422        0.5358  0.0393\n",
      "     56        0.5655       0.7422        \u001b[35m0.5337\u001b[0m  0.0394\n",
      "     57        0.5899       0.7422        0.5354  0.0419\n",
      "     58        \u001b[36m0.5613\u001b[0m       0.7422        0.5342  0.0469\n",
      "     59        0.5759       0.7422        \u001b[35m0.5330\u001b[0m  0.0426\n",
      "     60        0.5647       0.7344        \u001b[35m0.5324\u001b[0m  0.0394\n",
      "     61        0.5783       0.7344        0.5326  0.0395\n",
      "     62        \u001b[36m0.5562\u001b[0m       0.7344        \u001b[35m0.5323\u001b[0m  0.0400\n",
      "     63        0.5874       0.7344        0.5326  0.0391\n",
      "     64        \u001b[36m0.5559\u001b[0m       0.7344        \u001b[35m0.5305\u001b[0m  0.0439\n",
      "     65        \u001b[36m0.5392\u001b[0m       0.7344        \u001b[35m0.5285\u001b[0m  0.0426\n",
      "     66        0.5848       0.7344        \u001b[35m0.5280\u001b[0m  0.0394\n",
      "     67        0.5640       0.7344        \u001b[35m0.5279\u001b[0m  0.0405\n",
      "     68        0.5588       0.7344        0.5279  0.0407\n",
      "     69        0.5692       0.7266        \u001b[35m0.5274\u001b[0m  0.0432\n",
      "     70        0.5558       0.7266        \u001b[35m0.5273\u001b[0m  0.0400\n",
      "     71        \u001b[36m0.5388\u001b[0m       0.7266        \u001b[35m0.5265\u001b[0m  0.0407\n",
      "     72        0.5635       0.7266        0.5272  0.0400\n",
      "     73        0.5513       0.7266        \u001b[35m0.5264\u001b[0m  0.0393\n",
      "     74        0.5711       0.7266        0.5268  0.0392\n",
      "     75        0.5506       0.7188        \u001b[35m0.5257\u001b[0m  0.0386\n",
      "     76        0.5617       0.7266        \u001b[35m0.5256\u001b[0m  0.0394\n",
      "     77        0.5706       0.7266        0.5260  0.0389\n",
      "     78        0.5442       0.7266        0.5264  0.0393\n",
      "     79        0.5560       0.7344        0.5275  0.0383\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6917\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6874\u001b[0m  0.0335\n",
      "      2        \u001b[36m0.6897\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6844\u001b[0m  0.0456\n",
      "      3        \u001b[36m0.6877\u001b[0m       0.5234        \u001b[35m0.6815\u001b[0m  0.0408\n",
      "      4        \u001b[36m0.6854\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6784\u001b[0m  0.0448\n",
      "      5        \u001b[36m0.6831\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6750\u001b[0m  0.0372\n",
      "      6        \u001b[36m0.6806\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6714\u001b[0m  0.0630\n",
      "      7        \u001b[36m0.6780\u001b[0m       0.5781        \u001b[35m0.6675\u001b[0m  0.0444\n",
      "      8        \u001b[36m0.6751\u001b[0m       0.5781        \u001b[35m0.6632\u001b[0m  0.0523\n",
      "      9        \u001b[36m0.6720\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6585\u001b[0m  0.0551\n",
      "     10        \u001b[36m0.6687\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6534\u001b[0m  0.0512\n",
      "     11        \u001b[36m0.6651\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6478\u001b[0m  0.0561\n",
      "     12        \u001b[36m0.6612\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6418\u001b[0m  0.0397\n",
      "     13        \u001b[36m0.6569\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6352\u001b[0m  0.0441\n",
      "     14        \u001b[36m0.6523\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6281\u001b[0m  0.0362\n",
      "     15        \u001b[36m0.6473\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.6206\u001b[0m  0.0429\n",
      "     16        \u001b[36m0.6422\u001b[0m       0.7578        \u001b[35m0.6126\u001b[0m  0.0415\n",
      "     17        \u001b[36m0.6367\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.6043\u001b[0m  0.0425\n",
      "     18        \u001b[36m0.6311\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.5958\u001b[0m  0.0476\n",
      "     19        \u001b[36m0.6253\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.5871\u001b[0m  0.0367\n",
      "     20        \u001b[36m0.6193\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.5783\u001b[0m  0.0388\n",
      "     21        \u001b[36m0.6134\u001b[0m       0.8047        \u001b[35m0.5695\u001b[0m  0.0528\n",
      "     22        \u001b[36m0.6076\u001b[0m       0.7969        \u001b[35m0.5609\u001b[0m  0.0582\n",
      "     23        \u001b[36m0.6019\u001b[0m       0.8047        \u001b[35m0.5525\u001b[0m  0.0531\n",
      "     24        \u001b[36m0.5963\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.5445\u001b[0m  0.0467\n",
      "     25        \u001b[36m0.5909\u001b[0m       0.8125        \u001b[35m0.5368\u001b[0m  0.0482\n",
      "     26        \u001b[36m0.5859\u001b[0m       0.8125        \u001b[35m0.5294\u001b[0m  0.0560\n",
      "     27        \u001b[36m0.5812\u001b[0m       0.8047        \u001b[35m0.5226\u001b[0m  0.0437\n",
      "     28        \u001b[36m0.5768\u001b[0m       0.8047        \u001b[35m0.5160\u001b[0m  0.0375\n",
      "     29        \u001b[36m0.5728\u001b[0m       0.7969        \u001b[35m0.5098\u001b[0m  0.0387\n",
      "     30        \u001b[36m0.5690\u001b[0m       0.7969        \u001b[35m0.5041\u001b[0m  0.0409\n",
      "     31        \u001b[36m0.5654\u001b[0m       0.7969        \u001b[35m0.4988\u001b[0m  0.0412\n",
      "     32        \u001b[36m0.5622\u001b[0m       0.7969        \u001b[35m0.4940\u001b[0m  0.0402\n",
      "     33        \u001b[36m0.5591\u001b[0m       0.8047        \u001b[35m0.4895\u001b[0m  0.0432\n",
      "     34        \u001b[36m0.5564\u001b[0m       0.8047        \u001b[35m0.4853\u001b[0m  0.0608\n",
      "     35        \u001b[36m0.5539\u001b[0m       0.8047        \u001b[35m0.4815\u001b[0m  0.0615\n",
      "     36        \u001b[36m0.5512\u001b[0m       0.8047        \u001b[35m0.4779\u001b[0m  0.0671\n",
      "     37        \u001b[36m0.5490\u001b[0m       0.8047        \u001b[35m0.4746\u001b[0m  0.0432\n",
      "     38        \u001b[36m0.5469\u001b[0m       0.8047        \u001b[35m0.4716\u001b[0m  0.0450\n",
      "     39        \u001b[36m0.5449\u001b[0m       0.8047        \u001b[35m0.4688\u001b[0m  0.0358\n",
      "     40        \u001b[36m0.5431\u001b[0m       0.8047        \u001b[35m0.4661\u001b[0m  0.0374\n",
      "     41        \u001b[36m0.5413\u001b[0m       0.8047        \u001b[35m0.4635\u001b[0m  0.0372\n",
      "     42        \u001b[36m0.5397\u001b[0m       0.8047        \u001b[35m0.4610\u001b[0m  0.0376\n",
      "     43        \u001b[36m0.5381\u001b[0m       0.8047        \u001b[35m0.4587\u001b[0m  0.0383\n",
      "     44        \u001b[36m0.5366\u001b[0m       0.8047        \u001b[35m0.4565\u001b[0m  0.0373\n",
      "     45        \u001b[36m0.5351\u001b[0m       0.8125        \u001b[35m0.4544\u001b[0m  0.0373\n",
      "     46        \u001b[36m0.5336\u001b[0m       0.8125        \u001b[35m0.4524\u001b[0m  0.0375\n",
      "     47        \u001b[36m0.5322\u001b[0m       0.8125        \u001b[35m0.4505\u001b[0m  0.0370\n",
      "     48        \u001b[36m0.5309\u001b[0m       0.8125        \u001b[35m0.4487\u001b[0m  0.0436\n",
      "     49        \u001b[36m0.5296\u001b[0m       0.8203        \u001b[35m0.4471\u001b[0m  0.0395\n",
      "     50        \u001b[36m0.5282\u001b[0m       0.8203        \u001b[35m0.4456\u001b[0m  0.0392\n",
      "     51        \u001b[36m0.5270\u001b[0m       0.8203        \u001b[35m0.4441\u001b[0m  0.0382\n",
      "     52        \u001b[36m0.5259\u001b[0m       0.8125        \u001b[35m0.4427\u001b[0m  0.0374\n",
      "     53        \u001b[36m0.5247\u001b[0m       0.8125        \u001b[35m0.4412\u001b[0m  0.0372\n",
      "     54        \u001b[36m0.5235\u001b[0m       0.8125        \u001b[35m0.4398\u001b[0m  0.0430\n",
      "     55        \u001b[36m0.5225\u001b[0m       0.8125        \u001b[35m0.4383\u001b[0m  0.0382\n",
      "     56        \u001b[36m0.5214\u001b[0m       0.8047        \u001b[35m0.4369\u001b[0m  0.0421\n",
      "     57        \u001b[36m0.5203\u001b[0m       0.8047        \u001b[35m0.4356\u001b[0m  0.0388\n",
      "     58        \u001b[36m0.5192\u001b[0m       0.8047        \u001b[35m0.4343\u001b[0m  0.0410\n",
      "     59        \u001b[36m0.5181\u001b[0m       0.8047        \u001b[35m0.4329\u001b[0m  0.0368\n",
      "     60        \u001b[36m0.5169\u001b[0m       0.8047        \u001b[35m0.4317\u001b[0m  0.0368\n",
      "     61        \u001b[36m0.5158\u001b[0m       0.8125        \u001b[35m0.4306\u001b[0m  0.0422\n",
      "     62        \u001b[36m0.5147\u001b[0m       0.8125        \u001b[35m0.4294\u001b[0m  0.0377\n",
      "     63        \u001b[36m0.5136\u001b[0m       0.8125        \u001b[35m0.4282\u001b[0m  0.0376\n",
      "     64        \u001b[36m0.5125\u001b[0m       0.8125        \u001b[35m0.4271\u001b[0m  0.0407\n",
      "     65        \u001b[36m0.5114\u001b[0m       0.8125        \u001b[35m0.4260\u001b[0m  0.0381\n",
      "     66        \u001b[36m0.5102\u001b[0m       0.8125        \u001b[35m0.4249\u001b[0m  0.0404\n",
      "     67        \u001b[36m0.5090\u001b[0m       0.8125        \u001b[35m0.4237\u001b[0m  0.0373\n",
      "     68        \u001b[36m0.5078\u001b[0m       0.8125        \u001b[35m0.4227\u001b[0m  0.0370\n",
      "     69        \u001b[36m0.5066\u001b[0m       0.8125        \u001b[35m0.4215\u001b[0m  0.0417\n",
      "     70        \u001b[36m0.5055\u001b[0m       0.8125        \u001b[35m0.4204\u001b[0m  0.0371\n",
      "     71        \u001b[36m0.5043\u001b[0m       0.8125        \u001b[35m0.4192\u001b[0m  0.0425\n",
      "     72        \u001b[36m0.5033\u001b[0m       0.8125        \u001b[35m0.4181\u001b[0m  0.0376\n",
      "     73        \u001b[36m0.5022\u001b[0m       0.8125        \u001b[35m0.4170\u001b[0m  0.0414\n",
      "     74        \u001b[36m0.5010\u001b[0m       0.8125        \u001b[35m0.4159\u001b[0m  0.0381\n",
      "     75        \u001b[36m0.5000\u001b[0m       0.8125        \u001b[35m0.4149\u001b[0m  0.0396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     76        \u001b[36m0.4989\u001b[0m       0.8125        \u001b[35m0.4139\u001b[0m  0.0368\n",
      "     77        \u001b[36m0.4978\u001b[0m       0.8125        \u001b[35m0.4129\u001b[0m  0.0410\n",
      "     78        \u001b[36m0.4968\u001b[0m       0.8203        \u001b[35m0.4119\u001b[0m  0.0374\n",
      "     79        \u001b[36m0.4959\u001b[0m       0.8203        \u001b[35m0.4110\u001b[0m  0.0419\n",
      "     80        \u001b[36m0.4947\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m0.4101\u001b[0m  0.0365\n",
      "     81        \u001b[36m0.4937\u001b[0m       0.8281        \u001b[35m0.4093\u001b[0m  0.0383\n",
      "     82        \u001b[36m0.4928\u001b[0m       0.8281        \u001b[35m0.4083\u001b[0m  0.0512\n",
      "     83        \u001b[36m0.4918\u001b[0m       0.8281        \u001b[35m0.4073\u001b[0m  0.0506\n",
      "     84        \u001b[36m0.4908\u001b[0m       0.8281        \u001b[35m0.4063\u001b[0m  0.0562\n",
      "     85        \u001b[36m0.4898\u001b[0m       0.8281        \u001b[35m0.4053\u001b[0m  0.0378\n",
      "     86        \u001b[36m0.4889\u001b[0m       0.8281        \u001b[35m0.4044\u001b[0m  0.0375\n",
      "     87        \u001b[36m0.4878\u001b[0m       0.8281        \u001b[35m0.4037\u001b[0m  0.0373\n",
      "     88        \u001b[36m0.4868\u001b[0m       0.8281        \u001b[35m0.4028\u001b[0m  0.0370\n",
      "     89        \u001b[36m0.4858\u001b[0m       0.8281        \u001b[35m0.4021\u001b[0m  0.0376\n",
      "     90        \u001b[36m0.4849\u001b[0m       0.8281        \u001b[35m0.4013\u001b[0m  0.0388\n",
      "     91        \u001b[36m0.4840\u001b[0m       0.8281        \u001b[35m0.4003\u001b[0m  0.0374\n",
      "     92        \u001b[36m0.4831\u001b[0m       0.8281        \u001b[35m0.3993\u001b[0m  0.0373\n",
      "     93        \u001b[36m0.4821\u001b[0m       0.8281        \u001b[35m0.3984\u001b[0m  0.0377\n",
      "     94        \u001b[36m0.4812\u001b[0m       0.8281        \u001b[35m0.3976\u001b[0m  0.0376\n",
      "     95        \u001b[36m0.4801\u001b[0m       0.8281        \u001b[35m0.3968\u001b[0m  0.0372\n",
      "     96        \u001b[36m0.4791\u001b[0m       0.8281        \u001b[35m0.3961\u001b[0m  0.0371\n",
      "     97        \u001b[36m0.4782\u001b[0m       0.8281        \u001b[35m0.3954\u001b[0m  0.0368\n",
      "     98        \u001b[36m0.4773\u001b[0m       0.8281        \u001b[35m0.3947\u001b[0m  0.0373\n",
      "     99        \u001b[36m0.4764\u001b[0m       0.8281        \u001b[35m0.3940\u001b[0m  0.0369\n",
      "    100        \u001b[36m0.4755\u001b[0m       0.8281        \u001b[35m0.3934\u001b[0m  0.0363\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7120\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.7035\u001b[0m  0.0365\n",
      "      2        \u001b[36m0.7065\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6988\u001b[0m  0.0367\n",
      "      3        \u001b[36m0.7025\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6952\u001b[0m  0.0449\n",
      "      4        \u001b[36m0.6995\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6924\u001b[0m  0.0360\n",
      "      5        \u001b[36m0.6968\u001b[0m       0.5391        \u001b[35m0.6898\u001b[0m  0.0385\n",
      "      6        \u001b[36m0.6942\u001b[0m       0.5234        \u001b[35m0.6871\u001b[0m  0.0471\n",
      "      7        \u001b[36m0.6917\u001b[0m       0.5469        \u001b[35m0.6844\u001b[0m  0.0464\n",
      "      8        \u001b[36m0.6891\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6816\u001b[0m  0.0485\n",
      "      9        \u001b[36m0.6866\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6790\u001b[0m  0.0458\n",
      "     10        \u001b[36m0.6838\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6763\u001b[0m  0.0463\n",
      "     11        \u001b[36m0.6809\u001b[0m       0.6406        \u001b[35m0.6736\u001b[0m  0.0449\n",
      "     12        \u001b[36m0.6781\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6709\u001b[0m  0.0450\n",
      "     13        \u001b[36m0.6752\u001b[0m       0.6328        \u001b[35m0.6682\u001b[0m  0.0442\n",
      "     14        \u001b[36m0.6722\u001b[0m       0.6406        \u001b[35m0.6653\u001b[0m  0.0436\n",
      "     15        \u001b[36m0.6688\u001b[0m       0.6562        \u001b[35m0.6624\u001b[0m  0.0361\n",
      "     16        \u001b[36m0.6654\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6594\u001b[0m  0.0393\n",
      "     17        \u001b[36m0.6619\u001b[0m       0.6797        \u001b[35m0.6564\u001b[0m  0.0467\n",
      "     18        \u001b[36m0.6583\u001b[0m       0.6797        \u001b[35m0.6534\u001b[0m  0.0372\n",
      "     19        \u001b[36m0.6545\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6503\u001b[0m  0.0377\n",
      "     20        \u001b[36m0.6504\u001b[0m       0.6875        \u001b[35m0.6472\u001b[0m  0.0391\n",
      "     21        \u001b[36m0.6465\u001b[0m       0.6875        \u001b[35m0.6441\u001b[0m  0.0422\n",
      "     22        \u001b[36m0.6423\u001b[0m       0.6953        \u001b[35m0.6410\u001b[0m  0.0434\n",
      "     23        \u001b[36m0.6381\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6381\u001b[0m  0.0449\n",
      "     24        \u001b[36m0.6340\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6352\u001b[0m  0.0363\n",
      "     25        \u001b[36m0.6298\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6323\u001b[0m  0.0369\n",
      "     26        \u001b[36m0.6256\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6296\u001b[0m  0.0389\n",
      "     27        \u001b[36m0.6214\u001b[0m       0.7266        \u001b[35m0.6270\u001b[0m  0.0416\n",
      "     28        \u001b[36m0.6171\u001b[0m       0.7266        \u001b[35m0.6244\u001b[0m  0.0422\n",
      "     29        \u001b[36m0.6130\u001b[0m       0.7188        \u001b[35m0.6219\u001b[0m  0.0426\n",
      "     30        \u001b[36m0.6090\u001b[0m       0.7188        \u001b[35m0.6194\u001b[0m  0.0420\n",
      "     31        \u001b[36m0.6050\u001b[0m       0.7188        \u001b[35m0.6171\u001b[0m  0.0408\n",
      "     32        \u001b[36m0.6010\u001b[0m       0.7188        \u001b[35m0.6149\u001b[0m  0.0420\n",
      "     33        \u001b[36m0.5971\u001b[0m       0.7188        \u001b[35m0.6127\u001b[0m  0.0413\n",
      "     34        \u001b[36m0.5934\u001b[0m       0.7109        \u001b[35m0.6106\u001b[0m  0.0488\n",
      "     35        \u001b[36m0.5897\u001b[0m       0.7188        \u001b[35m0.6087\u001b[0m  0.0366\n",
      "     36        \u001b[36m0.5861\u001b[0m       0.7266        \u001b[35m0.6069\u001b[0m  0.0363\n",
      "     37        \u001b[36m0.5826\u001b[0m       0.7266        \u001b[35m0.6054\u001b[0m  0.0561\n",
      "     38        \u001b[36m0.5792\u001b[0m       0.7266        \u001b[35m0.6039\u001b[0m  0.0363\n",
      "     39        \u001b[36m0.5758\u001b[0m       0.7266        \u001b[35m0.6025\u001b[0m  0.0401\n",
      "     40        \u001b[36m0.5728\u001b[0m       0.7266        \u001b[35m0.6012\u001b[0m  0.0393\n",
      "     41        \u001b[36m0.5698\u001b[0m       0.7266        \u001b[35m0.6001\u001b[0m  0.0394\n",
      "     42        \u001b[36m0.5670\u001b[0m       0.7266        \u001b[35m0.5989\u001b[0m  0.0391\n",
      "     43        \u001b[36m0.5643\u001b[0m       0.7266        \u001b[35m0.5977\u001b[0m  0.0389\n",
      "     44        \u001b[36m0.5617\u001b[0m       0.7188        \u001b[35m0.5966\u001b[0m  0.0401\n",
      "     45        \u001b[36m0.5593\u001b[0m       0.7188        \u001b[35m0.5955\u001b[0m  0.0389\n",
      "     46        \u001b[36m0.5570\u001b[0m       0.7266        \u001b[35m0.5946\u001b[0m  0.0374\n",
      "     47        \u001b[36m0.5549\u001b[0m       0.7266        \u001b[35m0.5937\u001b[0m  0.0372\n",
      "     48        \u001b[36m0.5529\u001b[0m       0.7188        \u001b[35m0.5929\u001b[0m  0.0387\n",
      "     49        \u001b[36m0.5508\u001b[0m       0.7109        \u001b[35m0.5922\u001b[0m  0.0359\n",
      "     50        \u001b[36m0.5490\u001b[0m       0.7109        \u001b[35m0.5915\u001b[0m  0.0445\n",
      "     51        \u001b[36m0.5475\u001b[0m       0.6953        \u001b[35m0.5908\u001b[0m  0.0384\n",
      "     52        \u001b[36m0.5458\u001b[0m       0.6953        \u001b[35m0.5902\u001b[0m  0.0387\n",
      "     53        \u001b[36m0.5442\u001b[0m       0.6953        \u001b[35m0.5897\u001b[0m  0.0375\n",
      "     54        \u001b[36m0.5428\u001b[0m       0.6953        \u001b[35m0.5893\u001b[0m  0.0381\n",
      "     55        \u001b[36m0.5414\u001b[0m       0.6875        \u001b[35m0.5889\u001b[0m  0.0453\n",
      "     56        \u001b[36m0.5400\u001b[0m       0.6875        \u001b[35m0.5887\u001b[0m  0.0429\n",
      "     57        \u001b[36m0.5388\u001b[0m       0.6875        \u001b[35m0.5883\u001b[0m  0.0468\n",
      "     58        \u001b[36m0.5376\u001b[0m       0.6875        \u001b[35m0.5879\u001b[0m  0.0418\n",
      "     59        \u001b[36m0.5363\u001b[0m       0.6875        \u001b[35m0.5877\u001b[0m  0.0398\n",
      "     60        \u001b[36m0.5351\u001b[0m       0.6875        \u001b[35m0.5876\u001b[0m  0.0372\n",
      "     61        \u001b[36m0.5341\u001b[0m       0.6875        \u001b[35m0.5875\u001b[0m  0.0426\n",
      "     62        \u001b[36m0.5330\u001b[0m       0.6875        \u001b[35m0.5873\u001b[0m  0.0389\n",
      "     63        \u001b[36m0.5319\u001b[0m       0.6875        \u001b[35m0.5872\u001b[0m  0.0396\n",
      "     64        \u001b[36m0.5309\u001b[0m       0.6875        \u001b[35m0.5870\u001b[0m  0.0389\n",
      "     65        \u001b[36m0.5297\u001b[0m       0.6875        \u001b[35m0.5869\u001b[0m  0.0383\n",
      "     66        \u001b[36m0.5288\u001b[0m       0.6875        \u001b[35m0.5868\u001b[0m  0.0486\n",
      "     67        \u001b[36m0.5279\u001b[0m       0.6875        \u001b[35m0.5867\u001b[0m  0.0408\n",
      "     68        \u001b[36m0.5269\u001b[0m       0.6875        \u001b[35m0.5866\u001b[0m  0.0393\n",
      "     69        \u001b[36m0.5261\u001b[0m       0.6875        \u001b[35m0.5863\u001b[0m  0.0421\n",
      "     70        \u001b[36m0.5252\u001b[0m       0.6875        \u001b[35m0.5861\u001b[0m  0.0370\n",
      "     71        \u001b[36m0.5242\u001b[0m       0.6875        \u001b[35m0.5859\u001b[0m  0.0449\n",
      "     72        \u001b[36m0.5234\u001b[0m       0.6875        \u001b[35m0.5856\u001b[0m  0.0370\n",
      "     73        \u001b[36m0.5225\u001b[0m       0.6875        \u001b[35m0.5852\u001b[0m  0.0401\n",
      "     74        \u001b[36m0.5217\u001b[0m       0.6875        \u001b[35m0.5848\u001b[0m  0.0370\n",
      "     75        \u001b[36m0.5210\u001b[0m       0.6875        \u001b[35m0.5844\u001b[0m  0.0403\n",
      "     76        \u001b[36m0.5202\u001b[0m       0.6875        \u001b[35m0.5841\u001b[0m  0.0394\n",
      "     77        \u001b[36m0.5195\u001b[0m       0.6875        \u001b[35m0.5837\u001b[0m  0.0408\n",
      "     78        \u001b[36m0.5188\u001b[0m       0.6875        \u001b[35m0.5834\u001b[0m  0.0406\n",
      "     79        \u001b[36m0.5180\u001b[0m       0.6953        \u001b[35m0.5830\u001b[0m  0.0380\n",
      "     80        \u001b[36m0.5173\u001b[0m       0.6953        \u001b[35m0.5826\u001b[0m  0.0405\n",
      "     81        \u001b[36m0.5165\u001b[0m       0.6953        \u001b[35m0.5822\u001b[0m  0.0377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     82        \u001b[36m0.5159\u001b[0m       0.6953        \u001b[35m0.5818\u001b[0m  0.0398\n",
      "     83        \u001b[36m0.5153\u001b[0m       0.6953        \u001b[35m0.5814\u001b[0m  0.0420\n",
      "     84        \u001b[36m0.5147\u001b[0m       0.6953        \u001b[35m0.5810\u001b[0m  0.0478\n",
      "     85        \u001b[36m0.5141\u001b[0m       0.6953        \u001b[35m0.5806\u001b[0m  0.0404\n",
      "     86        \u001b[36m0.5135\u001b[0m       0.6953        \u001b[35m0.5802\u001b[0m  0.0366\n",
      "     87        \u001b[36m0.5129\u001b[0m       0.6953        \u001b[35m0.5798\u001b[0m  0.0380\n",
      "     88        \u001b[36m0.5123\u001b[0m       0.6953        \u001b[35m0.5794\u001b[0m  0.0385\n",
      "     89        \u001b[36m0.5117\u001b[0m       0.7031        \u001b[35m0.5790\u001b[0m  0.0437\n",
      "     90        \u001b[36m0.5112\u001b[0m       0.7031        \u001b[35m0.5786\u001b[0m  0.0419\n",
      "     91        \u001b[36m0.5106\u001b[0m       0.7031        \u001b[35m0.5783\u001b[0m  0.0406\n",
      "     92        \u001b[36m0.5100\u001b[0m       0.6953        \u001b[35m0.5780\u001b[0m  0.0385\n",
      "     93        \u001b[36m0.5095\u001b[0m       0.6953        \u001b[35m0.5776\u001b[0m  0.0370\n",
      "     94        \u001b[36m0.5089\u001b[0m       0.6875        \u001b[35m0.5773\u001b[0m  0.0371\n",
      "     95        \u001b[36m0.5085\u001b[0m       0.6875        \u001b[35m0.5769\u001b[0m  0.0417\n",
      "     96        \u001b[36m0.5079\u001b[0m       0.6875        \u001b[35m0.5765\u001b[0m  0.0436\n",
      "     97        \u001b[36m0.5074\u001b[0m       0.6875        \u001b[35m0.5762\u001b[0m  0.0365\n",
      "     98        \u001b[36m0.5068\u001b[0m       0.6953        \u001b[35m0.5758\u001b[0m  0.0378\n",
      "     99        \u001b[36m0.5063\u001b[0m       0.6953        \u001b[35m0.5754\u001b[0m  0.0368\n",
      "    100        \u001b[36m0.5058\u001b[0m       0.6953        \u001b[35m0.5750\u001b[0m  0.0389\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7095\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6969\u001b[0m  0.0361\n",
      "      2        \u001b[36m0.6974\u001b[0m       0.5234        \u001b[35m0.6862\u001b[0m  0.0404\n",
      "      3        \u001b[36m0.6871\u001b[0m       0.5000        \u001b[35m0.6774\u001b[0m  0.0492\n",
      "      4        \u001b[36m0.6782\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6696\u001b[0m  0.0388\n",
      "      5        \u001b[36m0.6700\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6624\u001b[0m  0.0389\n",
      "      6        \u001b[36m0.6622\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6555\u001b[0m  0.0459\n",
      "      7        \u001b[36m0.6544\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6489\u001b[0m  0.0376\n",
      "      8        \u001b[36m0.6467\u001b[0m       0.6875        \u001b[35m0.6425\u001b[0m  0.0389\n",
      "      9        \u001b[36m0.6392\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6362\u001b[0m  0.0454\n",
      "     10        \u001b[36m0.6316\u001b[0m       0.7188        \u001b[35m0.6300\u001b[0m  0.0404\n",
      "     11        \u001b[36m0.6237\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6238\u001b[0m  0.0434\n",
      "     12        \u001b[36m0.6156\u001b[0m       0.7188        \u001b[35m0.6177\u001b[0m  0.0418\n",
      "     13        \u001b[36m0.6074\u001b[0m       0.7188        \u001b[35m0.6119\u001b[0m  0.0419\n",
      "     14        \u001b[36m0.5992\u001b[0m       0.7266        \u001b[35m0.6062\u001b[0m  0.0434\n",
      "     15        \u001b[36m0.5911\u001b[0m       0.7266        \u001b[35m0.6008\u001b[0m  0.0434\n",
      "     16        \u001b[36m0.5832\u001b[0m       0.7188        \u001b[35m0.5955\u001b[0m  0.0440\n",
      "     17        \u001b[36m0.5754\u001b[0m       0.7266        \u001b[35m0.5907\u001b[0m  0.0408\n",
      "     18        \u001b[36m0.5679\u001b[0m       0.7188        \u001b[35m0.5862\u001b[0m  0.0409\n",
      "     19        \u001b[36m0.5608\u001b[0m       0.7109        \u001b[35m0.5822\u001b[0m  0.0500\n",
      "     20        \u001b[36m0.5542\u001b[0m       0.7188        \u001b[35m0.5785\u001b[0m  0.0367\n",
      "     21        \u001b[36m0.5481\u001b[0m       0.7188        \u001b[35m0.5751\u001b[0m  0.0381\n",
      "     22        \u001b[36m0.5426\u001b[0m       0.7188        \u001b[35m0.5723\u001b[0m  0.0433\n",
      "     23        \u001b[36m0.5376\u001b[0m       0.7188        \u001b[35m0.5699\u001b[0m  0.0500\n",
      "     24        \u001b[36m0.5331\u001b[0m       0.7109        \u001b[35m0.5678\u001b[0m  0.0667\n",
      "     25        \u001b[36m0.5290\u001b[0m       0.6953        \u001b[35m0.5659\u001b[0m  0.0433\n",
      "     26        \u001b[36m0.5254\u001b[0m       0.6953        \u001b[35m0.5643\u001b[0m  0.0446\n",
      "     27        \u001b[36m0.5222\u001b[0m       0.6875        \u001b[35m0.5628\u001b[0m  0.0534\n",
      "     28        \u001b[36m0.5193\u001b[0m       0.6875        \u001b[35m0.5616\u001b[0m  0.0409\n",
      "     29        \u001b[36m0.5168\u001b[0m       0.6875        \u001b[35m0.5605\u001b[0m  0.0602\n",
      "     30        \u001b[36m0.5145\u001b[0m       0.6875        \u001b[35m0.5594\u001b[0m  0.0406\n",
      "     31        \u001b[36m0.5125\u001b[0m       0.6875        \u001b[35m0.5585\u001b[0m  0.0443\n",
      "     32        \u001b[36m0.5108\u001b[0m       0.6797        \u001b[35m0.5576\u001b[0m  0.0405\n",
      "     33        \u001b[36m0.5091\u001b[0m       0.6797        \u001b[35m0.5568\u001b[0m  0.0401\n",
      "     34        \u001b[36m0.5076\u001b[0m       0.6797        \u001b[35m0.5560\u001b[0m  0.0398\n",
      "     35        \u001b[36m0.5062\u001b[0m       0.6875        \u001b[35m0.5552\u001b[0m  0.0405\n",
      "     36        \u001b[36m0.5049\u001b[0m       0.6875        \u001b[35m0.5543\u001b[0m  0.0371\n",
      "     37        \u001b[36m0.5037\u001b[0m       0.6875        \u001b[35m0.5535\u001b[0m  0.0374\n",
      "     38        \u001b[36m0.5027\u001b[0m       0.6953        \u001b[35m0.5527\u001b[0m  0.0370\n",
      "     39        \u001b[36m0.5016\u001b[0m       0.7031        \u001b[35m0.5519\u001b[0m  0.0380\n",
      "     40        \u001b[36m0.5006\u001b[0m       0.7031        \u001b[35m0.5512\u001b[0m  0.0375\n",
      "     41        \u001b[36m0.4996\u001b[0m       0.7031        \u001b[35m0.5504\u001b[0m  0.0373\n",
      "     42        \u001b[36m0.4986\u001b[0m       0.6953        \u001b[35m0.5497\u001b[0m  0.0380\n",
      "     43        \u001b[36m0.4977\u001b[0m       0.6953        \u001b[35m0.5490\u001b[0m  0.0375\n",
      "     44        \u001b[36m0.4967\u001b[0m       0.6953        \u001b[35m0.5482\u001b[0m  0.0374\n",
      "     45        \u001b[36m0.4959\u001b[0m       0.7031        \u001b[35m0.5474\u001b[0m  0.0369\n",
      "     46        \u001b[36m0.4950\u001b[0m       0.7031        \u001b[35m0.5467\u001b[0m  0.0368\n",
      "     47        \u001b[36m0.4941\u001b[0m       0.7031        \u001b[35m0.5460\u001b[0m  0.0374\n",
      "     48        \u001b[36m0.4933\u001b[0m       0.7031        \u001b[35m0.5453\u001b[0m  0.0394\n",
      "     49        \u001b[36m0.4925\u001b[0m       0.7031        \u001b[35m0.5446\u001b[0m  0.0442\n",
      "     50        \u001b[36m0.4917\u001b[0m       0.7031        \u001b[35m0.5440\u001b[0m  0.0425\n",
      "     51        \u001b[36m0.4910\u001b[0m       0.7031        \u001b[35m0.5435\u001b[0m  0.0434\n",
      "     52        \u001b[36m0.4903\u001b[0m       0.7031        \u001b[35m0.5429\u001b[0m  0.0387\n",
      "     53        \u001b[36m0.4896\u001b[0m       0.7109        \u001b[35m0.5424\u001b[0m  0.0374\n",
      "     54        \u001b[36m0.4889\u001b[0m       0.7109        \u001b[35m0.5419\u001b[0m  0.0425\n",
      "     55        \u001b[36m0.4882\u001b[0m       0.7188        \u001b[35m0.5414\u001b[0m  0.0381\n",
      "     56        \u001b[36m0.4876\u001b[0m       0.7266        \u001b[35m0.5408\u001b[0m  0.0381\n",
      "     57        \u001b[36m0.4870\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5403\u001b[0m  0.0411\n",
      "     58        \u001b[36m0.4864\u001b[0m       0.7344        \u001b[35m0.5398\u001b[0m  0.0459\n",
      "     59        \u001b[36m0.4858\u001b[0m       0.7344        \u001b[35m0.5394\u001b[0m  0.0435\n",
      "     60        \u001b[36m0.4852\u001b[0m       0.7344        \u001b[35m0.5390\u001b[0m  0.0385\n",
      "     61        \u001b[36m0.4846\u001b[0m       0.7344        \u001b[35m0.5386\u001b[0m  0.0378\n",
      "     62        \u001b[36m0.4841\u001b[0m       0.7344        \u001b[35m0.5381\u001b[0m  0.0388\n",
      "     63        \u001b[36m0.4835\u001b[0m       0.7344        \u001b[35m0.5377\u001b[0m  0.0368\n",
      "     64        \u001b[36m0.4829\u001b[0m       0.7344        \u001b[35m0.5372\u001b[0m  0.0376\n",
      "     65        \u001b[36m0.4823\u001b[0m       0.7344        \u001b[35m0.5367\u001b[0m  0.0408\n",
      "     66        \u001b[36m0.4817\u001b[0m       0.7344        \u001b[35m0.5362\u001b[0m  0.0381\n",
      "     67        \u001b[36m0.4812\u001b[0m       0.7344        \u001b[35m0.5356\u001b[0m  0.0371\n",
      "     68        \u001b[36m0.4806\u001b[0m       0.7344        \u001b[35m0.5351\u001b[0m  0.0391\n",
      "     69        \u001b[36m0.4800\u001b[0m       0.7344        \u001b[35m0.5345\u001b[0m  0.0421\n",
      "     70        \u001b[36m0.4794\u001b[0m       0.7344        \u001b[35m0.5340\u001b[0m  0.0412\n",
      "     71        \u001b[36m0.4789\u001b[0m       0.7344        \u001b[35m0.5335\u001b[0m  0.0388\n",
      "     72        \u001b[36m0.4783\u001b[0m       0.7344        \u001b[35m0.5330\u001b[0m  0.0377\n",
      "     73        \u001b[36m0.4778\u001b[0m       0.7344        \u001b[35m0.5325\u001b[0m  0.0408\n",
      "     74        \u001b[36m0.4773\u001b[0m       0.7344        \u001b[35m0.5320\u001b[0m  0.0421\n",
      "     75        \u001b[36m0.4768\u001b[0m       0.7344        \u001b[35m0.5316\u001b[0m  0.0453\n",
      "     76        \u001b[36m0.4762\u001b[0m       0.7344        \u001b[35m0.5312\u001b[0m  0.0369\n",
      "     77        \u001b[36m0.4758\u001b[0m       0.7344        \u001b[35m0.5309\u001b[0m  0.0397\n",
      "     78        \u001b[36m0.4753\u001b[0m       0.7344        \u001b[35m0.5305\u001b[0m  0.0374\n",
      "     79        \u001b[36m0.4748\u001b[0m       0.7344        \u001b[35m0.5301\u001b[0m  0.0436\n",
      "     80        \u001b[36m0.4743\u001b[0m       0.7344        \u001b[35m0.5297\u001b[0m  0.0442\n",
      "     81        \u001b[36m0.4738\u001b[0m       0.7344        \u001b[35m0.5293\u001b[0m  0.0432\n",
      "     82        \u001b[36m0.4733\u001b[0m       0.7344        \u001b[35m0.5290\u001b[0m  0.0455\n",
      "     83        \u001b[36m0.4728\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5286\u001b[0m  0.0438\n",
      "     84        \u001b[36m0.4723\u001b[0m       0.7344        \u001b[35m0.5283\u001b[0m  0.0424\n",
      "     85        \u001b[36m0.4718\u001b[0m       0.7344        \u001b[35m0.5280\u001b[0m  0.0438\n",
      "     86        \u001b[36m0.4713\u001b[0m       0.7344        \u001b[35m0.5277\u001b[0m  0.0433\n",
      "     87        \u001b[36m0.4708\u001b[0m       0.7344        \u001b[35m0.5274\u001b[0m  0.0401\n",
      "     88        \u001b[36m0.4704\u001b[0m       0.7344        \u001b[35m0.5271\u001b[0m  0.0691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     89        \u001b[36m0.4699\u001b[0m       0.7344        \u001b[35m0.5268\u001b[0m  0.0716\n",
      "     90        \u001b[36m0.4693\u001b[0m       0.7344        \u001b[35m0.5266\u001b[0m  0.0436\n",
      "     91        \u001b[36m0.4689\u001b[0m       0.7344        \u001b[35m0.5263\u001b[0m  0.0651\n",
      "     92        \u001b[36m0.4684\u001b[0m       0.7344        \u001b[35m0.5261\u001b[0m  0.0777\n",
      "     93        \u001b[36m0.4680\u001b[0m       0.7344        \u001b[35m0.5259\u001b[0m  0.0470\n",
      "     94        \u001b[36m0.4675\u001b[0m       0.7344        \u001b[35m0.5257\u001b[0m  0.0497\n",
      "     95        \u001b[36m0.4671\u001b[0m       0.7344        \u001b[35m0.5255\u001b[0m  0.0585\n",
      "     96        \u001b[36m0.4666\u001b[0m       0.7344        \u001b[35m0.5253\u001b[0m  0.0449\n",
      "     97        \u001b[36m0.4662\u001b[0m       0.7344        \u001b[35m0.5251\u001b[0m  0.0388\n",
      "     98        \u001b[36m0.4657\u001b[0m       0.7344        \u001b[35m0.5249\u001b[0m  0.0385\n",
      "     99        \u001b[36m0.4653\u001b[0m       0.7344        \u001b[35m0.5247\u001b[0m  0.0443\n",
      "    100        \u001b[36m0.4649\u001b[0m       0.7344        \u001b[35m0.5244\u001b[0m  0.0512\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7058\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7013\u001b[0m  0.0399\n",
      "      2        \u001b[36m0.6982\u001b[0m       0.5000        \u001b[35m0.6954\u001b[0m  0.0373\n",
      "      3        \u001b[36m0.6925\u001b[0m       0.5000        \u001b[35m0.6909\u001b[0m  0.0428\n",
      "      4        \u001b[36m0.6881\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6875\u001b[0m  0.0479\n",
      "      5        \u001b[36m0.6843\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6845\u001b[0m  0.0376\n",
      "      6        \u001b[36m0.6808\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6818\u001b[0m  0.0394\n",
      "      7        \u001b[36m0.6774\u001b[0m       0.6250        \u001b[35m0.6791\u001b[0m  0.0506\n",
      "      8        \u001b[36m0.6738\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6762\u001b[0m  0.0547\n",
      "      9        \u001b[36m0.6698\u001b[0m       0.6094        \u001b[35m0.6732\u001b[0m  0.0536\n",
      "     10        \u001b[36m0.6655\u001b[0m       0.6094        \u001b[35m0.6699\u001b[0m  0.0520\n",
      "     11        \u001b[36m0.6607\u001b[0m       0.6094        \u001b[35m0.6663\u001b[0m  0.0367\n",
      "     12        \u001b[36m0.6554\u001b[0m       0.6328        \u001b[35m0.6625\u001b[0m  0.0407\n",
      "     13        \u001b[36m0.6497\u001b[0m       0.6406        \u001b[35m0.6584\u001b[0m  0.0433\n",
      "     14        \u001b[36m0.6434\u001b[0m       0.6328        \u001b[35m0.6542\u001b[0m  0.0372\n",
      "     15        \u001b[36m0.6369\u001b[0m       0.6484        \u001b[35m0.6498\u001b[0m  0.0396\n",
      "     16        \u001b[36m0.6301\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6455\u001b[0m  0.0426\n",
      "     17        \u001b[36m0.6231\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6414\u001b[0m  0.0437\n",
      "     18        \u001b[36m0.6160\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6375\u001b[0m  0.0493\n",
      "     19        \u001b[36m0.6090\u001b[0m       0.7031        \u001b[35m0.6338\u001b[0m  0.0434\n",
      "     20        \u001b[36m0.6021\u001b[0m       0.6953        \u001b[35m0.6305\u001b[0m  0.0494\n",
      "     21        \u001b[36m0.5954\u001b[0m       0.6797        \u001b[35m0.6274\u001b[0m  0.0386\n",
      "     22        \u001b[36m0.5889\u001b[0m       0.6719        \u001b[35m0.6246\u001b[0m  0.0395\n",
      "     23        \u001b[36m0.5828\u001b[0m       0.6719        \u001b[35m0.6221\u001b[0m  0.0410\n",
      "     24        \u001b[36m0.5770\u001b[0m       0.6641        \u001b[35m0.6199\u001b[0m  0.0426\n",
      "     25        \u001b[36m0.5714\u001b[0m       0.6562        \u001b[35m0.6181\u001b[0m  0.0422\n",
      "     26        \u001b[36m0.5661\u001b[0m       0.6641        \u001b[35m0.6166\u001b[0m  0.0420\n",
      "     27        \u001b[36m0.5611\u001b[0m       0.6719        \u001b[35m0.6154\u001b[0m  0.0420\n",
      "     28        \u001b[36m0.5564\u001b[0m       0.6641        \u001b[35m0.6143\u001b[0m  0.0415\n",
      "     29        \u001b[36m0.5520\u001b[0m       0.6562        \u001b[35m0.6134\u001b[0m  0.0408\n",
      "     30        \u001b[36m0.5480\u001b[0m       0.6562        \u001b[35m0.6128\u001b[0m  0.0429\n",
      "     31        \u001b[36m0.5442\u001b[0m       0.6484        \u001b[35m0.6122\u001b[0m  0.0498\n",
      "     32        \u001b[36m0.5406\u001b[0m       0.6484        \u001b[35m0.6118\u001b[0m  0.0368\n",
      "     33        \u001b[36m0.5373\u001b[0m       0.6484        \u001b[35m0.6114\u001b[0m  0.0358\n",
      "     34        \u001b[36m0.5342\u001b[0m       0.6484        \u001b[35m0.6112\u001b[0m  0.0352\n",
      "     35        \u001b[36m0.5312\u001b[0m       0.6562        \u001b[35m0.6109\u001b[0m  0.0399\n",
      "     36        \u001b[36m0.5285\u001b[0m       0.6562        \u001b[35m0.6106\u001b[0m  0.0511\n",
      "     37        \u001b[36m0.5258\u001b[0m       0.6562        \u001b[35m0.6103\u001b[0m  0.0396\n",
      "     38        \u001b[36m0.5234\u001b[0m       0.6562        \u001b[35m0.6101\u001b[0m  0.0379\n",
      "     39        \u001b[36m0.5211\u001b[0m       0.6562        \u001b[35m0.6098\u001b[0m  0.0388\n",
      "     40        \u001b[36m0.5189\u001b[0m       0.6562        \u001b[35m0.6096\u001b[0m  0.0392\n",
      "     41        \u001b[36m0.5168\u001b[0m       0.6562        \u001b[35m0.6095\u001b[0m  0.0405\n",
      "     42        \u001b[36m0.5149\u001b[0m       0.6562        \u001b[35m0.6094\u001b[0m  0.0395\n",
      "     43        \u001b[36m0.5131\u001b[0m       0.6562        \u001b[35m0.6092\u001b[0m  0.0388\n",
      "     44        \u001b[36m0.5113\u001b[0m       0.6562        \u001b[35m0.6088\u001b[0m  0.0394\n",
      "     45        \u001b[36m0.5098\u001b[0m       0.6562        \u001b[35m0.6085\u001b[0m  0.0437\n",
      "     46        \u001b[36m0.5082\u001b[0m       0.6562        \u001b[35m0.6083\u001b[0m  0.0405\n",
      "     47        \u001b[36m0.5067\u001b[0m       0.6562        \u001b[35m0.6080\u001b[0m  0.0459\n",
      "     48        \u001b[36m0.5055\u001b[0m       0.6562        \u001b[35m0.6078\u001b[0m  0.0424\n",
      "     49        \u001b[36m0.5041\u001b[0m       0.6562        \u001b[35m0.6076\u001b[0m  0.0401\n",
      "     50        \u001b[36m0.5028\u001b[0m       0.6641        \u001b[35m0.6074\u001b[0m  0.0393\n",
      "     51        \u001b[36m0.5017\u001b[0m       0.6641        \u001b[35m0.6072\u001b[0m  0.0403\n",
      "     52        \u001b[36m0.5006\u001b[0m       0.6641        \u001b[35m0.6072\u001b[0m  0.0435\n",
      "     53        \u001b[36m0.4994\u001b[0m       0.6641        \u001b[35m0.6071\u001b[0m  0.0465\n",
      "     54        \u001b[36m0.4983\u001b[0m       0.6641        \u001b[35m0.6070\u001b[0m  0.0434\n",
      "     55        \u001b[36m0.4974\u001b[0m       0.6641        0.6071  0.0401\n",
      "     56        \u001b[36m0.4964\u001b[0m       0.6641        0.6071  0.0414\n",
      "     57        \u001b[36m0.4956\u001b[0m       0.6641        0.6071  0.0421\n",
      "     58        \u001b[36m0.4948\u001b[0m       0.6641        0.6072  0.0363\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6842\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6860\u001b[0m  0.0370\n",
      "      2        \u001b[36m0.6801\u001b[0m       0.5000        \u001b[35m0.6815\u001b[0m  0.0397\n",
      "      3        \u001b[36m0.6760\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6770\u001b[0m  0.0404\n",
      "      4        \u001b[36m0.6717\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6723\u001b[0m  0.0510\n",
      "      5        \u001b[36m0.6671\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6674\u001b[0m  0.0549\n",
      "      6        \u001b[36m0.6619\u001b[0m       0.7031        \u001b[35m0.6621\u001b[0m  0.0503\n",
      "      7        \u001b[36m0.6561\u001b[0m       0.7109        \u001b[35m0.6565\u001b[0m  0.0423\n",
      "      8        \u001b[36m0.6498\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6501\u001b[0m  0.0438\n",
      "      9        \u001b[36m0.6427\u001b[0m       0.7344        \u001b[35m0.6433\u001b[0m  0.0462\n",
      "     10        \u001b[36m0.6350\u001b[0m       0.7344        \u001b[35m0.6361\u001b[0m  0.0459\n",
      "     11        \u001b[36m0.6267\u001b[0m       0.7344        \u001b[35m0.6286\u001b[0m  0.0484\n",
      "     12        \u001b[36m0.6183\u001b[0m       0.7266        \u001b[35m0.6208\u001b[0m  0.0472\n",
      "     13        \u001b[36m0.6092\u001b[0m       0.7344        \u001b[35m0.6129\u001b[0m  0.0466\n",
      "     14        \u001b[36m0.5999\u001b[0m       0.7344        \u001b[35m0.6048\u001b[0m  0.0717\n",
      "     15        \u001b[36m0.5906\u001b[0m       0.7266        \u001b[35m0.5968\u001b[0m  0.0425\n",
      "     16        \u001b[36m0.5813\u001b[0m       0.7266        \u001b[35m0.5890\u001b[0m  0.0406\n",
      "     17        \u001b[36m0.5724\u001b[0m       0.7344        \u001b[35m0.5815\u001b[0m  0.0571\n",
      "     18        \u001b[36m0.5639\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5746\u001b[0m  0.0445\n",
      "     19        \u001b[36m0.5559\u001b[0m       0.7422        \u001b[35m0.5681\u001b[0m  0.0449\n",
      "     20        \u001b[36m0.5483\u001b[0m       0.7422        \u001b[35m0.5621\u001b[0m  0.0462\n",
      "     21        \u001b[36m0.5412\u001b[0m       0.7266        \u001b[35m0.5568\u001b[0m  0.0577\n",
      "     22        \u001b[36m0.5347\u001b[0m       0.7266        \u001b[35m0.5520\u001b[0m  0.0547\n",
      "     23        \u001b[36m0.5290\u001b[0m       0.7266        \u001b[35m0.5477\u001b[0m  0.0436\n",
      "     24        \u001b[36m0.5235\u001b[0m       0.7266        \u001b[35m0.5440\u001b[0m  0.0449\n",
      "     25        \u001b[36m0.5185\u001b[0m       0.7266        \u001b[35m0.5406\u001b[0m  0.0468\n",
      "     26        \u001b[36m0.5139\u001b[0m       0.7266        \u001b[35m0.5376\u001b[0m  0.0608\n",
      "     27        \u001b[36m0.5097\u001b[0m       0.7266        \u001b[35m0.5348\u001b[0m  0.0578\n",
      "     28        \u001b[36m0.5060\u001b[0m       0.7266        \u001b[35m0.5325\u001b[0m  0.0469\n",
      "     29        \u001b[36m0.5022\u001b[0m       0.7266        \u001b[35m0.5304\u001b[0m  0.0431\n",
      "     30        \u001b[36m0.4987\u001b[0m       0.7266        \u001b[35m0.5287\u001b[0m  0.0522\n",
      "     31        \u001b[36m0.4956\u001b[0m       0.7266        \u001b[35m0.5271\u001b[0m  0.0459\n",
      "     32        \u001b[36m0.4928\u001b[0m       0.7344        \u001b[35m0.5257\u001b[0m  0.0484\n",
      "     33        \u001b[36m0.4904\u001b[0m       0.7266        \u001b[35m0.5242\u001b[0m  0.0462\n",
      "     34        \u001b[36m0.4879\u001b[0m       0.7266        \u001b[35m0.5227\u001b[0m  0.0423\n",
      "     35        \u001b[36m0.4852\u001b[0m       0.7266        \u001b[35m0.5214\u001b[0m  0.0395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     36        \u001b[36m0.4827\u001b[0m       0.7266        \u001b[35m0.5201\u001b[0m  0.0349\n",
      "     37        \u001b[36m0.4808\u001b[0m       0.7344        \u001b[35m0.5191\u001b[0m  0.0342\n",
      "     38        \u001b[36m0.4787\u001b[0m       0.7422        \u001b[35m0.5180\u001b[0m  0.0349\n",
      "     39        \u001b[36m0.4768\u001b[0m       0.7422        \u001b[35m0.5170\u001b[0m  0.0452\n",
      "     40        \u001b[36m0.4752\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5155\u001b[0m  0.0412\n",
      "     41        \u001b[36m0.4730\u001b[0m       0.7500        \u001b[35m0.5144\u001b[0m  0.0380\n",
      "     42        \u001b[36m0.4713\u001b[0m       0.7500        \u001b[35m0.5134\u001b[0m  0.0376\n",
      "     43        \u001b[36m0.4695\u001b[0m       0.7500        \u001b[35m0.5124\u001b[0m  0.0389\n",
      "     44        \u001b[36m0.4679\u001b[0m       0.7422        \u001b[35m0.5116\u001b[0m  0.0428\n",
      "     45        \u001b[36m0.4663\u001b[0m       0.7422        \u001b[35m0.5107\u001b[0m  0.0360\n",
      "     46        \u001b[36m0.4646\u001b[0m       0.7422        \u001b[35m0.5096\u001b[0m  0.0404\n",
      "     47        \u001b[36m0.4631\u001b[0m       0.7344        \u001b[35m0.5086\u001b[0m  0.0427\n",
      "     48        \u001b[36m0.4616\u001b[0m       0.7344        \u001b[35m0.5076\u001b[0m  0.0402\n",
      "     49        \u001b[36m0.4598\u001b[0m       0.7266        \u001b[35m0.5065\u001b[0m  0.0370\n",
      "     50        \u001b[36m0.4579\u001b[0m       0.7266        \u001b[35m0.5056\u001b[0m  0.0382\n",
      "     51        \u001b[36m0.4563\u001b[0m       0.7344        \u001b[35m0.5049\u001b[0m  0.0371\n",
      "     52        \u001b[36m0.4546\u001b[0m       0.7344        \u001b[35m0.5042\u001b[0m  0.0360\n",
      "     53        \u001b[36m0.4530\u001b[0m       0.7344        \u001b[35m0.5037\u001b[0m  0.0377\n",
      "     54        \u001b[36m0.4515\u001b[0m       0.7344        \u001b[35m0.5032\u001b[0m  0.0483\n",
      "     55        \u001b[36m0.4501\u001b[0m       0.7344        \u001b[35m0.5028\u001b[0m  0.0470\n",
      "     56        \u001b[36m0.4488\u001b[0m       0.7344        \u001b[35m0.5025\u001b[0m  0.0392\n",
      "     57        \u001b[36m0.4475\u001b[0m       0.7344        \u001b[35m0.5021\u001b[0m  0.0375\n",
      "     58        \u001b[36m0.4462\u001b[0m       0.7422        \u001b[35m0.5018\u001b[0m  0.0372\n",
      "     59        \u001b[36m0.4449\u001b[0m       0.7422        \u001b[35m0.5015\u001b[0m  0.0492\n",
      "     60        \u001b[36m0.4436\u001b[0m       0.7422        \u001b[35m0.5013\u001b[0m  0.0461\n",
      "     61        \u001b[36m0.4424\u001b[0m       0.7422        \u001b[35m0.5011\u001b[0m  0.0473\n",
      "     62        \u001b[36m0.4412\u001b[0m       0.7422        \u001b[35m0.5010\u001b[0m  0.0467\n",
      "     63        \u001b[36m0.4399\u001b[0m       0.7500        \u001b[35m0.5009\u001b[0m  0.0419\n",
      "     64        \u001b[36m0.4388\u001b[0m       0.7500        \u001b[35m0.5007\u001b[0m  0.0399\n",
      "     65        \u001b[36m0.4376\u001b[0m       0.7500        \u001b[35m0.5006\u001b[0m  0.0398\n",
      "     66        \u001b[36m0.4365\u001b[0m       0.7500        \u001b[35m0.5006\u001b[0m  0.0382\n",
      "     67        \u001b[36m0.4355\u001b[0m       0.7500        0.5006  0.0376\n",
      "     68        \u001b[36m0.4344\u001b[0m       0.7500        0.5008  0.0492\n",
      "     69        \u001b[36m0.4332\u001b[0m       0.7422        0.5010  0.0427\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7942\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6855\u001b[0m  0.0378\n",
      "      2        \u001b[36m0.7213\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6761\u001b[0m  0.0464\n",
      "      3        0.7472       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6455\u001b[0m  0.0355\n",
      "      4        \u001b[36m0.7170\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5866\u001b[0m  0.0467\n",
      "      5        \u001b[36m0.6716\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5176\u001b[0m  0.0366\n",
      "      6        \u001b[36m0.6339\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4735\u001b[0m  0.0359\n",
      "      7        \u001b[36m0.6160\u001b[0m       \u001b[32m0.8203\u001b[0m        \u001b[35m0.4542\u001b[0m  0.0485\n",
      "      8        \u001b[36m0.6052\u001b[0m       0.8203        \u001b[35m0.4447\u001b[0m  0.0382\n",
      "      9        \u001b[36m0.5965\u001b[0m       0.8125        \u001b[35m0.4368\u001b[0m  0.0373\n",
      "     10        \u001b[36m0.5882\u001b[0m       0.8203        \u001b[35m0.4310\u001b[0m  0.0523\n",
      "     11        \u001b[36m0.5825\u001b[0m       0.8203        \u001b[35m0.4266\u001b[0m  0.0378\n",
      "     12        \u001b[36m0.5760\u001b[0m       0.8203        \u001b[35m0.4219\u001b[0m  0.0367\n",
      "     13        \u001b[36m0.5708\u001b[0m       0.8125        \u001b[35m0.4180\u001b[0m  0.0359\n",
      "     14        \u001b[36m0.5652\u001b[0m       0.8125        \u001b[35m0.4151\u001b[0m  0.0358\n",
      "     15        \u001b[36m0.5600\u001b[0m       0.8125        \u001b[35m0.4126\u001b[0m  0.0436\n",
      "     16        \u001b[36m0.5556\u001b[0m       0.8125        \u001b[35m0.4101\u001b[0m  0.0497\n",
      "     17        \u001b[36m0.5513\u001b[0m       0.8125        \u001b[35m0.4061\u001b[0m  0.0363\n",
      "     18        \u001b[36m0.5466\u001b[0m       0.8125        \u001b[35m0.4026\u001b[0m  0.0379\n",
      "     19        \u001b[36m0.5421\u001b[0m       0.8125        \u001b[35m0.3998\u001b[0m  0.0443\n",
      "     20        \u001b[36m0.5389\u001b[0m       0.8125        \u001b[35m0.3971\u001b[0m  0.0914\n",
      "     21        \u001b[36m0.5345\u001b[0m       0.8125        \u001b[35m0.3951\u001b[0m  0.0455\n",
      "     22        \u001b[36m0.5311\u001b[0m       \u001b[32m0.8281\u001b[0m        \u001b[35m0.3933\u001b[0m  0.0417\n",
      "     23        \u001b[36m0.5273\u001b[0m       0.8203        \u001b[35m0.3913\u001b[0m  0.0612\n",
      "     24        \u001b[36m0.5245\u001b[0m       0.8203        \u001b[35m0.3887\u001b[0m  0.0576\n",
      "     25        \u001b[36m0.5194\u001b[0m       0.8281        \u001b[35m0.3857\u001b[0m  0.0424\n",
      "     26        \u001b[36m0.5162\u001b[0m       0.8203        \u001b[35m0.3830\u001b[0m  0.0777\n",
      "     27        \u001b[36m0.5137\u001b[0m       0.8203        \u001b[35m0.3828\u001b[0m  0.0460\n",
      "     28        \u001b[36m0.5124\u001b[0m       0.8125        \u001b[35m0.3808\u001b[0m  0.0524\n",
      "     29        \u001b[36m0.5101\u001b[0m       0.8125        \u001b[35m0.3797\u001b[0m  0.0413\n",
      "     30        \u001b[36m0.5086\u001b[0m       0.8125        \u001b[35m0.3774\u001b[0m  0.0462\n",
      "     31        \u001b[36m0.5063\u001b[0m       0.8125        \u001b[35m0.3764\u001b[0m  0.0429\n",
      "     32        0.5088       0.8125        \u001b[35m0.3741\u001b[0m  0.0500\n",
      "     33        \u001b[36m0.5028\u001b[0m       0.8125        0.3745  0.0439\n",
      "     34        0.5065       0.8125        \u001b[35m0.3731\u001b[0m  0.0641\n",
      "     35        \u001b[36m0.5021\u001b[0m       0.8125        0.3735  0.0432\n",
      "     36        0.5030       0.8203        \u001b[35m0.3730\u001b[0m  0.0589\n",
      "     37        0.5023       0.8125        \u001b[35m0.3725\u001b[0m  0.0524\n",
      "     38        \u001b[36m0.5009\u001b[0m       0.8125        0.3726  0.0827\n",
      "     39        \u001b[36m0.5005\u001b[0m       0.8125        \u001b[35m0.3719\u001b[0m  0.0533\n",
      "     40        \u001b[36m0.4996\u001b[0m       0.8125        0.3719  0.0569\n",
      "     41        \u001b[36m0.4988\u001b[0m       0.8125        \u001b[35m0.3713\u001b[0m  0.0494\n",
      "     42        \u001b[36m0.4981\u001b[0m       0.8203        \u001b[35m0.3701\u001b[0m  0.0569\n",
      "     43        \u001b[36m0.4963\u001b[0m       0.8203        0.3703  0.0529\n",
      "     44        \u001b[36m0.4958\u001b[0m       0.8281        0.3701  0.0374\n",
      "     45        0.4962       0.8281        \u001b[35m0.3686\u001b[0m  0.0364\n",
      "     46        \u001b[36m0.4929\u001b[0m       0.8281        \u001b[35m0.3680\u001b[0m  0.0344\n",
      "     47        0.4946       0.8281        \u001b[35m0.3671\u001b[0m  0.0366\n",
      "     48        \u001b[36m0.4909\u001b[0m       0.8281        \u001b[35m0.3661\u001b[0m  0.0430\n",
      "     49        0.4934       0.8281        \u001b[35m0.3643\u001b[0m  0.0419\n",
      "     50        \u001b[36m0.4897\u001b[0m       0.8281        0.3652  0.0509\n",
      "     51        0.4919       0.8281        \u001b[35m0.3629\u001b[0m  0.0353\n",
      "     52        \u001b[36m0.4883\u001b[0m       0.8281        0.3645  0.0434\n",
      "     53        0.4903       \u001b[32m0.8359\u001b[0m        \u001b[35m0.3613\u001b[0m  0.0376\n",
      "     54        0.4890       0.8359        \u001b[35m0.3608\u001b[0m  0.0374\n",
      "     55        \u001b[36m0.4860\u001b[0m       0.8359        \u001b[35m0.3604\u001b[0m  0.0372\n",
      "     56        0.4886       \u001b[32m0.8438\u001b[0m        \u001b[35m0.3587\u001b[0m  0.0356\n",
      "     57        \u001b[36m0.4854\u001b[0m       0.8438        \u001b[35m0.3583\u001b[0m  0.0358\n",
      "     58        0.4864       0.8438        \u001b[35m0.3574\u001b[0m  0.0424\n",
      "     59        0.4855       \u001b[32m0.8516\u001b[0m        \u001b[35m0.3552\u001b[0m  0.0434\n",
      "     60        \u001b[36m0.4842\u001b[0m       0.8516        0.3557  0.0356\n",
      "     61        0.4847       0.8516        \u001b[35m0.3549\u001b[0m  0.0378\n",
      "     62        \u001b[36m0.4830\u001b[0m       0.8359        \u001b[35m0.3533\u001b[0m  0.0519\n",
      "     63        0.4832       0.8359        0.3547  0.0534\n",
      "     64        \u001b[36m0.4829\u001b[0m       0.8359        \u001b[35m0.3530\u001b[0m  0.0349\n",
      "     65        0.4830       0.8359        0.3537  0.0514\n",
      "     66        \u001b[36m0.4819\u001b[0m       0.8359        \u001b[35m0.3529\u001b[0m  0.0420\n",
      "     67        \u001b[36m0.4811\u001b[0m       0.8359        0.3539  0.0425\n",
      "     68        0.4814       0.8359        \u001b[35m0.3522\u001b[0m  0.0458\n",
      "     69        \u001b[36m0.4800\u001b[0m       0.8359        \u001b[35m0.3521\u001b[0m  0.0445\n",
      "     70        0.4806       0.8359        0.3521  0.0459\n",
      "     71        0.4803       0.8359        \u001b[35m0.3514\u001b[0m  0.0440\n",
      "     72        0.4801       0.8359        0.3518  0.0572\n",
      "     73        \u001b[36m0.4786\u001b[0m       0.8359        0.3515  0.0477\n",
      "     74        0.4801       0.8359        0.3519  0.0440\n",
      "     75        \u001b[36m0.4782\u001b[0m       0.8359        \u001b[35m0.3510\u001b[0m  0.0464\n",
      "     76        0.4790       0.8359        0.3525  0.0577\n",
      "     77        \u001b[36m0.4782\u001b[0m       0.8359        0.3513  0.0409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     78        \u001b[36m0.4778\u001b[0m       0.8359        0.3525  0.0466\n",
      "     79        \u001b[36m0.4778\u001b[0m       0.8359        0.3524  0.0402\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7896\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6397\u001b[0m  0.0453\n",
      "      2        \u001b[36m0.7090\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5978\u001b[0m  0.0404\n",
      "      3        \u001b[36m0.6568\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5515\u001b[0m  0.0533\n",
      "      4        \u001b[36m0.6167\u001b[0m       0.7344        \u001b[35m0.5332\u001b[0m  0.0394\n",
      "      5        \u001b[36m0.6006\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5232\u001b[0m  0.0656\n",
      "      6        \u001b[36m0.5887\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5165\u001b[0m  0.0641\n",
      "      7        \u001b[36m0.5752\u001b[0m       0.7422        \u001b[35m0.5128\u001b[0m  0.0606\n",
      "      8        \u001b[36m0.5690\u001b[0m       0.7500        \u001b[35m0.5092\u001b[0m  0.0543\n",
      "      9        \u001b[36m0.5598\u001b[0m       0.7578        \u001b[35m0.5070\u001b[0m  0.0659\n",
      "     10        \u001b[36m0.5550\u001b[0m       0.7578        \u001b[35m0.5062\u001b[0m  0.0841\n",
      "     11        \u001b[36m0.5479\u001b[0m       0.7578        \u001b[35m0.5047\u001b[0m  0.0725\n",
      "     12        \u001b[36m0.5439\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5042\u001b[0m  0.0891\n",
      "     13        \u001b[36m0.5409\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.5041\u001b[0m  0.0787\n",
      "     14        \u001b[36m0.5373\u001b[0m       0.7812        0.5048  0.0859\n",
      "     15        \u001b[36m0.5336\u001b[0m       0.7812        0.5052  0.0419\n",
      "     16        \u001b[36m0.5314\u001b[0m       0.7812        0.5057  0.0464\n",
      "     17        \u001b[36m0.5307\u001b[0m       0.7812        0.5055  0.0574\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7360\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6966\u001b[0m  0.0509\n",
      "      2        \u001b[36m0.7065\u001b[0m       0.5000        \u001b[35m0.6930\u001b[0m  0.0641\n",
      "      3        0.7153       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6873\u001b[0m  0.0573\n",
      "      4        \u001b[36m0.7043\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6671\u001b[0m  0.0435\n",
      "      5        \u001b[36m0.6742\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6242\u001b[0m  0.0752\n",
      "      6        \u001b[36m0.6252\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5793\u001b[0m  0.0756\n",
      "      7        \u001b[36m0.5897\u001b[0m       0.7266        \u001b[35m0.5523\u001b[0m  0.0909\n",
      "      8        \u001b[36m0.5710\u001b[0m       0.7188        \u001b[35m0.5388\u001b[0m  0.0897\n",
      "      9        \u001b[36m0.5640\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5312\u001b[0m  0.0878\n",
      "     10        \u001b[36m0.5584\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5259\u001b[0m  0.0412\n",
      "     11        \u001b[36m0.5558\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5217\u001b[0m  0.0456\n",
      "     12        \u001b[36m0.5513\u001b[0m       0.7578        \u001b[35m0.5182\u001b[0m  0.0583\n",
      "     13        \u001b[36m0.5468\u001b[0m       0.7578        \u001b[35m0.5158\u001b[0m  0.0538\n",
      "     14        \u001b[36m0.5444\u001b[0m       0.7500        \u001b[35m0.5127\u001b[0m  0.0555\n",
      "     15        \u001b[36m0.5368\u001b[0m       0.7422        \u001b[35m0.5095\u001b[0m  0.0422\n",
      "     16        \u001b[36m0.5325\u001b[0m       0.7500        \u001b[35m0.5080\u001b[0m  0.0657\n",
      "     17        \u001b[36m0.5282\u001b[0m       0.7500        \u001b[35m0.5074\u001b[0m  0.0507\n",
      "     18        \u001b[36m0.5222\u001b[0m       0.7500        0.5084  0.0654\n",
      "     19        \u001b[36m0.5178\u001b[0m       0.7422        0.5104  0.0399\n",
      "     20        \u001b[36m0.5146\u001b[0m       0.7422        0.5126  0.0429\n",
      "     21        \u001b[36m0.5109\u001b[0m       0.7422        0.5153  0.0542\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7197\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6795\u001b[0m  0.0507\n",
      "      2        \u001b[36m0.6896\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6548\u001b[0m  0.0433\n",
      "      3        \u001b[36m0.6546\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5905\u001b[0m  0.0572\n",
      "      4        \u001b[36m0.5843\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5393\u001b[0m  0.0552\n",
      "      5        \u001b[36m0.5438\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5215\u001b[0m  0.0476\n",
      "      6        \u001b[36m0.5254\u001b[0m       0.7500        \u001b[35m0.5174\u001b[0m  0.0648\n",
      "      7        \u001b[36m0.5103\u001b[0m       0.7344        0.5203  0.0518\n",
      "      8        \u001b[36m0.5027\u001b[0m       0.7344        0.5248  0.0553\n",
      "      9        \u001b[36m0.4951\u001b[0m       0.7422        0.5306  0.0560\n",
      "     10        \u001b[36m0.4902\u001b[0m       0.7266        0.5337  0.0470\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7488\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6793\u001b[0m  0.0402\n",
      "      2        \u001b[36m0.6959\u001b[0m       0.6328        \u001b[35m0.6612\u001b[0m  0.0517\n",
      "      3        \u001b[36m0.6886\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6214\u001b[0m  0.0506\n",
      "      4        \u001b[36m0.6325\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.5710\u001b[0m  0.0583\n",
      "      5        \u001b[36m0.5767\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5481\u001b[0m  0.0359\n",
      "      6        \u001b[36m0.5478\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5383\u001b[0m  0.0354\n",
      "      7        \u001b[36m0.5286\u001b[0m       0.7656        \u001b[35m0.5344\u001b[0m  0.0360\n",
      "      8        \u001b[36m0.5060\u001b[0m       0.7578        \u001b[35m0.5328\u001b[0m  0.0356\n",
      "      9        \u001b[36m0.4985\u001b[0m       0.7578        \u001b[35m0.5317\u001b[0m  0.0406\n",
      "     10        \u001b[36m0.4854\u001b[0m       0.7656        0.5372  0.0454\n",
      "     11        \u001b[36m0.4815\u001b[0m       0.7500        0.5410  0.0477\n",
      "     12        \u001b[36m0.4789\u001b[0m       0.7500        0.5443  0.0416\n",
      "     13        \u001b[36m0.4726\u001b[0m       0.7500        0.5469  0.0438\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6940\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.5056\u001b[0m  0.0398\n",
      "      2        2.1505       0.5000        \u001b[35m2.2410\u001b[0m  0.0445\n",
      "      3        2.1269       0.5000        \u001b[35m2.1919\u001b[0m  0.0481\n",
      "      4        2.0759       0.5000        2.2137  0.0508\n",
      "      5        2.0882       0.5000        2.2108  0.0716\n",
      "      6        2.0874       0.5000        2.2107  0.0457\n",
      "      7        2.0872       0.5000        2.2108  0.0446\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6840\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.9982\u001b[0m  0.0359\n",
      "      2        2.2699       0.5000        \u001b[35m2.0390\u001b[0m  0.0386\n",
      "      3        2.3372       0.5000        \u001b[35m1.9505\u001b[0m  0.0492\n",
      "      4        2.2483       0.5000        1.9861  0.0418\n",
      "      5        2.2684       0.5000        1.9798  0.0471\n",
      "      6        2.2662       0.5000        1.9802  0.0456\n",
      "      7        2.2661       0.5000        1.9803  0.0512\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8363\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.1744\u001b[0m  0.0422\n",
      "      2        1.0125       0.5000        1.4352  0.0446\n",
      "      3        1.1676       0.5000        1.4265  0.0447\n",
      "      4        1.1988       0.5000        1.4079  0.0451\n",
      "      5        1.2009       0.5000        1.4026  0.0396\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7078\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.9924\u001b[0m  0.0387\n",
      "      2        1.1648       0.5000        1.0708  0.0450\n",
      "      3        1.0399       0.5000        1.2499  0.0402\n",
      "      4        1.0582       0.5000        1.3052  0.0494\n",
      "      5        1.0767       0.5000        1.3084  0.0520\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5583\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.5968\u001b[0m  0.0446\n",
      "      2        0.8966       0.5000        3.2092  0.0461\n",
      "      3        1.1957       0.5000        2.0185  0.0678\n",
      "      4        1.5524       0.5000        1.9533  0.0450\n",
      "      5        1.6166       0.5000        1.8962  0.0528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4436\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.5463\u001b[0m  0.0212\n",
      "      2        0.6310       0.5000        \u001b[35m1.4772\u001b[0m  0.0225\n",
      "      3        0.6343       0.5000        \u001b[35m1.3921\u001b[0m  0.0282\n",
      "      4        0.6048       0.5000        \u001b[35m1.3779\u001b[0m  0.0328\n",
      "      5        0.5807       0.5000        \u001b[35m1.3557\u001b[0m  0.0287\n",
      "      6        0.5745       0.5000        \u001b[35m1.2706\u001b[0m  0.0302\n",
      "      7        0.5929       0.5000        1.3319  0.0301\n",
      "      8        0.5784       0.5000        1.3264  0.0305\n",
      "      9        0.5802       0.5000        1.3816  0.0322\n",
      "     10        0.5775       0.5000        1.3228  0.0406\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.3843\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.9120\u001b[0m  0.0226\n",
      "      2        0.5370       0.5000        \u001b[35m1.6656\u001b[0m  0.0251\n",
      "      3        0.5245       0.5000        \u001b[35m1.5744\u001b[0m  0.0382\n",
      "      4        0.5031       0.5000        1.6503  0.0293\n",
      "      5        0.4786       0.5000        1.8429  0.0298\n",
      "      6        0.4841       0.5000        \u001b[35m1.5119\u001b[0m  0.0318\n",
      "      7        0.5104       0.5000        \u001b[35m1.3771\u001b[0m  0.0251\n",
      "      8        0.5102       0.5000        1.4923  0.0263\n",
      "      9        0.4996       0.5000        1.5278  0.0385\n",
      "     10        0.4738       0.5000        1.4174  0.0286\n",
      "     11        0.4543       0.5000        \u001b[35m1.3006\u001b[0m  0.0241\n",
      "     12        0.4597       0.5000        \u001b[35m1.2808\u001b[0m  0.0302\n",
      "     13        0.4653       0.5000        1.3596  0.0417\n",
      "     14        0.4635       \u001b[32m0.5156\u001b[0m        \u001b[35m1.2755\u001b[0m  0.0293\n",
      "     15        0.4948       0.5000        \u001b[35m1.2239\u001b[0m  0.0259\n",
      "     16        0.4577       0.5078        \u001b[35m1.2060\u001b[0m  0.0284\n",
      "     17        0.4578       \u001b[32m0.5391\u001b[0m        1.2669  0.0297\n",
      "     18        0.4609       \u001b[32m0.5625\u001b[0m        \u001b[35m1.1253\u001b[0m  0.0280\n",
      "     19        0.4686       0.5625        \u001b[35m1.1253\u001b[0m  0.0294\n",
      "     20        0.4728       \u001b[32m0.5703\u001b[0m        \u001b[35m1.0882\u001b[0m  0.0293\n",
      "     21        0.4538       \u001b[32m0.5859\u001b[0m        1.1723  0.0291\n",
      "     22        0.4506       0.5625        1.1359  0.0289\n",
      "     23        0.4742       \u001b[32m0.6016\u001b[0m        \u001b[35m1.0382\u001b[0m  0.0293\n",
      "     24        0.4528       0.5859        1.1238  0.0294\n",
      "     25        0.4718       0.6016        \u001b[35m1.0168\u001b[0m  0.0295\n",
      "     26        0.4598       0.5938        1.0336  0.0283\n",
      "     27        0.4540       \u001b[32m0.6172\u001b[0m        1.0672  0.0246\n",
      "     28        0.4649       0.5938        1.1106  0.0330\n",
      "     29        0.4689       0.6094        \u001b[35m0.9887\u001b[0m  0.0348\n",
      "     30        0.4718       \u001b[32m0.6250\u001b[0m        \u001b[35m0.9858\u001b[0m  0.0293\n",
      "     31        0.4541       \u001b[32m0.6406\u001b[0m        1.0227  0.0252\n",
      "     32        0.4532       \u001b[32m0.6484\u001b[0m        0.9903  0.0301\n",
      "     33        0.4524       \u001b[32m0.6641\u001b[0m        \u001b[35m0.9367\u001b[0m  0.0261\n",
      "     34        0.4537       0.6484        0.9930  0.0291\n",
      "     35        0.4771       0.6406        0.9661  0.0298\n",
      "     36        0.4650       0.6406        0.9581  0.0335\n",
      "     37        0.4713       0.6484        0.9585  0.0305\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5740\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.3299\u001b[0m  0.0349\n",
      "      2        0.6737       0.5000        \u001b[35m1.3249\u001b[0m  0.0317\n",
      "      3        0.6192       0.5000        1.3637  0.0300\n",
      "      4        0.6134       0.5000        \u001b[35m1.2034\u001b[0m  0.0374\n",
      "      5        \u001b[36m0.5735\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m1.0957\u001b[0m  0.0293\n",
      "      6        0.5827       0.5469        \u001b[35m1.0892\u001b[0m  0.0324\n",
      "      7        0.6084       0.5000        1.2061  0.0371\n",
      "      8        0.5995       \u001b[32m0.5859\u001b[0m        \u001b[35m1.0835\u001b[0m  0.0425\n",
      "      9        0.5957       0.5078        1.1408  0.0363\n",
      "     10        0.6227       0.5391        \u001b[35m1.0211\u001b[0m  0.0385\n",
      "     11        \u001b[36m0.5595\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.8985\u001b[0m  0.0408\n",
      "     12        0.5681       0.6094        0.9581  0.0326\n",
      "     13        0.5777       0.5391        1.0890  0.0362\n",
      "     14        0.5922       0.5469        1.0305  0.0429\n",
      "     15        0.5912       0.5469        0.9962  0.0358\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5945\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.1389\u001b[0m  0.0267\n",
      "      2        0.6625       0.5000        1.1663  0.0338\n",
      "      3        0.6213       0.5000        \u001b[35m1.1239\u001b[0m  0.0356\n",
      "      4        0.6261       0.5000        \u001b[35m1.1017\u001b[0m  0.0328\n",
      "      5        \u001b[36m0.5794\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m1.0419\u001b[0m  0.0324\n",
      "      6        0.6188       \u001b[32m0.5703\u001b[0m        \u001b[35m0.9658\u001b[0m  0.0314\n",
      "      7        0.6094       0.5703        0.9779  0.0373\n",
      "      8        0.5963       0.5625        0.9812  0.0368\n",
      "      9        0.5987       0.5703        0.9823  0.0370\n",
      "     10        0.5922       \u001b[32m0.6172\u001b[0m        \u001b[35m0.8881\u001b[0m  0.0373\n",
      "     11        0.5999       0.5781        0.9393  0.0525\n",
      "     12        \u001b[36m0.5783\u001b[0m       0.6016        0.9177  0.0370\n",
      "     13        \u001b[36m0.5694\u001b[0m       0.5625        0.9523  0.0372\n",
      "     14        0.5707       0.5938        \u001b[35m0.8783\u001b[0m  0.0270\n",
      "     15        \u001b[36m0.5542\u001b[0m       0.5781        0.9019  0.0362\n",
      "     16        0.5657       0.5703        0.9765  0.0410\n",
      "     17        0.5705       0.5703        0.9120  0.0428\n",
      "     18        0.5715       0.6016        \u001b[35m0.8743\u001b[0m  0.0313\n",
      "     19        0.5871       0.5625        0.9276  0.0324\n",
      "     20        0.5770       0.5547        0.9913  0.0365\n",
      "     21        0.5785       0.5859        \u001b[35m0.8595\u001b[0m  0.0306\n",
      "     22        0.5569       0.5469        0.9991  0.0366\n",
      "     23        0.5798       0.5625        0.9638  0.0301\n",
      "     24        0.5651       0.6172        0.8736  0.0228\n",
      "     25        0.5686       0.5703        0.9216  0.0225\n",
      "     26        0.5577       \u001b[32m0.6406\u001b[0m        \u001b[35m0.8246\u001b[0m  0.0231\n",
      "     27        0.5718       0.5703        0.9181  0.0268\n",
      "     28        \u001b[36m0.5424\u001b[0m       0.6016        0.9125  0.0327\n",
      "     29        0.5661       0.5625        1.0037  0.0320\n",
      "     30        0.6036       0.6172        0.8308  0.0324\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5132\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.5243\u001b[0m  0.0277\n",
      "      2        0.7056       0.5000        \u001b[35m1.2868\u001b[0m  0.0232\n",
      "      3        0.6070       0.5000        \u001b[35m1.1670\u001b[0m  0.0247\n",
      "      4        0.5863       0.5000        1.1696  0.0344\n",
      "      5        0.5908       0.5000        \u001b[35m1.1502\u001b[0m  0.0282\n",
      "      6        0.5880       0.5000        \u001b[35m1.0924\u001b[0m  0.0318\n",
      "      7        0.5860       \u001b[32m0.5156\u001b[0m        \u001b[35m1.0576\u001b[0m  0.0319\n",
      "      8        0.5509       0.5000        1.0943  0.0295\n",
      "      9        0.5357       \u001b[32m0.5547\u001b[0m        1.0712  0.0247\n",
      "     10        0.5289       0.5234        1.0918  0.0419\n",
      "     11        0.5329       0.5000        1.1322  0.0377\n",
      "     12        \u001b[36m0.5021\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m1.0556\u001b[0m  0.0302\n",
      "     13        0.5427       0.5078        1.1541  0.0242\n",
      "     14        0.5376       0.5391        1.1095  0.0220\n",
      "     15        0.5237       0.5547        1.2026  0.0219\n",
      "     16        0.5349       0.5078        1.2010  0.0370\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8716\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8554\u001b[0m  0.0284\n",
      "      2        1.1862       0.5000        \u001b[35m0.6797\u001b[0m  0.0238\n",
      "      3        \u001b[36m0.8083\u001b[0m       0.5000        0.9069  0.0456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        1.1758       0.5000        0.7360  0.0383\n",
      "      5        0.9972       0.5000        0.6926  0.0264\n",
      "      6        0.8283       0.5000        0.7788  0.0278\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0356\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7837\u001b[0m  0.0252\n",
      "      2        1.2024       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6396\u001b[0m  0.0225\n",
      "      3        \u001b[36m0.7925\u001b[0m       0.5547        0.7874  0.0361\n",
      "      4        1.1916       0.7188        \u001b[35m0.5643\u001b[0m  0.0244\n",
      "      5        \u001b[36m0.6304\u001b[0m       0.7031        0.5893  0.0349\n",
      "      6        0.7806       0.7188        \u001b[35m0.5581\u001b[0m  0.0342\n",
      "      7        0.6924       0.7188        0.5606  0.0415\n",
      "      8        0.6603       0.7188        0.5766  0.0310\n",
      "      9        0.6927       0.7266        \u001b[35m0.5580\u001b[0m  0.0316\n",
      "     10        0.6398       0.7109        \u001b[35m0.5460\u001b[0m  0.0369\n",
      "     11        0.6467       0.7266        0.5576  0.0350\n",
      "     12        0.6376       0.7188        \u001b[35m0.5411\u001b[0m  0.0332\n",
      "     13        \u001b[36m0.6212\u001b[0m       \u001b[32m0.7422\u001b[0m        0.5468  0.0336\n",
      "     14        0.6254       0.7344        \u001b[35m0.5388\u001b[0m  0.0355\n",
      "     15        \u001b[36m0.6124\u001b[0m       0.7266        \u001b[35m0.5316\u001b[0m  0.0256\n",
      "     16        \u001b[36m0.6075\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5297\u001b[0m  0.0321\n",
      "     17        0.6166       \u001b[32m0.7656\u001b[0m        0.5312  0.0303\n",
      "     18        \u001b[36m0.5943\u001b[0m       0.7578        \u001b[35m0.5281\u001b[0m  0.0285\n",
      "     19        \u001b[36m0.5919\u001b[0m       0.7578        \u001b[35m0.5130\u001b[0m  0.0375\n",
      "     20        \u001b[36m0.5798\u001b[0m       0.7656        \u001b[35m0.5022\u001b[0m  0.0391\n",
      "     21        \u001b[36m0.5680\u001b[0m       0.7578        0.5050  0.0308\n",
      "     22        0.5854       \u001b[32m0.7734\u001b[0m        0.5174  0.0320\n",
      "     23        \u001b[36m0.5656\u001b[0m       0.7578        0.5040  0.0335\n",
      "     24        \u001b[36m0.5633\u001b[0m       0.7578        0.5158  0.0307\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8258\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7057\u001b[0m  0.0238\n",
      "      2        0.8922       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6659\u001b[0m  0.0233\n",
      "      3        \u001b[36m0.7009\u001b[0m       \u001b[32m0.7109\u001b[0m        0.6661  0.0305\n",
      "      4        0.7873       0.6875        \u001b[35m0.6017\u001b[0m  0.0364\n",
      "      5        0.7901       0.6562        \u001b[35m0.5513\u001b[0m  0.0328\n",
      "      6        \u001b[36m0.6114\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5298\u001b[0m  0.0319\n",
      "      7        0.6551       0.7422        0.5393  0.0294\n",
      "      8        0.6135       0.7422        \u001b[35m0.5234\u001b[0m  0.0333\n",
      "      9        \u001b[36m0.5836\u001b[0m       0.7344        0.5337  0.0290\n",
      "     10        0.5943       0.7344        0.5369  0.0353\n",
      "     11        0.5838       0.7344        0.5284  0.0298\n",
      "     12        \u001b[36m0.5721\u001b[0m       0.7344        0.5346  0.0315\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7428\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8344\u001b[0m  0.0254\n",
      "      2        0.9052       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6352\u001b[0m  0.0336\n",
      "      3        \u001b[36m0.6406\u001b[0m       0.6797        \u001b[35m0.5998\u001b[0m  0.0485\n",
      "      4        0.7090       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5392\u001b[0m  0.0477\n",
      "      5        0.6516       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5198\u001b[0m  0.0351\n",
      "      6        \u001b[36m0.5735\u001b[0m       0.7422        0.5274  0.0330\n",
      "      7        0.5872       0.7422        0.5283  0.0320\n",
      "      8        0.5877       0.7344        0.5267  0.0315\n",
      "      9        0.5801       \u001b[32m0.7500\u001b[0m        0.5346  0.0301\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8043\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8413\u001b[0m  0.0235\n",
      "      2        1.0124       \u001b[32m0.7500\u001b[0m        \u001b[35m0.7361\u001b[0m  0.0251\n",
      "      3        0.8698       0.7500        \u001b[35m0.6426\u001b[0m  0.0391\n",
      "      4        0.8315       0.6719        \u001b[35m0.5916\u001b[0m  0.0387\n",
      "      5        \u001b[36m0.7334\u001b[0m       0.7344        0.6348  0.0355\n",
      "      6        \u001b[36m0.6085\u001b[0m       0.7500        \u001b[35m0.5198\u001b[0m  0.0387\n",
      "      7        \u001b[36m0.5415\u001b[0m       0.7344        0.5478  0.0298\n",
      "      8        0.5750       0.7422        0.5360  0.0227\n",
      "      9        \u001b[36m0.5370\u001b[0m       0.7422        0.5286  0.0233\n",
      "     10        \u001b[36m0.5301\u001b[0m       0.7344        0.5329  0.0254\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7097\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6944\u001b[0m  0.0578\n",
      "      2        \u001b[36m0.7064\u001b[0m       0.5000        \u001b[35m0.6917\u001b[0m  0.0276\n",
      "      3        \u001b[36m0.7011\u001b[0m       0.5000        \u001b[35m0.6896\u001b[0m  0.0404\n",
      "      4        \u001b[36m0.7004\u001b[0m       0.5000        \u001b[35m0.6880\u001b[0m  0.1276\n",
      "      5        \u001b[36m0.6994\u001b[0m       0.5000        \u001b[35m0.6867\u001b[0m  0.0215\n",
      "      6        \u001b[36m0.6951\u001b[0m       0.5000        \u001b[35m0.6855\u001b[0m  0.0202\n",
      "      7        \u001b[36m0.6934\u001b[0m       0.5000        \u001b[35m0.6844\u001b[0m  0.0266\n",
      "      8        0.6995       0.5000        \u001b[35m0.6835\u001b[0m  0.0248\n",
      "      9        \u001b[36m0.6867\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6824\u001b[0m  0.0280\n",
      "     10        0.6915       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6814\u001b[0m  0.0162\n",
      "     11        0.6898       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6804\u001b[0m  0.0313\n",
      "     12        0.6942       \u001b[32m0.7656\u001b[0m        \u001b[35m0.6792\u001b[0m  0.0277\n",
      "     13        0.6972       \u001b[32m0.7969\u001b[0m        \u001b[35m0.6784\u001b[0m  0.0237\n",
      "     14        0.6953       \u001b[32m0.8125\u001b[0m        \u001b[35m0.6775\u001b[0m  0.0172\n",
      "     15        0.6957       0.8125        \u001b[35m0.6767\u001b[0m  0.0180\n",
      "     16        0.6881       0.8047        \u001b[35m0.6756\u001b[0m  0.0167\n",
      "     17        0.6906       0.7969        \u001b[35m0.6749\u001b[0m  0.0164\n",
      "     18        \u001b[36m0.6863\u001b[0m       0.7969        \u001b[35m0.6736\u001b[0m  0.0191\n",
      "     19        \u001b[36m0.6857\u001b[0m       0.7969        \u001b[35m0.6722\u001b[0m  0.0156\n",
      "     20        0.6900       0.7891        \u001b[35m0.6709\u001b[0m  0.0281\n",
      "     21        0.6911       0.7891        \u001b[35m0.6700\u001b[0m  0.0269\n",
      "     22        0.6906       0.7734        \u001b[35m0.6694\u001b[0m  0.0192\n",
      "     23        \u001b[36m0.6855\u001b[0m       0.7812        \u001b[35m0.6680\u001b[0m  0.0180\n",
      "     24        \u001b[36m0.6825\u001b[0m       0.7891        \u001b[35m0.6662\u001b[0m  0.0192\n",
      "     25        \u001b[36m0.6796\u001b[0m       0.7578        \u001b[35m0.6646\u001b[0m  0.0202\n",
      "     26        0.6843       0.7969        \u001b[35m0.6633\u001b[0m  0.0188\n",
      "     27        0.6842       0.8125        \u001b[35m0.6616\u001b[0m  0.0185\n",
      "     28        0.6860       0.7891        \u001b[35m0.6601\u001b[0m  0.0163\n",
      "     29        0.6848       0.7891        \u001b[35m0.6588\u001b[0m  0.0176\n",
      "     30        0.6833       0.8047        \u001b[35m0.6575\u001b[0m  0.0385\n",
      "     31        \u001b[36m0.6795\u001b[0m       0.8125        \u001b[35m0.6556\u001b[0m  0.0153\n",
      "     32        \u001b[36m0.6699\u001b[0m       0.7969        \u001b[35m0.6531\u001b[0m  0.0298\n",
      "     33        0.6703       0.7969        \u001b[35m0.6512\u001b[0m  0.0239\n",
      "     34        0.6753       0.8047        \u001b[35m0.6490\u001b[0m  0.0322\n",
      "     35        0.6713       0.8047        \u001b[35m0.6473\u001b[0m  0.0274\n",
      "     36        0.6760       0.7969        \u001b[35m0.6457\u001b[0m  0.0274\n",
      "     37        0.6815       0.7969        \u001b[35m0.6438\u001b[0m  0.0376\n",
      "     38        0.6729       0.7969        \u001b[35m0.6424\u001b[0m  0.0306\n",
      "     39        0.6742       0.7969        \u001b[35m0.6409\u001b[0m  0.0291\n",
      "     40        \u001b[36m0.6658\u001b[0m       0.7969        \u001b[35m0.6382\u001b[0m  0.0307\n",
      "     41        0.6788       0.7969        \u001b[35m0.6369\u001b[0m  0.0196\n",
      "     42        \u001b[36m0.6647\u001b[0m       0.7969        \u001b[35m0.6347\u001b[0m  0.0217\n",
      "     43        0.6779       0.7891        \u001b[35m0.6337\u001b[0m  0.0227\n",
      "     44        0.6680       0.7891        \u001b[35m0.6320\u001b[0m  0.0314\n",
      "     45        0.6744       0.7891        \u001b[35m0.6312\u001b[0m  0.0304\n",
      "     46        \u001b[36m0.6600\u001b[0m       0.7812        \u001b[35m0.6292\u001b[0m  0.0151\n",
      "     47        \u001b[36m0.6532\u001b[0m       0.7812        \u001b[35m0.6263\u001b[0m  0.0149\n",
      "     48        0.6743       0.7891        \u001b[35m0.6248\u001b[0m  0.0173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     49        0.6620       0.7891        \u001b[35m0.6229\u001b[0m  0.0171\n",
      "     50        0.6668       0.7891        \u001b[35m0.6212\u001b[0m  0.0194\n",
      "     51        0.6648       0.7812        \u001b[35m0.6193\u001b[0m  0.0254\n",
      "     52        0.6642       0.7812        \u001b[35m0.6174\u001b[0m  0.0203\n",
      "     53        0.6635       0.7812        \u001b[35m0.6155\u001b[0m  0.0193\n",
      "     54        \u001b[36m0.6471\u001b[0m       0.7812        \u001b[35m0.6130\u001b[0m  0.0191\n",
      "     55        \u001b[36m0.6396\u001b[0m       0.7891        \u001b[35m0.6099\u001b[0m  0.0450\n",
      "     56        0.6436       0.7891        \u001b[35m0.6072\u001b[0m  0.0209\n",
      "     57        0.6569       0.7891        \u001b[35m0.6058\u001b[0m  0.0356\n",
      "     58        0.6713       0.7891        \u001b[35m0.6050\u001b[0m  0.0241\n",
      "     59        0.6604       0.7891        \u001b[35m0.6050\u001b[0m  0.0242\n",
      "     60        0.6658       0.7812        \u001b[35m0.6043\u001b[0m  0.0273\n",
      "     61        0.6671       0.7812        \u001b[35m0.6042\u001b[0m  0.0281\n",
      "     62        0.6497       0.7734        \u001b[35m0.6024\u001b[0m  0.0166\n",
      "     63        0.6661       0.7734        \u001b[35m0.6022\u001b[0m  0.0302\n",
      "     64        0.6562       0.7734        \u001b[35m0.6014\u001b[0m  0.0198\n",
      "     65        0.6457       0.7734        \u001b[35m0.5994\u001b[0m  0.0220\n",
      "     66        0.6640       0.7734        \u001b[35m0.5986\u001b[0m  0.0275\n",
      "     67        0.6600       0.7734        \u001b[35m0.5982\u001b[0m  0.0251\n",
      "     68        0.6506       0.7734        \u001b[35m0.5967\u001b[0m  0.0248\n",
      "     69        0.6708       0.7656        \u001b[35m0.5965\u001b[0m  0.0237\n",
      "     70        0.6545       0.7734        \u001b[35m0.5961\u001b[0m  0.0287\n",
      "     71        0.6492       0.7656        \u001b[35m0.5943\u001b[0m  0.0260\n",
      "     72        0.6574       0.7656        \u001b[35m0.5937\u001b[0m  0.0292\n",
      "     73        \u001b[36m0.6394\u001b[0m       0.7656        \u001b[35m0.5918\u001b[0m  0.0290\n",
      "     74        \u001b[36m0.6386\u001b[0m       0.7656        \u001b[35m0.5897\u001b[0m  0.0172\n",
      "     75        0.6698       0.7656        \u001b[35m0.5897\u001b[0m  0.0180\n",
      "     76        0.6392       0.7656        \u001b[35m0.5886\u001b[0m  0.0182\n",
      "     77        0.6487       0.7656        \u001b[35m0.5874\u001b[0m  0.0182\n",
      "     78        0.6616       0.7734        0.5874  0.0152\n",
      "     79        0.6527       0.7734        \u001b[35m0.5865\u001b[0m  0.0266\n",
      "     80        0.6584       0.7734        0.5870  0.0231\n",
      "     81        0.6444       0.7734        \u001b[35m0.5861\u001b[0m  0.0226\n",
      "     82        \u001b[36m0.6224\u001b[0m       0.7734        \u001b[35m0.5829\u001b[0m  0.0244\n",
      "     83        0.6658       0.7734        \u001b[35m0.5827\u001b[0m  0.0199\n",
      "     84        0.6638       0.7734        0.5840  0.0349\n",
      "     85        0.6434       0.7734        \u001b[35m0.5827\u001b[0m  0.0206\n",
      "     86        0.6396       0.7734        \u001b[35m0.5809\u001b[0m  0.0238\n",
      "     87        0.6483       0.7734        \u001b[35m0.5790\u001b[0m  0.0297\n",
      "     88        0.6628       0.7734        0.5792  0.0245\n",
      "     89        0.6348       0.7734        0.5792  0.0281\n",
      "     90        0.6288       0.7734        \u001b[35m0.5771\u001b[0m  0.0368\n",
      "     91        0.6425       0.7734        \u001b[35m0.5764\u001b[0m  0.0158\n",
      "     92        0.6595       0.7812        0.5778  0.0265\n",
      "     93        0.6392       0.7734        \u001b[35m0.5763\u001b[0m  0.0270\n",
      "     94        0.6313       0.7734        \u001b[35m0.5752\u001b[0m  0.0206\n",
      "     95        0.6350       0.7734        \u001b[35m0.5737\u001b[0m  0.0169\n",
      "     96        0.6487       0.7734        \u001b[35m0.5736\u001b[0m  0.0294\n",
      "     97        0.6288       0.7734        \u001b[35m0.5719\u001b[0m  0.0366\n",
      "     98        0.6357       0.7734        \u001b[35m0.5712\u001b[0m  0.0251\n",
      "     99        0.6263       0.7812        \u001b[35m0.5706\u001b[0m  0.0192\n",
      "    100        0.6289       0.7734        \u001b[35m0.5688\u001b[0m  0.0320\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7288\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7048\u001b[0m  0.0228\n",
      "      2        \u001b[36m0.7191\u001b[0m       0.5000        \u001b[35m0.6988\u001b[0m  0.0238\n",
      "      3        \u001b[36m0.7112\u001b[0m       0.5000        \u001b[35m0.6953\u001b[0m  0.0265\n",
      "      4        0.7125       0.5000        \u001b[35m0.6934\u001b[0m  0.0220\n",
      "      5        \u001b[36m0.7030\u001b[0m       0.5000        \u001b[35m0.6922\u001b[0m  0.0181\n",
      "      6        \u001b[36m0.7024\u001b[0m       0.5000        \u001b[35m0.6915\u001b[0m  0.0190\n",
      "      7        \u001b[36m0.7023\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6910\u001b[0m  0.0221\n",
      "      8        0.7115       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6907\u001b[0m  0.0171\n",
      "      9        \u001b[36m0.6933\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6903\u001b[0m  0.0254\n",
      "     10        0.7022       0.5703        \u001b[35m0.6901\u001b[0m  0.0202\n",
      "     11        0.6988       0.5781        \u001b[35m0.6900\u001b[0m  0.0200\n",
      "     12        0.7035       0.5859        \u001b[35m0.6897\u001b[0m  0.0326\n",
      "     13        0.6943       0.5781        \u001b[35m0.6894\u001b[0m  0.0207\n",
      "     14        0.7047       0.5703        \u001b[35m0.6893\u001b[0m  0.0390\n",
      "     15        0.7049       0.5859        \u001b[35m0.6888\u001b[0m  0.0154\n",
      "     16        0.7003       0.5859        \u001b[35m0.6885\u001b[0m  0.0198\n",
      "     17        0.6967       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6880\u001b[0m  0.0390\n",
      "     18        0.7021       0.6016        \u001b[35m0.6877\u001b[0m  0.0204\n",
      "     19        0.7018       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6873\u001b[0m  0.0237\n",
      "     20        0.6966       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6868\u001b[0m  0.0169\n",
      "     21        0.6991       0.6250        \u001b[35m0.6863\u001b[0m  0.0176\n",
      "     22        0.6955       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6859\u001b[0m  0.0210\n",
      "     23        0.6994       0.6406        \u001b[35m0.6854\u001b[0m  0.0360\n",
      "     24        0.6958       0.6406        \u001b[35m0.6849\u001b[0m  0.0200\n",
      "     25        \u001b[36m0.6933\u001b[0m       0.6328        \u001b[35m0.6843\u001b[0m  0.0468\n",
      "     26        0.6996       0.6250        \u001b[35m0.6840\u001b[0m  0.0214\n",
      "     27        \u001b[36m0.6908\u001b[0m       0.6250        \u001b[35m0.6833\u001b[0m  0.0289\n",
      "     28        0.6950       0.6250        \u001b[35m0.6825\u001b[0m  0.0294\n",
      "     29        0.6936       0.6250        \u001b[35m0.6819\u001b[0m  0.0262\n",
      "     30        0.6945       0.6328        \u001b[35m0.6812\u001b[0m  0.0159\n",
      "     31        0.7051       0.6328        \u001b[35m0.6809\u001b[0m  0.0290\n",
      "     32        \u001b[36m0.6907\u001b[0m       0.6406        \u001b[35m0.6801\u001b[0m  0.0292\n",
      "     33        0.6973       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6794\u001b[0m  0.0239\n",
      "     34        0.6915       0.6328        \u001b[35m0.6786\u001b[0m  0.0248\n",
      "     35        \u001b[36m0.6840\u001b[0m       0.6406        \u001b[35m0.6778\u001b[0m  0.0207\n",
      "     36        \u001b[36m0.6825\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6770\u001b[0m  0.0208\n",
      "     37        0.6836       0.6406        \u001b[35m0.6759\u001b[0m  0.0203\n",
      "     38        0.6881       0.6406        \u001b[35m0.6747\u001b[0m  0.0303\n",
      "     39        0.6918       0.6406        \u001b[35m0.6737\u001b[0m  0.0232\n",
      "     40        0.7026       0.6406        \u001b[35m0.6730\u001b[0m  0.0332\n",
      "     41        0.6897       0.6484        \u001b[35m0.6723\u001b[0m  0.0237\n",
      "     42        0.6907       0.6484        \u001b[35m0.6713\u001b[0m  0.0210\n",
      "     43        0.6887       0.6562        \u001b[35m0.6702\u001b[0m  0.0195\n",
      "     44        0.6844       0.6562        \u001b[35m0.6691\u001b[0m  0.0205\n",
      "     45        \u001b[36m0.6808\u001b[0m       0.6562        \u001b[35m0.6680\u001b[0m  0.0287\n",
      "     46        \u001b[36m0.6765\u001b[0m       0.6562        \u001b[35m0.6666\u001b[0m  0.0277\n",
      "     47        \u001b[36m0.6723\u001b[0m       0.6641        \u001b[35m0.6649\u001b[0m  0.0313\n",
      "     48        0.6823       0.6719        \u001b[35m0.6635\u001b[0m  0.0317\n",
      "     49        0.6755       0.6641        \u001b[35m0.6620\u001b[0m  0.0294\n",
      "     50        0.6731       0.6641        \u001b[35m0.6601\u001b[0m  0.0303\n",
      "     51        0.6768       0.6641        \u001b[35m0.6586\u001b[0m  0.0197\n",
      "     52        0.6857       0.6719        \u001b[35m0.6573\u001b[0m  0.0314\n",
      "     53        0.6739       0.6719        \u001b[35m0.6560\u001b[0m  0.0191\n",
      "     54        0.6727       0.6719        \u001b[35m0.6542\u001b[0m  0.0203\n",
      "     55        0.6770       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6528\u001b[0m  0.0216\n",
      "     56        \u001b[36m0.6691\u001b[0m       0.6797        \u001b[35m0.6514\u001b[0m  0.0307\n",
      "     57        0.6725       0.6797        \u001b[35m0.6497\u001b[0m  0.0316\n",
      "     58        \u001b[36m0.6688\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6481\u001b[0m  0.0358\n",
      "     59        \u001b[36m0.6662\u001b[0m       0.6797        \u001b[35m0.6464\u001b[0m  0.0269\n",
      "     60        \u001b[36m0.6631\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6446\u001b[0m  0.0187\n",
      "     61        0.6741       0.6953        \u001b[35m0.6428\u001b[0m  0.0238\n",
      "     62        \u001b[36m0.6468\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6405\u001b[0m  0.0195\n",
      "     63        0.6654       0.6953        \u001b[35m0.6385\u001b[0m  0.0274\n",
      "     64        0.6642       0.6953        \u001b[35m0.6366\u001b[0m  0.0267\n",
      "     65        0.6580       0.6953        \u001b[35m0.6349\u001b[0m  0.0244\n",
      "     66        0.6564       0.6875        \u001b[35m0.6328\u001b[0m  0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     67        0.6642       0.6875        \u001b[35m0.6314\u001b[0m  0.0347\n",
      "     68        0.6619       0.6875        \u001b[35m0.6298\u001b[0m  0.0275\n",
      "     69        0.6571       0.6875        \u001b[35m0.6280\u001b[0m  0.0547\n",
      "     70        0.6475       0.6875        \u001b[35m0.6263\u001b[0m  0.0713\n",
      "     71        0.6581       0.6875        \u001b[35m0.6245\u001b[0m  0.0632\n",
      "     72        \u001b[36m0.6443\u001b[0m       0.6953        \u001b[35m0.6224\u001b[0m  0.0347\n",
      "     73        0.6563       0.6953        \u001b[35m0.6208\u001b[0m  0.0707\n",
      "     74        0.6506       0.6953        \u001b[35m0.6192\u001b[0m  0.0246\n",
      "     75        \u001b[36m0.6377\u001b[0m       0.6953        \u001b[35m0.6173\u001b[0m  0.0255\n",
      "     76        0.6465       0.6953        \u001b[35m0.6155\u001b[0m  0.0245\n",
      "     77        \u001b[36m0.6336\u001b[0m       0.7031        \u001b[35m0.6132\u001b[0m  0.0174\n",
      "     78        0.6490       0.6953        \u001b[35m0.6121\u001b[0m  0.0274\n",
      "     79        0.6458       0.7031        \u001b[35m0.6112\u001b[0m  0.0202\n",
      "     80        \u001b[36m0.6229\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6091\u001b[0m  0.0284\n",
      "     81        0.6443       0.7109        \u001b[35m0.6078\u001b[0m  0.0216\n",
      "     82        0.6264       0.7109        \u001b[35m0.6056\u001b[0m  0.0261\n",
      "     83        0.6244       0.7109        \u001b[35m0.6037\u001b[0m  0.0199\n",
      "     84        0.6388       0.7109        \u001b[35m0.6021\u001b[0m  0.0423\n",
      "     85        0.6365       0.7109        \u001b[35m0.6007\u001b[0m  0.0234\n",
      "     86        \u001b[36m0.6101\u001b[0m       0.7109        \u001b[35m0.5986\u001b[0m  0.0302\n",
      "     87        0.6486       0.7109        \u001b[35m0.5981\u001b[0m  0.0238\n",
      "     88        0.6535       0.7109        \u001b[35m0.5979\u001b[0m  0.0240\n",
      "     89        0.6387       0.7109        \u001b[35m0.5971\u001b[0m  0.0160\n",
      "     90        0.6275       0.7109        \u001b[35m0.5958\u001b[0m  0.0152\n",
      "     91        0.6362       0.7109        \u001b[35m0.5949\u001b[0m  0.0159\n",
      "     92        0.6242       0.7109        \u001b[35m0.5938\u001b[0m  0.0157\n",
      "     93        \u001b[36m0.6098\u001b[0m       0.7109        \u001b[35m0.5919\u001b[0m  0.0154\n",
      "     94        0.6207       0.7109        \u001b[35m0.5904\u001b[0m  0.0200\n",
      "     95        0.6162       0.7109        \u001b[35m0.5891\u001b[0m  0.0290\n",
      "     96        0.6201       0.7109        \u001b[35m0.5874\u001b[0m  0.0156\n",
      "     97        0.6309       0.7109        \u001b[35m0.5869\u001b[0m  0.0164\n",
      "     98        0.6178       0.7109        \u001b[35m0.5860\u001b[0m  0.0163\n",
      "     99        0.6251       0.7109        \u001b[35m0.5850\u001b[0m  0.0153\n",
      "    100        \u001b[36m0.5997\u001b[0m       0.7109        \u001b[35m0.5833\u001b[0m  0.0156\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7526\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7428\u001b[0m  0.0814\n",
      "      2        \u001b[36m0.7390\u001b[0m       0.5000        \u001b[35m0.7294\u001b[0m  0.0404\n",
      "      3        \u001b[36m0.7311\u001b[0m       0.5000        \u001b[35m0.7189\u001b[0m  0.0220\n",
      "      4        \u001b[36m0.7258\u001b[0m       0.5000        \u001b[35m0.7116\u001b[0m  0.0198\n",
      "      5        \u001b[36m0.7132\u001b[0m       0.5000        \u001b[35m0.7057\u001b[0m  0.0275\n",
      "      6        \u001b[36m0.7112\u001b[0m       0.5000        \u001b[35m0.7016\u001b[0m  0.0316\n",
      "      7        \u001b[36m0.6973\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6986\u001b[0m  0.0161\n",
      "      8        0.6980       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6963\u001b[0m  0.0244\n",
      "      9        0.6974       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6946\u001b[0m  0.0374\n",
      "     10        0.7023       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6934\u001b[0m  0.0177\n",
      "     11        0.7086       0.5391        \u001b[35m0.6925\u001b[0m  0.0156\n",
      "     12        0.6983       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6918\u001b[0m  0.0476\n",
      "     13        0.7012       0.5547        \u001b[35m0.6912\u001b[0m  0.0221\n",
      "     14        \u001b[36m0.6943\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6905\u001b[0m  0.0177\n",
      "     15        \u001b[36m0.6925\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6899\u001b[0m  0.0422\n",
      "     16        \u001b[36m0.6872\u001b[0m       0.5625        \u001b[35m0.6894\u001b[0m  0.0329\n",
      "     17        0.6940       0.5469        \u001b[35m0.6888\u001b[0m  0.0328\n",
      "     18        0.6962       0.5469        \u001b[35m0.6884\u001b[0m  0.0271\n",
      "     19        0.6911       0.5469        \u001b[35m0.6879\u001b[0m  0.0288\n",
      "     20        0.6971       0.5469        \u001b[35m0.6877\u001b[0m  0.0258\n",
      "     21        0.6947       0.5703        \u001b[35m0.6872\u001b[0m  0.0327\n",
      "     22        0.6901       0.5703        \u001b[35m0.6866\u001b[0m  0.0451\n",
      "     23        \u001b[36m0.6838\u001b[0m       0.5781        \u001b[35m0.6859\u001b[0m  0.0871\n",
      "     24        0.6936       0.5859        \u001b[35m0.6854\u001b[0m  0.0328\n",
      "     25        0.6947       0.5938        \u001b[35m0.6849\u001b[0m  0.0681\n",
      "     26        0.6912       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6844\u001b[0m  0.0345\n",
      "     27        0.6948       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6840\u001b[0m  0.0329\n",
      "     28        0.6859       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6834\u001b[0m  0.0304\n",
      "     29        \u001b[36m0.6816\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6825\u001b[0m  0.0248\n",
      "     30        0.6945       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6820\u001b[0m  0.0294\n",
      "     31        0.6839       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6812\u001b[0m  0.0253\n",
      "     32        0.6879       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6806\u001b[0m  0.0309\n",
      "     33        \u001b[36m0.6807\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6796\u001b[0m  0.0295\n",
      "     34        0.6922       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6788\u001b[0m  0.0309\n",
      "     35        0.6817       0.7031        \u001b[35m0.6776\u001b[0m  0.0283\n",
      "     36        0.6899       0.7188        \u001b[35m0.6769\u001b[0m  0.0212\n",
      "     37        \u001b[36m0.6771\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6755\u001b[0m  0.0303\n",
      "     38        0.6868       0.7266        \u001b[35m0.6746\u001b[0m  0.0370\n",
      "     39        0.6833       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6736\u001b[0m  0.0354\n",
      "     40        0.6818       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6725\u001b[0m  0.0204\n",
      "     41        0.6900       0.7500        \u001b[35m0.6716\u001b[0m  0.0179\n",
      "     42        0.6838       0.7500        \u001b[35m0.6704\u001b[0m  0.0263\n",
      "     43        0.6873       0.7500        \u001b[35m0.6696\u001b[0m  0.0184\n",
      "     44        0.6837       0.7500        \u001b[35m0.6686\u001b[0m  0.0174\n",
      "     45        \u001b[36m0.6647\u001b[0m       0.7500        \u001b[35m0.6666\u001b[0m  0.0286\n",
      "     46        0.6743       0.7188        \u001b[35m0.6653\u001b[0m  0.0204\n",
      "     47        0.6736       0.7031        \u001b[35m0.6640\u001b[0m  0.0209\n",
      "     48        0.6752       0.7031        \u001b[35m0.6626\u001b[0m  0.0191\n",
      "     49        0.6711       0.7344        \u001b[35m0.6611\u001b[0m  0.0178\n",
      "     50        0.6726       0.7344        \u001b[35m0.6596\u001b[0m  0.0186\n",
      "     51        \u001b[36m0.6631\u001b[0m       0.7188        \u001b[35m0.6575\u001b[0m  0.0232\n",
      "     52        0.6780       0.7344        \u001b[35m0.6563\u001b[0m  0.0217\n",
      "     53        0.6797       0.7422        \u001b[35m0.6551\u001b[0m  0.0251\n",
      "     54        0.6689       0.7344        \u001b[35m0.6535\u001b[0m  0.0215\n",
      "     55        \u001b[36m0.6442\u001b[0m       0.7266        \u001b[35m0.6513\u001b[0m  0.0226\n",
      "     56        0.6716       0.7266        \u001b[35m0.6495\u001b[0m  0.0229\n",
      "     57        0.6637       0.7422        \u001b[35m0.6477\u001b[0m  0.0214\n",
      "     58        0.6608       0.7422        \u001b[35m0.6456\u001b[0m  0.0213\n",
      "     59        0.6544       0.7344        \u001b[35m0.6434\u001b[0m  0.0214\n",
      "     60        0.6646       0.7344        \u001b[35m0.6418\u001b[0m  0.0207\n",
      "     61        0.6604       0.7422        \u001b[35m0.6402\u001b[0m  0.0186\n",
      "     62        0.6564       0.7422        \u001b[35m0.6379\u001b[0m  0.0176\n",
      "     63        0.6456       0.7344        \u001b[35m0.6350\u001b[0m  0.0169\n",
      "     64        0.6568       0.7188        \u001b[35m0.6331\u001b[0m  0.0153\n",
      "     65        0.6522       0.7188        \u001b[35m0.6308\u001b[0m  0.0198\n",
      "     66        0.6553       0.7188        \u001b[35m0.6285\u001b[0m  0.0180\n",
      "     67        0.6574       0.7188        \u001b[35m0.6268\u001b[0m  0.0172\n",
      "     68        \u001b[36m0.6385\u001b[0m       0.7188        \u001b[35m0.6248\u001b[0m  0.0181\n",
      "     69        0.6695       0.7188        \u001b[35m0.6238\u001b[0m  0.0174\n",
      "     70        0.6537       0.7188        \u001b[35m0.6225\u001b[0m  0.0165\n",
      "     71        0.6637       0.7188        \u001b[35m0.6212\u001b[0m  0.0172\n",
      "     72        0.6592       0.7188        \u001b[35m0.6203\u001b[0m  0.0212\n",
      "     73        0.6674       0.7188        \u001b[35m0.6196\u001b[0m  0.0181\n",
      "     74        0.6617       0.7188        \u001b[35m0.6190\u001b[0m  0.0199\n",
      "     75        0.6511       0.7188        \u001b[35m0.6174\u001b[0m  0.0204\n",
      "     76        0.6436       0.7188        \u001b[35m0.6151\u001b[0m  0.0244\n",
      "     77        0.6601       0.7188        \u001b[35m0.6142\u001b[0m  0.0316\n",
      "     78        0.6509       0.7188        \u001b[35m0.6130\u001b[0m  0.0203\n",
      "     79        0.6503       0.7188        \u001b[35m0.6117\u001b[0m  0.0222\n",
      "     80        0.6756       0.7188        0.6119  0.0250\n",
      "     81        \u001b[36m0.6328\u001b[0m       0.7188        \u001b[35m0.6101\u001b[0m  0.0248\n",
      "     82        0.6504       0.7188        \u001b[35m0.6089\u001b[0m  0.0322\n",
      "     83        0.6341       0.7266        \u001b[35m0.6070\u001b[0m  0.0181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     84        0.6383       0.7266        \u001b[35m0.6056\u001b[0m  0.0281\n",
      "     85        0.6329       0.7266        \u001b[35m0.6037\u001b[0m  0.0508\n",
      "     86        0.6554       0.7266        \u001b[35m0.6033\u001b[0m  0.0215\n",
      "     87        0.6342       0.7266        \u001b[35m0.6015\u001b[0m  0.0252\n",
      "     88        \u001b[36m0.6320\u001b[0m       0.7266        \u001b[35m0.5996\u001b[0m  0.0209\n",
      "     89        0.6353       0.7266        \u001b[35m0.5978\u001b[0m  0.0172\n",
      "     90        0.6431       0.7266        \u001b[35m0.5967\u001b[0m  0.0329\n",
      "     91        0.6353       0.7266        \u001b[35m0.5949\u001b[0m  0.0230\n",
      "     92        0.6432       0.7344        \u001b[35m0.5939\u001b[0m  0.0276\n",
      "     93        0.6354       0.7344        \u001b[35m0.5932\u001b[0m  0.0189\n",
      "     94        0.6514       0.7344        \u001b[35m0.5924\u001b[0m  0.0314\n",
      "     95        0.6444       0.7344        \u001b[35m0.5911\u001b[0m  0.0192\n",
      "     96        \u001b[36m0.6307\u001b[0m       0.7344        \u001b[35m0.5901\u001b[0m  0.0199\n",
      "     97        \u001b[36m0.6260\u001b[0m       0.7344        \u001b[35m0.5886\u001b[0m  0.0173\n",
      "     98        0.6389       0.7344        \u001b[35m0.5875\u001b[0m  0.0342\n",
      "     99        0.6305       0.7344        \u001b[35m0.5868\u001b[0m  0.0347\n",
      "    100        \u001b[36m0.6110\u001b[0m       0.7344        \u001b[35m0.5855\u001b[0m  0.0261\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7104\u001b[0m       \u001b[32m0.4766\u001b[0m        \u001b[35m0.6960\u001b[0m  0.0172\n",
      "      2        \u001b[36m0.7088\u001b[0m       0.4531        \u001b[35m0.6937\u001b[0m  0.0220\n",
      "      3        \u001b[36m0.7027\u001b[0m       0.4609        \u001b[35m0.6916\u001b[0m  0.0313\n",
      "      4        \u001b[36m0.7010\u001b[0m       0.4609        \u001b[35m0.6895\u001b[0m  0.0283\n",
      "      5        0.7018       0.4531        \u001b[35m0.6880\u001b[0m  0.0259\n",
      "      6        \u001b[36m0.6930\u001b[0m       0.4688        \u001b[35m0.6865\u001b[0m  0.0311\n",
      "      7        \u001b[36m0.6911\u001b[0m       \u001b[32m0.4844\u001b[0m        \u001b[35m0.6851\u001b[0m  0.0332\n",
      "      8        0.6937       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6840\u001b[0m  0.0485\n",
      "      9        0.6955       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6826\u001b[0m  0.0214\n",
      "     10        0.6956       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6815\u001b[0m  0.0198\n",
      "     11        \u001b[36m0.6869\u001b[0m       0.5859        \u001b[35m0.6803\u001b[0m  0.0303\n",
      "     12        \u001b[36m0.6786\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6789\u001b[0m  0.0182\n",
      "     13        0.6950       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6780\u001b[0m  0.0204\n",
      "     14        0.6882       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6768\u001b[0m  0.0301\n",
      "     15        \u001b[36m0.6782\u001b[0m       0.6250        \u001b[35m0.6757\u001b[0m  0.0180\n",
      "     16        0.6900       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6747\u001b[0m  0.0377\n",
      "     17        \u001b[36m0.6748\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6734\u001b[0m  0.0268\n",
      "     18        0.6850       0.6484        \u001b[35m0.6726\u001b[0m  0.0326\n",
      "     19        0.6780       0.6484        \u001b[35m0.6713\u001b[0m  0.0218\n",
      "     20        0.6900       0.6484        \u001b[35m0.6707\u001b[0m  0.0209\n",
      "     21        0.6829       0.6484        \u001b[35m0.6701\u001b[0m  0.0312\n",
      "     22        0.6923       0.6484        \u001b[35m0.6694\u001b[0m  0.1439\n",
      "     23        0.6776       0.6484        \u001b[35m0.6684\u001b[0m  0.0295\n",
      "     24        \u001b[36m0.6740\u001b[0m       0.6562        \u001b[35m0.6674\u001b[0m  0.0206\n",
      "     25        0.6755       0.6562        \u001b[35m0.6663\u001b[0m  0.0386\n",
      "     26        0.6850       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6657\u001b[0m  0.0436\n",
      "     27        0.6808       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6650\u001b[0m  0.0304\n",
      "     28        0.6842       0.6797        \u001b[35m0.6643\u001b[0m  0.0324\n",
      "     29        0.6745       0.6797        \u001b[35m0.6634\u001b[0m  0.0243\n",
      "     30        0.6779       0.6719        \u001b[35m0.6623\u001b[0m  0.0232\n",
      "     31        0.6755       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6612\u001b[0m  0.0160\n",
      "     32        0.6832       0.6875        \u001b[35m0.6603\u001b[0m  0.0149\n",
      "     33        0.6781       0.6797        \u001b[35m0.6594\u001b[0m  0.0267\n",
      "     34        \u001b[36m0.6720\u001b[0m       0.6797        \u001b[35m0.6585\u001b[0m  0.0260\n",
      "     35        0.6846       0.6875        \u001b[35m0.6581\u001b[0m  0.0296\n",
      "     36        0.6820       0.6875        \u001b[35m0.6573\u001b[0m  0.0289\n",
      "     37        \u001b[36m0.6695\u001b[0m       0.6875        \u001b[35m0.6562\u001b[0m  0.0260\n",
      "     38        \u001b[36m0.6683\u001b[0m       0.6797        \u001b[35m0.6550\u001b[0m  0.0260\n",
      "     39        0.6699       0.6797        \u001b[35m0.6538\u001b[0m  0.0222\n",
      "     40        0.6797       0.6875        \u001b[35m0.6532\u001b[0m  0.0186\n",
      "     41        0.6743       0.6875        \u001b[35m0.6525\u001b[0m  0.0188\n",
      "     42        \u001b[36m0.6670\u001b[0m       0.6797        \u001b[35m0.6515\u001b[0m  0.0167\n",
      "     43        0.6739       0.6797        \u001b[35m0.6506\u001b[0m  0.0266\n",
      "     44        0.6724       0.6875        \u001b[35m0.6499\u001b[0m  0.0245\n",
      "     45        0.6723       0.6797        \u001b[35m0.6490\u001b[0m  0.0237\n",
      "     46        0.6697       0.6797        \u001b[35m0.6482\u001b[0m  0.0230\n",
      "     47        \u001b[36m0.6580\u001b[0m       0.6797        \u001b[35m0.6464\u001b[0m  0.0184\n",
      "     48        0.6680       0.6797        \u001b[35m0.6452\u001b[0m  0.0208\n",
      "     49        0.6763       0.6875        \u001b[35m0.6447\u001b[0m  0.0164\n",
      "     50        0.6789       0.6875        \u001b[35m0.6447\u001b[0m  0.0261\n",
      "     51        0.6707       0.6875        \u001b[35m0.6440\u001b[0m  0.0262\n",
      "     52        0.6629       0.6875        \u001b[35m0.6430\u001b[0m  0.0228\n",
      "     53        0.6631       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6416\u001b[0m  0.0213\n",
      "     54        0.6640       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6403\u001b[0m  0.0199\n",
      "     55        0.6695       0.7031        \u001b[35m0.6394\u001b[0m  0.0143\n",
      "     56        0.6782       0.7031        \u001b[35m0.6392\u001b[0m  0.0154\n",
      "     57        0.6679       0.7031        \u001b[35m0.6384\u001b[0m  0.0267\n",
      "     58        0.6708       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6378\u001b[0m  0.0643\n",
      "     59        0.6762       0.7031        \u001b[35m0.6375\u001b[0m  0.0455\n",
      "     60        0.6600       0.7031        \u001b[35m0.6365\u001b[0m  0.0543\n",
      "     61        \u001b[36m0.6525\u001b[0m       0.7031        \u001b[35m0.6347\u001b[0m  0.0289\n",
      "     62        0.6644       0.7031        \u001b[35m0.6339\u001b[0m  0.0404\n",
      "     63        0.6599       0.6875        \u001b[35m0.6328\u001b[0m  0.0174\n",
      "     64        0.6641       0.7031        \u001b[35m0.6320\u001b[0m  0.0269\n",
      "     65        0.6744       0.7031        \u001b[35m0.6319\u001b[0m  0.0169\n",
      "     66        0.6629       0.7031        \u001b[35m0.6313\u001b[0m  0.0150\n",
      "     67        \u001b[36m0.6434\u001b[0m       0.7031        \u001b[35m0.6295\u001b[0m  0.0263\n",
      "     68        0.6568       0.7031        \u001b[35m0.6282\u001b[0m  0.0262\n",
      "     69        0.6682       0.7031        \u001b[35m0.6277\u001b[0m  0.0474\n",
      "     70        0.6563       0.7109        \u001b[35m0.6264\u001b[0m  0.0464\n",
      "     71        0.6613       0.7031        \u001b[35m0.6257\u001b[0m  0.0395\n",
      "     72        0.6503       0.7109        \u001b[35m0.6247\u001b[0m  0.0284\n",
      "     73        0.6637       0.7109        \u001b[35m0.6243\u001b[0m  0.0232\n",
      "     74        0.6519       0.7031        \u001b[35m0.6226\u001b[0m  0.0222\n",
      "     75        0.6585       0.7109        \u001b[35m0.6218\u001b[0m  0.0247\n",
      "     76        0.6518       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6204\u001b[0m  0.0349\n",
      "     77        0.6487       0.7109        \u001b[35m0.6193\u001b[0m  0.0500\n",
      "     78        0.6694       0.7109        \u001b[35m0.6192\u001b[0m  0.0497\n",
      "     79        \u001b[36m0.6388\u001b[0m       0.7109        \u001b[35m0.6181\u001b[0m  0.0500\n",
      "     80        0.6703       0.7109        \u001b[35m0.6176\u001b[0m  0.0446\n",
      "     81        0.6655       0.7031        0.6179  0.0435\n",
      "     82        0.6630       0.7109        \u001b[35m0.6174\u001b[0m  0.0365\n",
      "     83        0.6541       0.7031        \u001b[35m0.6166\u001b[0m  0.0497\n",
      "     84        0.6641       0.7031        \u001b[35m0.6160\u001b[0m  0.0435\n",
      "     85        0.6532       0.7109        \u001b[35m0.6153\u001b[0m  0.0417\n",
      "     86        0.6505       0.7188        \u001b[35m0.6140\u001b[0m  0.0385\n",
      "     87        0.6420       0.6953        \u001b[35m0.6134\u001b[0m  0.0424\n",
      "     88        0.6505       0.6953        \u001b[35m0.6125\u001b[0m  0.0453\n",
      "     89        0.6522       0.7031        \u001b[35m0.6125\u001b[0m  0.0359\n",
      "     90        0.6658       0.7031        \u001b[35m0.6124\u001b[0m  0.0294\n",
      "     91        0.6552       0.7031        \u001b[35m0.6121\u001b[0m  0.0251\n",
      "     92        \u001b[36m0.6387\u001b[0m       0.7109        \u001b[35m0.6110\u001b[0m  0.0198\n",
      "     93        0.6523       0.7109        \u001b[35m0.6106\u001b[0m  0.0163\n",
      "     94        0.6481       0.7109        \u001b[35m0.6100\u001b[0m  0.0157\n",
      "     95        0.6596       0.7188        \u001b[35m0.6097\u001b[0m  0.0239\n",
      "     96        0.6484       0.7109        \u001b[35m0.6095\u001b[0m  0.0287\n",
      "     97        0.6458       0.7188        \u001b[35m0.6086\u001b[0m  0.0260\n",
      "     98        0.6454       0.7188        \u001b[35m0.6081\u001b[0m  0.0220\n",
      "     99        0.6451       0.7109        \u001b[35m0.6073\u001b[0m  0.0197\n",
      "    100        0.6646       0.7188        0.6076  0.0222\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6972\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6695\u001b[0m  0.0210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.6955\u001b[0m       0.6797        \u001b[35m0.6687\u001b[0m  0.0220\n",
      "      3        \u001b[36m0.6842\u001b[0m       0.6875        \u001b[35m0.6677\u001b[0m  0.0185\n",
      "      4        \u001b[36m0.6798\u001b[0m       0.6953        \u001b[35m0.6664\u001b[0m  0.0181\n",
      "      5        \u001b[36m0.6684\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6652\u001b[0m  0.0257\n",
      "      6        0.6760       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6640\u001b[0m  0.0268\n",
      "      7        0.6750       0.7188        \u001b[35m0.6628\u001b[0m  0.0262\n",
      "      8        0.6767       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6616\u001b[0m  0.0255\n",
      "      9        0.6808       0.7266        \u001b[35m0.6608\u001b[0m  0.0255\n",
      "     10        0.6789       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6600\u001b[0m  0.0257\n",
      "     11        0.6714       0.7422        \u001b[35m0.6589\u001b[0m  0.0229\n",
      "     12        \u001b[36m0.6643\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6577\u001b[0m  0.0241\n",
      "     13        0.6704       0.7500        \u001b[35m0.6565\u001b[0m  0.0212\n",
      "     14        0.6729       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6557\u001b[0m  0.0315\n",
      "     15        0.6762       0.7578        \u001b[35m0.6545\u001b[0m  0.0224\n",
      "     16        0.6681       0.7578        \u001b[35m0.6534\u001b[0m  0.0251\n",
      "     17        0.6736       0.7500        \u001b[35m0.6523\u001b[0m  0.0181\n",
      "     18        0.6723       0.7500        \u001b[35m0.6511\u001b[0m  0.0180\n",
      "     19        \u001b[36m0.6543\u001b[0m       0.7500        \u001b[35m0.6496\u001b[0m  0.0237\n",
      "     20        0.6667       0.7109        \u001b[35m0.6485\u001b[0m  0.0230\n",
      "     21        0.6576       0.7109        \u001b[35m0.6471\u001b[0m  0.0180\n",
      "     22        0.6613       0.7500        \u001b[35m0.6458\u001b[0m  0.0241\n",
      "     23        0.6584       0.7500        \u001b[35m0.6446\u001b[0m  0.0188\n",
      "     24        \u001b[36m0.6503\u001b[0m       0.7109        \u001b[35m0.6432\u001b[0m  0.0190\n",
      "     25        0.6737       0.7109        \u001b[35m0.6425\u001b[0m  0.0420\n",
      "     26        0.6594       0.7109        \u001b[35m0.6414\u001b[0m  0.0193\n",
      "     27        \u001b[36m0.6490\u001b[0m       0.7109        \u001b[35m0.6400\u001b[0m  0.0241\n",
      "     28        0.6567       0.7031        \u001b[35m0.6387\u001b[0m  0.0203\n",
      "     29        0.6563       0.7031        \u001b[35m0.6375\u001b[0m  0.0284\n",
      "     30        0.6584       0.7109        \u001b[35m0.6364\u001b[0m  0.0495\n",
      "     31        0.6682       0.7109        \u001b[35m0.6356\u001b[0m  0.0541\n",
      "     32        \u001b[36m0.6485\u001b[0m       0.7188        \u001b[35m0.6342\u001b[0m  0.0275\n",
      "     33        0.6600       0.7188        \u001b[35m0.6333\u001b[0m  0.0280\n",
      "     34        0.6534       0.7188        \u001b[35m0.6317\u001b[0m  0.0250\n",
      "     35        \u001b[36m0.6464\u001b[0m       0.7266        \u001b[35m0.6300\u001b[0m  0.0262\n",
      "     36        0.6608       0.7266        \u001b[35m0.6289\u001b[0m  0.0215\n",
      "     37        \u001b[36m0.6333\u001b[0m       0.7266        \u001b[35m0.6271\u001b[0m  0.0193\n",
      "     38        0.6403       0.7422        \u001b[35m0.6252\u001b[0m  0.0163\n",
      "     39        0.6591       0.7422        \u001b[35m0.6244\u001b[0m  0.0381\n",
      "     40        0.6475       0.7422        \u001b[35m0.6235\u001b[0m  0.0237\n",
      "     41        0.6472       0.7422        \u001b[35m0.6226\u001b[0m  0.0193\n",
      "     42        0.6485       0.7422        \u001b[35m0.6218\u001b[0m  0.0227\n",
      "     43        0.6550       0.7422        \u001b[35m0.6209\u001b[0m  0.0247\n",
      "     44        \u001b[36m0.6315\u001b[0m       0.7422        \u001b[35m0.6191\u001b[0m  0.0220\n",
      "     45        0.6470       0.7422        \u001b[35m0.6179\u001b[0m  0.0286\n",
      "     46        0.6466       0.7422        \u001b[35m0.6168\u001b[0m  0.0194\n",
      "     47        0.6470       0.7422        \u001b[35m0.6154\u001b[0m  0.0320\n",
      "     48        \u001b[36m0.6296\u001b[0m       0.7422        \u001b[35m0.6141\u001b[0m  0.0258\n",
      "     49        0.6462       0.7422        \u001b[35m0.6135\u001b[0m  0.0310\n",
      "     50        0.6433       0.7422        \u001b[35m0.6130\u001b[0m  0.0161\n",
      "     51        0.6396       0.7422        \u001b[35m0.6117\u001b[0m  0.0214\n",
      "     52        0.6454       0.7422        \u001b[35m0.6108\u001b[0m  0.0197\n",
      "     53        \u001b[36m0.6190\u001b[0m       0.7422        \u001b[35m0.6090\u001b[0m  0.0187\n",
      "     54        0.6304       0.7500        \u001b[35m0.6078\u001b[0m  0.0172\n",
      "     55        0.6314       0.7500        \u001b[35m0.6064\u001b[0m  0.0257\n",
      "     56        0.6461       0.7500        \u001b[35m0.6056\u001b[0m  0.0224\n",
      "     57        0.6405       0.7500        \u001b[35m0.6054\u001b[0m  0.0221\n",
      "     58        0.6280       0.7500        \u001b[35m0.6041\u001b[0m  0.0264\n",
      "     59        0.6246       0.7422        \u001b[35m0.6034\u001b[0m  0.0237\n",
      "     60        0.6353       0.7422        \u001b[35m0.6026\u001b[0m  0.0168\n",
      "     61        0.6205       0.7500        \u001b[35m0.6012\u001b[0m  0.0170\n",
      "     62        0.6323       0.7422        \u001b[35m0.6002\u001b[0m  0.0235\n",
      "     63        0.6209       0.7500        \u001b[35m0.5986\u001b[0m  0.0242\n",
      "     64        0.6295       0.7422        \u001b[35m0.5976\u001b[0m  0.0230\n",
      "     65        0.6393       0.7500        \u001b[35m0.5974\u001b[0m  0.0219\n",
      "     66        \u001b[36m0.6141\u001b[0m       0.7500        \u001b[35m0.5962\u001b[0m  0.0224\n",
      "     67        0.6401       0.7344        \u001b[35m0.5959\u001b[0m  0.0236\n",
      "     68        0.6267       0.7344        \u001b[35m0.5951\u001b[0m  0.0280\n",
      "     69        0.6451       0.7422        \u001b[35m0.5947\u001b[0m  0.0243\n",
      "     70        \u001b[36m0.6120\u001b[0m       0.7422        \u001b[35m0.5935\u001b[0m  0.0195\n",
      "     71        0.6281       0.7422        \u001b[35m0.5930\u001b[0m  0.0182\n",
      "     72        0.6238       0.7344        \u001b[35m0.5925\u001b[0m  0.0177\n",
      "     73        \u001b[36m0.6096\u001b[0m       0.7344        \u001b[35m0.5916\u001b[0m  0.0171\n",
      "     74        0.6234       0.7422        \u001b[35m0.5908\u001b[0m  0.0265\n",
      "     75        0.6253       0.7422        \u001b[35m0.5899\u001b[0m  0.0232\n",
      "     76        0.6404       0.7266        \u001b[35m0.5898\u001b[0m  0.0222\n",
      "     77        0.6241       0.7266        \u001b[35m0.5889\u001b[0m  0.0247\n",
      "     78        0.6188       0.7266        \u001b[35m0.5880\u001b[0m  0.0249\n",
      "     79        0.6244       0.7266        \u001b[35m0.5876\u001b[0m  0.0202\n",
      "     80        0.6109       0.7266        \u001b[35m0.5870\u001b[0m  0.0189\n",
      "     81        0.6314       0.7266        \u001b[35m0.5865\u001b[0m  0.0186\n",
      "     82        0.6349       0.7266        0.5865  0.0183\n",
      "     83        0.6218       0.7266        \u001b[35m0.5859\u001b[0m  0.0178\n",
      "     84        0.6224       0.7188        \u001b[35m0.5854\u001b[0m  0.0221\n",
      "     85        0.6250       0.7188        \u001b[35m0.5850\u001b[0m  0.0180\n",
      "     86        0.6353       0.7188        0.5852  0.0233\n",
      "     87        0.6226       0.7188        \u001b[35m0.5845\u001b[0m  0.0274\n",
      "     88        0.6180       0.7188        \u001b[35m0.5842\u001b[0m  0.0254\n",
      "     89        0.6102       0.7188        \u001b[35m0.5829\u001b[0m  0.0212\n",
      "     90        0.6240       0.7266        \u001b[35m0.5824\u001b[0m  0.0162\n",
      "     91        0.6453       0.7188        \u001b[35m0.5823\u001b[0m  0.0168\n",
      "     92        0.6127       0.7266        \u001b[35m0.5815\u001b[0m  0.0166\n",
      "     93        0.6213       0.7188        0.5818  0.0192\n",
      "     94        \u001b[36m0.5999\u001b[0m       0.7188        \u001b[35m0.5807\u001b[0m  0.0214\n",
      "     95        0.6092       0.7188        \u001b[35m0.5800\u001b[0m  0.0240\n",
      "     96        \u001b[36m0.5920\u001b[0m       0.7266        \u001b[35m0.5789\u001b[0m  0.0236\n",
      "     97        0.6180       0.7266        \u001b[35m0.5785\u001b[0m  0.0245\n",
      "     98        0.6022       0.7266        \u001b[35m0.5777\u001b[0m  0.0223\n",
      "     99        0.6244       0.7266        \u001b[35m0.5775\u001b[0m  0.0217\n",
      "    100        0.6195       0.7266        \u001b[35m0.5770\u001b[0m  0.0236\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6981\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6933\u001b[0m  0.0561\n",
      "      2        0.6992       0.5000        \u001b[35m0.6916\u001b[0m  0.0412\n",
      "      3        0.7023       0.5000        \u001b[35m0.6906\u001b[0m  0.0482\n",
      "      4        \u001b[36m0.6972\u001b[0m       0.5000        \u001b[35m0.6890\u001b[0m  0.0450\n",
      "      5        0.6985       0.5000        \u001b[35m0.6874\u001b[0m  0.2259\n",
      "      6        \u001b[36m0.6969\u001b[0m       0.5000        \u001b[35m0.6857\u001b[0m  0.1073\n",
      "      7        \u001b[36m0.6901\u001b[0m       0.5000        \u001b[35m0.6834\u001b[0m  0.0420\n",
      "      8        0.6922       0.5000        \u001b[35m0.6815\u001b[0m  0.0454\n",
      "      9        0.6912       0.5000        \u001b[35m0.6796\u001b[0m  0.0508\n",
      "     10        0.6901       0.5000        \u001b[35m0.6776\u001b[0m  0.0995\n",
      "     11        \u001b[36m0.6896\u001b[0m       0.5000        \u001b[35m0.6753\u001b[0m  0.1115\n",
      "     12        \u001b[36m0.6862\u001b[0m       0.5000        \u001b[35m0.6729\u001b[0m  0.0626\n",
      "     13        \u001b[36m0.6840\u001b[0m       0.5000        \u001b[35m0.6700\u001b[0m  0.0738\n",
      "     14        \u001b[36m0.6812\u001b[0m       0.5000        \u001b[35m0.6668\u001b[0m  0.0894\n",
      "     15        \u001b[36m0.6790\u001b[0m       \u001b[32m0.5312\u001b[0m        \u001b[35m0.6638\u001b[0m  0.0610\n",
      "     16        \u001b[36m0.6723\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6600\u001b[0m  0.0477\n",
      "     17        0.6750       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6567\u001b[0m  0.0447\n",
      "     18        0.6762       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6536\u001b[0m  0.0433\n",
      "     19        \u001b[36m0.6685\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6491\u001b[0m  0.0482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     20        \u001b[36m0.6669\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6448\u001b[0m  0.0743\n",
      "     21        \u001b[36m0.6595\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6390\u001b[0m  0.0383\n",
      "     22        \u001b[36m0.6541\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6330\u001b[0m  0.0651\n",
      "     23        0.6575       \u001b[32m0.7578\u001b[0m        \u001b[35m0.6279\u001b[0m  0.0489\n",
      "     24        \u001b[36m0.6518\u001b[0m       0.7578        \u001b[35m0.6223\u001b[0m  0.0565\n",
      "     25        \u001b[36m0.6412\u001b[0m       0.7422        \u001b[35m0.6157\u001b[0m  0.0562\n",
      "     26        \u001b[36m0.6399\u001b[0m       0.7344        \u001b[35m0.6094\u001b[0m  0.0632\n",
      "     27        \u001b[36m0.6349\u001b[0m       0.7344        \u001b[35m0.6033\u001b[0m  0.0606\n",
      "     28        0.6435       0.7344        \u001b[35m0.5984\u001b[0m  0.0523\n",
      "     29        \u001b[36m0.6242\u001b[0m       0.7344        \u001b[35m0.5901\u001b[0m  0.0527\n",
      "     30        \u001b[36m0.6145\u001b[0m       0.7422        \u001b[35m0.5827\u001b[0m  0.0494\n",
      "     31        0.6262       0.7500        \u001b[35m0.5771\u001b[0m  0.0397\n",
      "     32        \u001b[36m0.6078\u001b[0m       0.7500        \u001b[35m0.5694\u001b[0m  0.0393\n",
      "     33        \u001b[36m0.6018\u001b[0m       0.7578        \u001b[35m0.5618\u001b[0m  0.0390\n",
      "     34        \u001b[36m0.5988\u001b[0m       0.7578        \u001b[35m0.5531\u001b[0m  0.0400\n",
      "     35        \u001b[36m0.5831\u001b[0m       0.7578        \u001b[35m0.5446\u001b[0m  0.0388\n",
      "     36        0.5853       0.7578        \u001b[35m0.5380\u001b[0m  0.0391\n",
      "     37        0.5908       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5336\u001b[0m  0.0388\n",
      "     38        \u001b[36m0.5728\u001b[0m       0.7656        \u001b[35m0.5269\u001b[0m  0.0384\n",
      "     39        0.5751       0.7656        \u001b[35m0.5230\u001b[0m  0.0403\n",
      "     40        0.5955       0.7656        \u001b[35m0.5184\u001b[0m  0.0383\n",
      "     41        0.5873       0.7656        \u001b[35m0.5137\u001b[0m  0.0396\n",
      "     42        \u001b[36m0.5651\u001b[0m       0.7656        \u001b[35m0.5083\u001b[0m  0.0380\n",
      "     43        0.5668       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5039\u001b[0m  0.0392\n",
      "     44        0.5708       0.7656        \u001b[35m0.5001\u001b[0m  0.0390\n",
      "     45        0.5664       0.7656        \u001b[35m0.4961\u001b[0m  0.0388\n",
      "     46        \u001b[36m0.5530\u001b[0m       0.7656        \u001b[35m0.4932\u001b[0m  0.0393\n",
      "     47        0.5690       0.7656        \u001b[35m0.4923\u001b[0m  0.0384\n",
      "     48        0.5540       0.7656        \u001b[35m0.4877\u001b[0m  0.0424\n",
      "     49        0.5625       0.7656        \u001b[35m0.4841\u001b[0m  0.0409\n",
      "     50        \u001b[36m0.5485\u001b[0m       0.7656        \u001b[35m0.4811\u001b[0m  0.0389\n",
      "     51        \u001b[36m0.5446\u001b[0m       0.7734        0.4813  0.0995\n",
      "     52        0.5574       0.7656        \u001b[35m0.4786\u001b[0m  0.0650\n",
      "     53        0.5455       0.7734        \u001b[35m0.4754\u001b[0m  0.0473\n",
      "     54        0.5549       0.7734        \u001b[35m0.4750\u001b[0m  0.0407\n",
      "     55        \u001b[36m0.5414\u001b[0m       0.7734        \u001b[35m0.4711\u001b[0m  0.0396\n",
      "     56        0.5457       0.7734        \u001b[35m0.4674\u001b[0m  0.0436\n",
      "     57        0.5588       0.7734        0.4681  0.0386\n",
      "     58        0.5562       0.7656        0.4692  0.0408\n",
      "     59        0.5642       0.7734        0.4684  0.0385\n",
      "     60        0.5537       \u001b[32m0.7812\u001b[0m        0.4690  0.0406\n",
      "     61        \u001b[36m0.5374\u001b[0m       0.7812        \u001b[35m0.4654\u001b[0m  0.0408\n",
      "     62        0.5398       0.7812        \u001b[35m0.4646\u001b[0m  0.0384\n",
      "     63        0.5556       \u001b[32m0.7891\u001b[0m        0.4654  0.0385\n",
      "     64        0.5543       0.7812        0.4662  0.0398\n",
      "     65        \u001b[36m0.5360\u001b[0m       0.7812        \u001b[35m0.4645\u001b[0m  0.0403\n",
      "     66        0.5551       0.7812        \u001b[35m0.4630\u001b[0m  0.0378\n",
      "     67        0.5443       0.7734        \u001b[35m0.4608\u001b[0m  0.0381\n",
      "     68        0.5691       0.7891        0.4638  0.0381\n",
      "     69        0.5486       0.7891        0.4628  0.0489\n",
      "     70        0.5513       0.7891        0.4625  0.0443\n",
      "     71        0.5472       0.7891        \u001b[35m0.4600\u001b[0m  0.0531\n",
      "     72        0.5411       0.7812        \u001b[35m0.4575\u001b[0m  0.0545\n",
      "     73        0.5470       0.7812        \u001b[35m0.4573\u001b[0m  0.0422\n",
      "     74        0.5391       0.7812        0.4582  0.0381\n",
      "     75        \u001b[36m0.5300\u001b[0m       0.7812        \u001b[35m0.4545\u001b[0m  0.0395\n",
      "     76        0.5580       0.7891        0.4575  0.0379\n",
      "     77        0.5488       0.7891        0.4567  0.0382\n",
      "     78        0.5303       0.7891        \u001b[35m0.4519\u001b[0m  0.0378\n",
      "     79        \u001b[36m0.5246\u001b[0m       0.7891        0.4530  0.0379\n",
      "     80        0.5300       \u001b[32m0.7969\u001b[0m        0.4531  0.0379\n",
      "     81        0.5579       0.7891        0.4548  0.0388\n",
      "     82        0.5415       0.7891        0.4531  0.0375\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7124\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7035\u001b[0m  0.0349\n",
      "      2        \u001b[36m0.7073\u001b[0m       0.5000        \u001b[35m0.6949\u001b[0m  0.0500\n",
      "      3        \u001b[36m0.6953\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6905\u001b[0m  0.0428\n",
      "      4        0.6957       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6882\u001b[0m  0.0451\n",
      "      5        \u001b[36m0.6948\u001b[0m       0.5781        \u001b[35m0.6863\u001b[0m  0.0385\n",
      "      6        \u001b[36m0.6886\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6838\u001b[0m  0.0404\n",
      "      7        \u001b[36m0.6877\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6813\u001b[0m  0.0466\n",
      "      8        \u001b[36m0.6858\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6789\u001b[0m  0.0381\n",
      "      9        \u001b[36m0.6794\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6758\u001b[0m  0.0422\n",
      "     10        0.6856       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6731\u001b[0m  0.0422\n",
      "     11        0.6825       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6698\u001b[0m  0.0454\n",
      "     12        \u001b[36m0.6754\u001b[0m       0.7109        \u001b[35m0.6656\u001b[0m  0.0376\n",
      "     13        \u001b[36m0.6701\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6609\u001b[0m  0.0391\n",
      "     14        \u001b[36m0.6665\u001b[0m       0.7188        \u001b[35m0.6554\u001b[0m  0.0431\n",
      "     15        0.6668       0.7344        \u001b[35m0.6507\u001b[0m  0.0447\n",
      "     16        \u001b[36m0.6492\u001b[0m       0.7344        \u001b[35m0.6434\u001b[0m  0.0464\n",
      "     17        0.6575       0.7344        \u001b[35m0.6373\u001b[0m  0.0381\n",
      "     18        \u001b[36m0.6398\u001b[0m       0.7266        \u001b[35m0.6298\u001b[0m  0.0377\n",
      "     19        \u001b[36m0.6389\u001b[0m       0.7266        \u001b[35m0.6234\u001b[0m  0.0415\n",
      "     20        \u001b[36m0.6206\u001b[0m       0.7266        \u001b[35m0.6161\u001b[0m  0.0417\n",
      "     21        \u001b[36m0.6132\u001b[0m       0.7188        \u001b[35m0.6081\u001b[0m  0.0434\n",
      "     22        0.6231       0.7266        \u001b[35m0.6028\u001b[0m  0.0429\n",
      "     23        \u001b[36m0.6093\u001b[0m       0.7344        \u001b[35m0.5976\u001b[0m  0.0431\n",
      "     24        \u001b[36m0.6002\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5914\u001b[0m  0.0454\n",
      "     25        0.6021       0.7344        \u001b[35m0.5881\u001b[0m  0.0416\n",
      "     26        0.6038       0.7422        \u001b[35m0.5841\u001b[0m  0.0423\n",
      "     27        \u001b[36m0.5935\u001b[0m       0.7422        \u001b[35m0.5800\u001b[0m  0.0428\n",
      "     28        0.6017       0.7344        \u001b[35m0.5747\u001b[0m  0.0435\n",
      "     29        \u001b[36m0.5933\u001b[0m       0.7422        \u001b[35m0.5718\u001b[0m  0.0435\n",
      "     30        \u001b[36m0.5910\u001b[0m       0.7422        \u001b[35m0.5683\u001b[0m  0.0401\n",
      "     31        0.5931       0.7422        \u001b[35m0.5654\u001b[0m  0.0480\n",
      "     32        \u001b[36m0.5745\u001b[0m       0.7422        \u001b[35m0.5617\u001b[0m  0.0414\n",
      "     33        0.5783       0.7344        \u001b[35m0.5583\u001b[0m  0.0452\n",
      "     34        0.5810       0.7422        \u001b[35m0.5574\u001b[0m  0.0438\n",
      "     35        \u001b[36m0.5691\u001b[0m       0.7422        \u001b[35m0.5529\u001b[0m  0.0407\n",
      "     36        0.5978       0.7422        \u001b[35m0.5512\u001b[0m  0.0413\n",
      "     37        \u001b[36m0.5623\u001b[0m       0.7422        \u001b[35m0.5483\u001b[0m  0.0407\n",
      "     38        0.5715       0.7422        \u001b[35m0.5473\u001b[0m  0.0397\n",
      "     39        0.5802       0.7422        \u001b[35m0.5463\u001b[0m  0.0474\n",
      "     40        0.5774       0.7422        \u001b[35m0.5448\u001b[0m  0.0450\n",
      "     41        0.5673       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5424\u001b[0m  0.0448\n",
      "     42        0.5736       0.7500        \u001b[35m0.5417\u001b[0m  0.0384\n",
      "     43        0.5725       0.7344        \u001b[35m0.5410\u001b[0m  0.0492\n",
      "     44        \u001b[36m0.5415\u001b[0m       0.7344        \u001b[35m0.5387\u001b[0m  0.0396\n",
      "     45        0.5713       0.7344        \u001b[35m0.5381\u001b[0m  0.0402\n",
      "     46        0.5597       0.7500        \u001b[35m0.5379\u001b[0m  0.0620\n",
      "     47        0.5568       0.7422        \u001b[35m0.5373\u001b[0m  0.1226\n",
      "     48        0.5778       0.7422        \u001b[35m0.5365\u001b[0m  0.0726\n",
      "     49        0.5539       0.7422        \u001b[35m0.5350\u001b[0m  0.0437\n",
      "     50        0.5480       0.7500        \u001b[35m0.5345\u001b[0m  0.0383\n",
      "     51        0.5543       0.7422        \u001b[35m0.5330\u001b[0m  0.0382\n",
      "     52        0.5569       0.7422        \u001b[35m0.5325\u001b[0m  0.0474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     53        0.5632       0.7422        \u001b[35m0.5313\u001b[0m  0.0397\n",
      "     54        0.5679       0.7422        0.5314  0.0388\n",
      "     55        0.5705       0.7422        \u001b[35m0.5304\u001b[0m  0.0470\n",
      "     56        0.5481       0.7422        \u001b[35m0.5291\u001b[0m  0.0373\n",
      "     57        0.5465       0.7422        \u001b[35m0.5287\u001b[0m  0.0393\n",
      "     58        0.5683       0.7422        \u001b[35m0.5284\u001b[0m  0.0382\n",
      "     59        0.5495       0.7500        \u001b[35m0.5269\u001b[0m  0.0379\n",
      "     60        0.5415       0.7422        \u001b[35m0.5253\u001b[0m  0.0394\n",
      "     61        0.5653       0.7422        0.5257  0.0372\n",
      "     62        0.5513       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5249\u001b[0m  0.0379\n",
      "     63        0.5505       0.7422        \u001b[35m0.5232\u001b[0m  0.0383\n",
      "     64        0.5692       0.7578        0.5239  0.0557\n",
      "     65        0.5633       0.7422        0.5240  0.0450\n",
      "     66        0.5422       0.7500        \u001b[35m0.5229\u001b[0m  0.0498\n",
      "     67        0.5689       0.7422        \u001b[35m0.5229\u001b[0m  0.0499\n",
      "     68        0.5554       0.7500        \u001b[35m0.5218\u001b[0m  0.0376\n",
      "     69        0.5470       0.7500        \u001b[35m0.5213\u001b[0m  0.0381\n",
      "     70        0.5539       0.7500        \u001b[35m0.5210\u001b[0m  0.0379\n",
      "     71        0.5468       0.7500        \u001b[35m0.5189\u001b[0m  0.0385\n",
      "     72        0.5527       0.7500        \u001b[35m0.5184\u001b[0m  0.0378\n",
      "     73        \u001b[36m0.5400\u001b[0m       0.7500        \u001b[35m0.5180\u001b[0m  0.0379\n",
      "     74        0.5533       0.7500        0.5180  0.0386\n",
      "     75        0.5492       0.7422        \u001b[35m0.5178\u001b[0m  0.0378\n",
      "     76        \u001b[36m0.5315\u001b[0m       0.7422        \u001b[35m0.5171\u001b[0m  0.0396\n",
      "     77        0.5493       0.7422        \u001b[35m0.5170\u001b[0m  0.0375\n",
      "     78        0.5393       0.7422        \u001b[35m0.5161\u001b[0m  0.0379\n",
      "     79        0.5416       0.7422        \u001b[35m0.5161\u001b[0m  0.0382\n",
      "     80        0.5456       0.7422        \u001b[35m0.5159\u001b[0m  0.0401\n",
      "     81        0.5509       0.7500        \u001b[35m0.5158\u001b[0m  0.0380\n",
      "     82        0.5402       0.7422        \u001b[35m0.5152\u001b[0m  0.0377\n",
      "     83        0.5559       0.7422        \u001b[35m0.5146\u001b[0m  0.0382\n",
      "     84        0.5374       0.7500        \u001b[35m0.5137\u001b[0m  0.0375\n",
      "     85        0.5395       0.7500        \u001b[35m0.5130\u001b[0m  0.0379\n",
      "     86        0.5431       0.7500        \u001b[35m0.5127\u001b[0m  0.0381\n",
      "     87        \u001b[36m0.5223\u001b[0m       0.7422        0.5127  0.0380\n",
      "     88        0.5398       0.7500        \u001b[35m0.5123\u001b[0m  0.0384\n",
      "     89        0.5538       0.7500        \u001b[35m0.5122\u001b[0m  0.0381\n",
      "     90        0.5502       0.7500        \u001b[35m0.5118\u001b[0m  0.0376\n",
      "     91        0.5294       0.7500        \u001b[35m0.5114\u001b[0m  0.0387\n",
      "     92        0.5469       \u001b[32m0.7656\u001b[0m        0.5120  0.0378\n",
      "     93        0.5469       0.7656        \u001b[35m0.5112\u001b[0m  0.0378\n",
      "     94        0.5331       0.7656        \u001b[35m0.5110\u001b[0m  0.0382\n",
      "     95        \u001b[36m0.5218\u001b[0m       0.7500        \u001b[35m0.5102\u001b[0m  0.0380\n",
      "     96        0.5414       0.7500        \u001b[35m0.5091\u001b[0m  0.0381\n",
      "     97        0.5405       0.7500        0.5092  0.0377\n",
      "     98        0.5346       0.7656        \u001b[35m0.5090\u001b[0m  0.0388\n",
      "     99        0.5443       0.7578        \u001b[35m0.5086\u001b[0m  0.0378\n",
      "    100        0.5352       0.7578        \u001b[35m0.5080\u001b[0m  0.0376\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7088\u001b[0m       \u001b[32m0.3516\u001b[0m        \u001b[35m0.7078\u001b[0m  0.0372\n",
      "      2        \u001b[36m0.7079\u001b[0m       \u001b[32m0.3672\u001b[0m        \u001b[35m0.7037\u001b[0m  0.0415\n",
      "      3        \u001b[36m0.7021\u001b[0m       \u001b[32m0.3906\u001b[0m        \u001b[35m0.7002\u001b[0m  0.0472\n",
      "      4        \u001b[36m0.7009\u001b[0m       \u001b[32m0.4219\u001b[0m        \u001b[35m0.6969\u001b[0m  0.0382\n",
      "      5        \u001b[36m0.6958\u001b[0m       \u001b[32m0.4609\u001b[0m        \u001b[35m0.6933\u001b[0m  0.0416\n",
      "      6        \u001b[36m0.6928\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6892\u001b[0m  0.0467\n",
      "      7        \u001b[36m0.6901\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6853\u001b[0m  0.0380\n",
      "      8        \u001b[36m0.6877\u001b[0m       0.6094        \u001b[35m0.6814\u001b[0m  0.0401\n",
      "      9        \u001b[36m0.6828\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6763\u001b[0m  0.0465\n",
      "     10        \u001b[36m0.6772\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6708\u001b[0m  0.0393\n",
      "     11        \u001b[36m0.6725\u001b[0m       0.6562        \u001b[35m0.6652\u001b[0m  0.0391\n",
      "     12        \u001b[36m0.6704\u001b[0m       0.6641        \u001b[35m0.6594\u001b[0m  0.0412\n",
      "     13        \u001b[36m0.6592\u001b[0m       0.6562        \u001b[35m0.6518\u001b[0m  0.0443\n",
      "     14        \u001b[36m0.6564\u001b[0m       0.6641        \u001b[35m0.6448\u001b[0m  0.0385\n",
      "     15        \u001b[36m0.6466\u001b[0m       0.6562        \u001b[35m0.6381\u001b[0m  0.0422\n",
      "     16        \u001b[36m0.6323\u001b[0m       0.6641        \u001b[35m0.6299\u001b[0m  0.0444\n",
      "     17        0.6418       0.6641        \u001b[35m0.6238\u001b[0m  0.0494\n",
      "     18        \u001b[36m0.6161\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6167\u001b[0m  0.0468\n",
      "     19        0.6321       0.6719        \u001b[35m0.6125\u001b[0m  0.0452\n",
      "     20        0.6210       0.6719        \u001b[35m0.6081\u001b[0m  0.0481\n",
      "     21        0.6291       0.6719        \u001b[35m0.6051\u001b[0m  0.0457\n",
      "     22        0.6171       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6015\u001b[0m  0.0392\n",
      "     23        \u001b[36m0.6069\u001b[0m       0.6875        \u001b[35m0.5977\u001b[0m  0.0408\n",
      "     24        0.6215       0.6875        \u001b[35m0.5941\u001b[0m  0.0414\n",
      "     25        0.6097       0.6875        \u001b[35m0.5913\u001b[0m  0.0417\n",
      "     26        \u001b[36m0.6011\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.5890\u001b[0m  0.0427\n",
      "     27        0.6088       0.6953        \u001b[35m0.5867\u001b[0m  0.0478\n",
      "     28        0.6028       0.6875        \u001b[35m0.5846\u001b[0m  0.0377\n",
      "     29        \u001b[36m0.5945\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.5824\u001b[0m  0.0409\n",
      "     30        0.6013       0.7031        \u001b[35m0.5807\u001b[0m  0.0394\n",
      "     31        0.5965       0.7031        \u001b[35m0.5791\u001b[0m  0.0398\n",
      "     32        0.5957       0.7031        \u001b[35m0.5776\u001b[0m  0.0479\n",
      "     33        \u001b[36m0.5918\u001b[0m       0.7031        \u001b[35m0.5763\u001b[0m  0.0367\n",
      "     34        \u001b[36m0.5727\u001b[0m       0.7031        \u001b[35m0.5749\u001b[0m  0.0496\n",
      "     35        \u001b[36m0.5700\u001b[0m       0.7109        \u001b[35m0.5741\u001b[0m  0.0371\n",
      "     36        0.5816       0.7109        \u001b[35m0.5721\u001b[0m  0.0433\n",
      "     37        0.5871       0.7109        \u001b[35m0.5716\u001b[0m  0.0375\n",
      "     38        0.5797       0.7109        \u001b[35m0.5700\u001b[0m  0.0386\n",
      "     39        0.5718       \u001b[32m0.7188\u001b[0m        \u001b[35m0.5682\u001b[0m  0.0645\n",
      "     40        0.5753       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5678\u001b[0m  0.0550\n",
      "     41        0.5847       0.7266        \u001b[35m0.5676\u001b[0m  0.0497\n",
      "     42        0.5885       0.7266        \u001b[35m0.5666\u001b[0m  0.0421\n",
      "     43        0.5836       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5651\u001b[0m  0.0507\n",
      "     44        0.5759       0.7344        \u001b[35m0.5649\u001b[0m  0.0381\n",
      "     45        \u001b[36m0.5617\u001b[0m       0.7422        \u001b[35m0.5638\u001b[0m  0.0436\n",
      "     46        \u001b[36m0.5513\u001b[0m       0.7422        \u001b[35m0.5620\u001b[0m  0.0411\n",
      "     47        0.5654       0.7344        \u001b[35m0.5609\u001b[0m  0.0409\n",
      "     48        0.5707       0.7344        \u001b[35m0.5607\u001b[0m  0.0465\n",
      "     49        0.5541       0.7344        \u001b[35m0.5601\u001b[0m  0.0484\n",
      "     50        0.5581       0.7344        \u001b[35m0.5599\u001b[0m  0.0443\n",
      "     51        0.5618       0.7344        \u001b[35m0.5591\u001b[0m  0.0494\n",
      "     52        0.5768       0.7266        \u001b[35m0.5586\u001b[0m  0.0572\n",
      "     53        0.5539       0.7344        0.5587  0.0459\n",
      "     54        0.5595       0.7266        \u001b[35m0.5582\u001b[0m  0.0425\n",
      "     55        0.5549       0.7266        0.5582  0.0441\n",
      "     56        \u001b[36m0.5500\u001b[0m       0.7266        \u001b[35m0.5574\u001b[0m  0.0466\n",
      "     57        \u001b[36m0.5333\u001b[0m       0.7188        \u001b[35m0.5568\u001b[0m  0.0462\n",
      "     58        0.5583       0.7188        \u001b[35m0.5555\u001b[0m  0.0482\n",
      "     59        0.5445       0.7188        \u001b[35m0.5554\u001b[0m  0.0552\n",
      "     60        0.5539       0.7188        \u001b[35m0.5552\u001b[0m  0.0463\n",
      "     61        0.5363       0.7188        0.5559  0.0442\n",
      "     62        0.5478       0.7188        \u001b[35m0.5548\u001b[0m  0.0460\n",
      "     63        0.5525       0.7188        \u001b[35m0.5547\u001b[0m  0.0455\n",
      "     64        0.5452       0.7188        \u001b[35m0.5542\u001b[0m  0.0449\n",
      "     65        0.5501       0.7188        \u001b[35m0.5533\u001b[0m  0.0508\n",
      "     66        0.5545       0.7266        \u001b[35m0.5527\u001b[0m  0.0435\n",
      "     67        0.5562       0.7188        0.5531  0.0588\n",
      "     68        0.5583       0.7188        0.5537  0.0511\n",
      "     69        0.5442       0.7188        0.5528  0.0443\n",
      "     70        0.5516       0.7188        \u001b[35m0.5522\u001b[0m  0.0452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     71        0.5563       0.7188        \u001b[35m0.5520\u001b[0m  0.0484\n",
      "     72        0.5419       0.7188        0.5522  0.0466\n",
      "     73        \u001b[36m0.5277\u001b[0m       0.7188        \u001b[35m0.5516\u001b[0m  0.0474\n",
      "     74        0.5339       0.7188        \u001b[35m0.5510\u001b[0m  0.0534\n",
      "     75        0.5579       0.7109        \u001b[35m0.5508\u001b[0m  0.1145\n",
      "     76        0.5467       0.7109        0.5509  0.0537\n",
      "     77        0.5433       0.7109        0.5516  0.0418\n",
      "     78        0.5529       0.7109        \u001b[35m0.5506\u001b[0m  0.0423\n",
      "     79        0.5485       0.7188        \u001b[35m0.5500\u001b[0m  0.0432\n",
      "     80        0.5406       0.7109        0.5510  0.0400\n",
      "     81        0.5306       0.7109        0.5507  0.0471\n",
      "     82        0.5362       0.7188        0.5501  0.0670\n",
      "     83        0.5517       0.7188        \u001b[35m0.5496\u001b[0m  0.0462\n",
      "     84        \u001b[36m0.5265\u001b[0m       0.7031        \u001b[35m0.5495\u001b[0m  0.0507\n",
      "     85        0.5385       0.7109        \u001b[35m0.5488\u001b[0m  0.0621\n",
      "     86        0.5466       0.7109        \u001b[35m0.5487\u001b[0m  0.0519\n",
      "     87        0.5274       0.7188        \u001b[35m0.5484\u001b[0m  0.0485\n",
      "     88        0.5266       0.7188        \u001b[35m0.5482\u001b[0m  0.0448\n",
      "     89        0.5405       0.7109        \u001b[35m0.5478\u001b[0m  0.0454\n",
      "     90        0.5366       0.7109        \u001b[35m0.5472\u001b[0m  0.0612\n",
      "     91        \u001b[36m0.5180\u001b[0m       0.7109        \u001b[35m0.5468\u001b[0m  0.0451\n",
      "     92        0.5228       0.7188        0.5471  0.0412\n",
      "     93        0.5371       0.7109        \u001b[35m0.5465\u001b[0m  0.0504\n",
      "     94        0.5343       0.7188        \u001b[35m0.5455\u001b[0m  0.0773\n",
      "     95        0.5284       0.7188        0.5462  0.0401\n",
      "     96        0.5259       0.7266        0.5473  0.0396\n",
      "     97        0.5272       0.7188        0.5468  0.0489\n",
      "     98        0.5367       0.7109        0.5467  0.0895\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7233\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.7007\u001b[0m  0.0768\n",
      "      2        \u001b[36m0.6946\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6732\u001b[0m  0.0548\n",
      "      3        \u001b[36m0.6830\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6557\u001b[0m  0.1672\n",
      "      4        \u001b[36m0.6496\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6412\u001b[0m  0.1837\n",
      "      5        \u001b[36m0.6444\u001b[0m       0.7266        \u001b[35m0.6315\u001b[0m  0.0825\n",
      "      6        \u001b[36m0.6181\u001b[0m       0.7188        \u001b[35m0.6228\u001b[0m  0.1012\n",
      "      7        0.6221       0.7188        \u001b[35m0.6158\u001b[0m  0.1557\n",
      "      8        \u001b[36m0.6120\u001b[0m       0.7031        \u001b[35m0.6103\u001b[0m  0.1089\n",
      "      9        \u001b[36m0.6053\u001b[0m       0.7188        \u001b[35m0.6050\u001b[0m  0.1131\n",
      "     10        0.6121       0.7109        \u001b[35m0.6007\u001b[0m  0.0538\n",
      "     11        \u001b[36m0.5903\u001b[0m       0.7188        \u001b[35m0.5973\u001b[0m  0.0426\n",
      "     12        0.6195       0.7188        \u001b[35m0.5947\u001b[0m  0.0469\n",
      "     13        0.5970       0.7188        \u001b[35m0.5923\u001b[0m  0.0451\n",
      "     14        0.6001       0.7109        \u001b[35m0.5903\u001b[0m  0.0414\n",
      "     15        0.5978       0.7031        \u001b[35m0.5894\u001b[0m  0.0966\n",
      "     16        \u001b[36m0.5884\u001b[0m       0.6953        \u001b[35m0.5880\u001b[0m  0.1391\n",
      "     17        0.6132       0.7031        \u001b[35m0.5873\u001b[0m  0.0752\n",
      "     18        \u001b[36m0.5834\u001b[0m       0.6953        \u001b[35m0.5859\u001b[0m  0.0943\n",
      "     19        \u001b[36m0.5752\u001b[0m       0.6875        \u001b[35m0.5856\u001b[0m  0.0496\n",
      "     20        \u001b[36m0.5744\u001b[0m       0.6875        \u001b[35m0.5845\u001b[0m  0.0512\n",
      "     21        0.5764       0.6875        0.5847  0.1428\n",
      "     22        0.5806       0.6953        0.5853  0.0883\n",
      "     23        \u001b[36m0.5678\u001b[0m       0.6953        0.5860  0.0583\n",
      "     24        0.5741       0.6875        0.5866  0.0534\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7188\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6962\u001b[0m  0.0388\n",
      "      2        \u001b[36m0.7051\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6878\u001b[0m  0.0444\n",
      "      3        \u001b[36m0.6985\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6826\u001b[0m  0.0412\n",
      "      4        \u001b[36m0.6927\u001b[0m       0.6016        \u001b[35m0.6788\u001b[0m  0.0502\n",
      "      5        \u001b[36m0.6914\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6756\u001b[0m  0.0383\n",
      "      6        \u001b[36m0.6868\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6727\u001b[0m  0.0500\n",
      "      7        \u001b[36m0.6781\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6693\u001b[0m  0.0407\n",
      "      8        \u001b[36m0.6770\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6656\u001b[0m  0.1637\n",
      "      9        \u001b[36m0.6743\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6624\u001b[0m  0.0829\n",
      "     10        \u001b[36m0.6718\u001b[0m       0.6953        \u001b[35m0.6586\u001b[0m  0.0822\n",
      "     11        \u001b[36m0.6689\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6549\u001b[0m  0.0456\n",
      "     12        \u001b[36m0.6651\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6509\u001b[0m  0.0479\n",
      "     13        \u001b[36m0.6510\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6456\u001b[0m  0.0416\n",
      "     14        0.6560       0.7188        \u001b[35m0.6409\u001b[0m  0.0441\n",
      "     15        \u001b[36m0.6483\u001b[0m       0.7266        \u001b[35m0.6360\u001b[0m  0.0391\n",
      "     16        0.6506       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6310\u001b[0m  0.0424\n",
      "     17        \u001b[36m0.6313\u001b[0m       0.7344        \u001b[35m0.6245\u001b[0m  0.0426\n",
      "     18        \u001b[36m0.6295\u001b[0m       0.7344        \u001b[35m0.6186\u001b[0m  0.0438\n",
      "     19        0.6305       0.7344        \u001b[35m0.6126\u001b[0m  0.0515\n",
      "     20        \u001b[36m0.6178\u001b[0m       0.7344        \u001b[35m0.6061\u001b[0m  0.0471\n",
      "     21        \u001b[36m0.6066\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5993\u001b[0m  0.0389\n",
      "     22        \u001b[36m0.6024\u001b[0m       0.7422        \u001b[35m0.5932\u001b[0m  0.0385\n",
      "     23        \u001b[36m0.5937\u001b[0m       0.7422        \u001b[35m0.5866\u001b[0m  0.0413\n",
      "     24        \u001b[36m0.5876\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5808\u001b[0m  0.0405\n",
      "     25        \u001b[36m0.5849\u001b[0m       0.7500        \u001b[35m0.5769\u001b[0m  0.0427\n",
      "     26        0.5868       0.7500        \u001b[35m0.5732\u001b[0m  0.0435\n",
      "     27        \u001b[36m0.5586\u001b[0m       0.7422        \u001b[35m0.5681\u001b[0m  0.0422\n",
      "     28        0.5596       0.7422        \u001b[35m0.5647\u001b[0m  0.0533\n",
      "     29        \u001b[36m0.5442\u001b[0m       0.7422        \u001b[35m0.5616\u001b[0m  0.0713\n",
      "     30        0.5752       0.7422        \u001b[35m0.5604\u001b[0m  0.0458\n",
      "     31        0.5443       0.7422        \u001b[35m0.5591\u001b[0m  0.0408\n",
      "     32        \u001b[36m0.5348\u001b[0m       0.7422        \u001b[35m0.5564\u001b[0m  0.0414\n",
      "     33        0.5422       0.7422        \u001b[35m0.5554\u001b[0m  0.0416\n",
      "     34        0.5539       0.7422        \u001b[35m0.5552\u001b[0m  0.0405\n",
      "     35        0.5416       0.7422        \u001b[35m0.5538\u001b[0m  0.0393\n",
      "     36        0.5381       0.7344        \u001b[35m0.5535\u001b[0m  0.0788\n",
      "     37        0.5537       0.7344        \u001b[35m0.5522\u001b[0m  0.1123\n",
      "     38        \u001b[36m0.5274\u001b[0m       0.7344        0.5526  0.0694\n",
      "     39        \u001b[36m0.5237\u001b[0m       0.7344        \u001b[35m0.5519\u001b[0m  0.0642\n",
      "     40        0.5278       0.7266        \u001b[35m0.5506\u001b[0m  0.1123\n",
      "     41        \u001b[36m0.5058\u001b[0m       0.7188        0.5513  0.1340\n",
      "     42        0.5382       0.7188        \u001b[35m0.5499\u001b[0m  0.0920\n",
      "     43        0.5203       0.7188        \u001b[35m0.5494\u001b[0m  0.0821\n",
      "     44        0.5280       0.7188        0.5496  0.0608\n",
      "     45        0.5212       0.7266        \u001b[35m0.5483\u001b[0m  0.0719\n",
      "     46        0.5226       0.7266        0.5484  0.0475\n",
      "     47        0.5154       0.7188        0.5492  0.0393\n",
      "     48        0.5247       0.7188        \u001b[35m0.5477\u001b[0m  0.0381\n",
      "     49        0.5067       0.7188        0.5481  0.0507\n",
      "     50        0.5297       0.7188        \u001b[35m0.5476\u001b[0m  0.0487\n",
      "     51        0.5100       0.7344        \u001b[35m0.5471\u001b[0m  0.0483\n",
      "     52        0.5304       0.7344        \u001b[35m0.5459\u001b[0m  0.0432\n",
      "     53        \u001b[36m0.4992\u001b[0m       0.7344        \u001b[35m0.5457\u001b[0m  0.0419\n",
      "     54        0.5202       0.7344        \u001b[35m0.5452\u001b[0m  0.0383\n",
      "     55        0.5069       0.7344        0.5457  0.0382\n",
      "     56        0.5189       0.7344        0.5453  0.0382\n",
      "     57        0.5291       0.7344        \u001b[35m0.5439\u001b[0m  0.0861\n",
      "     58        0.5177       0.7344        0.5440  0.0973\n",
      "     59        \u001b[36m0.4907\u001b[0m       0.7344        0.5445  0.0693\n",
      "     60        0.5131       0.7266        0.5447  0.0805\n",
      "     61        0.5076       0.7266        0.5441  0.0675\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.1776\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m7.9524\u001b[0m  0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        7.0911       0.5000        7.9712  0.0139\n",
      "      3        7.1994       0.5000        7.9712  0.0160\n",
      "      4        6.6945       0.5000        7.9712  0.0304\n",
      "      5        6.5648       0.5000        7.9712  0.0156\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0142\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m2.8167\u001b[0m  0.0189\n",
      "      2        4.0307       0.5000        \u001b[35m0.8210\u001b[0m  0.0235\n",
      "      3        1.3299       0.5000        1.6338  0.0277\n",
      "      4        2.9489       0.5000        0.8399  0.0250\n",
      "      5        2.2101       0.5000        1.1010  0.0226\n",
      "      6        2.4153       0.5000        1.1146  0.0236\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8217\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.2891\u001b[0m  0.0614\n",
      "      2        1.6061       0.5000        \u001b[35m0.8605\u001b[0m  0.0368\n",
      "      3        1.7596       0.5000        \u001b[35m0.7159\u001b[0m  0.0769\n",
      "      4        1.2550       0.5000        0.7304  0.1058\n",
      "      5        1.2738       0.5000        0.8225  0.0392\n",
      "      6        1.5131       0.5000        0.7173  0.0536\n",
      "      7        1.4240       0.5000        \u001b[35m0.7132\u001b[0m  0.0719\n",
      "      8        1.3511       0.5000        0.7457  0.0298\n",
      "      9        1.4028       0.5000        0.7398  0.0383\n",
      "     10        1.4227       0.5000        0.7258  0.0193\n",
      "     11        1.3953       0.5000        0.7312  0.0214\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7869\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.9126\u001b[0m  0.0348\n",
      "      2        1.8893       0.5000        \u001b[35m1.3600\u001b[0m  0.0287\n",
      "      3        1.6925       0.5000        \u001b[35m0.8469\u001b[0m  0.0170\n",
      "      4        1.0353       0.5000        1.2712  0.0181\n",
      "      5        1.3424       0.5000        1.4643  0.0403\n",
      "      6        1.5783       0.5000        1.1783  0.0269\n",
      "      7        1.3651       0.5000        1.1990  0.0181\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5345\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m4.2856\u001b[0m  0.0208\n",
      "      2        2.2254       0.5000        5.9758  0.0174\n",
      "      3        3.8677       0.5000        \u001b[35m0.6931\u001b[0m  0.0173\n",
      "      4        0.8448       0.5000        1.8071  0.0230\n",
      "      5        2.3837       0.5000        0.9937  0.0216\n",
      "      6        1.8474       0.5000        0.9837  0.0167\n",
      "      7        1.6111       0.5000        1.3368  0.0255\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7126\u001b[0m       \u001b[32m0.3906\u001b[0m        \u001b[35m0.7119\u001b[0m  0.0229\n",
      "      2        \u001b[36m0.7089\u001b[0m       0.3906        \u001b[35m0.7082\u001b[0m  0.0340\n",
      "      3        \u001b[36m0.7063\u001b[0m       \u001b[32m0.4141\u001b[0m        \u001b[35m0.7051\u001b[0m  0.0322\n",
      "      4        \u001b[36m0.7042\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m0.7024\u001b[0m  0.0269\n",
      "      5        \u001b[36m0.7024\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m0.7001\u001b[0m  0.0295\n",
      "      6        \u001b[36m0.7009\u001b[0m       \u001b[32m0.4766\u001b[0m        \u001b[35m0.6980\u001b[0m  0.0299\n",
      "      7        \u001b[36m0.6995\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6961\u001b[0m  0.0302\n",
      "      8        \u001b[36m0.6984\u001b[0m       0.5000        \u001b[35m0.6944\u001b[0m  0.0416\n",
      "      9        \u001b[36m0.6973\u001b[0m       0.5000        \u001b[35m0.6929\u001b[0m  0.0322\n",
      "     10        \u001b[36m0.6963\u001b[0m       0.5000        \u001b[35m0.6914\u001b[0m  0.0325\n",
      "     11        \u001b[36m0.6954\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m0.6900\u001b[0m  0.0325\n",
      "     12        \u001b[36m0.6945\u001b[0m       0.4922        \u001b[35m0.6887\u001b[0m  0.0322\n",
      "     13        \u001b[36m0.6935\u001b[0m       0.5078        \u001b[35m0.6874\u001b[0m  0.0276\n",
      "     14        \u001b[36m0.6926\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6860\u001b[0m  0.0304\n",
      "     15        \u001b[36m0.6916\u001b[0m       0.5234        \u001b[35m0.6846\u001b[0m  0.0302\n",
      "     16        \u001b[36m0.6905\u001b[0m       0.5234        \u001b[35m0.6831\u001b[0m  0.0304\n",
      "     17        \u001b[36m0.6893\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6814\u001b[0m  0.0317\n",
      "     18        \u001b[36m0.6881\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6796\u001b[0m  0.0308\n",
      "     19        \u001b[36m0.6867\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6777\u001b[0m  0.0412\n",
      "     20        \u001b[36m0.6851\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6755\u001b[0m  0.1171\n",
      "     21        \u001b[36m0.6835\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6730\u001b[0m  0.0482\n",
      "     22        \u001b[36m0.6816\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6703\u001b[0m  0.0526\n",
      "     23        \u001b[36m0.6796\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6674\u001b[0m  0.0727\n",
      "     24        \u001b[36m0.6773\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6641\u001b[0m  0.0602\n",
      "     25        \u001b[36m0.6747\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6606\u001b[0m  0.0339\n",
      "     26        \u001b[36m0.6718\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6568\u001b[0m  0.0550\n",
      "     27        \u001b[36m0.6686\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6526\u001b[0m  0.0384\n",
      "     28        \u001b[36m0.6651\u001b[0m       0.6953        \u001b[35m0.6480\u001b[0m  0.0328\n",
      "     29        \u001b[36m0.6613\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6432\u001b[0m  0.0255\n",
      "     30        \u001b[36m0.6572\u001b[0m       0.7109        \u001b[35m0.6380\u001b[0m  0.0226\n",
      "     31        \u001b[36m0.6528\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6323\u001b[0m  0.0301\n",
      "     32        \u001b[36m0.6481\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6263\u001b[0m  0.0256\n",
      "     33        \u001b[36m0.6430\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6200\u001b[0m  0.0317\n",
      "     34        \u001b[36m0.6378\u001b[0m       0.7344        \u001b[35m0.6135\u001b[0m  0.0300\n",
      "     35        \u001b[36m0.6324\u001b[0m       0.7344        \u001b[35m0.6067\u001b[0m  0.0234\n",
      "     36        \u001b[36m0.6269\u001b[0m       0.7344        \u001b[35m0.5996\u001b[0m  0.0419\n",
      "     37        \u001b[36m0.6212\u001b[0m       0.7422        \u001b[35m0.5923\u001b[0m  0.0254\n",
      "     38        \u001b[36m0.6153\u001b[0m       0.7344        \u001b[35m0.5847\u001b[0m  0.0231\n",
      "     39        \u001b[36m0.6095\u001b[0m       0.7266        \u001b[35m0.5769\u001b[0m  0.0365\n",
      "     40        \u001b[36m0.6036\u001b[0m       0.7344        \u001b[35m0.5691\u001b[0m  0.0861\n",
      "     41        \u001b[36m0.5978\u001b[0m       0.7422        \u001b[35m0.5613\u001b[0m  0.0805\n",
      "     42        \u001b[36m0.5920\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5534\u001b[0m  0.0374\n",
      "     43        \u001b[36m0.5864\u001b[0m       0.7500        \u001b[35m0.5457\u001b[0m  0.0581\n",
      "     44        \u001b[36m0.5809\u001b[0m       0.7500        \u001b[35m0.5381\u001b[0m  0.0314\n",
      "     45        \u001b[36m0.5755\u001b[0m       \u001b[32m0.7656\u001b[0m        \u001b[35m0.5307\u001b[0m  0.0244\n",
      "     46        \u001b[36m0.5704\u001b[0m       0.7656        \u001b[35m0.5236\u001b[0m  0.0337\n",
      "     47        \u001b[36m0.5657\u001b[0m       \u001b[32m0.7734\u001b[0m        \u001b[35m0.5167\u001b[0m  0.0365\n",
      "     48        \u001b[36m0.5613\u001b[0m       0.7734        \u001b[35m0.5103\u001b[0m  0.0372\n",
      "     49        \u001b[36m0.5572\u001b[0m       \u001b[32m0.7812\u001b[0m        \u001b[35m0.5042\u001b[0m  0.0285\n",
      "     50        \u001b[36m0.5536\u001b[0m       0.7812        \u001b[35m0.4985\u001b[0m  0.0353\n",
      "     51        \u001b[36m0.5502\u001b[0m       0.7734        \u001b[35m0.4932\u001b[0m  0.0384\n",
      "     52        \u001b[36m0.5472\u001b[0m       0.7656        \u001b[35m0.4882\u001b[0m  0.0597\n",
      "     53        \u001b[36m0.5445\u001b[0m       0.7578        \u001b[35m0.4837\u001b[0m  0.0394\n",
      "     54        \u001b[36m0.5420\u001b[0m       0.7578        \u001b[35m0.4794\u001b[0m  0.0378\n",
      "     55        \u001b[36m0.5398\u001b[0m       0.7656        \u001b[35m0.4754\u001b[0m  0.0384\n",
      "     56        \u001b[36m0.5378\u001b[0m       0.7656        \u001b[35m0.4717\u001b[0m  0.0324\n",
      "     57        \u001b[36m0.5360\u001b[0m       0.7656        \u001b[35m0.4683\u001b[0m  0.0348\n",
      "     58        \u001b[36m0.5345\u001b[0m       0.7578        \u001b[35m0.4651\u001b[0m  0.0294\n",
      "     59        \u001b[36m0.5330\u001b[0m       0.7578        \u001b[35m0.4622\u001b[0m  0.0370\n",
      "     60        \u001b[36m0.5317\u001b[0m       0.7578        \u001b[35m0.4595\u001b[0m  0.0625\n",
      "     61        \u001b[36m0.5305\u001b[0m       0.7578        \u001b[35m0.4570\u001b[0m  0.0826\n",
      "     62        \u001b[36m0.5294\u001b[0m       0.7578        \u001b[35m0.4547\u001b[0m  0.0359\n",
      "     63        \u001b[36m0.5285\u001b[0m       0.7656        \u001b[35m0.4525\u001b[0m  0.0330\n",
      "     64        \u001b[36m0.5276\u001b[0m       0.7656        \u001b[35m0.4505\u001b[0m  0.0542\n",
      "     65        \u001b[36m0.5268\u001b[0m       0.7656        \u001b[35m0.4486\u001b[0m  0.0517\n",
      "     66        \u001b[36m0.5261\u001b[0m       0.7656        \u001b[35m0.4468\u001b[0m  0.0393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     67        \u001b[36m0.5254\u001b[0m       0.7656        \u001b[35m0.4452\u001b[0m  0.0439\n",
      "     68        \u001b[36m0.5248\u001b[0m       0.7734        \u001b[35m0.4436\u001b[0m  0.0343\n",
      "     69        \u001b[36m0.5242\u001b[0m       0.7734        \u001b[35m0.4422\u001b[0m  0.0315\n",
      "     70        \u001b[36m0.5236\u001b[0m       0.7812        \u001b[35m0.4409\u001b[0m  0.0238\n",
      "     71        \u001b[36m0.5231\u001b[0m       0.7812        \u001b[35m0.4397\u001b[0m  0.0280\n",
      "     72        \u001b[36m0.5226\u001b[0m       0.7812        \u001b[35m0.4385\u001b[0m  0.0350\n",
      "     73        \u001b[36m0.5222\u001b[0m       \u001b[32m0.7891\u001b[0m        \u001b[35m0.4375\u001b[0m  0.0419\n",
      "     74        \u001b[36m0.5218\u001b[0m       0.7891        \u001b[35m0.4365\u001b[0m  0.0267\n",
      "     75        \u001b[36m0.5215\u001b[0m       0.7891        \u001b[35m0.4355\u001b[0m  0.0294\n",
      "     76        \u001b[36m0.5211\u001b[0m       0.7891        \u001b[35m0.4346\u001b[0m  0.0230\n",
      "     77        \u001b[36m0.5208\u001b[0m       0.7891        \u001b[35m0.4338\u001b[0m  0.0277\n",
      "     78        \u001b[36m0.5205\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4331\u001b[0m  0.0306\n",
      "     79        \u001b[36m0.5202\u001b[0m       0.7969        \u001b[35m0.4324\u001b[0m  0.0261\n",
      "     80        \u001b[36m0.5199\u001b[0m       0.7969        \u001b[35m0.4318\u001b[0m  0.0237\n",
      "     81        \u001b[36m0.5196\u001b[0m       0.7969        \u001b[35m0.4312\u001b[0m  0.0815\n",
      "     82        \u001b[36m0.5193\u001b[0m       0.7969        \u001b[35m0.4307\u001b[0m  0.0773\n",
      "     83        \u001b[36m0.5190\u001b[0m       0.7969        \u001b[35m0.4302\u001b[0m  0.0320\n",
      "     84        \u001b[36m0.5187\u001b[0m       0.7969        \u001b[35m0.4298\u001b[0m  0.0418\n",
      "     85        \u001b[36m0.5184\u001b[0m       0.7969        \u001b[35m0.4293\u001b[0m  0.0634\n",
      "     86        \u001b[36m0.5181\u001b[0m       0.7969        \u001b[35m0.4289\u001b[0m  0.0776\n",
      "     87        \u001b[36m0.5178\u001b[0m       0.7969        \u001b[35m0.4285\u001b[0m  0.0473\n",
      "     88        \u001b[36m0.5176\u001b[0m       0.7969        \u001b[35m0.4282\u001b[0m  0.1002\n",
      "     89        \u001b[36m0.5173\u001b[0m       0.7969        \u001b[35m0.4278\u001b[0m  0.0592\n",
      "     90        \u001b[36m0.5170\u001b[0m       0.7969        \u001b[35m0.4275\u001b[0m  0.0562\n",
      "     91        \u001b[36m0.5167\u001b[0m       0.7969        \u001b[35m0.4273\u001b[0m  0.0703\n",
      "     92        \u001b[36m0.5164\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4271\u001b[0m  0.0348\n",
      "     93        \u001b[36m0.5161\u001b[0m       0.8047        \u001b[35m0.4268\u001b[0m  0.0293\n",
      "     94        \u001b[36m0.5159\u001b[0m       0.8047        \u001b[35m0.4266\u001b[0m  0.0217\n",
      "     95        \u001b[36m0.5157\u001b[0m       0.8047        \u001b[35m0.4263\u001b[0m  0.0303\n",
      "     96        \u001b[36m0.5154\u001b[0m       0.8047        \u001b[35m0.4260\u001b[0m  0.0223\n",
      "     97        \u001b[36m0.5151\u001b[0m       0.8047        \u001b[35m0.4258\u001b[0m  0.0389\n",
      "     98        \u001b[36m0.5149\u001b[0m       \u001b[32m0.8125\u001b[0m        \u001b[35m0.4256\u001b[0m  0.0295\n",
      "     99        \u001b[36m0.5146\u001b[0m       0.8125        \u001b[35m0.4253\u001b[0m  0.0331\n",
      "    100        \u001b[36m0.5143\u001b[0m       0.8125        \u001b[35m0.4250\u001b[0m  0.0224\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6803\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6738\u001b[0m  0.0278\n",
      "      2        \u001b[36m0.6743\u001b[0m       0.5000        \u001b[35m0.6690\u001b[0m  0.0331\n",
      "      3        \u001b[36m0.6691\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6645\u001b[0m  0.0455\n",
      "      4        \u001b[36m0.6641\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6602\u001b[0m  0.0629\n",
      "      5        \u001b[36m0.6592\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6559\u001b[0m  0.0362\n",
      "      6        \u001b[36m0.6543\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6513\u001b[0m  0.0617\n",
      "      7        \u001b[36m0.6491\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6466\u001b[0m  0.0566\n",
      "      8        \u001b[36m0.6439\u001b[0m       0.7031        \u001b[35m0.6418\u001b[0m  0.0333\n",
      "      9        \u001b[36m0.6386\u001b[0m       0.7109        \u001b[35m0.6369\u001b[0m  0.0622\n",
      "     10        \u001b[36m0.6330\u001b[0m       0.7109        \u001b[35m0.6317\u001b[0m  0.0970\n",
      "     11        \u001b[36m0.6274\u001b[0m       0.7031        \u001b[35m0.6264\u001b[0m  0.0575\n",
      "     12        \u001b[36m0.6218\u001b[0m       0.7031        \u001b[35m0.6211\u001b[0m  0.0564\n",
      "     13        \u001b[36m0.6162\u001b[0m       0.7109        \u001b[35m0.6159\u001b[0m  0.0365\n",
      "     14        \u001b[36m0.6107\u001b[0m       0.7188        \u001b[35m0.6107\u001b[0m  0.0307\n",
      "     15        \u001b[36m0.6053\u001b[0m       0.7188        \u001b[35m0.6056\u001b[0m  0.0296\n",
      "     16        \u001b[36m0.6000\u001b[0m       0.7188        \u001b[35m0.6008\u001b[0m  0.0486\n",
      "     17        \u001b[36m0.5948\u001b[0m       0.7266        \u001b[35m0.5961\u001b[0m  0.0375\n",
      "     18        \u001b[36m0.5899\u001b[0m       0.7266        \u001b[35m0.5917\u001b[0m  0.0274\n",
      "     19        \u001b[36m0.5851\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5874\u001b[0m  0.0340\n",
      "     20        \u001b[36m0.5806\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5835\u001b[0m  0.0338\n",
      "     21        \u001b[36m0.5763\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5797\u001b[0m  0.0272\n",
      "     22        \u001b[36m0.5722\u001b[0m       0.7500        \u001b[35m0.5761\u001b[0m  0.0253\n",
      "     23        \u001b[36m0.5683\u001b[0m       0.7500        \u001b[35m0.5728\u001b[0m  0.0376\n",
      "     24        \u001b[36m0.5647\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.5697\u001b[0m  0.0416\n",
      "     25        \u001b[36m0.5613\u001b[0m       0.7500        \u001b[35m0.5668\u001b[0m  0.0760\n",
      "     26        \u001b[36m0.5580\u001b[0m       0.7422        \u001b[35m0.5641\u001b[0m  0.0742\n",
      "     27        \u001b[36m0.5548\u001b[0m       0.7422        \u001b[35m0.5614\u001b[0m  0.0676\n",
      "     28        \u001b[36m0.5518\u001b[0m       0.7422        \u001b[35m0.5590\u001b[0m  0.0660\n",
      "     29        \u001b[36m0.5489\u001b[0m       0.7422        \u001b[35m0.5567\u001b[0m  0.0341\n",
      "     30        \u001b[36m0.5463\u001b[0m       0.7422        \u001b[35m0.5546\u001b[0m  0.0334\n",
      "     31        \u001b[36m0.5438\u001b[0m       0.7422        \u001b[35m0.5526\u001b[0m  0.0264\n",
      "     32        \u001b[36m0.5414\u001b[0m       0.7422        \u001b[35m0.5508\u001b[0m  0.0328\n",
      "     33        \u001b[36m0.5393\u001b[0m       0.7422        \u001b[35m0.5490\u001b[0m  0.0334\n",
      "     34        \u001b[36m0.5372\u001b[0m       0.7422        \u001b[35m0.5473\u001b[0m  0.0416\n",
      "     35        \u001b[36m0.5352\u001b[0m       0.7422        \u001b[35m0.5457\u001b[0m  0.0332\n",
      "     36        \u001b[36m0.5334\u001b[0m       0.7422        \u001b[35m0.5442\u001b[0m  0.0353\n",
      "     37        \u001b[36m0.5316\u001b[0m       0.7422        \u001b[35m0.5427\u001b[0m  0.0311\n",
      "     38        \u001b[36m0.5300\u001b[0m       0.7344        \u001b[35m0.5413\u001b[0m  0.0286\n",
      "     39        \u001b[36m0.5285\u001b[0m       0.7266        \u001b[35m0.5400\u001b[0m  0.0326\n",
      "     40        \u001b[36m0.5270\u001b[0m       0.7266        \u001b[35m0.5388\u001b[0m  0.0270\n",
      "     41        \u001b[36m0.5257\u001b[0m       0.7266        \u001b[35m0.5377\u001b[0m  0.0329\n",
      "     42        \u001b[36m0.5244\u001b[0m       0.7266        \u001b[35m0.5366\u001b[0m  0.0423\n",
      "     43        \u001b[36m0.5232\u001b[0m       0.7266        \u001b[35m0.5356\u001b[0m  0.0378\n",
      "     44        \u001b[36m0.5220\u001b[0m       0.7266        \u001b[35m0.5346\u001b[0m  0.0373\n",
      "     45        \u001b[36m0.5210\u001b[0m       0.7266        \u001b[35m0.5337\u001b[0m  0.0297\n",
      "     46        \u001b[36m0.5199\u001b[0m       0.7266        \u001b[35m0.5328\u001b[0m  0.0305\n",
      "     47        \u001b[36m0.5190\u001b[0m       0.7266        \u001b[35m0.5319\u001b[0m  0.0316\n",
      "     48        \u001b[36m0.5180\u001b[0m       0.7266        \u001b[35m0.5311\u001b[0m  0.0401\n",
      "     49        \u001b[36m0.5171\u001b[0m       0.7266        \u001b[35m0.5303\u001b[0m  0.0470\n",
      "     50        \u001b[36m0.5163\u001b[0m       0.7266        \u001b[35m0.5295\u001b[0m  0.0513\n",
      "     51        \u001b[36m0.5155\u001b[0m       0.7266        \u001b[35m0.5287\u001b[0m  0.0433\n",
      "     52        \u001b[36m0.5148\u001b[0m       0.7344        \u001b[35m0.5280\u001b[0m  0.0419\n",
      "     53        \u001b[36m0.5141\u001b[0m       0.7344        \u001b[35m0.5273\u001b[0m  0.0345\n",
      "     54        \u001b[36m0.5135\u001b[0m       0.7344        \u001b[35m0.5266\u001b[0m  0.0361\n",
      "     55        \u001b[36m0.5129\u001b[0m       0.7344        \u001b[35m0.5259\u001b[0m  0.0580\n",
      "     56        \u001b[36m0.5123\u001b[0m       0.7344        \u001b[35m0.5252\u001b[0m  0.0479\n",
      "     57        \u001b[36m0.5118\u001b[0m       0.7344        \u001b[35m0.5245\u001b[0m  0.0432\n",
      "     58        \u001b[36m0.5112\u001b[0m       0.7344        \u001b[35m0.5239\u001b[0m  0.0691\n",
      "     59        \u001b[36m0.5108\u001b[0m       0.7344        \u001b[35m0.5233\u001b[0m  0.0799\n",
      "     60        \u001b[36m0.5103\u001b[0m       0.7344        \u001b[35m0.5228\u001b[0m  0.0308\n",
      "     61        \u001b[36m0.5099\u001b[0m       0.7422        \u001b[35m0.5222\u001b[0m  0.0288\n",
      "     62        \u001b[36m0.5095\u001b[0m       0.7422        \u001b[35m0.5217\u001b[0m  0.0299\n",
      "     63        \u001b[36m0.5091\u001b[0m       0.7422        \u001b[35m0.5212\u001b[0m  0.0321\n",
      "     64        \u001b[36m0.5088\u001b[0m       0.7500        \u001b[35m0.5207\u001b[0m  0.0250\n",
      "     65        \u001b[36m0.5085\u001b[0m       0.7500        \u001b[35m0.5202\u001b[0m  0.0409\n",
      "     66        \u001b[36m0.5081\u001b[0m       0.7500        \u001b[35m0.5198\u001b[0m  0.0252\n",
      "     67        \u001b[36m0.5078\u001b[0m       0.7500        \u001b[35m0.5193\u001b[0m  0.0330\n",
      "     68        \u001b[36m0.5075\u001b[0m       0.7422        \u001b[35m0.5188\u001b[0m  0.0310\n",
      "     69        \u001b[36m0.5071\u001b[0m       0.7422        \u001b[35m0.5184\u001b[0m  0.0347\n",
      "     70        \u001b[36m0.5068\u001b[0m       0.7422        \u001b[35m0.5180\u001b[0m  0.0634\n",
      "     71        \u001b[36m0.5065\u001b[0m       0.7422        \u001b[35m0.5176\u001b[0m  0.0606\n",
      "     72        \u001b[36m0.5062\u001b[0m       0.7422        \u001b[35m0.5172\u001b[0m  0.0491\n",
      "     73        \u001b[36m0.5060\u001b[0m       0.7422        \u001b[35m0.5168\u001b[0m  0.0658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     74        \u001b[36m0.5057\u001b[0m       0.7422        \u001b[35m0.5165\u001b[0m  0.0461\n",
      "     75        \u001b[36m0.5054\u001b[0m       0.7422        \u001b[35m0.5161\u001b[0m  0.0327\n",
      "     76        \u001b[36m0.5052\u001b[0m       0.7422        \u001b[35m0.5158\u001b[0m  0.0286\n",
      "     77        \u001b[36m0.5050\u001b[0m       0.7422        \u001b[35m0.5155\u001b[0m  0.0359\n",
      "     78        \u001b[36m0.5048\u001b[0m       0.7422        \u001b[35m0.5152\u001b[0m  0.0431\n",
      "     79        \u001b[36m0.5047\u001b[0m       0.7422        \u001b[35m0.5149\u001b[0m  0.0515\n",
      "     80        \u001b[36m0.5045\u001b[0m       0.7422        \u001b[35m0.5146\u001b[0m  0.0277\n",
      "     81        \u001b[36m0.5043\u001b[0m       0.7422        \u001b[35m0.5143\u001b[0m  0.0604\n",
      "     82        \u001b[36m0.5041\u001b[0m       0.7500        \u001b[35m0.5141\u001b[0m  0.0517\n",
      "     83        \u001b[36m0.5039\u001b[0m       0.7500        \u001b[35m0.5138\u001b[0m  0.0619\n",
      "     84        \u001b[36m0.5038\u001b[0m       0.7500        \u001b[35m0.5136\u001b[0m  0.0497\n",
      "     85        \u001b[36m0.5037\u001b[0m       0.7500        \u001b[35m0.5134\u001b[0m  0.0406\n",
      "     86        \u001b[36m0.5035\u001b[0m       0.7500        \u001b[35m0.5132\u001b[0m  0.0509\n",
      "     87        \u001b[36m0.5034\u001b[0m       0.7500        \u001b[35m0.5130\u001b[0m  0.0740\n",
      "     88        \u001b[36m0.5033\u001b[0m       0.7500        \u001b[35m0.5128\u001b[0m  0.0604\n",
      "     89        \u001b[36m0.5031\u001b[0m       0.7500        \u001b[35m0.5126\u001b[0m  0.0334\n",
      "     90        \u001b[36m0.5030\u001b[0m       0.7500        \u001b[35m0.5125\u001b[0m  0.0308\n",
      "     91        \u001b[36m0.5029\u001b[0m       0.7500        \u001b[35m0.5123\u001b[0m  0.0488\n",
      "     92        \u001b[36m0.5028\u001b[0m       0.7500        \u001b[35m0.5122\u001b[0m  0.0453\n",
      "     93        \u001b[36m0.5027\u001b[0m       0.7500        \u001b[35m0.5121\u001b[0m  0.0592\n",
      "     94        \u001b[36m0.5026\u001b[0m       0.7500        \u001b[35m0.5121\u001b[0m  0.0352\n",
      "     95        \u001b[36m0.5025\u001b[0m       0.7500        \u001b[35m0.5120\u001b[0m  0.0317\n",
      "     96        \u001b[36m0.5024\u001b[0m       0.7500        \u001b[35m0.5119\u001b[0m  0.0403\n",
      "     97        \u001b[36m0.5023\u001b[0m       0.7500        \u001b[35m0.5119\u001b[0m  0.0293\n",
      "     98        \u001b[36m0.5022\u001b[0m       0.7500        \u001b[35m0.5118\u001b[0m  0.0310\n",
      "     99        \u001b[36m0.5022\u001b[0m       0.7500        \u001b[35m0.5118\u001b[0m  0.0553\n",
      "    100        \u001b[36m0.5021\u001b[0m       0.7500        \u001b[35m0.5117\u001b[0m  0.0585\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6966\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6912\u001b[0m  0.0492\n",
      "      2        \u001b[36m0.6953\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6904\u001b[0m  0.0518\n",
      "      3        \u001b[36m0.6945\u001b[0m       0.5703        \u001b[35m0.6895\u001b[0m  0.0309\n",
      "      4        \u001b[36m0.6936\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6885\u001b[0m  0.0327\n",
      "      5        \u001b[36m0.6926\u001b[0m       0.5859        \u001b[35m0.6874\u001b[0m  0.0674\n",
      "      6        \u001b[36m0.6915\u001b[0m       0.5781        \u001b[35m0.6862\u001b[0m  0.0512\n",
      "      7        \u001b[36m0.6902\u001b[0m       0.5859        \u001b[35m0.6848\u001b[0m  0.0363\n",
      "      8        \u001b[36m0.6887\u001b[0m       0.5859        \u001b[35m0.6832\u001b[0m  0.0489\n",
      "      9        \u001b[36m0.6870\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.6814\u001b[0m  0.0632\n",
      "     10        \u001b[36m0.6851\u001b[0m       0.5938        \u001b[35m0.6792\u001b[0m  0.0723\n",
      "     11        \u001b[36m0.6828\u001b[0m       0.5938        \u001b[35m0.6768\u001b[0m  0.0436\n",
      "     12        \u001b[36m0.6802\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6740\u001b[0m  0.0352\n",
      "     13        \u001b[36m0.6772\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6708\u001b[0m  0.0523\n",
      "     14        \u001b[36m0.6738\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6670\u001b[0m  0.0663\n",
      "     15        \u001b[36m0.6697\u001b[0m       0.6562        \u001b[35m0.6628\u001b[0m  0.0642\n",
      "     16        \u001b[36m0.6651\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6580\u001b[0m  0.1190\n",
      "     17        \u001b[36m0.6598\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6524\u001b[0m  0.0376\n",
      "     18        \u001b[36m0.6540\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6463\u001b[0m  0.0534\n",
      "     19        \u001b[36m0.6477\u001b[0m       0.7031        \u001b[35m0.6400\u001b[0m  0.0760\n",
      "     20        \u001b[36m0.6410\u001b[0m       0.7188        \u001b[35m0.6335\u001b[0m  0.0621\n",
      "     21        \u001b[36m0.6341\u001b[0m       0.7109        \u001b[35m0.6266\u001b[0m  0.0586\n",
      "     22        \u001b[36m0.6270\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.6198\u001b[0m  0.0544\n",
      "     23        \u001b[36m0.6199\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.6128\u001b[0m  0.0641\n",
      "     24        \u001b[36m0.6128\u001b[0m       0.7422        \u001b[35m0.6058\u001b[0m  0.0450\n",
      "     25        \u001b[36m0.6059\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5988\u001b[0m  0.0325\n",
      "     26        \u001b[36m0.5991\u001b[0m       0.7422        \u001b[35m0.5921\u001b[0m  0.0431\n",
      "     27        \u001b[36m0.5925\u001b[0m       0.7422        \u001b[35m0.5857\u001b[0m  0.0515\n",
      "     28        \u001b[36m0.5860\u001b[0m       0.7422        \u001b[35m0.5796\u001b[0m  0.0392\n",
      "     29        \u001b[36m0.5799\u001b[0m       0.7344        \u001b[35m0.5739\u001b[0m  0.0495\n",
      "     30        \u001b[36m0.5743\u001b[0m       0.7266        \u001b[35m0.5686\u001b[0m  0.0454\n",
      "     31        \u001b[36m0.5690\u001b[0m       0.7266        \u001b[35m0.5637\u001b[0m  0.0569\n",
      "     32        \u001b[36m0.5642\u001b[0m       0.7344        \u001b[35m0.5591\u001b[0m  0.0453\n",
      "     33        \u001b[36m0.5597\u001b[0m       0.7422        \u001b[35m0.5550\u001b[0m  0.0237\n",
      "     34        \u001b[36m0.5555\u001b[0m       0.7422        \u001b[35m0.5511\u001b[0m  0.0814\n",
      "     35        \u001b[36m0.5515\u001b[0m       0.7422        \u001b[35m0.5476\u001b[0m  0.0827\n",
      "     36        \u001b[36m0.5480\u001b[0m       0.7422        \u001b[35m0.5445\u001b[0m  0.0578\n",
      "     37        \u001b[36m0.5447\u001b[0m       0.7422        \u001b[35m0.5416\u001b[0m  0.0489\n",
      "     38        \u001b[36m0.5418\u001b[0m       0.7422        \u001b[35m0.5389\u001b[0m  0.0336\n",
      "     39        \u001b[36m0.5390\u001b[0m       0.7344        \u001b[35m0.5364\u001b[0m  0.0495\n",
      "     40        \u001b[36m0.5365\u001b[0m       0.7344        \u001b[35m0.5343\u001b[0m  0.0648\n",
      "     41        \u001b[36m0.5343\u001b[0m       0.7344        \u001b[35m0.5323\u001b[0m  0.0383\n",
      "     42        \u001b[36m0.5323\u001b[0m       0.7344        \u001b[35m0.5306\u001b[0m  0.0522\n",
      "     43        \u001b[36m0.5305\u001b[0m       0.7344        \u001b[35m0.5290\u001b[0m  0.0634\n",
      "     44        \u001b[36m0.5288\u001b[0m       0.7344        \u001b[35m0.5277\u001b[0m  0.0605\n",
      "     45        \u001b[36m0.5273\u001b[0m       0.7344        \u001b[35m0.5265\u001b[0m  0.0561\n",
      "     46        \u001b[36m0.5259\u001b[0m       0.7344        \u001b[35m0.5254\u001b[0m  0.0865\n",
      "     47        \u001b[36m0.5246\u001b[0m       0.7344        \u001b[35m0.5244\u001b[0m  0.0647\n",
      "     48        \u001b[36m0.5233\u001b[0m       0.7344        \u001b[35m0.5236\u001b[0m  0.0411\n",
      "     49        \u001b[36m0.5223\u001b[0m       0.7344        \u001b[35m0.5228\u001b[0m  0.0508\n",
      "     50        \u001b[36m0.5213\u001b[0m       0.7344        \u001b[35m0.5221\u001b[0m  0.0364\n",
      "     51        \u001b[36m0.5204\u001b[0m       0.7344        \u001b[35m0.5216\u001b[0m  0.0665\n",
      "     52        \u001b[36m0.5196\u001b[0m       0.7344        \u001b[35m0.5210\u001b[0m  0.0384\n",
      "     53        \u001b[36m0.5189\u001b[0m       0.7344        \u001b[35m0.5205\u001b[0m  0.0424\n",
      "     54        \u001b[36m0.5183\u001b[0m       0.7344        \u001b[35m0.5201\u001b[0m  0.0585\n",
      "     55        \u001b[36m0.5177\u001b[0m       0.7344        \u001b[35m0.5198\u001b[0m  0.0698\n",
      "     56        \u001b[36m0.5172\u001b[0m       0.7344        \u001b[35m0.5195\u001b[0m  0.0629\n",
      "     57        \u001b[36m0.5166\u001b[0m       0.7344        \u001b[35m0.5192\u001b[0m  0.0415\n",
      "     58        \u001b[36m0.5161\u001b[0m       0.7344        \u001b[35m0.5189\u001b[0m  0.0638\n",
      "     59        \u001b[36m0.5158\u001b[0m       0.7344        \u001b[35m0.5187\u001b[0m  0.0638\n",
      "     60        \u001b[36m0.5154\u001b[0m       0.7344        \u001b[35m0.5185\u001b[0m  0.0730\n",
      "     61        \u001b[36m0.5151\u001b[0m       0.7344        \u001b[35m0.5184\u001b[0m  0.0456\n",
      "     62        \u001b[36m0.5148\u001b[0m       0.7344        \u001b[35m0.5183\u001b[0m  0.0370\n",
      "     63        \u001b[36m0.5145\u001b[0m       0.7422        \u001b[35m0.5182\u001b[0m  0.0836\n",
      "     64        \u001b[36m0.5143\u001b[0m       0.7422        \u001b[35m0.5182\u001b[0m  0.1017\n",
      "     65        \u001b[36m0.5141\u001b[0m       0.7422        \u001b[35m0.5181\u001b[0m  0.0366\n",
      "     66        \u001b[36m0.5139\u001b[0m       0.7422        0.5181  0.0547\n",
      "     67        \u001b[36m0.5137\u001b[0m       0.7422        0.5182  0.0532\n",
      "     68        \u001b[36m0.5135\u001b[0m       0.7422        0.5182  0.0530\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7090\u001b[0m       \u001b[32m0.4453\u001b[0m        \u001b[35m0.6955\u001b[0m  0.0442\n",
      "      2        \u001b[36m0.7069\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m0.6944\u001b[0m  0.0302\n",
      "      3        \u001b[36m0.7055\u001b[0m       \u001b[32m0.4688\u001b[0m        \u001b[35m0.6935\u001b[0m  0.0371\n",
      "      4        \u001b[36m0.7042\u001b[0m       0.4688        \u001b[35m0.6926\u001b[0m  0.0421\n",
      "      5        \u001b[36m0.7030\u001b[0m       0.4688        \u001b[35m0.6918\u001b[0m  0.0475\n",
      "      6        \u001b[36m0.7018\u001b[0m       0.4688        \u001b[35m0.6910\u001b[0m  0.0649\n",
      "      7        \u001b[36m0.7008\u001b[0m       0.4688        \u001b[35m0.6903\u001b[0m  0.0801\n",
      "      8        \u001b[36m0.6998\u001b[0m       \u001b[32m0.4766\u001b[0m        \u001b[35m0.6895\u001b[0m  0.0445\n",
      "      9        \u001b[36m0.6988\u001b[0m       0.4766        \u001b[35m0.6887\u001b[0m  0.0467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        \u001b[36m0.6979\u001b[0m       \u001b[32m0.4922\u001b[0m        \u001b[35m0.6880\u001b[0m  0.0391\n",
      "     11        \u001b[36m0.6970\u001b[0m       \u001b[32m0.5156\u001b[0m        \u001b[35m0.6873\u001b[0m  0.0339\n",
      "     12        \u001b[36m0.6961\u001b[0m       \u001b[32m0.5234\u001b[0m        \u001b[35m0.6865\u001b[0m  0.0352\n",
      "     13        \u001b[36m0.6952\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m0.6857\u001b[0m  0.0352\n",
      "     14        \u001b[36m0.6943\u001b[0m       \u001b[32m0.5547\u001b[0m        \u001b[35m0.6849\u001b[0m  0.0373\n",
      "     15        \u001b[36m0.6934\u001b[0m       0.5547        \u001b[35m0.6841\u001b[0m  0.0398\n",
      "     16        \u001b[36m0.6925\u001b[0m       \u001b[32m0.5625\u001b[0m        \u001b[35m0.6833\u001b[0m  0.0353\n",
      "     17        \u001b[36m0.6915\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m0.6826\u001b[0m  0.0473\n",
      "     18        \u001b[36m0.6907\u001b[0m       0.5703        \u001b[35m0.6817\u001b[0m  0.0530\n",
      "     19        \u001b[36m0.6898\u001b[0m       \u001b[32m0.5781\u001b[0m        \u001b[35m0.6809\u001b[0m  0.0579\n",
      "     20        \u001b[36m0.6888\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6800\u001b[0m  0.0715\n",
      "     21        \u001b[36m0.6879\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6791\u001b[0m  0.0782\n",
      "     22        \u001b[36m0.6868\u001b[0m       0.5938        \u001b[35m0.6782\u001b[0m  0.0522\n",
      "     23        \u001b[36m0.6858\u001b[0m       \u001b[32m0.6094\u001b[0m        \u001b[35m0.6773\u001b[0m  0.0526\n",
      "     24        \u001b[36m0.6847\u001b[0m       0.6094        \u001b[35m0.6763\u001b[0m  0.0385\n",
      "     25        \u001b[36m0.6835\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m0.6753\u001b[0m  0.0983\n",
      "     26        \u001b[36m0.6823\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6743\u001b[0m  0.0854\n",
      "     27        \u001b[36m0.6811\u001b[0m       0.6250        \u001b[35m0.6732\u001b[0m  0.0664\n",
      "     28        \u001b[36m0.6798\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m0.6720\u001b[0m  0.0515\n",
      "     29        \u001b[36m0.6784\u001b[0m       0.6406        \u001b[35m0.6708\u001b[0m  0.0437\n",
      "     30        \u001b[36m0.6769\u001b[0m       0.6406        \u001b[35m0.6696\u001b[0m  0.0349\n",
      "     31        \u001b[36m0.6753\u001b[0m       0.6406        \u001b[35m0.6682\u001b[0m  0.0367\n",
      "     32        \u001b[36m0.6736\u001b[0m       0.6406        \u001b[35m0.6669\u001b[0m  0.0497\n",
      "     33        \u001b[36m0.6718\u001b[0m       0.6406        \u001b[35m0.6655\u001b[0m  0.0970\n",
      "     34        \u001b[36m0.6698\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6641\u001b[0m  0.0444\n",
      "     35        \u001b[36m0.6677\u001b[0m       0.6484        \u001b[35m0.6625\u001b[0m  0.0498\n",
      "     36        \u001b[36m0.6654\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6608\u001b[0m  0.0459\n",
      "     37        \u001b[36m0.6629\u001b[0m       0.6406        \u001b[35m0.6590\u001b[0m  0.0636\n",
      "     38        \u001b[36m0.6603\u001b[0m       0.6562        \u001b[35m0.6572\u001b[0m  0.0513\n",
      "     39        \u001b[36m0.6574\u001b[0m       0.6562        \u001b[35m0.6553\u001b[0m  0.0784\n",
      "     40        \u001b[36m0.6544\u001b[0m       0.6562        \u001b[35m0.6533\u001b[0m  0.0541\n",
      "     41        \u001b[36m0.6513\u001b[0m       \u001b[32m0.6641\u001b[0m        \u001b[35m0.6511\u001b[0m  0.0506\n",
      "     42        \u001b[36m0.6479\u001b[0m       0.6641        \u001b[35m0.6490\u001b[0m  0.0521\n",
      "     43        \u001b[36m0.6444\u001b[0m       \u001b[32m0.6719\u001b[0m        \u001b[35m0.6465\u001b[0m  0.0444\n",
      "     44        \u001b[36m0.6405\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6441\u001b[0m  0.0658\n",
      "     45        \u001b[36m0.6362\u001b[0m       0.6797        \u001b[35m0.6412\u001b[0m  0.0572\n",
      "     46        \u001b[36m0.6317\u001b[0m       0.6797        \u001b[35m0.6379\u001b[0m  0.0438\n",
      "     47        \u001b[36m0.6272\u001b[0m       0.6797        \u001b[35m0.6347\u001b[0m  0.0286\n",
      "     48        \u001b[36m0.6226\u001b[0m       0.6797        \u001b[35m0.6313\u001b[0m  0.0650\n",
      "     49        \u001b[36m0.6180\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6281\u001b[0m  0.0603\n",
      "     50        \u001b[36m0.6134\u001b[0m       0.6875        \u001b[35m0.6250\u001b[0m  0.0393\n",
      "     51        \u001b[36m0.6089\u001b[0m       0.6875        \u001b[35m0.6220\u001b[0m  0.0471\n",
      "     52        \u001b[36m0.6045\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6193\u001b[0m  0.0584\n",
      "     53        \u001b[36m0.6003\u001b[0m       \u001b[32m0.7031\u001b[0m        \u001b[35m0.6166\u001b[0m  0.0405\n",
      "     54        \u001b[36m0.5961\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6139\u001b[0m  0.0337\n",
      "     55        \u001b[36m0.5919\u001b[0m       0.7188        \u001b[35m0.6113\u001b[0m  0.0465\n",
      "     56        \u001b[36m0.5878\u001b[0m       0.7266        \u001b[35m0.6087\u001b[0m  0.0475\n",
      "     57        \u001b[36m0.5839\u001b[0m       0.7188        \u001b[35m0.6062\u001b[0m  0.0634\n",
      "     58        \u001b[36m0.5801\u001b[0m       0.7188        \u001b[35m0.6038\u001b[0m  0.0547\n",
      "     59        \u001b[36m0.5765\u001b[0m       0.7188        \u001b[35m0.6015\u001b[0m  0.0326\n",
      "     60        \u001b[36m0.5731\u001b[0m       0.7109        \u001b[35m0.5993\u001b[0m  0.0559\n",
      "     61        \u001b[36m0.5697\u001b[0m       0.7109        \u001b[35m0.5971\u001b[0m  0.0592\n",
      "     62        \u001b[36m0.5662\u001b[0m       0.7031        \u001b[35m0.5950\u001b[0m  0.0430\n",
      "     63        \u001b[36m0.5629\u001b[0m       0.7031        \u001b[35m0.5930\u001b[0m  0.0705\n",
      "     64        \u001b[36m0.5597\u001b[0m       0.7188        \u001b[35m0.5911\u001b[0m  0.0336\n",
      "     65        \u001b[36m0.5566\u001b[0m       0.7188        \u001b[35m0.5893\u001b[0m  0.0357\n",
      "     66        \u001b[36m0.5538\u001b[0m       0.7188        \u001b[35m0.5877\u001b[0m  0.0343\n",
      "     67        \u001b[36m0.5510\u001b[0m       0.7188        \u001b[35m0.5862\u001b[0m  0.0511\n",
      "     68        \u001b[36m0.5485\u001b[0m       0.7266        \u001b[35m0.5849\u001b[0m  0.0728\n",
      "     69        \u001b[36m0.5461\u001b[0m       0.7266        \u001b[35m0.5836\u001b[0m  0.0622\n",
      "     70        \u001b[36m0.5437\u001b[0m       0.7266        \u001b[35m0.5825\u001b[0m  0.0546\n",
      "     71        \u001b[36m0.5415\u001b[0m       0.7188        \u001b[35m0.5815\u001b[0m  0.0355\n",
      "     72        \u001b[36m0.5395\u001b[0m       0.7188        \u001b[35m0.5806\u001b[0m  0.0414\n",
      "     73        \u001b[36m0.5376\u001b[0m       0.7188        \u001b[35m0.5798\u001b[0m  0.0480\n",
      "     74        \u001b[36m0.5358\u001b[0m       0.7188        \u001b[35m0.5790\u001b[0m  0.0404\n",
      "     75        \u001b[36m0.5341\u001b[0m       0.7188        \u001b[35m0.5784\u001b[0m  0.0723\n",
      "     76        \u001b[36m0.5325\u001b[0m       0.7188        \u001b[35m0.5778\u001b[0m  0.0531\n",
      "     77        \u001b[36m0.5309\u001b[0m       0.7188        \u001b[35m0.5773\u001b[0m  0.0433\n",
      "     78        \u001b[36m0.5294\u001b[0m       0.7188        \u001b[35m0.5768\u001b[0m  0.0843\n",
      "     79        \u001b[36m0.5279\u001b[0m       0.7188        \u001b[35m0.5764\u001b[0m  0.1071\n",
      "     80        \u001b[36m0.5266\u001b[0m       0.7188        \u001b[35m0.5761\u001b[0m  0.0678\n",
      "     81        \u001b[36m0.5253\u001b[0m       0.7188        \u001b[35m0.5758\u001b[0m  0.0535\n",
      "     82        \u001b[36m0.5240\u001b[0m       0.7188        \u001b[35m0.5755\u001b[0m  0.0505\n",
      "     83        \u001b[36m0.5228\u001b[0m       0.7188        \u001b[35m0.5753\u001b[0m  0.0513\n",
      "     84        \u001b[36m0.5218\u001b[0m       0.7188        \u001b[35m0.5750\u001b[0m  0.0548\n",
      "     85        \u001b[36m0.5208\u001b[0m       0.7109        \u001b[35m0.5748\u001b[0m  0.0499\n",
      "     86        \u001b[36m0.5197\u001b[0m       0.7109        \u001b[35m0.5746\u001b[0m  0.0638\n",
      "     87        \u001b[36m0.5188\u001b[0m       0.7109        \u001b[35m0.5744\u001b[0m  0.0620\n",
      "     88        \u001b[36m0.5179\u001b[0m       0.7109        \u001b[35m0.5743\u001b[0m  0.0906\n",
      "     89        \u001b[36m0.5171\u001b[0m       0.7109        \u001b[35m0.5742\u001b[0m  0.0501\n",
      "     90        \u001b[36m0.5164\u001b[0m       0.7109        \u001b[35m0.5741\u001b[0m  0.0516\n",
      "     91        \u001b[36m0.5157\u001b[0m       0.7109        \u001b[35m0.5741\u001b[0m  0.0687\n",
      "     92        \u001b[36m0.5150\u001b[0m       0.7109        \u001b[35m0.5741\u001b[0m  0.0389\n",
      "     93        \u001b[36m0.5144\u001b[0m       0.7109        \u001b[35m0.5741\u001b[0m  0.0403\n",
      "     94        \u001b[36m0.5137\u001b[0m       0.7109        \u001b[35m0.5740\u001b[0m  0.0853\n",
      "     95        \u001b[36m0.5131\u001b[0m       0.7109        \u001b[35m0.5740\u001b[0m  0.0565\n",
      "     96        \u001b[36m0.5125\u001b[0m       0.7109        \u001b[35m0.5740\u001b[0m  0.0487\n",
      "     97        \u001b[36m0.5120\u001b[0m       0.7109        \u001b[35m0.5740\u001b[0m  0.0490\n",
      "     98        \u001b[36m0.5113\u001b[0m       0.7109        \u001b[35m0.5739\u001b[0m  0.0449\n",
      "     99        \u001b[36m0.5107\u001b[0m       0.7109        \u001b[35m0.5739\u001b[0m  0.0469\n",
      "    100        \u001b[36m0.5102\u001b[0m       0.7109        \u001b[35m0.5739\u001b[0m  0.0544\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7207\u001b[0m       \u001b[32m0.4297\u001b[0m        \u001b[35m0.7103\u001b[0m  0.0408\n",
      "      2        \u001b[36m0.7149\u001b[0m       \u001b[32m0.4375\u001b[0m        \u001b[35m0.7057\u001b[0m  0.0504\n",
      "      3        \u001b[36m0.7103\u001b[0m       \u001b[32m0.4766\u001b[0m        \u001b[35m0.7019\u001b[0m  0.0531\n",
      "      4        \u001b[36m0.7065\u001b[0m       0.4766        \u001b[35m0.6986\u001b[0m  0.0419\n",
      "      5        \u001b[36m0.7031\u001b[0m       \u001b[32m0.4844\u001b[0m        \u001b[35m0.6955\u001b[0m  0.0304\n",
      "      6        \u001b[36m0.6999\u001b[0m       \u001b[32m0.5391\u001b[0m        \u001b[35m0.6927\u001b[0m  0.0259\n",
      "      7        \u001b[36m0.6968\u001b[0m       \u001b[32m0.5859\u001b[0m        \u001b[35m0.6898\u001b[0m  0.0314\n",
      "      8        \u001b[36m0.6937\u001b[0m       \u001b[32m0.6328\u001b[0m        \u001b[35m0.6869\u001b[0m  0.0372\n",
      "      9        \u001b[36m0.6905\u001b[0m       \u001b[32m0.6484\u001b[0m        \u001b[35m0.6839\u001b[0m  0.0446\n",
      "     10        \u001b[36m0.6871\u001b[0m       \u001b[32m0.6797\u001b[0m        \u001b[35m0.6806\u001b[0m  0.0463\n",
      "     11        \u001b[36m0.6835\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6772\u001b[0m  0.0487\n",
      "     12        \u001b[36m0.6798\u001b[0m       0.6953        \u001b[35m0.6737\u001b[0m  0.0450\n",
      "     13        \u001b[36m0.6760\u001b[0m       0.6875        \u001b[35m0.6701\u001b[0m  0.0469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     14        \u001b[36m0.6721\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.6663\u001b[0m  0.0873\n",
      "     15        \u001b[36m0.6680\u001b[0m       0.7109        \u001b[35m0.6622\u001b[0m  0.0795\n",
      "     16        \u001b[36m0.6635\u001b[0m       0.7109        \u001b[35m0.6579\u001b[0m  0.0371\n",
      "     17        \u001b[36m0.6587\u001b[0m       0.7109        \u001b[35m0.6532\u001b[0m  0.0325\n",
      "     18        \u001b[36m0.6535\u001b[0m       0.7109        \u001b[35m0.6482\u001b[0m  0.0276\n",
      "     19        \u001b[36m0.6480\u001b[0m       0.7109        \u001b[35m0.6430\u001b[0m  0.0371\n",
      "     20        \u001b[36m0.6421\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6375\u001b[0m  0.0396\n",
      "     21        \u001b[36m0.6360\u001b[0m       0.7188        \u001b[35m0.6316\u001b[0m  0.0576\n",
      "     22        \u001b[36m0.6296\u001b[0m       0.7188        \u001b[35m0.6255\u001b[0m  0.0706\n",
      "     23        \u001b[36m0.6228\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.6194\u001b[0m  0.0434\n",
      "     24        \u001b[36m0.6159\u001b[0m       0.7266        \u001b[35m0.6131\u001b[0m  0.0523\n",
      "     25        \u001b[36m0.6088\u001b[0m       0.7266        \u001b[35m0.6068\u001b[0m  0.0444\n",
      "     26        \u001b[36m0.6016\u001b[0m       0.7266        \u001b[35m0.6004\u001b[0m  0.0367\n",
      "     27        \u001b[36m0.5943\u001b[0m       0.7266        \u001b[35m0.5941\u001b[0m  0.0392\n",
      "     28        \u001b[36m0.5871\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.5880\u001b[0m  0.0636\n",
      "     29        \u001b[36m0.5799\u001b[0m       0.7344        \u001b[35m0.5820\u001b[0m  0.0949\n",
      "     30        \u001b[36m0.5727\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5763\u001b[0m  0.0376\n",
      "     31        \u001b[36m0.5657\u001b[0m       0.7422        \u001b[35m0.5709\u001b[0m  0.0399\n",
      "     32        \u001b[36m0.5590\u001b[0m       0.7344        \u001b[35m0.5659\u001b[0m  0.0391\n",
      "     33        \u001b[36m0.5525\u001b[0m       0.7344        \u001b[35m0.5612\u001b[0m  0.0353\n",
      "     34        \u001b[36m0.5463\u001b[0m       0.7422        \u001b[35m0.5569\u001b[0m  0.0527\n",
      "     35        \u001b[36m0.5404\u001b[0m       0.7344        \u001b[35m0.5529\u001b[0m  0.0510\n",
      "     36        \u001b[36m0.5350\u001b[0m       0.7344        \u001b[35m0.5493\u001b[0m  0.0375\n",
      "     37        \u001b[36m0.5298\u001b[0m       0.7344        \u001b[35m0.5461\u001b[0m  0.0351\n",
      "     38        \u001b[36m0.5250\u001b[0m       0.7344        \u001b[35m0.5431\u001b[0m  0.0438\n",
      "     39        \u001b[36m0.5204\u001b[0m       0.7344        \u001b[35m0.5404\u001b[0m  0.0523\n",
      "     40        \u001b[36m0.5162\u001b[0m       0.7344        \u001b[35m0.5381\u001b[0m  0.0362\n",
      "     41        \u001b[36m0.5122\u001b[0m       0.7422        \u001b[35m0.5360\u001b[0m  0.0535\n",
      "     42        \u001b[36m0.5085\u001b[0m       0.7422        \u001b[35m0.5342\u001b[0m  0.0425\n",
      "     43        \u001b[36m0.5051\u001b[0m       0.7422        \u001b[35m0.5326\u001b[0m  0.0438\n",
      "     44        \u001b[36m0.5020\u001b[0m       0.7344        \u001b[35m0.5312\u001b[0m  0.0351\n",
      "     45        \u001b[36m0.4990\u001b[0m       0.7344        \u001b[35m0.5300\u001b[0m  0.0465\n",
      "     46        \u001b[36m0.4962\u001b[0m       0.7422        \u001b[35m0.5289\u001b[0m  0.0465\n",
      "     47        \u001b[36m0.4936\u001b[0m       0.7422        \u001b[35m0.5280\u001b[0m  0.0323\n",
      "     48        \u001b[36m0.4910\u001b[0m       0.7422        \u001b[35m0.5272\u001b[0m  0.0362\n",
      "     49        \u001b[36m0.4885\u001b[0m       0.7422        \u001b[35m0.5265\u001b[0m  0.0964\n",
      "     50        \u001b[36m0.4863\u001b[0m       0.7422        \u001b[35m0.5258\u001b[0m  0.0537\n",
      "     51        \u001b[36m0.4841\u001b[0m       0.7422        \u001b[35m0.5253\u001b[0m  0.0416\n",
      "     52        \u001b[36m0.4821\u001b[0m       0.7422        \u001b[35m0.5248\u001b[0m  0.0657\n",
      "     53        \u001b[36m0.4801\u001b[0m       0.7422        \u001b[35m0.5245\u001b[0m  0.0315\n",
      "     54        \u001b[36m0.4783\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5242\u001b[0m  0.0467\n",
      "     55        \u001b[36m0.4766\u001b[0m       0.7500        \u001b[35m0.5240\u001b[0m  0.0558\n",
      "     56        \u001b[36m0.4750\u001b[0m       0.7500        \u001b[35m0.5239\u001b[0m  0.0559\n",
      "     57        \u001b[36m0.4734\u001b[0m       0.7500        \u001b[35m0.5238\u001b[0m  0.0479\n",
      "     58        \u001b[36m0.4718\u001b[0m       0.7500        \u001b[35m0.5237\u001b[0m  0.0511\n",
      "     59        \u001b[36m0.4703\u001b[0m       0.7500        \u001b[35m0.5236\u001b[0m  0.0393\n",
      "     60        \u001b[36m0.4689\u001b[0m       0.7500        \u001b[35m0.5236\u001b[0m  0.0453\n",
      "     61        \u001b[36m0.4675\u001b[0m       0.7422        0.5236  0.0502\n",
      "     62        \u001b[36m0.4662\u001b[0m       0.7344        0.5237  0.0589\n",
      "     63        \u001b[36m0.4649\u001b[0m       0.7344        0.5237  0.0463\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7211\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7110\u001b[0m  0.0912\n",
      "      2        \u001b[36m0.7109\u001b[0m       0.5000        \u001b[35m0.7029\u001b[0m  0.1150\n",
      "      3        \u001b[36m0.7041\u001b[0m       0.5000        \u001b[35m0.6972\u001b[0m  0.1057\n",
      "      4        \u001b[36m0.6992\u001b[0m       0.5000        \u001b[35m0.6928\u001b[0m  0.0946\n",
      "      5        \u001b[36m0.6953\u001b[0m       0.5000        \u001b[35m0.6892\u001b[0m  0.0978\n",
      "      6        \u001b[36m0.6920\u001b[0m       0.5000        \u001b[35m0.6858\u001b[0m  0.1385\n",
      "      7        \u001b[36m0.6888\u001b[0m       0.5000        \u001b[35m0.6824\u001b[0m  0.1440\n",
      "      8        \u001b[36m0.6855\u001b[0m       0.5000        \u001b[35m0.6787\u001b[0m  0.1082\n",
      "      9        \u001b[36m0.6818\u001b[0m       \u001b[32m0.5125\u001b[0m        \u001b[35m0.6747\u001b[0m  0.1611\n",
      "     10        \u001b[36m0.6778\u001b[0m       \u001b[32m0.5375\u001b[0m        \u001b[35m0.6701\u001b[0m  0.0972\n",
      "     11        \u001b[36m0.6733\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m0.6649\u001b[0m  0.0680\n",
      "     12        \u001b[36m0.6681\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6591\u001b[0m  0.0594\n",
      "     13        \u001b[36m0.6622\u001b[0m       \u001b[32m0.6500\u001b[0m        \u001b[35m0.6525\u001b[0m  0.0742\n",
      "     14        \u001b[36m0.6557\u001b[0m       \u001b[32m0.6562\u001b[0m        \u001b[35m0.6452\u001b[0m  0.0817\n",
      "     15        \u001b[36m0.6483\u001b[0m       \u001b[32m0.6625\u001b[0m        \u001b[35m0.6371\u001b[0m  0.1572\n",
      "     16        \u001b[36m0.6403\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.6285\u001b[0m  0.0770\n",
      "     17        \u001b[36m0.6317\u001b[0m       \u001b[32m0.7125\u001b[0m        \u001b[35m0.6194\u001b[0m  0.1169\n",
      "     18        \u001b[36m0.6224\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.6099\u001b[0m  0.1269\n",
      "     19        \u001b[36m0.6126\u001b[0m       0.7188        \u001b[35m0.6005\u001b[0m  0.1177\n",
      "     20        \u001b[36m0.6030\u001b[0m       0.7188        \u001b[35m0.5911\u001b[0m  0.0718\n",
      "     21        \u001b[36m0.5933\u001b[0m       \u001b[32m0.7250\u001b[0m        \u001b[35m0.5821\u001b[0m  0.0690\n",
      "     22        \u001b[36m0.5839\u001b[0m       0.7188        \u001b[35m0.5738\u001b[0m  0.0929\n",
      "     23        \u001b[36m0.5749\u001b[0m       0.7250        \u001b[35m0.5662\u001b[0m  0.1232\n",
      "     24        \u001b[36m0.5664\u001b[0m       0.7250        \u001b[35m0.5594\u001b[0m  0.0826\n",
      "     25        \u001b[36m0.5585\u001b[0m       \u001b[32m0.7438\u001b[0m        \u001b[35m0.5532\u001b[0m  0.0590\n",
      "     26        \u001b[36m0.5512\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.5477\u001b[0m  0.0862\n",
      "     27        \u001b[36m0.5445\u001b[0m       0.7438        \u001b[35m0.5431\u001b[0m  0.1028\n",
      "     28        \u001b[36m0.5385\u001b[0m       0.7500        \u001b[35m0.5393\u001b[0m  0.1040\n",
      "     29        \u001b[36m0.5331\u001b[0m       \u001b[32m0.7625\u001b[0m        \u001b[35m0.5362\u001b[0m  0.0934\n",
      "     30        \u001b[36m0.5285\u001b[0m       0.7625        \u001b[35m0.5337\u001b[0m  0.1013\n",
      "     31        \u001b[36m0.5243\u001b[0m       0.7562        \u001b[35m0.5316\u001b[0m  0.0922\n",
      "     32        \u001b[36m0.5207\u001b[0m       0.7562        \u001b[35m0.5299\u001b[0m  0.1110\n",
      "     33        \u001b[36m0.5175\u001b[0m       0.7625        \u001b[35m0.5284\u001b[0m  0.0908\n",
      "     34        \u001b[36m0.5147\u001b[0m       0.7625        \u001b[35m0.5272\u001b[0m  0.0998\n",
      "     35        \u001b[36m0.5120\u001b[0m       0.7625        \u001b[35m0.5259\u001b[0m  0.0490\n",
      "     36        \u001b[36m0.5096\u001b[0m       0.7625        \u001b[35m0.5248\u001b[0m  0.0833\n",
      "     37        \u001b[36m0.5073\u001b[0m       0.7562        \u001b[35m0.5238\u001b[0m  0.1139\n",
      "     38        \u001b[36m0.5054\u001b[0m       0.7562        \u001b[35m0.5230\u001b[0m  0.1233\n",
      "     39        \u001b[36m0.5036\u001b[0m       0.7562        \u001b[35m0.5223\u001b[0m  0.0916\n",
      "     40        \u001b[36m0.5020\u001b[0m       0.7562        \u001b[35m0.5216\u001b[0m  0.0720\n",
      "     41        \u001b[36m0.5003\u001b[0m       0.7500        \u001b[35m0.5210\u001b[0m  0.0841\n",
      "     42        \u001b[36m0.4989\u001b[0m       0.7500        \u001b[35m0.5204\u001b[0m  0.0643\n",
      "     43        \u001b[36m0.4976\u001b[0m       0.7500        \u001b[35m0.5199\u001b[0m  0.1113\n",
      "     44        \u001b[36m0.4963\u001b[0m       0.7500        \u001b[35m0.5194\u001b[0m  0.0844\n",
      "     45        \u001b[36m0.4952\u001b[0m       0.7562        \u001b[35m0.5188\u001b[0m  0.0889\n",
      "     46        \u001b[36m0.4939\u001b[0m       0.7562        \u001b[35m0.5182\u001b[0m  0.0725\n",
      "     47        \u001b[36m0.4928\u001b[0m       0.7438        \u001b[35m0.5176\u001b[0m  0.1045\n",
      "     48        \u001b[36m0.4915\u001b[0m       0.7438        \u001b[35m0.5171\u001b[0m  0.0899\n",
      "     49        \u001b[36m0.4906\u001b[0m       0.7438        \u001b[35m0.5166\u001b[0m  0.0886\n",
      "     50        \u001b[36m0.4896\u001b[0m       0.7375        \u001b[35m0.5160\u001b[0m  0.1510\n",
      "     51        \u001b[36m0.4887\u001b[0m       0.7375        \u001b[35m0.5154\u001b[0m  0.0986\n",
      "     52        \u001b[36m0.4877\u001b[0m       0.7312        \u001b[35m0.5148\u001b[0m  0.1104\n",
      "     53        \u001b[36m0.4867\u001b[0m       0.7375        \u001b[35m0.5142\u001b[0m  0.1047\n",
      "     54        \u001b[36m0.4856\u001b[0m       0.7375        \u001b[35m0.5137\u001b[0m  0.0854\n",
      "     55        \u001b[36m0.4847\u001b[0m       0.7438        \u001b[35m0.5132\u001b[0m  0.0929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     56        \u001b[36m0.4839\u001b[0m       0.7438        \u001b[35m0.5127\u001b[0m  0.0893\n",
      "     57        \u001b[36m0.4830\u001b[0m       0.7500        \u001b[35m0.5123\u001b[0m  0.1114\n",
      "     58        \u001b[36m0.4822\u001b[0m       0.7500        \u001b[35m0.5119\u001b[0m  0.0752\n",
      "     59        \u001b[36m0.4814\u001b[0m       0.7500        \u001b[35m0.5115\u001b[0m  0.0793\n",
      "     60        \u001b[36m0.4807\u001b[0m       0.7500        \u001b[35m0.5111\u001b[0m  0.0959\n",
      "     61        \u001b[36m0.4799\u001b[0m       0.7562        \u001b[35m0.5107\u001b[0m  0.1006\n",
      "     62        \u001b[36m0.4791\u001b[0m       0.7562        \u001b[35m0.5103\u001b[0m  0.1023\n",
      "     63        \u001b[36m0.4785\u001b[0m       0.7562        \u001b[35m0.5098\u001b[0m  0.1556\n",
      "     64        \u001b[36m0.4778\u001b[0m       0.7562        \u001b[35m0.5094\u001b[0m  0.1469\n",
      "     65        \u001b[36m0.4772\u001b[0m       0.7562        \u001b[35m0.5091\u001b[0m  0.1186\n",
      "     66        \u001b[36m0.4766\u001b[0m       0.7562        \u001b[35m0.5089\u001b[0m  0.0906\n",
      "     67        \u001b[36m0.4760\u001b[0m       0.7562        \u001b[35m0.5087\u001b[0m  0.0772\n",
      "     68        \u001b[36m0.4753\u001b[0m       0.7500        \u001b[35m0.5085\u001b[0m  0.1040\n",
      "     69        \u001b[36m0.4746\u001b[0m       0.7500        \u001b[35m0.5084\u001b[0m  0.1191\n",
      "     70        \u001b[36m0.4739\u001b[0m       0.7500        \u001b[35m0.5083\u001b[0m  0.0717\n",
      "     71        \u001b[36m0.4734\u001b[0m       0.7500        \u001b[35m0.5082\u001b[0m  0.1269\n",
      "     72        \u001b[36m0.4728\u001b[0m       0.7500        \u001b[35m0.5081\u001b[0m  0.1097\n",
      "     73        \u001b[36m0.4722\u001b[0m       0.7500        \u001b[35m0.5080\u001b[0m  0.0496\n",
      "     74        \u001b[36m0.4716\u001b[0m       0.7500        \u001b[35m0.5079\u001b[0m  0.1058\n",
      "     75        \u001b[36m0.4710\u001b[0m       0.7500        0.5079  0.0993\n",
      "     76        \u001b[36m0.4705\u001b[0m       0.7500        \u001b[35m0.5078\u001b[0m  0.0988\n",
      "     77        \u001b[36m0.4699\u001b[0m       0.7500        \u001b[35m0.5078\u001b[0m  0.0578\n",
      "     78        \u001b[36m0.4694\u001b[0m       0.7500        \u001b[35m0.5077\u001b[0m  0.0909\n",
      "     79        \u001b[36m0.4689\u001b[0m       0.7500        \u001b[35m0.5076\u001b[0m  0.1143\n",
      "     80        \u001b[36m0.4683\u001b[0m       0.7500        \u001b[35m0.5076\u001b[0m  0.0784\n",
      "     81        \u001b[36m0.4678\u001b[0m       0.7500        \u001b[35m0.5076\u001b[0m  0.0961\n",
      "     82        \u001b[36m0.4673\u001b[0m       0.7500        \u001b[35m0.5075\u001b[0m  0.1128\n",
      "     83        \u001b[36m0.4668\u001b[0m       0.7500        \u001b[35m0.5074\u001b[0m  0.1091\n",
      "     84        \u001b[36m0.4662\u001b[0m       0.7500        \u001b[35m0.5074\u001b[0m  0.1753\n",
      "     85        \u001b[36m0.4657\u001b[0m       0.7500        \u001b[35m0.5073\u001b[0m  0.1048\n",
      "     86        \u001b[36m0.4651\u001b[0m       0.7500        0.5074  0.0567\n",
      "     87        \u001b[36m0.4647\u001b[0m       0.7500        0.5075  0.1026\n",
      "     88        \u001b[36m0.4643\u001b[0m       0.7500        0.5076  0.1166\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best parameters found:\n",
      "\n",
      "{'optimizer__momentum': 0.1, 'module__num_unitsB': 3, 'module__num_unitsA': 12, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 16}\n",
      "\n",
      "Randomized search scores on training set:\n",
      "\n",
      "0.835 (+/-0.060) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 6, 'module__num_unitsA': 9, 'module__dropout': 0.5, 'lr': 0.01, 'batch_size': 16}\n",
      "0.840 (+/-0.060) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 3, 'module__num_unitsA': 12, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 16}\n",
      "0.838 (+/-0.058) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 6, 'module__num_unitsA': 6, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 16}\n",
      "0.500 (+/-0.000) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 3, 'module__num_unitsA': 12, 'module__dropout': 0.2, 'lr': 0.1, 'batch_size': 16}\n",
      "0.805 (+/-0.060) for {'optimizer__momentum': 0.1, 'module__num_unitsB': 6, 'module__num_unitsA': 3, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 32}\n",
      "0.790 (+/-0.183) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 12, 'module__num_unitsA': 6, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 32}\n",
      "0.817 (+/-0.060) for {'optimizer__momentum': 0.6, 'module__num_unitsB': 9, 'module__num_unitsA': 3, 'module__dropout': 0.5, 'lr': 0.01, 'batch_size': 64}\n",
      "0.833 (+/-0.076) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 6, 'module__num_unitsA': 6, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 16}\n",
      "0.500 (+/-0.000) for {'optimizer__momentum': 0.9, 'module__num_unitsB': 3, 'module__num_unitsA': 6, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 64}\n",
      "0.833 (+/-0.046) for {'optimizer__momentum': 0.3, 'module__num_unitsB': 9, 'module__num_unitsA': 3, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 32}\n",
      "\n",
      "Time taken in seconds: 427.95\n"
     ]
    }
   ],
   "source": [
    "# Perform Randomized Search on the neural network with two hidden layers\n",
    "\n",
    "# Start timer\n",
    "tic = time()\n",
    "\n",
    "# Define the search values of the hyperparameters\n",
    "tuned_parameters = [{'module__num_unitsA':[3,6,9,12],\n",
    "                    'module__num_unitsB':[3,6,9,12],\n",
    "                    'optimizer__momentum':[0.1,0.3,0.6,0.9],\n",
    "                    'lr':[1,0.1,0.01],\n",
    "                    'module__dropout':[0.0,0.2,0.5],\n",
    "                    'batch_size':[16,32,64]}]\n",
    "\n",
    "# Print the accuracy, precision, recall, F1 score and AUC score for each set hyperparameters\n",
    "for score in ['accuracy','precision','recall','f1','roc_auc']:\n",
    " print(\"# Tuning hyper-parameters for %s\" %score)\n",
    " print()\n",
    " classifier = RandomizedSearchCV(searchNet, tuned_parameters, scoring=score, cv=5)\n",
    " classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    " print(\"Best parameters found:\")\n",
    " print()\n",
    " print(classifier.best_params_)\n",
    " print()\n",
    " print(\"Randomized search scores on training set:\")\n",
    " print()\n",
    " means = classifier.cv_results_['mean_test_score']\n",
    " stds = classifier.cv_results_['std_test_score']\n",
    " for mean, std, params in zip(means, stds, classifier.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    \n",
    " print()\n",
    "\n",
    "# Print time required in seconds for the search\n",
    "toc = time()\n",
    "print('Time taken in seconds: %.2f'%(toc-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different optimal hyperparameters were given by the different performance metrics.\n",
    "\n",
    "Highest accuracy was achieved using 'optimizer__momentum': 0.3, 'module__num_unitsB': 6, 'module__num_unitsA': 12, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 32.\n",
    "\n",
    "Highest precision was attained using 'optimizer__momentum': 0.9, 'module__num_unitsB': 3, 'module__num_unitsA': 12, 'module__dropout': 0.2, 'lr': 0.01, 'batch_size': 32.\n",
    "\n",
    "Highest recall was attained using 'optimizer__momentum': 0.3, 'module__num_unitsB': 9, 'module__num_unitsA': 12, 'module__dropout': 0.5, 'lr': 1, 'batch_size': 16.\n",
    "\n",
    "Highest F1 score was achieved using 'optimizer__momentum': 0.3, 'module__num_unitsB': 12, 'module__num_unitsA': 9, 'module__dropout': 0.0, 'lr': 0.1, 'batch_size': 64.\n",
    "\n",
    "Highest AUC score of 0.84 was attained using 'optimizer__momentum': 0.1, 'module__num_unitsB': 3, 'module__num_unitsA': 12, 'module__dropout': 0.0, 'lr': 0.01, 'batch_size': 16. \n",
    "\n",
    "Amongst all MLP models tested, MLP with single hidden layer, 'optimizer__momentum': 0.3, 'module__num_units': 8, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 64 yielded the highest AUC score of 0.844. We will use this as the best MLP model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters found by Randomized Search were  'optimizer__momentum': 0.3, 'module__num_units': 8, 'module__dropout': 0.2, 'lr': 1, 'batch_size': 64 for a MLP with single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network that has 8 neurons in one hidden layer\n",
    "\n",
    "# Build neural network\n",
    "class netModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=8, # Set number of neurons to 8\n",
    "            dropout=0.2 # Apply dropout of 0.2\n",
    "    ):\n",
    "        super(netModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.num_units = nn.Linear(X.shape[1], num_units)\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.num_units(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X),dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the neural network \n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "best_mlp = NeuralNetClassifier(module=netModule, \n",
    "                    max_epochs=100, # maximum epcohs of 100\n",
    "                    callbacks=[EarlyStopping()], # Apply early stopping\n",
    "                    device='cpu', # set device to 'cpu'\n",
    "                    optimizer__momentum = 0.3, # optimizer momentum of 0.3\n",
    "                    module__dropout = 0.2, # dropout of 0.2\n",
    "                    lr = 1, # learning rate of 1 \n",
    "                    iterator_train__shuffle=True,# Shuffle training data on each epoch\n",
    "                    batch_size = 64) # batch size of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6082\u001b[0m       \u001b[32m0.7375\u001b[0m        \u001b[35m0.5212\u001b[0m  0.0183\n",
      "      2        \u001b[36m0.4959\u001b[0m       \u001b[32m0.7500\u001b[0m        0.5213  0.0156\n",
      "      3        0.4972       0.7125        \u001b[35m0.5129\u001b[0m  0.0172\n",
      "      4        \u001b[36m0.4912\u001b[0m       0.7188        \u001b[35m0.5083\u001b[0m  0.0153\n",
      "      5        \u001b[36m0.4693\u001b[0m       0.6937        0.5443  0.0160\n",
      "      6        0.4699       0.7250        \u001b[35m0.5059\u001b[0m  0.0171\n",
      "      7        \u001b[36m0.4691\u001b[0m       0.7250        0.5119  0.0273\n",
      "      8        \u001b[36m0.4575\u001b[0m       0.7250        \u001b[35m0.5030\u001b[0m  0.0339\n",
      "      9        0.4667       \u001b[32m0.7750\u001b[0m        \u001b[35m0.5012\u001b[0m  0.0256\n",
      "     10        \u001b[36m0.4477\u001b[0m       0.7250        0.5113  0.0194\n",
      "     11        \u001b[36m0.4413\u001b[0m       0.7562        0.5146  0.0291\n",
      "     12        0.4641       0.7438        0.5083  0.0248\n",
      "     13        0.4569       0.7438        0.5055  0.0204\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=netModule(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (num_units): Linear(in_features=6, out_features=8, bias=True)\n",
       "    (output): Linear(in_features=8, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit best MLP model to training data\n",
    "best_mlp.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABFCUlEQVR4nO3dd3iUZdb48e9JhxRqSIAACRESWiAhAoLSLAs2xIqIgq4FFV3XXV/Rta6v7891XWUVFVFR18ZiAVERFURQQSD0GiDUUEIoCQkJqffvj2cShpAyk8xkJuR8rivXzPPMU86EMGfuLsYYlFJKKUf5eDoApZRSDYsmDqWUUk7RxKGUUsopmjiUUko5RROHUkopp/h5OoD60Lp1axMdHe3pMJRSqkFZtWrVEWNMeMX9jSJxREdHk5KS4ukwlFKqQRGRPZXt16oqpZRSTtHEoZRSyimaOJRSSjmlUbRxKKXqX1FREenp6Zw6dcrToagaBAUFERUVhb+/v0PHa+JQSrlFeno6oaGhREdHIyKeDkdVwRjD0aNHSU9PJyYmxqFztKqqEtMWp7E07cgZ+5amHWHa4jQPRaRUw3Pq1ClatWqlScPLiQitWrVyqmSoiaMSCVHNmPTJmvLksTTtCJM+WUNCVDMPR6ZUw6JJo2Fw9t9Jq6oqMTC2NVPHJnL3f1bRK6oZqYdymDo2kYGxrT0dmlJKeZyWOKowMLY1XdqEsCztKGP7ddSkoVQDk5WVxRtvvFGrcy+//HKysrKqPeapp55iwYIFtbp+RdHR0Rw5cqTmA72EJo4qLE07wraMHAA+/H3PWW0eSinXcUe7YnWJo6SkpNpz582bR/Pmzas95u9//zuXXHJJbcNr0DRxVKKsTePxy7sBMGFg9BltHkop13JHu+LkyZNJS0ujT58+PPLII/z8888MGzaMsWPH0qtXLwCuueYa+vbtS48ePZg+fXr5uWUlgN27d9OtWzfuuusuevTowWWXXUZ+fj4AEyZM4PPPPy8//umnnyYpKYlevXqxdetWADIzM7n00ktJSkrinnvuoVOnTjWWLF5++WV69uxJz549mTJlCgAnT57kiiuuoHfv3vTs2ZP//ve/5e+xe/fuJCQk8Ne//rXWvytnaRtHJdanZzN1bCJJHVvw5FcbMcDUsYmsT8/WKiulauHZrzex+cCJao9pExrIbe+uICIskIwTBZzXJoR/L9jOvxdsr/T47u3CePqqHlVe74UXXmDjxo2sXbsWgJ9//pkVK1awcePG8m6nM2bMoGXLluTn53P++edz3XXX0apVqzOus337dj799FPefvttbrzxRr744gvGjRt31v1at27N6tWreeONN3jppZd45513ePbZZxk+fDiPPfYY8+fPPyM5VWbVqlW89957LF++HGMM/fv3Z8iQIezcuZN27drx7bffApCdnc2xY8eYPXs2W7duRURqrFpzJS1xVGLikFgGxrYmyN+X6FbBpB46wcDY1kwcEuvp0JQ6ZzVr4k9EWCD7s04RERZIsyaODUZzRr9+/c4Yq/Dqq6/Su3dvBgwYwL59+9i+/ewkFRMTQ58+fQDo27cvu3fvrvTa11577VnH/Prrr4wZMwaAESNG0KJFi2rj+/XXXxk9ejTBwcGEhIRw7bXX8ssvv9CrVy8WLFjAo48+yi+//EKzZs0ICwsjKCiIO++8ky+//JKmTZs6+duoPS1x1CC+bWiN35SUUtWrrmRQpqx66sHh5/HR8r386ZIuLi/hBwcHlz//+eefWbBgAcuWLaNp06YMHTq00rEMgYGB5c99fX3Lq6qqOs7X15fi4mLAGlznjKqO79q1K6tWrWLevHk89thjXHbZZTz11FOsWLGChQsXMnPmTKZOncpPP/3k1P1qS0scNYiLCGPPsTzyCos9HYpS56yypDF1bCIPXxbH1LGJdW5XDA0NJScnp8rXs7OzadGiBU2bNmXr1q38/vvvtb5XVS688EJmzZoFwA8//MDx48erPX7w4MHMmTOHvLw8Tp48yezZs7nooos4cOAATZs2Zdy4cfz1r39l9erV5Obmkp2dzeWXX86UKVPKq+Tqg1sTh4iMEJFUEdkhIpOrOGaoiKwVkU0isrimc0WkpYj8KCLbbY/Vl/3qKC4yFGNge0auO2+jVKNW1q5YVsIoG0u1Pj271tds1aoVgwYNomfPnjzyyCNnvT5ixAiKi4tJSEjgySefZMCAAbW+V1WefvppfvjhB5KSkvjuu+9o27YtoaGhVR6flJTEhAkT6NevH/379+fOO+8kMTGRDRs20K9fP/r06cPzzz/PE088QU5ODldeeSUJCQkMGTKEV155xeXxV8kY45YfwBdIAzoDAcA6oHuFY5oDm4GOtu02NZ0LvAhMtj2fDPyjplj69u1ramtXZq7p9Og35r8r9tb6Gko1Rps3b/Z0CB536tQpU1RUZIwxZunSpaZ3796eDagalf17ASmmks9Ud7Zx9AN2GGN2AojITGCULVGUGQt8aYzZC2CMOezAuaOAobbjPgB+Bh5115vo2LIpTfx92XJI2zmUUs7Zu3cvN954I6WlpQQEBPD22297OiSXcGfiaA/ss9tOB/pXOKYr4C8iPwOhwL+NMf+p4dwIY8xBAGPMQRFpU9nNReRu4G6Ajh071vpN+PgIXSNCSD1UdV2pUkpVpkuXLqxZs8bTYbicO9s4Kps1q2KXAT+gL3AF8AfgSRHp6uC51TLGTDfGJBtjksPDz1pr3SlxkaGaOJRSysadiSMd6GC3HQUcqOSY+caYk8aYI8ASoHcN52aISFsA2+Nh3CwuMoyjJwvJzClw962UUsrruTNxrAS6iEiMiAQAY4C5FY75CrhIRPxEpClWddSWGs6dC4y3PR9vu4ZbxUdavSC01KGUUm5MHMaYYmAS8D1WMphljNkkIhNFZKLtmC3AfGA9sAJ4xxizsapzbZd+AbhURLYDl9q23SrOlji2agO5Ukq5dxyHMWaeMaarMSbWGPO8bd80Y8w0u2P+aYzpbozpaYyZUt25tv1HjTEXG2O62B6PufM9ALQOCaR1SKCWOJQ6x4WEhABw4MABrr/++kqPGTp0KCkpKdVeZ8qUKeTl5ZVvOzJNuyOeeeYZXnrppTpfp6505LiD4iNDSc3QxKGUW/w6BXYtOXPfriXWfg9o165d+cy3tVExcTgyTXtDoonDQXGRoWzLyKGk1Lm5Z5RSDmifBJ9NOJ08di2xttsn1fqSjz766BnrcTzzzDP861//Ijc3l4svvrh8CvSvvjq7mXT37t307NkTgPz8fMaMGUNCQgI33XTTGXNV3XvvvSQnJ9OjRw+efvppwJo48cCBAwwbNoxhw4YBZy7UVNm06dVN316VtWvXMmDAABISEhg9enT5dCavvvpq+VTrZRMsLl68mD59+tCnTx8SExOrnYrFETrJoYPiIkM5VVTKnqMn6Rwe4ulwlGpYvpsMhzZUf0xoW/hwtPWYcxDC4+Hnf1g/lYnsBSOrbuIcM2YMDz30EPfddx8As2bNYv78+QQFBTF79mzCwsI4cuQIAwYM4Oqrr65y3e0333yTpk2bsn79etavX09S0ulk9vzzz9OyZUtKSkq4+OKLWb9+PQ8++CAvv/wyixYtonXrMydprGra9BYtWjg8fXuZ2267jddee40hQ4bw1FNP8eyzzzJlyhReeOEFdu3aRWBgYHn12EsvvcTrr7/OoEGDyM3NJSgoqMrrOkJLHA7SnlVKuVlQcytpZO+zHoOa1+lyiYmJHD58mAMHDrBu3TpatGhBx44dMcbw+OOPk5CQwCWXXML+/fvJyMio8jpLliwp/wBPSEggISGh/LVZs2aRlJREYmIimzZtYvPmzVVdBqh62nRwfPp2sCZozMrKYsiQIQCMHz+eJUuWlMd4yy238NFHH+HnZ5UNBg0axMMPP8yrr75KVlZW+f7a0hKHg7q0CUUEth7KYWSvtp4OR6mGpZqSQbmy6qnB/wMp78LQRyFmcJ1ue/311/P5559z6NCh8mqbjz/+mMzMTFatWoW/vz/R0dGVTqdur7LSyK5du3jppZdYuXIlLVq0YMKECTVex1Qzzbqj07fX5Ntvv2XJkiXMnTuX5557jk2bNjF58mSuuOIK5s2bx4ABA1iwYAHx8fG1uj5oicNhTQLKFnXSEodSLleWNG54H4b/zXq0b/OopTFjxjBz5kw+//zz8l5S2dnZtGnTBn9/fxYtWsSePXuqvcbgwYP5+OOPAdi4cSPr168H4MSJEwQHB9OsWTMyMjL47rvvys+pakr3qqZNd1azZs1o0aJFeWnlww8/ZMiQIZSWlrJv3z6GDRvGiy++SFZWFrm5uaSlpdGrVy8effRRkpOTy5e2rS0tcTghLkJ7VinlFvtXW8mirIQRM9ja3r+6TqWOHj16kJOTQ/v27Wnb1qopuOWWW7jqqqtITk6mT58+NX7zvvfee7n99ttJSEigT58+9OvXD4DevXuTmJhIjx496Ny5M4MGDSo/5+6772bkyJG0bduWRYsWle+3nzYdKJ82vbpqqap88MEHTJw4kby8PDp37sx7771HSUkJ48aNIzs7G2MMf/7zn2nevDlPPvkkixYtwtfXl+7duzNy5Ein72dPqis6nSuSk5NNTf2uHfHKj9t49aftbH52BE0CfF0QmVLnri1bttCtWzdPh6EcVNm/l4isMsYkVzxWq6qcEF+2qNNhLXUopRovTRxOiG8bBlgN5Eop1Vhp4nBCx5ZNCfL30QZypRzUGKrCzwXO/jtp4nCCr4/QNULX5lDKEUFBQRw9elSTh5czxnD06FGnBgVqryonxUWEsijV7UuAKNXgRUVFkZ6eTmZmpqdDUTUICgoiKirK4eM1cTgpLjKUz1alcyS3gNYhgTWfoFQj5e/vT0xMjKfDUG6gVVVOio+0Gsi1ukop1Vhp4nDS6UWdNHEopRonTRxOCg8NpFVwAKm6GqBSqpHSxFELcZHas0op1Xhp4qgFa1GnXEp1USelVCOkiaMWukWGkV9Uwt5jeTUfrJRS5xi3Jg4RGSEiqSKyQ0QmV/L6UBHJFpG1tp+nbPvj7PatFZETIvKQ7bVnRGS/3WuXu/M9VEYbyJVSjZnbxnGIiC/wOnApkA6sFJG5xpiKS2T9Yoy50n6HMSYV6GN3nf3AbLtDXjHGvOSu2GvSNcJa1Cn1UA4jekZ6KgyllPIId5Y4+gE7jDE7jTGFwExgVC2uczGQZoypfrWVetQkwJdOLZuyVXtWKaUaIXcmjvbAPrvtdNu+ii4QkXUi8p2I9Kjk9THApxX2TRKR9SIyQ0RauChep2jPKqVUY+XOxHH2Ir1QsRvSaqCTMaY38Bow54wLiAQAVwOf2e1+E4jFqso6CPyr0puL3C0iKSKS4o65cuIiw9h99CSnikpcfm2llPJm7kwc6UAHu+0o4ID9AcaYE8aYXNvzeYC/iLS2O2QksNoYk2F3ToYxpsQYUwq8jVUldhZjzHRjTLIxJjk8PNw178hOfGQopQa2Z+S6/NpKKeXN3Jk4VgJdRCTGVnIYA8y1P0BEIkVEbM/72eI5anfIzVSophKRtnabo4GNboi9Rqd7Vmk7h1KqcXFbrypjTLGITAK+B3yBGcaYTSIy0fb6NOB64F4RKQbygTHGNnm/iDTF6pF1T4VLvygifbCqvXZX8nq9iG4VTKCfLuqklGp83Dqtuq36aV6FfdPsnk8FplZxbh7QqpL9t7o4zFrx9RG6RISQmqGJQynVuOjI8TqIjwzTQYBKqUZHE0cdxEeGkplTwLGThZ4ORSml6o0mjjrQBnKlVGOkiaMOyhPHQa2uUko1Hpo46iA8JJCWwQHas0op1aho4qgDESEuIpSt2rNKKdWIaOKoo7jIULZn5OiiTkqpRkMTRx3FR4aSV1jCvuO6qJNSqnHQxFFHuqiTUqqx0cRRR/aLOimlVGOgiaOOggP96NiyqSYOpVSjoYnDBeIiQnUQoFKq0dDE4QLxkaHsOqKLOimlGgdNHC4QFxlGqYEdh3VRJ6XUuU8ThwtozyqlVGOiicMFols1JcDPh1Rt51BKNQKaOFzAz9eHLm1CtMShlGoUNHG4SFxkqHbJVUo1Cpo4XCQ+MpTDOQUc10WdlFLnOE0cLhIfGQZoA7lS6tynicNF4m09q7SBXCl1rnNr4hCRESKSKiI7RGRyJa8PFZFsEVlr+3nK7rXdIrLBtj/Fbn9LEflRRLbbHlu48z04Kjw0kBZN/UnVtTmUUuc4tyUOEfEFXgdGAt2Bm0WkeyWH/mKM6WP7+XuF14bZ9ifb7ZsMLDTGdAEW2rY9TkSIiwzVqiql1DnPnSWOfsAOY8xOY0whMBMY5YLrjgI+sD3/ALjGBdd0ifjIMFIP6aJOSqlzmzsTR3tgn912um1fRReIyDoR+U5EetjtN8APIrJKRO622x9hjDkIYHtsU9nNReRuEUkRkZTMzMy6vRMHxdkWdUo/nl8v91NKKU9wZ+KQSvZV/Cq+GuhkjOkNvAbMsXttkDEmCauq634RGezMzY0x040xycaY5PDwcGdOrbXTU49oA7lS6tzlzsSRDnSw244CDtgfYIw5YYzJtT2fB/iLSGvb9gHb42FgNlbVF0CGiLQFsD0eduN7cErXiLKeVdrOoZQ6d7kzcawEuohIjIgEAGOAufYHiEikiIjteT9bPEdFJFhEQm37g4HLgI220+YC423PxwNfufE9OCUk0I8OLZuwVXtWKaXOYX7uurAxplhEJgHfA77ADGPMJhGZaHt9GnA9cK+IFAP5wBhjjBGRCGC2Laf4AZ8YY+bbLv0CMEtE/gjsBW5w13uojbiIMC1x1NavU6B9EsTY1UruWgL7V8OFD3kqKqVUBW5LHFBe/TSvwr5pds+nAlMrOW8n0LuKax4FLnZtpK7TrW0oi1IPU1BcQqCfr6fDaVjaJ8FnE+CG963ksWvJ6W2llNdwa+JojOIiQykpNew4nEuPds08HU7DEjMYrnsXProOzrsE9i0/nUSUUl5DpxxxsdNTj2h1Va1k7YGSQkidB31u0aShlBfSxOFi0a2CbYs6aeJwWkEu/PgMiO3PcuXbVnWVUsqraOJwMT9fH84LD2GLJg7nzXsETh2HES9A91HWqJ9Z4zV5KOVlNHG4QXxkqM6S66ycDNjwGXQcCP3vgaGPQ/Ep6DzU6lWllPIamjjcIC4ylIwTBWTl6aJODvv5/wEGRtk62bWJh143QOp30Ptmj4amlDqTJg43OD31iFZXOSQzFVb/B5LvgFaxp/cPnWw1lP/6iudiU0qdRROHG5StBqgN5A5a8AwEBMOQR8/c3yoW+oyFlHchO90joSmlzqaJww0iwgJp1sRfSxyO2P2b1fX2wocguPXZrw/5HzAGlrxU76EppSqnicMNREQbyB1RWgo/PAGh7aD/vZUf07wj9J0Aaz6EY7vqNTylVOU0cbhJfGQo2zJyMUYXdarS5tlwYDUMfwICmlZ93EV/AR8/WPLP+otNKVUlTRxuEhcZRm5BsS7qVJXiAljwLET0hN5jqj82rC2cfyes+xSObK+f+JRSVdLE4SZxOvVI9Va+Y00vcumz4OPAZJCDHgK/JrZuu0opT9LE4Sa6GmA18o/D4heh8zBrMkNHhITDgImw8Qs4tLHm45VSbqOJw01CAv2IatFEe1ZV5peX4VQ2XPacc+cNfAACm2mpQykP08ThRlbPKk0cZ8jaC8vfskaDR/Zy7twmLeCC+2HrN3BgjXviU0rVyKHEYVvK1cf2vKuIXC0i/u4NreGLiwxl55GTFBSXeDoU77HwORCB4X+r3fkD7rUSyE/PuzYupZTDHC1xLAGCRKQ9sBC4HXjfXUGdK+IiwygpNaQdPunpULzDgbWwYZb14d8sqnbXCAqzGsp3/Ah7f3dldEopBzmaOMQYkwdcC7xmjBkNdHdfWOeGbmU9qzK0gRxj4McnoWkruPDPdbtWv7sguA389L+uiU0p5RSHE4eIXADcAnxr26fLztYgunUwAb4+2kAOsP1Ha12NIY9CUB2X1A0Ihoseht2/wM7FrolPKeUwRxPHQ8BjwGxjzCYR6QwscltU5wh/Xx9i24RoA3lpCfz4FLTsDH1vd801+95uTVWy6HmrNKOUqjcOJQ5jzGJjzNXGmH/YGsmPGGMerOk8ERkhIqkiskNEJlfy+lARyRaRtbafp2z7O4jIIhHZIiKbRORPduc8IyL77c653In3W++0ZxWw9mPI3AIXPw1+Aa65pn8QDHkE9i2HHQtcc02llEMc7VX1iYiEiUgwsBlIFZFHajjHF3gdGInVHnKziFTWLvKLMaaP7efvtn3FwF+MMd2AAcD9Fc59xe6ceY68B0+JiwzlYPYpsvOKPB2KZxSetHpARfWzloN1pT7joHkn+Ok5LXUoVY8crarqbow5AVwDzAM6ArfWcE4/YIcxZqcxphCYCTj0yWGMOWiMWW17ngNsAdo7GKtXafQjyJe9AbmHrMF+Iq69tl+AtdjTwXXW2A6lVL1wNHH428ZtXAN8ZYwpAmr6itce2Ge3nU7lH/4XiMg6EflORHpUfFFEooFEYLnd7kkisl5EZohIi8puLiJ3i0iKiKRkZmbWEKr7xJf3rGqE1VW5h+G3KRB/JXQc4J579LoRWp0Hi/7PmqZdKeV2jiaOt4DdQDCwREQ6ATV9ha7s62XFZLMa6GSM6Q28Bsw54wIiIcAXwEO2Eg/Am0As0Ac4CPyrspsbY6YbY5KNMcnh4eE1hFrBr1OsHkD2di2x9jspMiyIsCC/M3tWufD6Xu3nF6D4FFzyrPvu4esHQx+Dw5th05fuu49SqpyjjeOvGmPaG2MuN5Y9wLAaTksHOthtRwEHKlz3hDEm1/Z8HlbJpjWArYTzBfCxMeZLu3MyjDElxphS4G2sKjHXap8En004/eG+a4m13T7J6UtZizqFndlA7sLre63MbbDqfav3U+vz3HuvHtdCm+7WHFYlxe69l1LKsbEYItIMeBoYbNu1GPg7kF3NaSuBLiISA+wHxgBjK1w3EsgwxhgR6YeVyI6KiADvAluMMS9XOKetMeagbXM04PqpUmMGww3vw6c3W+teZ26FmCGw/r+w7r+AsTXG2h5N6dn7sO03hqfzszmYlY+ZGY4YrP0tO8NH10HsxZC+wrpfzOCqY2poFj4L/k3PXkfcHXx8YNjf4L+3WP9Gibe4/55KNWKODuKbgfUBfaNt+1bgPayR5JUyxhSLyCTge8AXmGEbAzLR9vo04HrgXhEpBvKBMbYkcqHtHhtEZK3tko/bSiUvikgfrGqv3cA9Dr4H58QMhjY9IH05+AfDoQ2A2Bp4bY/2z8949DljX/uSInxNIUWZOQT4+dkq8QT8gmDbd9Y6Ezt/hpax0KxB9gE4056lVmP18Ces6dDrQ/wV0LYPLH4Bet3gum6/SjVEv06xajDsv4zuWgL7V8OFD9X58uLI0qYistYY06emfd4qOTnZpKSkOHdSWfVR8h8h5d06lQhW7TnGdW8u493xyVzcLeLM6593CWyaDSVFVsLpdhX0vwc6XuD6Xkj1wRh45xI4cQAeWFX9krCutv1H+Ph6uPIVSL6j/u6rlLcp+3wp+9yquO0gEVlljEmuuN/RxvF8Wymg7GKDsEoI5yb7X/Lwv1mP9m0STuoaUdYlN+fs6187HcZ9AU2aQ/errZLHeyNh2kWw+kMoamC/5s1zYH+K9Xurz6QBVhLu0B8W/xOKTtXvvZXyJjGD4Zpp8MmN8OMztUoa1XE0cUwEXheR3SKyG5iKu6qIvMH+1Wf+ksvaPPavrtXlQoP8ad+8yekG8squf+N/rKqWh7fAVf+22kHmToKXu8OCZyBrXxVX9yLFhdY64m16WOtt1DcRq3os5wCseq/+76+Ut9i1BOb91fri+dsrVs2JC9tQHaqqKj9YJAys3lAi8pAxZorLInGjWlVVudgf319J+vF8vv+zg/94xsDuX2HFW7DVNq9k/BXQfyJ0GuSd1Vi/vwnzJ8MtX0AXB5eEdYcProLDW+BP66wJEZVqLApyrHnhUmZAaFtr5ob+E2td3V7XqiqgvPts2XiKh52KoJGLiwwlLTOXwmIHB6mJQMxFcNNH1gfgwAetRPL+FfDmIFj1ARTmuTdoZ+Rn2dYRHwrnXezZWIY9ASczYcXbno1DuVdjGQ/lqB0L4Y0LIOU96H4NFBfAmI9dUt1eUV2WjvXCr7zeKy4ylOJSQ1pmrvMnN+8Ilz5rVWNd/ZrViP71g/ByN/jhSTi+x/UBO+vXVyD/OFz6d8+Xhjr2h/MutUatn2qkU700Bo1hPJQjTmXDV5Pgo2vBvwn88Qdolwg3fuCy6vaK6rKmhs4q54T4yDAAUg/l0K1tWO0u4t8Ekm6DxFutLq8r3oJlr8OyqRB3udUba/9qt3bDq1TWPquaKuEmaNvbPfdw1vC/wfShVlxD62Esiao/xli99kqKoPtoqyddixjITofRb51b46Fqsu0H+PpP1nxwgx6yZlHwD4IOlYyLjhnsst9NtYlDRHKoPEEI0MQlETQSncOD8fcV1yzqJALRg6yf7HRY+a41SnvrN9ZssUtehOvfh66XndmDy10W2db/Hv6E++7hrHaJ1hxZy6ZaKwY2bene+7m533yjVFoKJ9IhM9UahJu5FQ5vtbYL7f4f+QVZrwHMug06DbT+7btdWfslir1d/nGY/xis+xTCu8GYj6B933q7fbWJwxgTWl+BnOv8fX2IDQ8h1dWz5DaLgkuehiH/Axu/gOVvQdYeqxteZC84thOu+BdEX+Ta+5Y5uB7WzYRBf4LmHWo+vj4Ne9zqWLD0Net35E5l1SaV9ZtvzBxJqKWl1t9seYJItdZvydwGRSdPnxfcBsLjoPcY6zE83voA/eYhGPgArJgOXf4Ah9bD/Eetn7Z9rATS7WrrnHPB1m/hmz/DySMw+BHrxy+wXkNwqldVQ+UNvaoAHpq5hhW7jrH0MTc2HhsDe3+3/jOVfQsD6z9dh37WLLUdBlhVSnUdXW0MfHiNlTz+tLbuS8K6w+d3QOp8q4OBO0exlxRbVYc/PWetO7L9x3NvGpnasE+gnQbBhs+sbqJljbeZW+HIdii2G68U2vZ0Yih/jD+71FjdILfQdrD1a9jyNexfZR3fqouVROKvskqkPnVp4vWAk0fhu/+BjZ9DRC+45nW3Vw1X1atK1w2vR3GRYcxZe4Ds/CKaNfF3z01EoLTI6lV00SOw8m1rTEX+MSuhlK1b4RcE7ZKshuQOA6yk4mx1zo6F1oDFES94Z9IAq85302yrofwPz7v22qdOQNpCSP0Otn0Pp7Ks/etmQkgE5GRY9fC+bvq3bghiBsOFf4EPR9vmdSux9q/5EMKirMQQfZH12KYbtO5qDYZ1RHXjrS4cDBf+2fo5ccD6lr7la/jtVasjR2g7q3t7tyuthObt/0ab5lgJN/84DH3cel8enFZHSxz1aNHWw9z+/ko+m3gB50e7qc69pqkGcg5ZCWTfcuvx0Hootc0o2zrudCLpOMCaiNG+h5R9tUNpiTW6Pe8o9LsbBv/FPe/HFebcZ1XjPbgGwtrV7VrZ6VaiSJ0Hu36xknSTFtB1BLToZFUVRp1vJVVTYn049r8H+o733uTqLnuXw6L/tf4GA0KgMBe6jrSqVlp3gaBadhKpi7xjVpLf+o31b1ScD0HNIW6k1S4SO/z0jAfe0G6Vmwnz/gKbv7JKF6PegMie9XNvqi5xaOKoRwey8hn4wk88d01Pbh3QyT03cfaPvTDPKsrv+936j56+wureBxAcbk3h0aG/lUgKcuDLu6wklLUXvrofAkLh5k+8u0rm+G54rS/0nWC19zjDGGuFwbJkcWi9tb9lLMRfbvVmi+oHe5eemaDTFsOsW6B5NGRssD44k26zBmO1cNO/vbfYv9paWGvHj9bfULdRsPlLSL6zzvO+uVRhnlVi3PKNNdnoqWxrwtHzLrbmjAsMhbkP1Hm+p1oxxvqyM+8RK+EOnQwD/2StP1OPNHF4QeIwxpDw7A+M6tOO/72ml6fDqVxpqVXvXJZI9v1uffAC+AZa08wf2wU+vtYiTeO+hM5DPBqyQ775szX314OrrXEx1SkugN2/wNZ5sG0+nNgPiJVA40ZaySK865nnVJewOw+1uk1v+tKaSqb7KLjgAYiqv14w9eLQRithpH5rlcIGPWStkzJnomc+fJ1RUmQNsN36jVWtlXMQfPwgogcc3WGt+bL12zPHRrhLziH45mHr99i+r1XKaBPv3ntWQROHFyQOgBumLcUY+PzegZ4OxXE5GXaJZLmtsdFA77Ew+k1PR+eYBX+Hpa9aPXJGTbX22ZfE8o7B9h+sUsWOhda3PP+mVtVF3OXQ9Q8Q3LpuMWTvh+XTrFH/BdnWDMgX3G9d38e3zm/RYzJTrUW0Ns2GwGYwcJJVsgoK847qHmeVlsKB1VabyNZvrMRRpklLqwq3Vaz12LLsMabuXb6NsdaT+e5Ra46p4X+DAffXeynDniYOL0kcT8zZwFdrD7D+6csQT4+wro1dS+Cz8dDzBqt3h7d9c6zKriXw8Q3WRIwPpFiliP/eCj2vtT749i6zSgMhkadLFTGDrcFUrlaQA2s+gt/fsKr8WnaGAfdBn7ENa26to2nWNDMbZllJtv9EK2k0aeHpyFxn52JrbEjsMKttJGYwFOVZpe7sdM4Y5takxZnJpDy5dD47qVRMqCcOWH+P+1Osku2o1612IA/TxOEliePD3/fw5JyN/DZ5OO2bN7AxlC6a499jNn0Fn91mdU3OO3q6h09ET1uyGAlt67GbZkmx1WV06VTrAyOoOZz/R6uzQWhk/cRQG1l7rYSx9hPwDbAGWA56CIJbeToy16rp773olFWNe2wnHEuzPe6Eozshex9nJJWg5mcmk5Iiq71n1BtWT6nv/sdKSMl3wuUvek0JVBOHlySOlbuPccO0ZcyYkMzw+AhPh+OchljtUNGMkVZDdvNOVjVRWW8oT9u7HJa9ZjXU+vhZqxhecH+99qCp0YkD8Mu/rKo2EWuxrAsfhtAG9nfsqLr8vRcX2CWVnVbprCzBZKfblpu24+NnlTJ6j3Hxm6gbHcfhJewXdWpwiaOy/ywunP/G7XYtgSOp1riC1e9b4wa8IWmA1Q26Y3/rw+X3aVZV1rpPoPMwa3aAXjec2QmhPhN2bqY19mHlO1YpLfFWGPzXc3c6jzJ1+Xv3C7QNXqxktHpxgVVqO5pmdd/e+RMM+rPXJY3qNLChkw1fsyYVFnVS9cO+muGSp1w+zbTLtOxsVVU8vAkuftpaV2TNh9YAuh+etBpN62sW2Lxj1iJi/06A5W9Cr+thUgpcNeXcTxru5BdotV8ENIVD62Dw/8CqGd73t1gNrarygDveX8mBrHzmP9RAvqmfCxpqNVtxodWff/ELp7tFI9YHd8sYa4R6SASEtLF7bvtp0qLm9prKfi+p31mlnv2rrN5lPa+zxhF4QWPtOaOBtBd6pKpKREYA/wZ8gXeMMS9UeH0o8BWwy7brS2PM36s7V0RaAv8FooHdwI3GmOPufB+uFhcZyi/bMykqKcXfVwt99aKhVrP5BUCfm61qjNn3WN012/WBZh0g9zCkr7S6S9vP9VTGx8/qCFCWVEIjzk40oW1h1nhrfEK7JGsFxzUfAcaaGHDoYxDRvb7f9bmvuulSvP1vEjcmDhHxBV4HLgXSgZUiMtcYs7nCob8YY6504tzJwEJjzAsiMtm23aAWXIiPDKWoxLAz8yRxkToBsXLA7l9gxwKrWiPlXWvBrLIPGGOskkHuYcjNsP0ctgaSle3LOWiNgD95+OyGWYAPrrYSTWmRNWXKFf/ynrVVzkUN9YuMjTtLHP2AHcaYnQAiMhMYBVRMHM6eOwoYajvuA+BnGljiKEsWWw+d0MShalaxGiPmojO3RazpMQJDre6e1SktsdoucjOsxX/KEsuWb6wuwYnjrN49SlXDnfUk7YF9dtvptn0VXSAi60TkOxHp4cC5EcaYgwC2xzaV3VxE7haRFBFJyczMrMv7cLnOrUPw83HRok7q3FddtYazfHyt6eUje8J5l1iDDtv3heO7rNJM6ncNqpFWeYY7E0dlw6IrtsSvBjoZY3oDrwFznDi3WsaY6caYZGNMcni4G9dhqIUAv7JFnVyfOKYtTmNp2pEz9i1NO8K0xWkuv5eqJxc+dHYVRsxg1zTq25dmhv/Ne3ubKa/izsSRDtgvCRcFHLA/wBhzwhiTa3s+D/AXkdY1nJshIm0BbI+H3RO++0xbnEarkIAzEoerPtzjI0O576PV/HflPjJzCliadoRJn6whIaqRTemtHOPK0oxqNNzZxrES6CIiMcB+YAww1v4AEYkEMowxRkT6YSWyo0BWNefOBcYDL9gev3Lje3CLhKhm/HvBdvKLSjhxqoiN+7OZ9Mkapo5NBKCopJTs/CKy8orIzi/iRH4RWfmFZOcVkZ1fbD3PL7JtWz9ZtsfCYqvh89EvrOm/fX2E65OiaBUciDGmYc6PpdyngTfSKs9w6zgOEbkcmILVpXaGMeZ5EZkIYIyZJiKTgHuBYiAfeNgYs7Sqc237WwGzgI7AXuAGY8yx6uLwtnEcAK8v2s4/v99GVIsmHMo+RdtmQZSUGrLzizhZWFLtuaGBfoQ18adZE3+aNz39WL6vSQBLtmcyf+MhIkIDycgpAKBjy6Zc0i2CS7q34fzoltoVWClVLZ2ryssSR1ZeIZe8vJgjuYW0axZE93bNypOAfUKw/2neNICwID/8avjAL6ueGte/Ix8t38tzo3qQnV/Mgi0Z/LrjCIXFpYQF+TEsvg2XdItgSFw4YUFevnSmUqre6VxVXmbzwROUGnhw+Hl8tHwvd1wYzcDYOq73wOmkMXVsIgNjWzMgtlX59owJ55NXWMwv24/w4+YMftp6mK/WHsDPRxjQuRWXdGvDxd0i6NCyqQveoVLqXKUlDg+o+OFecbsupi1OIyGq2RnXWZp2hPXp2UwccmYf/5JSw5q9x/lxSwYLNmeQlnkSsBrYL+0ewSXdIujVvhk+PtouolRjpFVVXpQ4nPlwr087M3NZuOUwP27JIGX3MUoNtAkN5OJuEVzWPYJNB7JJ6tTC6+JWSrmHJg4vShwNwfGThSxKPcyCLRksTs3kZGEJAb4+GAx3DIrh7sGdSc3IcVlJSSnlfTRxaOKotYLiEn7feYwFmzP4dsMBjp0swkcgONCPt27tq0lDqXNUVYlD+2OqGgX6+TKkazjPXdOTVU9cypjzO1Bq4FRhCSGB2r9CqcZGE4dyyrKdR/lhcwZ3DIqmxBjGvbOcXUdOejospVQ90sShHGbf++upq3rwz+sTyDlVzI1vLeVwzilPh6eUqieaOJTD1qdnn9EQfl3fDvx9VA+y8oqYMGMlOaeKPByhUqo+aOJQDps4JPashvBbL4jmnfHnsy0jh7v/s4qC4uqnS1FKNXyaOFSdDekazj9vSGDZzqM8/N91lJSe+z31lGrMtEuMconRiVEcySnk+XlbaBUSwLNX99CZeJU6R2niUC5z1+DOZOYWMH3JTtqEBjJpeBdPh6SUcgNNHMqlJo+IJzOngJd+2EbrkEDG9Ovo6ZCUUi6miUO5lI+P8OL1CRw7WcjjszfQKiSQS7tHeDospZQLaeO4cjl/Xx/euCWJXu2bMemT1aTsrnadLaVUA6OJQ7lFcKAfMyacT/vmTbjj/ZVsy8ip+SSlVIOgiUO5TauQQD64ox9B/r6Mn7GCA1n5ng5JKeUCmjiUW3Vo2ZQP7uhH7qlibpuxgqy8Qk+HpJSqI00cyu26tQ3j7fHJ7D2Wxx3vryS/UEeXK9WQaeJQ9WJA51a8OqYPa/ZlMemT1RSXlHo6JKVULbk1cYjICBFJFZEdIjK5muPOF5ESEbneth0nImvtfk6IyEO2154Rkf12r13uzvegXGdEz7Y8N6onC7ce5vHZG2gMi4gpdS5y2zgOEfEFXgcuBdKBlSIy1xizuZLj/gF8X7bPGJMK9LF7fT8w2+60V4wxL7krduU+4wZ0IjOngH8v3E54aCCP/CHe0yEppZzkzgGA/YAdxpidACIyExgFbK5w3APAF8D5VVznYiDNGLPHXYGq+vXQJV04nFPA64vSCA8JZMKgGE+HpJRygjurqtoD++y20237yolIe2A0MK2a64wBPq2wb5KIrBeRGSLSorKTRORuEUkRkZTMzEzno1duIyL87zU9+UOPCJ79ZjNfrzvg6ZCUUk5wZ+KobGrUipXaU4BHjTGVdrMRkQDgauAzu91vArFYVVkHgX9Vdq4xZroxJtkYkxweHu5c5MrtfH2Ef49J5PxOLXl41lp+23HE0yEppRzkzsSRDnSw244CKn61TAZmishu4HrgDRG5xu71kcBqY0xG2Q5jTIYxpsQYUwq8jVUlphqgIH9f3h6fTGx4CPd8uIqN+7M9HZJSygHuTBwrgS4iEmMrOYwB5tofYIyJMcZEG2Oigc+B+4wxc+wOuZkK1VQi0tZuczSw0Q2xq3rSrIk/H9zRj2ZN/Jnw3gr2HD3plvtMW5zG0rQzSzVL044wbXGaW+6n1LnMbYnDGFMMTMLqLbUFmGWM2SQiE0VkYk3ni0hTrB5ZX1Z46UUR2SAi64FhwJ9dHLqqZxFhQXxwRz9OFhRz41vLyMwpKH/NVR/uCVHNmPTJmvLksTTtCJM+WUNCVLM6Xxs0ManGRRpDX/rk5GSTkpLi6TBUDf6zbDdPfbWJ6NZNeXVMIqv3ZvGvH1K5d2gsseEhFBSXUlBUQmFJKQVFpRQUl1JYXEpBcYn1WnGJbdt6vbDE9prt2Ky8QvZn5RMS6MfJgmKiWwXTOjSQJgG+NPH3Pf1oex7kf+b+oLOO8SHI35emAX6s35fFw7PWMfWWRAbGti5PTFPHJp61TrtSDYWIrDLGJJ+1XxOH8iZv/LyDF+enOnWOv68Q6OdLoJ8PAX4+BPr5EOjne/q5vw8Bvta+nUdy2ZaRS2x4MB1aNiWvsIRTRSXkF5aQX3T6eV5RCbX9r5HQvhn7jufx+i1JmjRUg1ZV4tCFnJRXuW/oeaQfz+OT5fsY1acdN/fraJcQfG1JwfbclhB8fBxb27ysFPDg8PP4aPlenrumc5Uf7MYYCktKOVVYSn6RlVTyCottieX0vlO2hJNvSzjfbzrE+v3ZBPn5sPtIHv1jDL4OxucJ0xankRDV7Izfw9K0I6xPz2bikFgPRqa8mSYO5VWWph1h/saM8g/3m87vQGLHSofqOH1d+6qjAbGtqq1KEikrxfjSDH+H7/Hh73sY068Dn6ek8/jsDXyyYg/PXt2Dvp1a1vk9uENZ28/UsYn0jmrOuvSs8m2lqqJVVcprVPxwd2U7gbu/WZ8V+44j3PXhKgJ8heN5RYxObM/kkfFEhAXV+V6uZIzhrSU7een7VIpLDU0DfHlnfLJWsSlA2zg0cTQADbnapKrYU3Yfp6C4hLeX7MLfV3jg4i7cPiiaQD9fD0YLxSWlzNt4iGk/p7H54AmCA3w5aZvu/okrunHnRZ09Gp83aMh/j66iiUMTh/KgPUdP8tw3m1mw5TAxrYN56qruDItrU+9xnCoq4bOUfUz/ZSf7juXTOTyYS+Ij+GzVPsb278jbS3ZRWFLKXy7tygMXd6n3+LxJeSny5kQGntc4e8pp4tDEobzAotTDPPf1ZnYeOcnF8W148sruRLcOdvt9s/OK+PD33bz3226OniykT4fm3Ds0lpAAPx6YefrD8JftmfzxgxQKi0u5f1gsf70sDhHvbdx3t1kp+3j08/WEhwaSW1DMyzf2ZkTPtjWfeI7QxKGJQ3mJwuJS3vttF68u3E5RieHOi2K4f9h5BAe6vq/KoexTvPvrTj5ZvpeThSUMjQtn4pBY+se0REQqrY75bfsRXvwhlXX7svjjhTE8cUW3Rpk8Dp84xeg3lnI8r5A8WzWen48wNC6ca5OiGB7fhiB/z1Y5upsmDk0cysscPnGKF77bypdr9hMZFsRjl8dzde92LvmQ3nE4l+lL0pi9Zj+lBq5MaMs9g2Pp3i7MofONMTz79WbeX7qbW/p35LlRPR3u9nwuOFlQzE3Tl7E9I5dAPx8mDIzmg2V7uKhLa1buPkbGiQLCgvy4snc7rktqT1LHFudkctXEoYlDealVe47x9NxNbNx/gvOjW/DM1T3o0a52U6Gs3nucaT+n8eOWDAL9fLgpuQN3XtSZDi2bOn0tYwz/mJ/KtMVpXN83in9cl+DVY1JcpaTUcM+HKSzccpjgQD+m39b3jF5+r45JxGD4cvV+5m88RH5RCZ1aNeXaxChGJ7anYyvnf9feShOHJg7lxUpKDbNS9vHP71PJyitkbP+O/OXSOFoEB9R4rjGGn7dlMu3nNJbvOkazJv6Mv6AT4wdG0yoksE5xGWN4deEOXlmwjSsT2vLKTX3w93XritMeZYzhmbmb+GDZHi7rHsGEQdHV9qrKLShm/sZDfLk6nWU7j2IM9ItuybVJ7bk8oS1hQY6NAfJWmjg0cagGIDuviFcWbOPD3/cQEujHXy/rytj+nSr9pl9cUsq3Gw7y5s9pbD2UQ9tmQfzxwhhu7tfR5e0lby1O4/99t5XLukfw2thEj3cndpd3f93Fc99s5q6LYvjbFd2dOnd/Vj5z1uzni9Xp7Mw8SaCfD5d2j+C6pCgu6tIavwaYcDVxaOJQDcjWQyd4du5mlu08SpvQQO4Z0pk/XmiNrcgvLOEf87cye0062fnFdGkTwj1DYrm6dzsC/Nz34fTB0t08PXcTQ+PCmTau7znXMDx/4yHu/XgVI3pE8vrYpFq36RhjWJ+ezZer05m77gDH84poHRLIqD7tuDapPd3bhvHWkp0NYoyIJg5NHKqBMcbw3cZDPDVnI0dOFjIwthX9Y1rxzq87yTlVTNeIEB75QzwXx7ept4brmSv28tjsDVzQuRXvjE+macC5MWvRmr3Hufnt3+nWNoxP7xrgsqRYWFzKz6mH+XL1fhZuzaCoxBAfGUpSp+bMW3+IN8YlefVsypo4NHGoBiq/sITHZ29g9pr9gDUb8OOXd+P2QTEeiWf2mnT+MmsdSR1b8N7t5xPawOvx9x7NY/QbvxEc6MeX9w2kdR3bhapy/GQh32w4yJer01mzNwsB/HyFET0i+S3tqNclDag6cTS8SjelGpkmAb68clMf7hgUDcC9Q2I9ljQARidGMXVsEmv3ZTHuneVk5RV6LJa6ysorZML7KyguNbx3+/luSxoALYIDuHVAJ2bfN4if/jKEScPPI8jPl6/XH6RTy6b0i/bOiTAro4lDqQZgadoR5qw9UD5rcMXVBuvb5b3aMm1cX7YczOHmt5dzNLeg5pO8TEFxCfd8uIr0Y/lMv7UvseEh9XbvzuEhXBDbCj9fIaF9M9bsy+Lqqb81mN+jJg6lvJx9/ffDl8UxdWziGcvgesol3SN4d0Iyu47kctP03zl84pRH43GGMYZHP1/P8l3H+OcNCfTv3Kpe71/2b/r6LUnMfeBCJg6JZfPBE1z2ymI2pGfXayy1oYlDKS+3Pj37jPrvgbGtmTo2kfVe8AFzUZdw3r+9Hwez8rnxrWXsz8r3dEgOeeXHbcxZe4C/XtaVUX3a1/v9K/6bTh4Zz/PX9KSoxHDdtKV8lrKv3mNyhjaOK6XqbNWe40x4bwVhQf58cld/OrVy/8SNtfVZyj4e+Xw9NyZbo+G9aaqQo7kFPPDpGpamHeW2CzrxxBXd3drFuiYeaRwXkREikioiO0RkcjXHnS8iJSJyvd2+3SKyQUTWikiK3f6WIvKjiGy3PdZ9eTilVJ307dSCT+8awMnCYm58axk7Dud6OqRK/bbjCI99uYELz2vN86N7eVXSAGgVEsh/7ujHXRfF8J9le7jlnd85nON9VYBuSxwi4gu8DowEugM3i8hZQzFtx/0D+L6SywwzxvSpkPEmAwuNMV2AhbZtpZSH9WzfjJl3D6Ck1DBm+jK2Hjrh6ZDOkHooh4kfriI2PIQ3xiV57dQpfr4+/O2K7rx6cyIb9mdz1Wu/smrPcU+HdQZ3/ub6ATuMMTuNMYXATGBUJcc9AHwBHHbwuqOAD2zPPwCuqWOcSikXiY8M47/3XICfjw9jpv/Oxv2eb4cBaybiO95fSZMAX2bcfn6DmEPq6t7tmH3fIAL9fBkzfRmfLN/r6ZDKuTNxtAfsW3jSbfvKiUh7YDQwrZLzDfCDiKwSkbvt9kcYYw4C2B4rXUZNRO4WkRQRScnMzKzD21BKOSM2PIRZ91xAcIAf1765lPeX7j7j9aVpR5i2OK3e4jlZUMwdH6zkeF4hMyacT/vmTert3nXVrW0YcycNYmBsax6fvYHJX6ynoLjE02G5NXFUVnlYsSV+CvCoMaay38QgY0wSVlXX/SIy2JmbG2OmG2OSjTHJ4eHhzpyqlKqjjq2aMmviBbRo6s8zczfx7q87gdPdUBOiajdtvLNKSg0PfrqGzQdOMHVsIj3b1899Xal50wBmTDif+4fFMnPlPm5663cOZnu295o7E0c60MFuOwo4UOGYZGCmiOwGrgfeEJFrAIwxB2yPh4HZWFVfABki0hbA9uhoFZdSqh61b96EryddSLvmQTz3zRYmzFjBfR+vrrepNazFqDaxcOthnr26B8PjI9x+T3fx9REe+UM808YlsT0jh6te+5XlO496LB53Jo6VQBcRiRGRAGAMMNf+AGNMjDEm2hgTDXwO3GeMmSMiwSISCiAiwcBlwEbbaXOB8bbn44Gv3PgelFJ10CYsiK8nXUhEWCA/b8skK6+IVxdu5/3fdrn9W/O7v+7iP8v2cPfgztx6QbRb71VfRvRsy5z7BxEW5M8t7yzn/d924YkhFW5LHMaYYmASVm+pLcAsY8wmEZkoIhNrOD0C+FVE1gErgG+NMfNtr70AXCoi24FLbdtKKS+VmpFDUYlhTL8OBPn7sO9YHs98vZkL/t9PXPP6b0xbnMbuIyddes/5Gw/x/LwtjOwZyeQR8S69tqd1iQhlzqRBDI0L55mvN/OXz9Zxqqh+2z10AKBSym0qThdetv34yHgycgqYv/EQG2w9r+IjQxnRM5IRPSOJiwit9RgLd02R7m1KSw2v/bSDKQu30aNdGNPG9SWqhWuXrdVp1TVxKFXvpi1Oq3HBovTjeXy/KYPvNx5i5Z5jGAMxrYP5Qw8rifSOauZwEqmvKdK9yU9bM/jTzLX4+Qivj01i4Hmuaz/SxKGJQymvl5lTwA+bDzF/4yGWpR2luNTQtllQeRI5P7plpcvogjVF+rVvLuVobiFf3jewXme79bRdR05y939SSMvMZfLIeO66qLNLRsVr4tDEoVSDkp1XxMKtGczfeIjF2zIpKC6lVXAAl3aP4A89I9l84ASJHZszMLY1BcUl3PbuClbtOc6NyR34v2t7eTr8eneyoJhHPl/HvA2HiI8M5dERcQyz60lWm6VpNXFo4lCqwTpZUMzibZnM33iIn7YeJregmCb+PpSUwv3DYtl15CRz1h4gONCXt29L9rqV9OqLMYZpi3fy4vyt+Ijw0o0JjE6MqvXStJo4NHEodU4oKC5h6Y6jfLfxIPM2HCS3wOpR1MTfl3cnNN6kYW/Jtkzu/WgVeYUlXJvUnkWpmbUaP6NLxyqlzgmBfr4Mi2/Di9f3Zu1TlzE60ZrJ6M6LYjRp2AzuGs78hwYT1bIJX6zez7j+HV36u9HEoZRqsFbsPsbibZk8OPw8PvaCJXW9yb7jeZwsKHHLcsOaOJRSDZK3LqnrDdz9u9HEoZRqkLx5SV1Pc/fvRhvHlVJKVUobx5VSSrmEJg6llFJO0cShlFLKKZo4lFJKOUUTh1JKKac0il5VIpIJ7Knl6a2BhtoxXGP3jIYae0ONGzR2d+lkjAmvuLNRJI66EJGUyrqjNQQau2c01Ngbatygsdc3rapSSinlFE0cSimlnKKJo2bTPR1AHWjsntFQY2+ocYPGXq+0jUMppZRTtMShlFLKKZo4lFJKOUUTRzVEZISIpIrIDhGZ7Ol4HCUiHURkkYhsEZFNIvInT8fkDBHxFZE1IvKNp2Nxhog0F5HPRWSr7Xd/gadjcpSI/Nn2t7JRRD4VkSBPx1QVEZkhIodFZKPdvpYi8qOIbLc9tvBkjFWpIvZ/2v5m1ovIbBFp7sEQHaKJowoi4gu8DowEugM3i0h3z0blsGLgL8aYbsAA4P4GFDvAn4Atng6iFv4NzDfGxAO9aSDvQUTaAw8CycaYnoAvMMazUVXrfWBEhX2TgYXGmC7AQtu2N3qfs2P/EehpjEkAtgGP1XdQztLEUbV+wA5jzE5jTCEwExjl4ZgcYow5aIxZbXueg/UB1t6zUTlGRKKAK4B3PB2LM0QkDBgMvAtgjCk0xmR5NCjn+AFNRMQPaAoc8HA8VTLGLAGOVdg9CvjA9vwD4Jr6jMlRlcVujPnBGFNs2/wdiKr3wJykiaNq7YF9dtvpNJAPX3siEg0kAss9HIqjpgD/A5R6OA5ndQYygfds1WzviEiwp4NyhDFmP/ASsBc4CGQbY37wbFROizDGHATrixPQxsPx1NYdwHeeDqImmjiqJpXsa1B9l0UkBPgCeMgYc8LT8dRERK4EDhtjVnk6llrwA5KAN40xicBJvLe65Ay29oBRQAzQDggWkXGejarxEZG/YVUzf+zpWGqiiaNq6UAHu+0ovLj4XpGI+GMljY+NMV96Oh4HDQKuFpHdWFWDw0XkI8+G5LB0IN0YU1ay+xwrkTQElwC7jDGZxpgi4EtgoIdjclaGiLQFsD0e9nA8ThGR8cCVwC2mAQyu08RRtZVAFxGJEZEArMbCuR6OySEiIlh17VuMMS97Oh5HGWMeM8ZEGWOisX7fPxljGsQ3X2PMIWCfiMTZdl0MbPZgSM7YCwwQkaa2v52LaSAN+3bmAuNtz8cDX3kwFqeIyAjgUeBqY0yep+NxhCaOKtgaqyYB32P9J5pljNnk2agcNgi4Fesb+1rbz+WeDqoReAD4WETWA32A//NsOI6xlZI+B1YDG7A+F7x2GgwR+RRYBsSJSLqI/BF4AbhURLYDl9q2vU4VsU8FQoEfbf9Xp3k0SAfolCNKKaWcoiUOpZRSTtHEoZRSyimaOJRSSjlFE4dSSimnaOJQSinlFE0cStWBiJTYdXle68pZlEUk2n4WVaW8hZ+nA1Cqgcs3xvTxdBBK1SctcSjlBiKyW0T+ISIrbD/n2fZ3EpGFtrUXFopIR9v+CNtaDOtsP2VTfviKyNu2tTJ+EJEmtuMfFJHNtuvM9NDbVI2UJg6l6qZJhaqqm+xeO2GM6Yc1MniKbd9U4D+2tRc+Bl617X8VWGyM6Y01x1XZLAVdgNeNMT2ALOA62/7JQKLtOhPd89aUqpyOHFeqDkQk1xgTUsn+3cBwY8xO24STh4wxrUTkCNDWGFNk23/QGNNaRDKBKGNMgd01ooEfbYsTISKPAv7GmP8VkflALjAHmGOMyXXzW1WqnJY4lHIfU8Xzqo6pTIHd8xJOt0tegbVCZV9glW0BJqXqhSYOpdznJrvHZbbnSzm9LOstwK+25wuBe6F8zfWwqi4qIj5AB2PMIqxFr5oDZ5V6lHIX/ZaiVN00EZG1dtvzjTFlXXIDRWQ51he0m237HgRmiMgjWCsG3m7b/ydgum221BKsJHKwinv6Ah+JSDOsBcdeaWDL1KoGTts4lHIDWxtHsjHmiKdjUcrVtKpKKaWUU7TEoZRSyila4lBKKeUUTRxKKaWcoolDKaWUUzRxKKWUcoomDqWUUk75/++2hMn/WoDRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Plot training loss and validation loss for best MLP model\n",
    "training_loss = best_mlp.history[:, 'train_loss']\n",
    "validation_loss = best_mlp.history[:, 'valid_loss']\n",
    "\n",
    "plt.plot(training_loss, 'x-', label='training loss')\n",
    "plt.plot(validation_loss, 'x-', label='validation loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Validation loss: %.02f'%min(validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Plot accuracy on validation data on MLP model\n",
    "validation_accuracy = best_mlp.history[:,'valid_acc']\n",
    "\n",
    "plt.plot(validation_accuracy,'x-', label='validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Maximum accuracy: %.02f'%max(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best MLP model to file\n",
    "with open('best_mlp.pkl', 'wb') as f:\n",
    "    pickle.dump(best_mlp, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Best SVM and MLP Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best SVM model from file\n",
    "best_svm = pickle.load(open('best_svm.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network that has 9 neurons in one hidden layer\n",
    "class netModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=8, # Set number of neurons to 8\n",
    "            dropout=0.2 # Dropout of 0.2\n",
    "    ):\n",
    "        super(netModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.num_units = nn.Linear(X.shape[1], num_units)\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = torch.relu(self.num_units(X))\n",
    "        X = self.dropout(X)\n",
    "        X = torch.softmax(self.output(X),dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load best MLP model\n",
    "with open('best_mlp.pkl', 'rb') as f:\n",
    "    best_mlp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dummy model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=1, strategy='stratified')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Dummy Classifier model that makes stratified random class predictions\n",
    "dummy_model = DummyClassifier(strategy='stratified', random_state=1)\n",
    "dummy_model.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate AUC score on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for best SVM model on training data: 0.889\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC on training set for best SVM model\n",
    "best_svm_y_pred_train = best_svm.predict_proba(X_train_smote)\n",
    "best_svm_auc_train = roc_auc_score(y_train_smote, best_svm_y_pred_train[:, 1])\n",
    "print(\"AUC score for best SVM model on training data: %.03f\" %best_svm_auc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for best MLP model on training data: 0.878\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC on training set for best MLP model\n",
    "best_mlp_y_pred_train = best_mlp.predict_proba(X_train_smote)\n",
    "best_mlp_auc_train = roc_auc_score(y_train_smote, best_mlp_y_pred_train[:, 1])\n",
    "print(\"AUC score for best MLP model on training data: %.03f\" %best_mlp_auc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for dummy model on training data: 0.533\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC on training set for dummy model\n",
    "dummy_y_pred_train = dummy_model.predict_proba(X_train_smote)\n",
    "dummy_auc_train = roc_auc_score(y_train_smote, dummy_y_pred_train[:, 1])\n",
    "print(\"AUC score for dummy model on training data: %.03f\" %dummy_auc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate AUC score on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for best SVM model on test data: 0.820\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC score on test set for best SVM model\n",
    "best_svm_y_pred = best_svm.predict_proba(X_test)\n",
    "best_svm_auc = roc_auc_score(y_test, best_svm_y_pred[:, 1])\n",
    "print(\"AUC score for best SVM model on test data: %.03f\" %best_svm_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for best MLP model on test data: 0.831\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC score on test set for best MLP model\n",
    "best_mlp_y_pred = best_mlp.predict_proba(X_test)\n",
    "best_mlp_auc = roc_auc_score(y_test, best_mlp_y_pred[:, 1])\n",
    "print(\"AUC score for best MLP model on test data: %.03f\" %best_mlp_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for dummy model on test data: 0.434\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC score on test set for dummy model\n",
    "dummy_y_pred = dummy_model.predict_proba(X_test)\n",
    "dummy_auc = roc_auc_score(y_test, dummy_y_pred[:, 1])\n",
    "print(\"AUC score for dummy model on test data: %.03f\" %dummy_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for best SVM model on test data: 0.740259740260\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on test set for best SVM model\n",
    "best_svm_y_pred_class = best_svm.predict(X_test)\n",
    "best_svm_accuracy = accuracy_score(y_test, best_svm_y_pred_class)\n",
    "print(\"Accuracy for best SVM model on test data: %.12f\" %best_svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for best MLP model on test data: 0.734\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on test set for best MLP model\n",
    "best_mlp_y_pred_class = best_mlp.predict(X_test)\n",
    "best_mlp_accuracy = accuracy_score(y_test, best_mlp_y_pred_class)\n",
    "print(\"Accuracy for best MLP model on test data: %.03f\" %best_mlp_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dummy model on test data: 0.442\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on test set for dummy model\n",
    "dummy_y_pred_class = dummy_model.predict(X_test)\n",
    "dummy_accuracy = accuracy_score(y_test, dummy_y_pred_class)\n",
    "print(\"Accuracy for dummy model on test data: %.03f\" %dummy_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.72       0.28      ]\n",
      " [0.22222222 0.77777778]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix for best SVM model\n",
    "\n",
    "# Code is from https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "  disp = plot_confusion_matrix(best_svm, X_test, y_test,\n",
    "                               display_labels=data.Outcome.unique(),\n",
    "                               cmap=plt.cm.Blues,\n",
    "                               normalize=normalize)\n",
    "  disp.ax_.set_title(title)\n",
    "\n",
    "print(title)\n",
    "print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.65       0.35      ]\n",
      " [0.11111111 0.88888889]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEWCAYAAADl+xvlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfHklEQVR4nO3debxVdb3/8df7HARRQUWGcAQVUdRAwznNNEvN0vppOV7samqZZuqvvP28aurtWr/qakndSL2SpjnkgFkOkYSWpaA44iwyiEyCIOIAfO4f63tkczrn7L1hb/Zah/fzPNZjr/G7PnuvvT/nu75rUkRgZlZkTY0OwMxsdTmRmVnhOZGZWeE5kZlZ4TmRmVnhOZGZWeEVNpFJ6i7pLklvSbplNco5TtJ9tYytUSTtK+n5vKxP0gBJIanLmoqpCFp/LpL+KGlEHdbzjKT9a11uHqne55FJOhY4G9geWARMAv4jIh5azXJPAM4A9o6IpasbZ95JCmBQRLzU6FjaI2kKcHJE/CkNDwBeBdap9TaSdC0wPSLOr2W5a0I9Ppcifx61UNcamaSzgcuB7wP9gC2BnwOH16D4rYAX1oYkVgnXeurHn20BRERdOmBD4G3gqA7m6UaW6F5P3eVAtzRtf2A6cA4wG5gJfCVN+x7wPvBBWsdJwEXA9SVlDwAC6JKGTwReIasVvgocVzL+oZLl9gYeBd5Kr3uXTBsHXAL8NZVzH9C7nffWEv+3S+I/AjgUeAF4E/huyfy7Aw8DC9K8VwJd07Tx6b0sTu/3yyXlfwd4A7iuZVxaZpu0jl3T8KbAXGD/CrbdaOCc1L9ZWvfX0/C2qVy1Wt91wHJgSYrx2yXbYAQwNa3//1W4/VfaLmlcpPWfkrb9+2ldd7XzPgI4DXgRmA+MZMVeSBNwPvBa2j6/BjZs9d05KcU9PsXzV+C/0jZ6hey7ciIwLZUxomTdnwUeBxam6Rd18N0cR1aTBXgivaeWLlq2GXBL2tZvpZh2TOPb/DyAKcCnVue3VpSunonsYGBpy8ZqZ56Lgb8DfYE+wN+AS0o+3KVpnnXIEsA7wMZp+kWsnLhaD3/4ZQHWT1+owWla/5IvwYmkHwzQi+wLf0Ja7pg0vEnJF+5lYDugexq+rINEthS4IMX/VWAOcAPQA9gReBfYOs3/MWDPtN4BwGTgrNY/4jbK/0H6knanJLGkeb6aylkPuBf4UYXb7l9LfgzHpvd8U8m0O0t/ACXLTSH9cFptg1+l+IYC7wE7VLD9P9wubX0GwLXApWXeRwC/BzYi2xuYAxxc8j5eArYGNgBuA65rFfevyb473VM8S4GvAM3ApWRJbmT6/D9N9s9tg5LPZmeyhPlRYBZwROvvZsn36uQ24j8FeA7oWRJzD1YkpUkl8/7T58HKiWyVf2tF6OqZyI4D3igzz8vAoSXDnwGmlHy4SyhJhGT/LfZM/RdRXSJbAPwfoHurGE5kRSI7AXik1fSHgRNLvnDnl0z7OnBPO++tJf7mNNwjxbNHyTwTW77cbSx/FnB7qx9l60T2PrBuq3HTW5UzBngKeJL0H7iCbbdN+ryagP8GTmVFzWs0cHZb66P9RLZ5ybhHgKMr2P4fbpe2PgMqT2QfLxm+GTgv9Y8l1TLT8GCyWk3LP5Ig/ZMpiefFkuGd0zz9SsbNA4a1E8vlwH+1/m6WfK9ObjX/x8m+79u1U95GqYwN2/s8WDmRrfJvrQhdPdvI5gG9y7QvbEpWtW/xWhr3YRmxchvYO2T/PasSEYvJdsdOA2ZKulvS9hXE0xLTZiXDb1QRz7yIWJb6l6TXWSXTl7QsL2k7Sb+X9IakhWTtir07KBtgTkS8W2aeXwE7AT+LiPfKzAtARLxMtosyDNiXrFbzuqTBwCeAv1RSTon2PrNy278Wqll3F7K23BbTWpXVetsREe1tzz0kPSBpjqS3yL575bYnadktyJLuiIh4IY1rlnSZpJfT92NKmr2iMllDv7VGqWcie5hs1+mIDuZ5nazRvsWWadyqWEy2C9XiI6UTI+LeiDiIbLfyObIfeLl4WmKasYoxVeMXZHENioiewHfJ2qE6Eh1NlLQBWU3gauAiSb2qiOcvwJFk7XQz0vC/ABuTHXmuOp42dLT9V9qeklbanquwrkrWvZSVk9XqrOMGstrwFhGxIVnNttz2RFJ34A7g8oj4Y8mkY8kOkn2KrP15QMsiFcZay99a7tQtkUXEW2TtQyMlHSFpPUnrSDpE0g/TbDcC50vqI6l3mv/6VVzlJGA/SVtK2hD4t5YJkvpJ+ryk9cnaaN4GlrVRxh+A7SQdK6mLpC8DQ8hqJPXWg6wd7+1UW/xaq+mzyNpzqnEFMDEiTgbuJvsxASDpIknjOlj2L8A3yBqVIdv9OYNsd6+tz25VYuxo+z8B7ChpmKR1yZoOVmddba37W5IGpoT/fbJ2wFodBe8BvBkR70ranSwRVeIa4LmI+GGr8T3IvrvzyBL891tNL/d51PK3ljt1Pf0iIn5Cdg7Z+WQNrdPIfhx3pFkuBSaQtd88BTyWxq3Kuu4HbkplTWTl5NNEdkTmdbIjbp8ga99qXcY84LA07zyyI2+HRcTcVYmpSueSfdkXkdUWb2o1/SJgtKQFkr5UrjBJh5MdcDktjTob2FXScWl4C7KjcO35C9mPpyWRPUT2Axrf7hLwn2Q/lgWSzi0XIx1s/7RLdTHwJ7Kjjq3PO7waGJLWdUcF62rtGrIjrePJjmK/S5aoa+XrwMWSFpEljZsrXO5o4AuS3i7p9iU78PAa2d7Bs2QN96XKfR41+63lUd1PiLV8kjQJODAlb7NCcyIzs8Ir7LWWZmYtnMjMrPCcyMys8HJ1May6dA917dHoMKwKfTbt2+gQrAoLZ89gycL5Zc9n60hzz60ili4pPyMQS+bcGxEHr876KpGvRNa1B90Glz2zwHLkmItOb3QIVoUbzzlqtcuIpUsq/p2+O2lkpVcerJZcJTIzKwKB8tUq5URmZtUR0NTc6ChW4kRmZtXTajWz1ZwTmZlVybuWZtYZuEZmZoUmXCMzs6KTa2Rm1gn4qKWZFZsb+82s6IR3Lc2sE3CNzMyKzbuWZlZ0Aprd2G9mRZezNrJ81Q/NrADSrmUlXbmSpI0k3SrpOUmTJe0lqZek+yW9mF43LleOE5mZVU+qrCvvCuCeiNgeGApMBs4DxkbEIGBsGu6QE5mZVa8GNTJJPYH9yJ7JSUS8HxELyJ6oPjrNNho4olw4TmRmVp1Ka2NZjay3pAkl3SklJW1N9uDu/5H0uKSrJK0P9IuImQDptez91N3Yb2bVq/wSpbkRMbydaV2AXYEzIuIfkq6ggt3INsNZlYXMbG1Ws8b+6cD0iPhHGr6VLLHNktQfIL3OLleQE5mZVa8Gjf0R8QYwTdLgNOpA4FlgDDAijRsB3FkuHO9amll1ans/sjOA30jqCrwCfIWsgnWzpJOAqUDZRz85kZlZlWp3iVJETALaakM7sJpynMjMrHq+H5mZFV7OLlFyIjOz6sh3vzCzzsA1MjMrOjmRmVmRZXe6diIzsyKTUJMTmZkVnGtkZlZ4TmRmVnhOZGZWbEpdjjiRmVlVhFwjM7Pia2rymf1mVnCukZlZsbmNzMw6A9fIzKzQ3NhvZp2CL1Eys2KTdy3NrBNwIjOzwnMiM7NCc2O/mXUO+cpjTmRmViX5EiUz6wS8a2lmxZevPOZEVms9N+jOT88/lh226U8EnHHJbzhgzx34lyP2Zt6CtwG4ZOQY7v/bsw2O1ACWfrCUMf9zO8uWLSOWL2fgkG3Y7ZN7MOGBR5j82LN0X29dAHY/cE+23G5AY4PNkbWmRibpGuAwYHZE7FSv9eTNZeccydiHn+XE865mnS7NdF+3KwfsuQO/uPEBrrx+bKPDs1aauzTzuRGHs063rixbtowx19zGlttuBcBH9xzK0H12aXCE+SPV7qilpCnAImAZsDQihkvqBdwEDACmAF+KiPkdlVPPFrtrgYPrWH7u9Fh/XfbeZRuuu/NhAD5YuoyFby9pcFTWEUms060rAMuXLWf5suW5223Ko5ZkVq6r0CcjYlhEDE/D5wFjI2IQMDYNd6huNbKIGC9pQL3Kz6OtNtuEuQveZuSFx7PToM2YNHka//bjWwH46lH7cfShu/P45Kmcf/ltvLXICS4vli9fzm2/vJm33nyLHXffmX6bf4RpL07l6Uee4oUnnqfPpn3Y6zP70K37uo0ONTfqfK3l4cD+qX80MA74TkcLNPwYqqRTJE2QNCGWFvvH3aW5maGDt+CaWx/kE8f/gHfefY+zTjyIa373ILt84SL2Pe4yZs1dyKVnfbHRoVqJpqYmjvza0Rx/9onMmTGbN2fNY8huO3HMN4/nyNO+zHo91ufhe//a6DBzpYY1sgDukzRR0ilpXL+ImAmQXvuWK6ThiSwiRkXE8IgYri7dGx3Oanl99nxen72Aic+8BsCYsZMYOngL5ry5iOXLg4hg9B1/5WM7btXgSK0t3bp3o/+ATZn20lTW22A9mpqaUJPYYdchzJ4xu9Hh5YeqSmS9WyoqqTulVWn7RMSuwCHA6ZL2W5WQGp7IOpPZ8xYxY9Z8tt0q+wey326Def7VN+i3Sc8P5zls/6FMfnlmo0K0VpYsXsJ7S94DsiOYM16Zzka9N2bxosUfzvPqc6/Qq2+vRoWYOwKkyjpgbktFJXWjSsuKiNfT62zgdmB3YJak/gDptex/EZ9+UWPf/tEtjLr4RLqu08yUGXM5/eLr+cG5R7HzdpsTEUyd+Sbf+v6NjQ7TkncWLeaBO8YSqca8zY7bstXgAfz5tvuZ98ZcQPTYqAf7fm7/RoeaI7U5ailpfaApIhal/k8DFwNjgBHAZen1znJl1fP0ixvJGux6S5oOXBgRV9drfXnx9AszOGDED1cad9qFv25QNFbOJh/pzZGnffmfxh/wxYMaEE1xNNWmsb8fcHtKil2AGyLiHkmPAjdLOgmYChxVrqB6HrU8pl5lm1kDrdhtXC0R8QowtI3x84ADqynLu5ZmVhVRsxpZzTiRmVnVcnaFkhOZmVVvrbnW0sw6qRq1kdWSE5mZVUXIN1Y0s+JzjczMCs9tZGZWbG4jM7Oiy661zFcmcyIzs6rlLI85kZlZ9Xxmv5kVm7xraWYF13I/sjxxIjOzKtXuKUq14kRmZlXLWR5zIjOzKsmN/WZWcD6PzMw6BScyMyu8nOUxJzIzq55rZGZWbL5o3MyKLruxYr4ymROZmVWtKWdVMicyM6tazvKYE5mZVUe+aNzMOoOcNZG1n8gk/QyI9qZHxJl1icjMcq9Ijf0T1lgUZlYYIjtymSftJrKIGF06LGn9iFhc/5DMLO9qWSGT1ExWcZoREYdJ6gXcBAwApgBfioj5HcZTwUr2kvQsMDkND5X089WM3cyKStn9yCrpKvRNUn5JzgPGRsQgYGwa7lAljwu+HPgMMA8gIp4A9qs0QjPrfKTKuvLlaHPgs8BVJaMPB1r2CEcDR5Qrp6KjlhExrVV2XVbJcmbW+YiqTojtLam0vX1URIwqGb4c+DbQo2Rcv4iYCRARMyX1LbeSShLZNEl7AyGpK3AmK1cDzWwtU8VRy7kRMbytCZIOA2ZHxERJ+69OPJUkstOAK4DNgBnAvcDpq7NSMyuuSncbK7AP8HlJhwLrAj0lXQ/MktQ/1cb6A7PLFVS2jSwi5kbEcRHRLyL6RMTxETFvtd+CmRVWk1RR15GI+LeI2DwiBgBHA3+OiOOBMcCINNsI4M6y8ZSbQdLWku6SNEfSbEl3Stq63HJm1nmpwm4VXQYcJOlF4KA03KFKdi1vAEYCX0jDRwM3AnusYpBmVnC1vtYyIsYB41L/PODAapav5PQLRcR1EbE0ddfTwaVLZta5ZUctK+vWlI6uteyVeh+QdB7wW7IE9mXg7jUQm5nlkYp1Y8WJZImrJeJTS6YFcEm9gjKzfCvMbXwiYuCaDMTMiqFl1zJPKjqzX9JOwBCycz0AiIhf1ysoM8u3wtTIWki6ENifLJH9ATgEeAhwIjNbS+UrjVV21PJIskOhb0TEV4ChQLe6RmVmuSVBc5Mq6taUSnYtl0TEcklLJfUku1zAJ8SarcUKt2sJTJC0EfArsiOZbwOP1DMoM8u3nOWx8oksIr6eev9b0j1Az4h4sr5hmVleifLXUa5pHZ0Qu2tH0yLisfqEZGa5Vru7X9RMRzWyH3cwLYADahwLu+ywJX/9x5W1Ltbq6GMX3tfoEKwKCxe/X5NyCtNGFhGfXJOBmFkxCGguSiIzM2tPIc/sNzMr5URmZoWW3eo6X5mskjvEStLxki5Iw1tK2r3+oZlZXuXtfmSVXKL0c2Av4Jg0vIjsjrFmtpaq1XMta6WSXcs9ImJXSY8DRMT89Fg4M1sLCeiSs13LShLZB5KaSbe3ltQHWF7XqMws13KWxypKZD8Fbgf6SvoPsrthnF/XqMwst1TBo97WtEqutfyNpIlkt/IRcERE+EnjZmuxnOWxim6suCXwDnBX6biImFrPwMwsv4p4HtndrHgIybrAQOB5YMc6xmVmOSVYozdNrEQlu5Y7lw6nu2Kc2s7sZtbZreFzxCpR9Zn9EfGYpN3qEYyZFYNydtf+StrIzi4ZbAJ2BebULSIzy7WiPg6uR0n/UrI2s9/VJxwzK4JCJbJ0IuwGEfF/11A8ZlYAtbhoXNK6wHiyp7J1AW6NiAsl9QJuAgYAU4AvRcT8jspq91pLSV0iYhnZrqSZGdDyOLjKujLeAw6IiKHAMOBgSXsC5wFjI2IQMDYNd6ijGtkjZElskqQxwC3A4paJEXFb2TDNrFOqxZn9ERFkT2UDWCd1ARxO9lBwgNHAOOA7HZVVSRtZL2Ae2T36W84nC8CJzGwtVGVjf29JE0qGR0XEqA/LypqvJgLbAiMj4h+S+kXETICImCmpb7mVdJTI+qYjlk+zIoG1iIrfhpl1OlVUyOZGxPD2Jqbmq2Hp2bm3S9ppVeLpKJE1AxtAmyeMOJGZrbVEU43PI4uIBZLGAQcDsyT1T7Wx/sDscst3lMhmRsTFNYrTzDoJUZuLxtMtwT5ISaw78CngB8AYYARwWXq9s1xZHSWynJ0pYma5IOhSmxPJ+gOjUztZE3BzRPxe0sPAzZJOAqYCR5UrqKNEdmAtIjWzzqVWNbKIeBLYpY3x86gy/3T0gN43qw/NzNYGhbuxoplZaznLY05kZlYdUdnj19YkJzIzq468a2lmBZed2e9EZmYFl6805kRmZqsgZxUyJzIzq5Zqcj+yWnIiM7Oq+KilmXUKbuw3s2JTbW51XUtOZGZWFe9amlmn4BqZmRVevtKYE5mZVUlAs2tkZlZ0OctjTmRmVi2hnO1cOpGZWdVcIzOzQstOv8hXJnMiM7PqyDUyM+sEfImSmRVadmPFRkexMicyM6uaj1qaWeHlbM/Siaye3lr0DmdeegOTX56JBD/79+PY/aNbNzosa0OT4LpT92TOwvc464bH2e4jPfjuYTvQtUsTy5YHl909mWdmLGx0mLmxVtXIJB0MXAE0A1dFxGX1XF/enPfjWzlwryGM/sHJvP/BUpa8+36jQ7J2HLPnVkyZs5j1u2U/iW8eNIhR417hby/NZZ9BvTnzoO049doJDY4yH/LYRla3u3FIagZGAocAQ4BjJA2p1/ryZuHbS/jb4y9zwuF7AdB1nS5s2GO9Bkdlbenbsxsf3643dzw248NxAazfrRmADbp1Ye6i9xoUXQ5JNFXYrSn1rJHtDrwUEa8ASPotcDjwbB3XmRuvzZhH74024PTvXc/TL85g2A5b8J/nHMn63bs1OjRr5ZyDt+eK+174sDYG8KM/Ps/IE3blrM8MpknwlaseaWCE+ZOzClld74+2GTCtZHh6GrcSSadImiBpwpy5c+oYzpq1dNkynnh+Gv965L6M/815rLduNy6/9v5Gh2Wt7Ltdb+Yvfp/nZi5aafxRu23Oj+95ns/+ZDw/ued5Ljh8xwZFmD8tz7Vc3RqZpC0kPSBpsqRnJH0zje8l6X5JL6bXjcvFVM9E1ta7iH8aETEqIoZHxPA+vfvUMZw1a9O+G7Np340YvtMAAD5/4DCeeH5axwvZGjd0y43Yb3Af7jprX75/5EfZbWAvLvniThw2bFP+PHk2APc/M4sdN9uwwZHmiyrsylgKnBMROwB7Aqen5qfzgLERMQgYm4Y7VM9ENh3YomR4c+D1Oq4vV/r17slm/TbmxSmzABj/6PMMHviRBkdlrV35p5c49Cfj+dzlD/LdW5/k0Vff5N9ve5o5i97jYwOyisBuA3sx7c13GhxpztQgk0XEzIh4LPUvAiaT7bUdDoxOs40GjigXTj3byB4FBkkaCMwAjgaOreP6cueH5x7FKRdcy/sfLGPAZr0ZecHxjQ7JKnTpmGc595DtaW4S7y9dzqVjnml0SLlSRUN+b0mlh3tHRcSo1jNJGgDsAvwD6BcRMyFLdpL6lltJ3RJZRCyV9A3gXrLTL66JiLXq27Dz4M154NffaXQYVqGJU+Yzccp8ACZNXcDxv/x7gyPKryoa++dGxPAOy5I2AH4HnBURC1fleQB1PY8sIv4A/KGe6zCzBqjRYUtJ65Alsd9ExG1p9CxJ/VNtrD8wu1w5eXuqk5nlXNb8Vdlfh+VkVa+rgckR8ZOSSWOAEal/BHBnuZh8iZKZVad29yPbBzgBeErSpDTuu8BlwM2STgKmAkeVK8iJzMyqVos8FhEPdVDUgdWU5URmZlWSH9BrZsWXszzmRGZm1anwrP01yonMzKqXs0zmRGZmVVurbqxoZp2T28jMrNj8XEsz6wy8a2lmhSZcIzOzTiBnecyJzMxWQc4ymROZmVVtTT4hqRJOZGZWtXylMScyM1sVOctkTmRmVpWWGyvmiROZmVXHJ8SaWWeQszzmRGZm1fKNFc2sE8hZHnMiM7Pq+MaKZtY55CyTOZGZWdV8+oWZFZ7byMys2ARNTmRmVnz5ymROZGZWFd9Y0cw6hZzlMScyM6te3mpkTY0OwMyKR1JFXQXlXCNptqSnS8b1knS/pBfT68blynEiM7OqqcKuAtcCB7cadx4wNiIGAWPTcIecyMysKlLlXTkRMR54s9Xow4HRqX80cES5ctxGZmZVq+LM/t6SJpQMj4qIUWWW6RcRMwEiYqakvuVW4kRmZtWrvLF/bkQMr2MkgHctzWwV1LCNrC2zJPUHSK+zyy3gRGZmVRJNqqxbRWOAEal/BHBnuQWcyMysKi1n9teisV/SjcDDwGBJ0yWdBFwGHCTpReCgNNwht5GZWcNExDHtTDqwmnKcyMysank7s9+JzMyq5hsrmlmx+bmWZlZ0vo2PmXUK3rU0s8JzjczMCi9necyJzMxWQc4ymROZmVVFsDqXH9WFIqLRMXxI0hzgtUbHUQe9gbmNDsKq0lm32VYR0Wd1CpB0D9nnU4m5EdH6xok1l6tE1llJmrAmbmViteNtViy+aNzMCs+JzMwKz4lszSh3a1/LH2+zAnEbmZkVnmtkZlZ4TmRmVnhOZHXU1lOULd8kHSzpeUkvSSr7YFjLByey+rqWf36KsuWUpGZgJHAIMAQ4RtKQxkZllXAiq6N2nqJs+bU78FJEvBIR7wO/JXvqteWcE5nZCpsB00qGp6dxlnNOZGYrtHUltM9PKgAnMrMVpgNblAxvDrzeoFisCk5kZis8CgySNFBSV+BosqdeW845kdVRO09RtpyKiKXAN4B7gcnAzRHxTGOjskr4EiUzKzzXyMys8JzIzKzwnMjMrPCcyMys8JzIzKzwnMgKRNIySZMkPS3pFknrrUZZ10o6MvVf1dHF0ZL2l7T3KqxjiqR/etpOe+NbzfN2leu6SNK51cZonYMTWbEsiYhhEbET8D5wWunEdPeGqkXEyRHxbAez7A9UncjM1hQnsuJ6ENg21ZYekHQD8JSkZkn/X9Kjkp6UdCqAMldKelbS3UDfloIkjZM0PPUfLOkxSU9IGitpAFnC/FaqDe4rqY+k36V1PCppn7TsJpLuk/S4pF9SwfOoJd0haaKkZySd0mraj1MsYyX1SeO2kXRPWuZBSdvX5NO0YosIdwXpgLfTaxfgTuBrZLWlxcDANO0U4PzU3w2YAAwEvgjcDzQDmwILgCPTfOOA4UAfsrs/tJTVK71eBJxbEscNwMdT/5bA5NT/U+CC1P9Zsguue7fxPqa0jC9ZR3fgaWCTNBzAcan/AuDK1D8WGJT69wD+3FaM7taursuqpT9rkO6SJqX+B4GryXb5HomIV9P4TwMfbWn/AjYEBgH7ATdGxDLgdUl/bqP8PYHxLWVFRHv3UvsUMET6sMLVU1KPtI4vpmXvljS/gvd0pqQvpP4tUqzzgOXATWn89cBtkjZI7/eWknV3q2Ad1sk5kRXLkogYVjoi/aAXl44CzoiIe1vNdyjlb0mjCuaBrElir4hY0kYsFV/zJml/sqS4V0S8I2kcsG47s0da74LWn4GZ28g6n3uBr0laB0DSdpLWB8YDR6c2tP7AJ9tY9mHgE5IGpmV7pfGLgB4l891HdnE1ab5hqXc8cFwadwiwcZlYNwTmpyS2PVmNsEUT0FKrPBZ4KCIWAq9KOiqtQ5KGllmHrQWcyDqfq4BngcfSQ09+SVbzvh14EXgK+AXwl9YLRsQcsja22yQ9wYpdu7uAL7Q09gNnAsPTwYRnWXH09HvAfpIeI9vFnVom1nuALpKeBC4B/l4ybTGwo6SJwAHAxWn8ccBJKb5n8K2oDd/9wsw6AdfIzKzwnMjMrPCcyMys8JzIzKzwnMjMrPCcyMys8JzIzKzw/hfCiEx1kgHCfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix for best MLP model\n",
    "\n",
    "# Code is from https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "  disp = plot_confusion_matrix(best_mlp, X_test, y_test,\n",
    "                               display_labels=data.Outcome.unique(),\n",
    "                               cmap=plt.cm.Blues,\n",
    "                               normalize=normalize)\n",
    "  disp.ax_.set_title(title)\n",
    "\n",
    "print(title)\n",
    "print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Receiver Operation Curve (ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code is based on https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate False Positive Rate (FPR), True Positive Rate (TPR) and threshold for best SVM model\n",
    "svm_FPR, svm_TPR, svm_thresholds = roc_curve(y_test, best_svm_y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the geometric mean for the threshold for best SVM model\n",
    "svm_gmeans = np.sqrt(svm_TPR * (1-svm_FPR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best False Positive Rate=0.280, Best True Positive Rate = 0.778\n"
     ]
    }
   ],
   "source": [
    "# Determine the best FPR and TPR at largest geometric mean for best SVM model\n",
    "svm_ix = np.argmax(svm_gmeans)\n",
    "print('Best False Positive Rate=%.3f, Best True Positive Rate = %.3f' %(svm_FPR[svm_ix],svm_TPR[svm_ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate False Positive Rate (FPR), True Positive Rate (TPR) and threshold for best MLP model\n",
    "mlp_FPR, mlp_TPR, mlp_thresholds = roc_curve(y_test, best_mlp_y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the geometric mean for the threshold for best MLP model\n",
    "mlp_gmeans = np.sqrt(mlp_TPR * (1-mlp_FPR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best False Positive Rate=0.350, Best True Positive Rate = 0.889\n"
     ]
    }
   ],
   "source": [
    "# Determine the best FPR and TPR at largest geometric mean for best MLP model\n",
    "mlp_ix = np.argmax(mlp_gmeans)\n",
    "print('Best False Positive Rate=%.3f, Best True Positive Rate = %.3f' %(mlp_FPR[mlp_ix],mlp_TPR[mlp_ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAAEWCAYAAAAO4GKjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABcfElEQVR4nO3dd3wU1RbA8d8hlNCr+JAiKIhSIyCIIqIoTQUUKYIiKGLvivrsKIpdsTxElKJAAAugIigKYqFDpCpdOtJ7gCTn/XEn6yakbHaTbMr5fj75ZKefmdmdO3PvnXtFVTHGGGNyuwLhDsAYY4zJDJagGWOMyRMsQTPGGJMnWIJmjDEmT7AEzRhjTJ5gCZoxxpg8wRK0DBBnhIjsE5H5mbC+6iKiIlIwM+LL77xjWTOA+VqJyJYA1xnwvCZlGfmei0gfEfk1m+KaJSL9Apw3T30Psnp/RGSoiDztN3yniOwUkcMiUt77f1ZmbzfdBE1ENorIMS+AHSIyUkRKJJvnIhH5SUQOicgBEflaROokm6eUiLwtIpu8da31hitk9k5loRbAlUAVVW0a7mBSE8gPVURuFZE/vXO2U0S+FZGSIvKEiMxOYf4KInJCROp5Fx0VkTeTzdPZGz8yk3cpz/F+V1ekMb2Vdyy/TDa+oTd+lt+4FBNy7zzFe7+3gyISIyJXZ+qOGJMCVb1DVV8AEJFCwJtAG1Utoap7vP/rM3u7gT6hXaOqJYAo4HzgicQJItIc+B6YDJwB1AD+AH5LTIFFpDDwI1AXaAeUAi4C9gBZljBkwZPPmcBGVT2SA2IJmohcCrwE3KCqJYHzgAne5E+Bi0SkRrLFegDLVHW5N7wO6J5sv3oDq7Mu8nxnF+5clPcbdzMZO8ZzvN9uGeBjYIKIlMu8EI1J1+lAJLAi1BWldx3NUJajqu4ApuMStkSvAqNV9R1VPaSqe1X1KWAu8Jw3T2+gGnCtqq5U1QRV/UdVX1DVqakEXldEfhCRvd4TxH+98SNF5EW/+ZI8Ont3vo+JyFLgiIg8JSKfJ1v3OyIyxPtcWkQ+FpHtIrJVRF4UkYgU4rkVGA409+54n/fG3+Y9be4VkSkicobfMioid4vIGmBNGof2FhHZ5sXwsN/yBUTkcRFZJyJ7RMR3MRKRSBH5zBu/X0QWiMjpIjIIuAR4z4vzvRS2dwHuQrcEwDtno7zztwX4Cbgp2TK9gVF+wzuAZUBbL55yuJuUKantZOK5EpEBIvKPt7+dRaSDiKz2juF//eYv4j3Fb/P+3haRIn7TH/XWsU1Ebkm2rSIi8rqXI7BTXBZI0VTPQDpE5L8istv7fvUKZDveU+033vnZKyK/eOf0U9zv4WvvHA1IZbMngEm4mwm872U3YExG41fVBOAToChwSlaP9zT3m4i85cW7XlzOSx8R2eydr5v95i8tIqNFZJeI/O39zgokxukdk90ish64Ktm2AvrNpUREJorLKTogIrNFpK7ftJEi8r643IZDIjJPRM72m36luFyJA97vQtLYTlFvfftEZCXuN+M/PclTsfhdl4L4nj/n7ddnXtzLROQccbkl/3jHv403b1cRWZQslodFZFIq+1FOXDHJNm9fUpsv8TpzSERWisi1ftNqisjP3nHbLSLjvfHifV/+8aYtFZF6/sdDRM4B/vJWtV9Efkp+/NL5DSUey8dEZAcwIrVzBoCqpvkHbASu8D5XwV3E3vGGiwHxwGUpLNcX2O59jgZGpbctv2VLAtuBh3Epe0mgmTdtJPCi37ytgC3J4o0BquJ+vGcCR4FS3vQIb90XesOTgA+B4kBFYD5weypx9QF+9Ru+HNgNNAKKAO8Cs/2mK/ADUA4omsL6qnvzjPO2Xx93V554vB/A3RhU8db/ITDOm3Y78LV3DiKAxn77OAvol8bxvQQ4BjwPXAwUSTa9F7DGb7g27uJ6mv9xAHoC471xd3nxvQiMTGW7rYA44BmgEHCbt79jvXNcF4gFzvLmH+jtf0XgNOB34AVvWjtgJ1DPO3ZjvWNZ05v+Ni5xLeet+2vg5ZS+M+l8FxNjftM7B5cCR4DaAWznZWCot6+FvOMuyX9XaWx3C+4mYZ43rgPuhrIfMCvZ96xmWt9XoCBwP3AIKJ3KvHG4322Edx43Ae97+93GW7aEN/9oXK5MSdz3eDVwqzftDuBP3G+wHDDTi7Fger85kv3GUojzFm+bRbxjH+M3bSSwF5frUxCX8Ed70yoAB4HrvXPxoLe/Kf5OgMHAL178VYHlJL3OJDnm+F2XyPj3/DlvuK0X92hgA/Ck3/IbvHmLePt4nt+2lwBdUtmPb4HxQFlvXZemct3sisthKwB0x33HK3nTxnmxFMBdj1t449sCi3BP/4LL6amUwvGo7n/+kx8/0v+txgGvePt+ynU0yf4G8IPeCBzGfZkVl3VYxptWxRt3bgrLtQNOep9/AAYHcgHx5r8BWJLKNN+BSuXEbARuSbbMr0Bv7/OVwDrv8+nAcf+D5G17Zirb7kPSBO1j4FW/4RLASaC630m7PI39TDzR5/qNexX42Pu8CmjtN62St/6CuB/270CDFNY7izQSNG+e9t4XZ793ft8EIrxpxXA//ou84UHA5OTHAXfDsBMojUt4Lib9BO2Y33ZKevvfzG+eRUBn7/M6oIPftLa4LF9wTxuD/aad462rJu7HdQQ42296c/69KCT5zqRznFrhflDF/cZNAJ4OYDsDcRf9lBKbjQSQoHmf1+BuKqJxNxsZSdDivHO82ztHKW7Tm9f/Jqa+t97T/cbtweXOROB+N3X8pt2eGBPuCf8Ov2ltvHUVJJ3fHOkkaMliLuOtt7TftWG43/QOwJ/e597AXL9pgrthSC1BWw+08xvuT8YStIx8z58DfvCbdg3uN5l8+cTr7v+AQd7nusA+kt2U+l0vEoCyaX2/Utn/GKCT93k0MAxXd8B/nstxNzIXAgWSTfM/HtVJJUEjsN/qCSAykO9EoFmOndWVtbQCzsXd7eAdyATvwCVXCfcjAvdDSGme1FTFXcyCtTnZ8FjcjwbcU8VY7/OZuLuW7V42y37cnWPFALdzBvB34oCqHsbta+U0Ykkv3r+99SbG95VfbKtwT8Sn48q6pgPRXnbCq+IKXwOiqt+p6jW4u6JOuAtJP2/aUWAi0FtEBHcRHZXCOo7h7gCfAiqo6m8BbHqPqsZ7n495/3f6TT+GuzGAZMeXpMfmDE49bolOwyXKi/yO3TRvfDD2adJy08Q40tvOa8Ba4HsvC+/xILf/KXAPcBnwVQaXnauqZVS1gqpeqKoz0pg3+XlAVVM6NxWAwpx6bhK/92mdm6B/c15W5mAva+wg7qYA/r0egcsKT3SUpN8lX0zqrpZp/TbT2odAZOR7ntK03Sksnzj/KKCn99u8CZigqsdTiKEqsFdV96UXrIj0FldpKPGc1OPf4zoAl/DMF5EV4mXvq+pPwHu4p/idIjJMREqlt61kAvmt7lLV2EBWltEytJ9xKe/r3vARYA7ucTW5brinOYAZQFsRKR7gpjYDZ6cy7QjuACT6T0qhJhueCLQSkSrAtfyboG3G3S1W8H70ZVS1lKrWJTDbcD9QALz9Kw9sTSOWlFT1+1zNW29ifO39YiujqpGqulVVT6rq86paB5ctdTXuLjTQbboZXXnmj7i76np+k0bhzuGVuDvEb1JZxWhc1vCngW4zA5IcX5Iem+2cetwS7cZdBOr6HbfS6ipHBKNssu9uYhxpbkddmeTDqnoW7q77IRFp7a0j4HOEO7Z3AVO9m41w243LKUh+bhK/92mdm1B+cz1xN19X4HIFqnvjUy0L85MkJi8xqJr67GnuA7jEMr3rUJZQ1bm4p5ZLcMcktd/eZqCciJRJa30icibwEe6mqbyqlsFlsYq3vR2qepuqnoF7Ev8gsfxLVYeoamPck+I5wKMZ3J1AfqsB/1aCeQ/tbeBKEYnyhh8HbhaR+8RV+y7rFY42x5XRgDvgm4EvRORccQXj5cUVtHdIYRvfAP8RkQe8AsOSItLMmxYDdPAKO/+DK2dKk6ruwmXDjcA9yq7yxm/H1dB8Q9xrBQVE5GxxtQADMRboKyJR4iorvIQr79gY4PKJnhaRYuIKuPvi8rzBlb8M8r5wiMhpItLJ+3yZiNQXV5h+EHeBSbyj20kKBf+JRKSTiPTwzpWISFNc2dBcv9l+wWVVDcOVQ5xIZXU/4xK9dzO4z4EYBzzl7XcFXJnEZ960CUAfEakjIsWAZxMXUlcB4iPgLRGpCCAilUWkbUob8QqwR6YTy/MiUlhELsHdPExMbzsicrW4AnXBnaN4AjxH/lR1A+78PJnGbIXFVRRK/AuokkUwvCeHCbjvZknv+/kQSc/NfSJSRUTK4q4RicuG8psriUsM9+ASk5cyEPa3QF0RuU5cTbn7SDsRmgA84f1GqgD3Jpseg3tKihCRdrjzk51G456O4lQ1xff2vGP9HS4BKisihUSkZQqzFsclGrsARKQvfje34iqiVPEG93nzxovIBSLSzMsZOoIrB4wnAzL6W01PhhM0L3EYjStDwDuYbYHrcHc1f+Oq9rdQ1TXePMdxd1V/4srTDuIKgisA81LYxiHcRfIaXBbCGlx2C7jE8Q9cdsP3/HvxT89YL4axycb3xmWfrMSdrM8JMHvUe7J5GvgCt+9n49VIy6CfcVlTPwKvq+r33vh3cIWl34vIIVyCk5iw/8eL9SAuK/Jn/r2gvANcL65W05AUtrcPV9C8xlv+M+A1VfXVnvOyZEbj7sJHpxa4Oj+q6t4M73X6XgQWAktxlZEWe+NQ1e9wN1c/4Y7dT8mWfcwbP9fLnpqBK4dKSVUgrezSHbhjtg1X0eAOVf0zgO3U8oYP43IyPlDVWd60l3GJ9X4ReSSNbePt76+qui2NWVbg7nQT//qmt84Q3Yu7iK3HlaeOxZVrgrtATcf9ThcDXyZbNtjf3Gjc9WWrt+zctGf/l6ruxuUkDcYliLVI+5w/721rA+46k/wp6H7c9Wk/Lkt+UqCxZJJPcYlOejkjN+Fudv8E/iGFBwBVXQm8gfuO7sSVn/ofmwuAeSJyGHc9ut+7ySqFO9f7cMdqD17uXQZl5LeapsQaV8bkS+LekfwDV7nmZLjjMSYQ4qq1/wM0SnxwMK7WkTH5lpeVel644zAmg+4EFlhilpQlaMYYk4uIyEZchY3O4Y0k57EsR2OMMXmCtbZvjDEmT8hTWY4VKlTQ6tWrhzsMY4zJNRYtWrRbVYNtdCBHyVMJWvXq1Vm4cGG4wzDGmFxDRDLaCkqOZVmOxhhj8gRL0IwxxuQJlqAZY4zJEyxBM8YYkydYgmaMMSZPCEuCJiKfiOu2e3kq00VEhojIWnHdejfK7hiNMcbkLuF6QhuJ69E6Ne1xrWHXwvUU+79siMkYY0wuFpb30FR1tohUT2OWTsBorwuTuSJSRkQqef37GGNMtho7bxOTY7amP2OQ9kXM5kDE/KCWjUw4Rj0K8P6tqfXBm3/k1DK0yiTt/nwL/3bvnoSI9BeRhSKycNeuXdkSnDEmf5kcs5WV2w9m2foPRMwnVjanP2MypeIPUP3kOk6PXQ/H9mVBZLlLTm0pJKUu1VNsRVlVh+F6VaZJkybW0rIxJkvUqVSK8bc3z5J1951WCqjLiHYjAltAFWa/DjNfhKrN4MYxULRslsSWm+TUBG0LrhfhRFVwvQUbY0z+djIWptwDyyZCgx5wzTtQKDLcUeUIOTVBmwLcIyLRQDPggJWfGRO8rC4Dyov8y7WOahzFihT0nqQy3197/6J2udrpz3hoJ0T3hK0LofWz0OJBkJQytPKnsCRoIjIOaAVUEJEtwLNAIQBVHQpMBToAa4GjQN9wxGlMXpFYBlSnUtZckPOixHKtSK1KsSIFqVC8SJZtq3a52nQ4q0PaM+1YBmN7wLG90P0zOO+aLIsntwpXLccb0pmuwN3ZFI4x+UJWlgHlRRku18pKf34LX9wGRcvALdOgUsNwR5Qj5dRajsYYY1Th17cguhdUPBdu+8kSszTk1DI0Y/KtiasnMnX9VAD+OXic3UeOh7zOrC4DyosCLtfKKnHH4esH4I+xUK8LdHofChUNXzy5gD2hGZPDTF0/lb/2/gXA7iPHOXo8LuR1ZnUZUF4UULlWVjmyG0Z1dIlZq/9Cl48tMQuAPaEZkwPVLlebEe1G0P3DOSAwvq+VfeUbO1fCuO5w+B+4fgTUuy7cEeUalqAZkwr/rL9AZFb2YGLNuu4fzrGaifnN6unw+S1QuAT0nQqVG4c7olzFshyNSYV/1l8gMit7MFKrUjq+KeBqJnaKSrHVN5OXqMLv78HY7lD+bOg/0xKzIIT0hCYiBYCGwBnAMWCFqu7MjMCMyQkSs/4CYdmDJihxJ2Dqw7B4NJzXEa4dCoWLhzuqXCmoBE1EzgYeA64A1gC7gEjgHBE5CnwIjFLVhMwK1Bhj8pyje2H8TfD3r9DyUVcBpIBlnAUr2Ce0F3F9lN3uvQTtIyIVgZ7ATcCo0MIzJmMCbeIpkO46/MuyAmHlXSZDdv3lshgPboPrhkODruGOKNcLKkFLq6UPVf0HeDvYgIwJRaBNPPk3a5Qa/7KsQFh5lwnY2hkwsS8UjIQ+30LVC8IdUZ6Q6bUcReRKVf0hs9drTKACaeIpRzVrZPIPVZg/DKY9DhXrwg3joEzqN1UmY7Ki2v7HQLUsWK8xxuRe8Sfhu8dg4cdQuwNc9xEUKRHuqPKUYCuFTEltElA++HCMyTj/98U2Fna9CqfXxFPYmzUy+cuxfTDhZtjwM1z8gOv6xSp/ZLpgn9AuAW4EDicbL0DghQ7GBGjMGHjySdi0CapVg0GDoFcvNy3xfbGMJFBhbdbI5C+717qWP/b9DZ3/B1E9wx1RnhVsgjYXOKqqPyefICKBv4lqTADGjIH+/eHoUTf8999uGP5N1JI0FQWMaGfvgpkcYP0smNAbChSEm7+GM+17mZWCreXYPo1pLYMPx5hTPfmkS8xKNNxE8Tr/Vsl/8keYcvjfbEZrKsrkKAs/gW8fgQrnQM9oKFs93BHleZaJa3K8TZvc/+J1tlK44kHf+NjYU+e1qvMm7OLjXOWPbx6Emq3h1u8tMcsm1jixyfGqVXPZjAAn/inFznEu2+bMM2H82H8rgFg2owm72AOuceG1M6D5PXDlQCgQEe6o8g17QjM53qBBUKxY0nHFirnxxuQYe9fD8Ctdudk1Q6DtIEvMspk9oZkcx7/5qsQmqs55E2Lj4kg4UZCy55SiRg2YUR5mTLMq+CYH2PgbjL8RULhpEtS4JNwR5UshP6GJyHNpDRuTUYnNV8G/TVQVLgylihWkZuUiXHghnH76v/NbFXwTVos/hdGdoHgF6PejJWZhlBlPaIvSGTYmwxKbr7ImqkyOlRAPM56F39+Fsy93vUsXLRPuqPK1kBM0Vf06rWFjjMlzjh+CL/rB6mnQ9HZo+xJEWAlOuAXb9NW7gKY2XVXvCzoik2/4N1nlz7/5KisfMznOvr9hXA/X/ctVb8AF/cIdkfEEe0uxMFOjMPlSIE1WWfmYyVE2zYXoXpBwEm78As6+LNwRGT/BthSSpONOESmuqkcyJySTnyQ2WeXPmq8yOdIf0TDlXihdFXqOhwq1wh2RSSakTF8RaY7rLqYEUE1EGuJ6sb4rM4IzOV8gPUSn1jt0aj1CW/NVJkdJSICfXoBf34QaLaHrKChWLtxRmRSEWm3/baAtsAdAVf8ArC3HfMS/in1qEqveJ5daj9DWfJXJMY4fhgk3ucSscV+48UtLzHKwzKjluFlE/EfFh7pOk7uk10O0Vb03udKBLa7yx84V0P5VaNofkl7rTA4TaoK2WUQuAlRECgP3AatCD8sYY8Joy0IYdwPExULPiVDrinBHZAIQaoJ2B/AOUBnYCkwH7g41KJP7+VfJt6r3JldZ9jlMugtKVXJ9mFU8N9wRmQCFVIamqrtVtZeqnq6qp6nqjaq6J73lRKSdiPwlImtF5PEUppcWka9F5A8RWSEifUOJ02S/xCr5YFXvTS6RkAAzX4IvboUqTaDfT5aY5TKh1nI8C/eEdiHuRes5wIOquj6NZSKA94ErgS3AAhGZoqor/Wa7G1ipqteIyGnAXyIyRlVPhBKvyV4pVck3Jkc6cRQm3QkrJ8H5N8JVb0HBwuGOymRQqLUcxwITgErAGcBEYFw6yzQF1qrqei+BigY6JZtHgZLiapuUAPYCcSHGaowxpzq4DUa0h5WToc0g6PieJWa5VKgJmqjqp6oa5/19RhpNYnkqA/51uLd44/y9B5wHbAOWAferakKKAYj0F5GFIrJw165dwe2FMSZ/2rYEProc9qyFG6LhonusJmMuFlSCJiLlRKQcMFNEHheR6iJypogMAL5Nb/EUxiVPBNsCMbinvijgPRFJ8U1bVR2mqk1Utclpp52Wof0wWWPMsjHM3TKXn//+mepvV2fMsjHhDsmYU62YBJ+0hwKF4NbvoXa7cEdkQhRsGdoiXCKUmDjd7jdNgRfSWHYLUNVvuAruScxfX2CwqiqwVkQ2AOcCpzY3YXKUMcvG0P/r/pxe3nVY9veBv+n/dX8AetXvFc7QjHFUYfbrMPNFqNoMuo+BEnYznBcE25ZjjRC2uQCoJSI1cFX9ewA9k82zCWgN/CIipwO1gVQrmpjs5d/clX8zVRNXT+TFeS9yevnTiSwcSeyJWACOnjzKkz8+aQmaCb+Tx2DyPbD8c2h4A1zzDhQsEu6oTCYJuaUQEakH1AEiE8ep6ujU5lfVOBG5B/fOWgTwiaquEJE7vOlDcU94I0VkGe4p8DFV3R1qrCZzJDZ3VadSqSTNVE1dPxWJEIiH2BOx7D+837fMpgObwhStMZ5DOyG6J2xdBFc8Bxc/YOVleUyo1fafBVrhErSpQHvgVyDVBA1AVad68/uPG+r3eRvQJpTYTNZKrbkrjVc27NhwyvhqpatlR1jGpGz7Utfyx7G90P0zOO/qcEdkskCotRyvx2UN7lDVvkBDwJ7f87EaZWtQrFCxJOOKFSrGoNaDwhSRyfdWfQOftAUUbpluiVkeFmqCdsyrTh/n1UL8Bzgr9LBMTjN23ia6fziH7h/OSbN1/dOLn86wa4ZxZukzEYQzS5/JsGuGWfmZyX6q8OtbMP5GqHge3PYTVGoQ7qhMFgq1DG2hiJQBPsLVfDyM1UTMk1IrN0tJr/q9LAEz4RV3HL6+H/4YB/W6QKf3oVDRcEdlslhICZpfR55DRWQaUEpVl4YelsmJ0usmxpgc4fAu91S2eS5c9iS0fNQqf+QTQSVoItIorWmqujj4kIwxJkg7V8DYHnBkF3QdCXWvDXdEJhsF+4T2RhrTFLg8yPUaY0xw/prmWsovUhL6ToXKqd53mzwq2BerL8vsQIwxJiiqMOd9+P4pV+njhmgodUa4ozJhEPKL1cYYEzZxJ+Dbh2DJp1CnE3QeCoWLpb+cyZMsQTPG5E5H9sCEm+Dv36DlAGj1BBQI9U0kk5tZgmaMyX3++RPGdYeD2+G64dCga7gjMjlASLcz4twoIs94w9VEpGnmhGaMMSlYMwM+vtL1Mt13qiVmxifU5/MPgObADd7wIeD9ENdpjDGnUoV5H8LYrlDmTNfyR5Um4Y7K5CChZjk2U9VGIrIEQFX3iYj1XZ4H7YuYzYGI+fSdlmI/qwD8tfcvapernY1RmXwj/iR8NwAWfgK1r4LrhkGREuGOyuQwoSZoJ0UkAq/HaRE5DUgIOSqT4xyImE+sbAbqpjpP7XK16XBWh+wLyuQPR/fCxJthw2xo8SBc/oxV/jApCjVBGwJ8BVQUkUG41vefCjkqkyNFalVGtBsR7jBMfrJ7LYztBgc2uyr5UTekv4zJt0Jty3GMiCzCdSEjQGdVXZUpkZmweHT6h8ze9v0p44/qJoqJ9WlmstH6WTChNxQoBDd/DdUuDHdEJocLtYPPd4DxqmoVQfKI2du+TzHxKibVaHmG9blqssnCT+DbR+C02q7lj7JnhjsikwuEmuW4GHhKRM7BZT2OV9WFoYdlwqmYVGNe3y/CHYbJj+Lj4PsnYd5QqNUWugyHyNQrIhnjL6SSVVUdpaodgKbAauAVEVmTKZEZY/KX2AOuvGzeUGh+D9wwzhIzkyGZ1VJITeBcoDqwMpPWabLQxNUTmbp+6injY2UzkVo1DBGZfG3vetfty9510PFdaNQ73BGZXCjUlkISn8gGAiuAxqp6TaZEZrLU1PVT+WvvX6eMj9SqlI63xl5MNtr4K3x0ORz5B3pPtsTMBC3UJ7QNQHNV3Z0ZwZjsVbtc7VOq4Xf/cE6YojH50uLR8M1DUK4G9BwP5c4Kd0QmFwu2x+pzVfVPYD5QTSRplTjrsdoYk6aEePjhGZjzHpzdGrqOgMjS4Y7K5HLBPqE9BPQn5Z6rrcfqHCS1sjL/ZqrGztvE5JitAKzcfpA6lawg3mSh2IPwRT9YMx2a3QFtBkGEdfxhQhdsj9X9vY/tVTXWf5qIRIYclck0iWVlydtY9G+manLMVl9CVqdSKTpFVQ5HqCY/2Pc3jOsBu/6Cq96EC24Nd0QmDwn1tuh3oFEA40wYpVRWllydSqUYf3vzbIrI5Eub5kJ0L0g4CTd9CWe1CndEJo8JtgztP0BloKiInI9r9gqgFGD9n+cCls1oslXMOPj6PihdFXpOgAo1wx2RyYOCfUJrC/QBqgBv+o0/BPw3xJhMNrBsRpMtEhLgp4Hw61tQ41LoNgqKlg13VCaPCrYMbRQwSkS6qKq1kZRLWTajyVLHD8NXt8Of30CTW6D9qxBRKNxRmTws2CzHG1X1M6C6iDyUfLqqvpnCYsaY/GL/Zhh3A/yzAtq/Bk1vA5H0lzMmBMFmORb3/gfVZayItAPeASKA4ao6OIV5WgFvA4WA3ap6aTDbyi8CqZ5vTLbYvACie0JcLPSaCDWvCHdEJp8INsvxQ+//8xld1uvh+n3gSmALsEBEpqjqSr95ygAfAO1UdZOIVAwmzvwkkOr5xmS5ZZ/DpLugVCXo843r/sWYbBJqf2ivAi8Cx4BpQEPgAS87MjVNgbWqut5bRzTQiaSNGvcEvlTVTQCq+k8oceYXgVTPNyZLJCTArJdh9qtwZgvo/ikUKxfuqEw+E1LjxEAbVT0IXI172joHeDSdZSoDm/2Gt3jj/J0DlBWRWSKySERSba1URPqLyEIRWbhr166M74ExJjQnjsLnfVxidv5NcNNXlpiZsAj1xerEKksdgHGqulfSL/hNaQZNIa7GQGugKDBHROaq6upTFlQdBgwDaNKkSfL15FnJy8yW7VpFRFzlgBsXtnfPTKY4uM1V/tj+B7R9CS68yyp/mLAJNUH7WkT+xGU53iUipwGx6SyzBfDvcKsKsC2FeXar6hHgiIjMxmVnnpKg5VfJy8wi4ipzdG+DgKvp2LtnJmRbF7vE7MRh11L+OW3DHZHJ50JK0FT1cRF5BTioqvEicgRXHpaWBUAtEakBbAV64MrM/E0G3hORgkBhoBnwViix5kX+ZWbdP5wDJbD3ykz2WPEVfHUnlDgNbvoBTq8T7oiMCblSSCHgJqCll9X4MzA0rWVUNU5E7gGm46rtf6KqK0TkDm/6UFVdJSLTgKVAAq5q//JQYs0L/LMZrTq+CQtVmP0azBwEVS+E7p+5RM2YHCDULMf/4crRPvCGb/LG9UtrIVWdCkxNNm5osuHXgNdCjC9P8c9mtOr4JtudPAaT74blX0DDG+Cad6BgkXBHZYxPqAnaBara0G/4JxH5I8R1mjRY1XwTFod2uJelty6GK56Dix+wyh8mxwk1QYsXkbNVdR2AiJwFxIceljEmx9j+h6v8cWyfy2I87+pwR2RMikJN0B4FZorIelx1/DOBviFHZXys3MyE1apv4MvbXAv5t0yHSg3CHZExqQo6QfOq6B/AtfxREZeg/amqxzMpNoOVm5kwUXVdvvz4PFRuAj3GQsnTwx2VMWkKtrX9fsBLwDqgBtBfVadkZmDmX1ZuZrJV3HGYch8sjYZ610On96BQ0XBHZUy6gn1CewCoq6q7vHKzMYAlaMbkdod3wfhesHkeXPYUtHzEKn+YXCPYBO2Equ4CUNX1ImJ1d43J7XaugLE94Mgu6DoK6nYOd0TGZEiwCVoVERmS2rCq3hdaWMaYbPXXNPjiVihSEvpOhcqNwh2RMRkWbIKWvEX9RaEGYowJA1WY8x58/zRUagg3jINSZ4Q7KmOCEmwHn6MyOxDzL/+q+oG2om+t55sMizsB3z4ISz6DOp2g81AoXCzcURkTtKD6QxORYSJSL5VpxUXkFhHpFVpo+VdiVX3wa0U/HdZ6vsmQI3vg084uMbv0Mbh+pCVmJtcLNsvxA+AZEakPLAd2AZFALaAU8Amu5qMJUmJVfWtF32S6f/6Ecd3h4Hbo8jHUvz7cERmTKYLNcowBuolICaAJUAnXJ9oqVf0r88IzxmSqNTPg875QMNJV/qjSJNwRGZNpQu0P7TAwK3NCybvGztvE5Jitac6zL2I2ByLmAxArm4nUqnT/cI6VjZnMoQrzh8G0x6FiXegZDaWrhDsqYzJVUGVoJmMmx2xl5faDac5zIGI+sbIZgEitSun4poCVjZlMEH8Svn0IvhsAtTvALdMsMTN5UqiNE5sA1alUKs1ysL7TSgF1rYkrk7mO7oWJN8OG2dDiIbj8aShg97Emb8qUBE1EiqvqkcxYlzEmk+xeC2O7wYHNcO2H0LBHuCMyJkuFlKCJyEXAcKAEUE1EGgK3q+pdmRFcbpNaWZmVg5lst34WTOgNBQrBzV9DtQvDHZExWS7UvIe3gLbAHgBV/QNoGWpQuVVqZWVWDmay1YKP4dProFRluO0nS8xMvhFylqOqbpakrXHn6x6r0ysrMybLxMfB9P/C/A/hnHbQZbhrm9GYfCLUBG2zl+2oIlIYuA9YFXpY+YP1Rm0yzbH97v2ydT/BRffCFc9DgYhwR2VMtgo1y/EO4G6gMrAFiALyZflZMPybuLLeqE3Q9qyDj6+EDb9Ax/egzYuWmJl8KdQntNqqmqTNRhG5GPgtxPXmG9YbtQnJxl9h/I2AQO9JUL1FuCMyJmxCfUJ7N8BxxpjMtng0jO4ExSvCbT9aYmbyvaCe0ESkOXARcJqIPOQ3qRRgeR3GZKWEePjhGdeP2dmtoesIiCwd7qiMCbtgsxwL4949Kwj4V6M6CFjT3cZkldiDrmfpNd9DsztdeVmENfhjDATf2v7PwM8iMlJV/87kmIwxKdm3Ecb2gD1r4Oq3oMkt4Y7ImBwl1Fu7oyLyGlAX1x8aAKp6eYjrNcb4+3sOjO/lshtv/BLOujTcERmT44RaKWQM8CdQA3ge2AgsCHGdxhh/MWNhdEcoWhb6/WiJmTGpCDVBK6+qHwMnVfVnVb0FsHZ2jMkMCQnww7Mw6U6o1hz6zYAKNcMdlTE5VqhZjie9/9tF5CpgG2AdLRkTquOH4cv+8Ne30ORWaP8KRBQKd1TG5GihJmgvikhp4GHc+2elgAfSW0hE2gHv4Kr4D1fVwanMdwEwF+iuqp+HGGvY+Ddx5c+auzIp2rMOJtwM/6yA9q9Bs/7hjsiYXCGkBE1Vv/E+HgAuA19LIakSkQjgfeBKXHNZC0RkiqquTGG+V4DpocSYEyQ2cZU88bLmrkwSu9fAL2/A0glQuDj0+hxqtg53VMbkGsG+WB0BdMO14ThNVZeLyNXAf4GiwPlpLN4UWKuq6711RQOdgJXJ5rsX+AK4IJgYcxpr4sqk6p9VMPt1WPElRBSBC+90DQyX/E+4IzMmVwn2Ce1joCowHxgiIn8DzYHHVXVSOstWBjb7DW8BmvnPICKVgWuBy0knQROR/kB/gGrVqgW+B8aE245lMPs1WDnFPZFddB80vwdKnBbuyIzJlYJN0JoADVQ1QUQigd1ATVXdEcCyksI4TTb8NvCYqsYn62vt1AVVhwHDAJo0aZJ8PWFjXcOYVG1bAj+/5ip8FCkFLR+BC++CYuXCHZkxuVqwCdoJVU0AUNVYEVkdYGIG7omsqt9wFVztSH9NgGgvMasAdBCRuACe/nIM/3IzKyszAGxeALNfdc1WRZaBVv+FZrdD0TLhjsyYPCHYBO1cEVnqfRbgbG9YAFXVBmksuwCoJSI1gK1AD6Cn/wyqWiPxs4iMBL7JTYlZIis3MwD8/Tv8/CqsnwnFykPrZ+GCfhBZKtyRGZOnBJugnRfsBlU1TkTuwdVejAA+UdUVInKHN31osOs2JsdQhQ2zXRnZxl9cFy9tXnTtLxYuHu7ojMmTgm2cOKQGiVV1KjA12bgUEzJV7RPKtozJVqqw7kf3RLZ5HpSsBO1egcY3Q6Gi4Y7OmDzN+p0wJjOowurp8PMrsG0xlK4KV70BUTdCocj0lzfGhMwSNGNCkZAAf37jshZ3LIUyZ8I1Q6DhDVCwcLijMyZfCTlBE5GiQDVV/SsT4skVxs7bxOSYraeMX7n9IHUqWUF/vpAQDysnuRei/1kJ5c6Gzv+D+l2tzUVjwiSk1vZF5BogBpjmDUeJyJRMiCtHmxyzlZXbD54yvk6lUnSKqhyGiEy2iY+DP8bDBxfC57e4hO264XDPAojqaYmZMWEU6hPac7imrGYBqGqMiFQPcZ25Qp1KpRh/e/Nwh2GyS/xJWDretbW4dz2cXg+6joTzOkGBUHthMsZkhlATtDhVPZBeax7G5FpxJyBmDPz6JuzfBJUaQvcxULuDJWTG5DChJmjLRaQnECEitYD7gN9DDyt3suau8pCTsbDkU/j1bTi4BSo3gQ5vQK0rwW7gjMmRQk3Q7gWeBI4DY3EvS78YalC5lTV3lQecOAqLRsJv78DhHa6n6E7vwlmXWUJmTA4XaoJWW1WfxCVqBmvuKtc6fhgWfgy/vwtHdkH1S6DLcKjewhIyY3KJUBO0N0WkEjARiFbVFZkQkzHZJ/YgzB8Gc96HY3vh7NZw6QCodmG4IzPGZFCoPVZfJiL/wXX2OUxESgHjVTXfZDtauVkudWwfzB0K8/4HsQfgnHbQcgBUaRzuyIwxQQr5xWqv25ghIjITGAA8Qz4qR7Nys1zmyB6Y+z7MGwYnDsG5V0PLR+GMqHBHZowJUUgJmoicB3QHrgf2ANHAw5kQV65i5Wa5wOF/XPnYgo/h5FGo2xkueQT+Uy/ckRljMkmoT2gjgHFAG1VN3kmnMeF3cDv8PgQWjoD441DvetdD9GmWNWxMXhNqGZqVnJuc6cAW9w7Z4tGQEAcNe8AlD0P5s8MdmTEmiwSVoInIBFXtJiLLAPWfRPo9VhuTdfZthF/fgiVj3HBUT2jxIJSrkeZixpjcL9gntPu9/1dnViDGhGTPOvjlTfhjHBSIcB1qXvwAlKka7siMMdkk2B6rt3sf71LVx/ynicgrwGOnLmVMFti1Gn55HZZNhIjC0Ox2uOg+KFUp3JEZY7JZqJVCruTUxKt9CuOMyVw7V7pONVd8BYWKQfN74KJ7oUTFcEdmjAmTYMvQ7gTuAs4SkaV+k0oCv2VGYMakaPsf8POrrpfowiXhkofgwruhePlwR2aMCbNgn9DGAt8BLwOP+40/pKp7Q47KmOS2LILZr8LqaRBZGi593GUvFisX7siMMTlEsAmaqupGEbk7+QQRKWeJmsk0m+a6J7J1P0LRsnD5U9C0v0vUjDHGTyhPaFcDi3DV9v2bI1fgrBDjMvndxl/h51dgw2woVgGueB4uuBWKlAx3ZMaYHCrYWo5Xe//t5R6TeVRh/Uz4+TXY9DuUOB3avgSN+0Dh4uGOzhiTw4XaluPFQIyqHhGRG4FGwNuquilTostBxs7bxOSYrQCs3H6QOpVKhTmiPEQV1vzgysi2LIBSlaH9a9DoJihUNNzRGWNyiVCr7f8PaCgiDXEt7X8MfApcGmpgOc3kmK2+hKxOpVJ0iqoc7pByP1X4a6orI9seA6WrwdVvQVQvKFgk3NEZY3KZUBO0OFVVEekEvKOqH4vIzZkRWE5Up1Ipxt/ePNxh5H4JCbBqinuPbOdyKFsDOr0PDbpDRKFwR2eMyaVCTdAOicgTwE3AJSISAdgVyaQsId69CD37Ndj1J5SvBdcOg3pdICLkrvmMMflcqFeR7kBP4BZV3SEi1YDXQg8r59kXMZsDEfPpOy1p2Zn1Uh2A+DjXNNUvr8OetXDaeXD9J1Cns2t30RhjMkGo3cfsEJExwAUicjUwX1VHZ05oOcuBiPnEymagbpLx1kt1GuJOwNJo+OUN1wr+f+pDt09dL9EFCoQ7OmNMHhNqLcduuCeyWbh30d4VkUdV9fN0lmsHvANEAMNVdXCy6b34tz3Iw8CdqvpHKLFmhkitaj1TByLuOCz51PVHdmAznNEI2g2Gc9qBSLqLB+vkyZNs2bKF2NjYLNuGMblVZGQkVapUoVChvFsqFGqW45PABar6D4CInAbMAFJN0LxytvdxDRtvARaIyBRVXek32wbgUlXdJyLtgWFAsxBjNVnt5DFYNAp+ewcObYMqTeHqt6Fm6yxNyBJt2bKFkiVLUr16dSQbtmdMbqGq7Nmzhy1btlCjRt59fTjUBK1AYmLm2QOkl5fUFFirqusBRCQa6AT4EjRV/d1v/rlAlRDjDIr/u2dHNY5iRaziQopOHIGFn8BvQ+DIP3BmC7j2f1Dj0mxJyBLFxsZaYmZMCkSE8uXLs2vXrnCHkqVCvUJPE5HpwDhvuDswNZ1lKgOb/Ya3kPbT1624hpBTJCL9gf4A1apVSy/eDPF/96xYkYJUKG7vRiVx/BDM/wjmvAdH98BZraDlSKh+cdhCssTMmJTlh99GqJVCHhWR64AWuDK0Yar6VTqLpXRUNcUZRS7DJWgt0ohhGC5LkiZNmqS4nlAkvnuWvHZjvnZsP8wfBnM/gGP7oOaVcOkAqNo03JEZY/KxoKqaiUgtEZksIsuBrsAbqvpgAIkZuCeyqn7DVYBtKWyjATAc6KSqe4KJ02Syo3vhp0Hwdn2YOQiqNYfbZsKNn1ti5hERHn74Yd/w66+/znPPPZfl223VqhULFy4EoHr16nTp0sU37fPPP6dPnz5pLh8TE8PUqUkzV7777juaNGnCeeedx7nnnssjjzwCwHPPPcfrr7+eabFfdNFFvs+PPvoodevW5dFHH2Xo0KGMHh1apeklS5bQr1+/JOM6depE8+ZJG0jo06cPn3+etOi/RIkSvs+rV6+mQ4cO1KxZk/POO49u3bqxc+fOkGLbu3cvV155JbVq1eLKK69k3759Kc731ltvUbduXerVq8cNN9zgq/T09NNP06BBA6KiomjTpg3btrnL6LJly9I933lVsHWnPwG+AbrgWtx/NwPLLgBqiUgNESkM9ACm+M/gvc/2JXCTqq4OMkaTWY7shhnPuYRs9qsua/H2X+CGcVC5Ubijy1GKFCnCl19+ye7duzN1vapKQkJCwPMvXLiQFStWBDx/8gRt+fLl3HPPPXz22WesWrWK5cuXc9ZZWdOJxu+//1tk/uGHH7J48WJee+017rjjDnr37h3weuLi4k4Z99JLL3Hvvff6hvfv38/ixYvZv38/GzZsCGi9sbGxXHXVVdx5552sXbuWVatWceedd4ZcHjV48GBat27NmjVraN26NYMHDz5lnq1btzJkyBAWLlzI8uXLiY+PJzo6GnCJ/9KlS4mJieHqq69m4MCBANSvX58tW7awaVOea1I3XcFmOZZU1Y+8z3+JyOJAF1TVOBG5B5iOq7b/iaquEJE7vOlDgWeA8sAHXr5vnKo2CTJWE6xDO+H3Ia7Cx8ljrkWPlo9AxfPCHVm6nv96BSu3HczUddY5oxTPXlM3zXkKFixI//79eeuttxg0aFCSabt27eKOO+7wXWjefvttLr74Yp577jlKlCjhewKqV68e33zzDQDt27fnsssuY86cOUyaNInBgwezYMECjh07xvXXX8/zzz+fYhyPPPIIL730EmPGjEky/siRI9x7770sW7aMuLg4nnvuOdq3b88zzzzDsWPH+PXXX3niiSf49ttvefLJJzn33HN9+3XXXXedsp2PPvqIYcOGceLECWrWrMmnn35KsWLFmDhxIs8//zwRERGULl2a2bNns2LFCvr27cuJEydISEjgiy++oFatWpQoUYLDhw/TsWNHjhw5QrNmzXjiiSdYtWqV77isW7eOu+++m127dlGsWDE++ugjzj33XPr06UO5cuVYsmQJjRo14o033vDFdujQIZYuXUrDhg1947744guuueYaTj/9dKKjo3niiSfSPJ8AY8eOpXnz5lxzzTW+cZdddlm6y6Vn8uTJzJo1C4Cbb76ZVq1a8corr5wyX1xcHMeOHaNQoUIcPXqUM844A4BSpf4tBjly5EiSMrJrrrmG6OhoBgwYEHKcuUmwCVqkiJzPv+VhRf2HVTXNBE5Vp5Ks8oiXkCV+7gf0S76cySYHt7mq94tGQvxJaNANLnkYKtQKd2S5wt13302DBg1OuZjcf//9PPjgg7Ro0YJNmzbRtm1bVq1alea6/vrrL0aMGMEHH3wAwKBBgyhXrhzx8fG0bt2apUuX0qBBg1OW69atGx988AFr165NMn7QoEFcfvnlfPLJJ+zfv5+mTZtyxRVXMHDgQBYuXMh7770HwCuvvJIk6zQ11113HbfddhsATz31FB9//DH33nsvAwcOZPr06VSuXJn9+/cDMHToUO6//3569erFiRMniI+PT7KuKVOmUKJECWJiYgCSZNX279+foUOHUqtWLebNm8ddd93FTz/9BLjswBkzZhARkbTVmYULF1KvXr0k48aNG8ezzz7L6aefzvXXXx9QgrZ8+XIaN26c7nyHDh3ikksuSXHa2LFjqVOnTpJxO3fupFKlSgBUqlSJf/7555TlKleuzCOPPEK1atUoWrQobdq0oU2bNr7pTz75JKNHj6Z06dLMnDnTN75JkyYMHjzYErQAbQfe9Bve4TeswOWhBJVT+Dd3lS+auNq/CX59C5Z8BpoADW+ASx6Ccrmvv9b0nqSyUqlSpejduzdDhgyhaNF/u7+ZMWMGK1f++7rlwYMHOXToUJrrOvPMM7nwwgt9wxMmTGDYsGHExcWxfft2Vq5cmWKCFhERwaOPPsrLL79M+/btfeO///57pkyZ4isDi42NDSlravny5Tz11FPs37+fw4cP07ZtWwAuvvhi+vTpQ7du3bjuuusAaN68OYMGDWLLli1cd9111KoV2A3S4cOH+f333+natatv3PHjx32fu3btekpiBrB9+3ZOO+003/DOnTtZu3YtLVq0QEQoWLAgy5cvp169einWAMxorcCSJUv6EuPMsm/fPiZPnsyGDRsoU6YMXbt25bPPPuPGG28E3A3KoEGDePnll3nvvfd8T+wVK1b0lanlJ8F28Bn683Yu4N/cVZ5u4mrvevjlTfhjHEgBOP9GuPgBKHtmuCPLtR544AEaNWpE3759feMSEhKYM2dOkkQOXHaef/mYf0snxYv/27Hphg0beP3111mwYAFly5alT58+abaKctNNN/Hyyy9Tt+6/ibuq8sUXX1C7dtKbs3nz5iUZrlu3LosWLUqSXZeSPn36MGnSJBo2bMjIkSN9WWhDhw5l3rx5fPvtt0RFRRETE0PPnj1p1qwZ3377LW3btmX48OFcfnn6974JCQmUKVMm1cTC/xj5K1q0aJLjM378ePbt2+d7sfjgwYNER0fz4osvUr58+SSVMvbu3UuFChV8x+Lnn39ON86MPqGdfvrpbN++nUqVKrF9+3YqVqx4ynIzZsygRo0avoT5uuuu4/fff/claIl69uzJVVdd5UvQYmNjT/me5QfWoF46Epu7GtFuBF3P6Zr+ArnJ7jXw1R3wbhPXeHCTW+G+GNcnmSVmISlXrhzdunXj448/9o1r06aNL0sP8F2gq1evzuLFLpd+8eLFqVZWOHjwIMWLF6d06dLs3LmT775L9fVMAAoVKsSDDz7I22+/7RvXtm1b3n33XVTdGy5LliwB3NOF/9Pio48+yksvvcTq1a5OVkJCAm++6Z8p4xw6dIhKlSpx8uTJJOV169ato1mzZgwcOJAKFSqwefNm1q9fz1lnncV9991Hx44dWbp0aZrxJypVqhQ1atRg4sSJgEuU//gj/ZbwzjvvvCRZruPGjWPatGls3LiRjRs3smjRIl8Fi1atWjF+/HhOnDgBwMiRI33lZD179uT333/n22+/9a1r2rRpLFu2LMn2Ep/QUvpLnpgBdOzYkVGjRgEwatQoOnXqdMo81apVY+7cuRw9ehRV5ccff+S881wZ9po1a3zzTZkyxVfeCS4bNnl2a35gCVp+9M8q+PxWeL8prJgEF94J9/8BHV6F0tZxaWZ5+OGHk9R2TKyt1qBBA+rUqcPQoa7YuEuXLuzdu5eoqCj+97//cc4556S4voYNG3L++edTt25dbrnlFi6+OP0X2G+99dYktf+efvppTp48SYMGDahXrx5PP/004Co5rFy5kqioKMaPH0+DBg14++23ueGGGzjvvPOoV68e27dvP2X9L7zwAs2aNePKK69MckF99NFHqV+/PvXq1aNly5Y0bNiQ8ePHU69ePaKiovjzzz8zVINxzJgxfPzxxzRs2JC6desyefLkdJc599xzOXDgAIcOHWLjxo1s2rQpSfZtjRo1KFWqFPPmzePqq6/mkksuoXHjxkRFRfHbb7/5KmgULVqUb775hnfffZdatWpRp04dRo4cmeITVUY8/vjj/PDDD9SqVYsffviBxx9/HIBt27bRoYPLDWrWrBnXX389jRo1on79+iQkJNC/f3/f8vXq1aNBgwZ8//33vPPOO751z5w5k6uuuiqk+HIjSbxTywuaNGmiie/iZIZmI9y7PPP6fpFp6wyrHctcX2Qrp0Dh4nBBP2h+D5Q4Lf1lc4FVq1b57l6NAfcOV8mSJU95Fy0vO378OJdeeim//vorBQsmLVVK6TciIovySi3yUFvbF6AXcJaqDvTeH/uPqs7PlOhM5ti2BH5+Df76FoqUclXvL7wLipULd2TGZKk777zTl1WZX2zatInBgwefkpjlB6Hu8QdAAq5W40DgEPAFcEGI6zWZYfMC9yL0mu8hsgy0+i80ux2Klgl3ZMZki8jISG666aZwh5GtatWqFXAN0rwm1AStmao2EpElAF53L4UzIS4Tir9/h59fgfWzoFh5aP2sy16MtPYojTF5V6gJ2kmvfzMFX39ogbfPYzKPKmyYDT+/Cn//CsUrQpsXocktrrzMGGPyuFATtCHAV0BFERkEXA88FXJUJnCqsO5Hl5BtngclK0G7V6DxzVAo/72HYozJv0LtPmaMiCwCWuOaveqsqmm35WMyhyqsnu6yFrcthtJV4ao3IOpGKBQZ7uiMMSbbhfQemler8SjwNa7F/CPeOJNVEhJctfsPW8K47q5jzWuGwL2LXTmZJWZhFRERQVRUFHXr1qVhw4a8+eabGWolPyudPHmSxx9/nFq1alGvXj2aNm3qezm7evXqmdZDwJQpU3wtx+/atYtmzZpx/vnn88svv9ChQwdf247BeuCBB5g9e7ZveNeuXRQqVIgPP/wwyXz+3b+Ae1n6nnvu8Q2PHj2aevXqUbduXerUqZMpXeJMmzaN2rVrU7NmzRRbz/e3YMECIiIifN3WxMbG0rRpU9+7ds8++6xv3kceecTXdqVJg6oG/QcsA5Z6/9cAccCKUNYZyl/jxo01MzX95Dpt+sl1mbrOoMXHqS77XPX9C1WfLaX6zvmqS8aoxp0Id2Q5xsqVK8MdghYvXtz3eefOndq6dWt95plnwhjRvx577DHt3bu3xsbGqqrqjh07dPz48aqqeuaZZ+quXbsyfZvjxo3T3r17B718XFxckuE9e/Zos2bNkox7//33tUWLFnrppZcmGe9/LlRVR4wYoXfffbeqqk6dOlXPP/983bp1q6qqHjt2TIcNGxZ0nImxnnXWWbpu3To9fvy4NmjQQFesWJHqvJdddpm2b99eJ06cqKqqCQkJeujQIVVVPXHihDZt2lTnzJmjqqobN27UK6+8MqT4VFP+jQALNUzX7Mz+CzXLsb7/sIg0Am4PZZ0mmfg4WP4F/PI67F4NFWrDdcOh3nVQ4NQGWY3nu8fdi+SZ6T/1oX3ad93+KlasyLBhw7jgggt47rnnGDVqVJIW7a+++moeeeQRWrVqRYkSJbj77ruZMWMGZcuW5aWXXmLAgAFs2rSJt99+m44dOzJy5EgmTZpEfHw8y5cv5+GHH+bEiRN8+umnFClShKlTp7Jv3z66du3qa0przZo19OjRg19++YWPPvqIDRs2UKRIEcC1JditW7dT4u7cuTObN28mNjaW+++/n/79+xMfH8+tt97KwoULERFuueUWHnzwQYYMGcLQoUMpWLAgderUITo6mpEjR7Jw4UL69evHgAEDOHbsGFFRUcyZM4fzzjuPhQsXUqFCBT777DOGDBnCiRMnaNasGR988AERERGUKFGChx56iOnTp/PGG2/QosW/HdZ//vnntGvXLkm848aN44033qBnz55s3bqVypXTb+3m5Zdf5vXXX/d1xRIZGenrNSBY8+fPp2bNmr5+43r06MHkyZNTbPbq3XffpUuXLixYsMA3TkR8T5UnT57k5MmTvgaSzzzzTPbs2cOOHTv4z3/+E1KceVmmNn2lrtsYewctM8SfdK3ev38BfNUfIgpD15Fw11xo0NUSs1zirLPOIiEhIcWuQfwdOXKEVq1asWjRIkqWLMlTTz3FDz/8wFdffcUzzzzjm2/58uWMHTuW+fPn8+STT1KsWDGWLFlC8+bNGT16NGeffTalS5f2tRM5YsQI+vTpw9q1a6lWrVqSPrRS88knn7Bo0SIWLlzIkCFD2LNnDzExMWzdupXly5ezbNkyX6PLgwcPZsmSJSxdutTXlFeiqKgoBg4cSPfu3YmJiUnSWO6qVasYP348v/32GzExMURERPjagjxy5Aj16tVj3rx5SRIzgN9++y1JVy6bN29mx44dNG3alG7dujF+/Ph09y/xOAbSJcyYMWOIioo65e/6668/Zd6tW7dStWpV33CVKlXYunVrivN99dVX3HHHHadMi4+PJyoqiooVK3LllVfSrFkz37RGjRrx22+/BbR/+VWoLYU85DdYAGgEhNaNa34XdxxixsKvb7ruXCo1hO5joHYHKGBNbwYsA09SWU0DaF6ucOHCvieP+vXrU6RIEQoVKkT9+vXZuHGjb77LLruMkiVLUrJkSUqXLu3rdLJ+/fq+xn779evHiBEjePPNNxk/fjzz589P8cKamiFDhvDVV18BLsFYs2YNtWvXZv369dx7771cddVVvj65GjRoQK9evejcuTOdO3cOeBs//vgjixYt4oIL3P3vsWPHfG0jRkRE0KVLlxSXS94lTHR0tO8ps0ePHtx666089NBDKS4LGe8SplevXvTq1SugeVM6zylt74EHHuCVV15JscubiIgIYmJi2L9/P9dee62vexvIv13CZESo1fZL+n2OA77FtRRiMupkLCz51PVHdnArVG4CHd6AWldCBn+EJudYv349ERERVKxYMc1uYgoVKuS7+BUoUMCXLVigQIEkjQsnjk9rvi5duvD8889z+eWX07hxY8qXL0/RokXZtGkThw4domRJ/59tUrNmzWLGjBnMmTOHYsWK0apVK2JjYylbtix//PEH06dP5/3332fChAl88sknfPvtt8yePZspU6bwwgsvsGLFioCOi6py88038/LLL58yLTIyMsWLPZzaJcy4cePYuXOn7+lu27ZtrFmzhlq1alG0aFFOnDhB4cKurYfkXcIsWrQo3e5rxowZw2uvvXbK+Jo1a/oqcySqUqUKmzdv9g1v2bLFl6Xpb+HChfTo0QOA3bt3M3XqVAoWLJjkhqBMmTK0atWKadOm+RK0/NolTEYEfcvvvVBdQlWf9/4GqeoYVU29gyZzqhNHYc4H8E5DmPoIlKkGN30F/WbAOW0sMcvFdu3axR133ME999yDiFC9enViYmJISEhg8+bNzJ+fNU2eRkZG0rZtW+68805f1mCxYsW49dZbue+++3xdpGzfvp3PPvssybIHDhygbNmyFCtWjD///JO5c+cC7sKbkJBAly5deOGFF1i8eLFvPy677DJeffVVXyefgWjdujWff/65Lyt27969/P333+ku598lzF9//cWRI0fYunWrr0uYJ554wtclzKWXXurbv2PHjjFhwgRflzBPPPEEAwYMYMeOHYBr0HfIkCGnbK9Xr14pdgeTPDEDuOCCC1izZg0bNmzgxIkTREdH07Fjx1Pm27Bhgy/e66+/ng8++IDOnTuza9cuXw3QY8eOMWPGDOsSJoOCekITkYKqGudVAjHBOH4YFn4Mv78LR3ZB9Uugy3Co3sISsVwssQLEyZMnKViwIDfddJMvC+ziiy+mRo0avm5VGjXKup9Pr169+PLLL31ZgwAvvvgiTz31FHXq1CEyMpLixYszcODAJMu1a9eOoUOH0qBBA2rXru3rbmXr1q307dvX94T58ssvEx8fz4033siBAwdQVR588EHKlCkTUHx16tThxRdfpE2bNiQkJFCoUCHef/99zjwz7X74rrrqKj788EP69evHuHHjuPbaa5NM79KlCz169ODpp5/mnXfe4fbbb2fIkCGoKr1796Zly5YAdOjQgZ07d3LFFVegqr6KLqEoWLAg7733Hm3btiU+Pp5bbrnF17lqYvliSuVmibZv387NN99MfHw8CQkJdOvWjauvvhpwlUTWrl1LkyZ5olH8LBNU9zEislhdG45vALWAicCRxOmq+mXmhRi4XNF9TOwBmD/MPZUd2wtnt4ZLB0C1C9Nf1qTJuo/51+uvv86BAwd44YUXwh1KpmvRogXffPNNwIlnXvDVV1+xePHikM+ndR+TtnLAHlxr+4prLUSBsCRoOdqxfTB3KMz7n0vUzmkHLQdAlfRrWhmTEddeey3r1q3Lsy/ivvHGG2zatClfJWhxcXE8/PDD4Q4jxws2Qavo1XBczr8JWaK802NoZjiyB+a+D/OGwYlDcO7V0PJROCMq3JGZPCqxhmJe5V+VPb/o2rVruEPIFYJN0CKAEiRNyBLl6gRt4uqJTF0/FYBY2UykVk1niVQc/seVjy34GE4ehbqdXUJ2et3MC9YYY4xPsAnadlUdmP5suc/U9VP5a+9f1C5Xm0itSun4phlbwcHt8PsQWDgC4o9DvetdD9Gn1c6agI0xxgDBJ2h5uhpe7XK1GdFuBN0/nBP4Qge2wK9vw+LRkBAHDXvAJQ9D+bOzLE5jjDH/CjZBa52pUeRm+za6l6GXuBc7ieoJLR6EcjXCGpYxxuQ3Qb1Yrap7MzuQXGfPOph0Nwxp5Jqqanwz3LcEOg6xxCwfGzRoEHXr1qVBgwZERUUxb948nnvuOZ544okk88XExPiqTx8+fJjbb7+ds88+m7p169KyZUvmzZt3yrpVlcsvv5yDBw/6xn311VeICH/++adv3KxZs3zvLyXq06eP72XgtLqRCcXLL79MzZo1qV27NtOnT09xnpiYGC688EKioqJo0qSJ7+XyH374gcaNG1O/fn0aN26cpIbmFVdcwb59+0KOz+R9oVbbz392/QWzX4fln7sGg5vdDhfdB6UqhTsyE2Zz5szhm2++YfHixRQpUoTdu3dz4sQJbrjhBtq3b5+kmafo6Gh69uwJuLYXa9SowZo1ayhQoADr169n1apT+8mdOnUqDRs2TNLA8Lhx42jRogXR0dE899xzAcX59NNPs337dpYvX06RIkXYuXMnP//8c0j7vnLlSqKjo1mxYgXbtm3jiiuuYPXq1ac0YTVgwACeffZZ2rdvz9SpUxkwYACzZs2iQoUKfP3115xxxhksX76ctm3b+tqfvOmmm/jggw948sknQ4rR5H2WoAVq5wqY/RqsmASFikHze+Cie6FExXBHZlLwyvxX+HPvn+nPmAHnljuXx5o+lur07du3U6FCBV/7iontBoJrm2/evHm+KucTJkxg+vTprFu3jnnz5jFmzBgKeI1Pn3XWWb4uSPyNGTOG/v37+4YPHz7Mb7/9xsyZM+nYsWNACdrRo0cD7kYmIyZPnkyPHj0oUqQINWrUoGbNmsyfP5/mzZsnmU9EfE+YBw4c8LV1eP755/vmqVu3LrGxsRw/fpwiRYrQsWNHLrnkEkvQTLosQSNpVf1lu1YREVeZ7h/OYeX2g3So8A9Evwd/fgOFS8IlD8GFd0Px8mGO2uQ0bdq0YeDAgZxzzjlcccUVdO/enUsvvRSAG264gejoaJo1a8bcuXMpX748tWrVYsqUKURFRaXaGK+/3377LUmvzJMmTaJdu3acc845lCtXjsWLF6fbnFZGupF58MEHmTlz5inje/ToweOPP55k3NatW33NZEHqXae8/fbbtG3blkceeYSEhAR+//33U+b54osvOP/8830JbtmyZTl+/Dh79uyhfHn73ZnUWYJG0qr6EXGVObq3AWcX/osBRcbSePc8OFwaLn3cZS8WKxfucE0A0nqSyiolSpRg0aJF/PLLL8ycOZPu3bszePBg+vTpQ48ePbjooot44403iI6O5oYbbsjw+vfu3Zukpfxx48bxwAMPAC6RGTduHI0aNUq1i5SMdp3y1ltvBTxvoF2n/O9//+Ott96iS5cuTJgwgVtvvZUZM2b4pq9YsYLHHnuM77//PslyiV2nWIJm0hKWBE1E2gHv4F7QHq6qg5NNF296B+Ao0MfrPDTLJFbVf+bd4Vx3YixRhxZB0bJw+VPQtD9Els7KzZs8IiIiglatWtGqVSvq16/PqFGj6NOnD1WrVqV69er8/PPPfPHFF8yZ414JqVu3Ln/88QcJCQm+LMfUJHY/U6BAAfbs2cNPP/3E8uXLERHi4+MREV599VXKly9/SiWKxK5TatasGVA3MpCxJ7RAu04ZNWoU77zzDuBav+jXr1+SZa699lpfR6X+rOsUExBVzdY/XCK2DjgLKAz8AdRJNk8H4Dvc+24XAvMCWXfjxo01GH2+66N9vrpWdeTVqs+W0v3PV1X95S3V2INBrc+Ex8qVK8O6/T///FNXr17tG37yySf17rvv9g2///772rBhQ7300kuTLNe1a1d96qmnNCEhQVVVV69erZMmTTpl/c2aNdM1a9aoqurQoUO1f//+Saa3bNlSZ8+erbGxsVq9enXf8di4caNWq1ZN9+/fr6qqjz76qPbp00ePHz+uqqrbtm3TTz/9NKR9X758uTZo0EBjY2N1/fr1WqNGDY2LiztlvnPPPVdnzpypqqozZszQRo0aqarqvn37tEGDBvr555+fskxCQoKeccYZevLkyZBiNCn/RoCFms3pQFb9haML5KbAWlVdr6ongGigU7J5OgGjveM9FygjIllTjfDEUWI3x8COZez7exmv0pt7TxsFLR6AImnfwRrj7/Dhw9x8883UqVOHBg0asHLlyiQVNbp27cqKFSt8nTsmGj58ODt27KBmzZrUr1+f2267LcWnm6uuuopZs2YBpNp1ytixYylSpAifffYZffv2JSoqiuuvv57hw4dTurTLZXjxxRc57bTTqFOnDvXq1aNz585JeoEORt26denWrRt16tShXbt2vP/++75ywX79+pHYC8ZHH33Eww8/TMOGDfnvf//LsGHDAHjvvfdYu3YtL7zwAlFRUURFRfn6Slu0aBEXXnghBQtaCYlJW1Ddx4S0QZHrgXaq2s8bvglopqr3+M3zDTBYVX/1hn8EHlPVU/qGEZH+QH+AatWqNQ6kk8DkHh52GbsSSpLAQ5yUInSKqkzPZtWC2T0TRnm9+5jt27fTu3dvfvjhh3CHkq3uv/9+OnbsSOvW1p5DqKz7mMwXSIPGATd6rKrDgGHg+kMLJqA3+p9aTmBMTlOpUiVuu+02Dh48GFAtxbyiXr16lpiZgIQjQdsC+DdhXwXYFsQ8xuQ7ob4vlhvddttt4Q7B5BLhKENbANQSkRoiUhjoAUxJNs8UoLc4FwIHVHV7dgdqcp/szkI3JrfID7+NbH9CU9U4EbkHmI6r8fiJqq4QkTu86UOBqbiajmtx1fb7ZnecJveJjIz0vXyb0XeujMnLVJU9e/YQGRkZ7lCyVLZXCslKTZo00cTaVCb/OXnyJFu2bCE2NjbcoRiT40RGRlKlShUKFSqUZLxVCjEmBypUqBA1alhPB8bkV+EoQzPGGGMynSVoxhhj8gRL0IwxxuQJeapSiIjsAjLeVIhTAdidieHkBrbPeV9+21+wfc6oM1U1tLbPcog8laCFQkQW5pWaPoGyfc778tv+gu1zfmZZjsYYY/IES9CMMcbkCZag/WtYuAMIA9vnvC+/7S/YPudbVoZmjDEmT7AnNGOMMXmCJWjGGGPyhHyVoIlIOxH5S0TWisjjKUwXERniTV8qIo3CEWdmCmCfe3n7ulREfheRhuGIMzOlt89+810gIvFeL+q5WiD7LCKtRCRGRFaIyM/ZHWNmC+C7XVpEvhaRP7x9ztW9dojIJyLyj4gsT2V6nrt+ZZiq5os/XFc164CzgMLAH0CdZPN0AL7D9Zh9ITAv3HFnwz5fBJT1PrfPD/vsN99PuK6Krg933NlwnssAK4Fq3nDFcMedDfv8X+AV7/NpwF6gcLhjD2GfWwKNgOWpTM9T169g/vLTE1pTYK2qrlfVE0A00CnZPJ2A0erMBcqISKXsDjQTpbvPqvq7qu7zBufiegfPzQI5zwD3Al8A/2RncFkkkH3uCXypqpsAVDW373cg+6xASXGd45XAJWhx2Rtm5lHV2bh9SE1eu35lWH5K0CoDm/2Gt3jjMjpPbpLR/bkVd4eXm6W7zyJSGbgWGJqNcWWlQM7zOUBZEZklIotEpHe2RZc1Atnn94DzgG3AMuB+VU3InvDCIq9dvzIsP/WHllIXxsnfWQhkntwk4P0RkctwCVqLLI0o6wWyz28Dj6lqfB7p2TqQfS4INAZaA0WBOSIyV1VXZ3VwWSSQfW4LxACXA2cDP4jIL6p6MItjC5e8dv3KsPyUoG0BqvoNV8HduWV0ntwkoP0RkQbAcKC9qu7JptiySiD73ASI9hKzCkAHEYlT1UnZEmHmC/S7vVtVjwBHRGQ20BDIrQlaIPvcFxisroBprYhsAM4F5mdPiNkur12/Miw/ZTkuAGqJSA0RKQz0AKYkm2cK0NurLXQhcEBVt2d3oJko3X0WkWrAl8BNufhu3V+6+6yqNVS1uqpWBz4H7srFiRkE9t2eDFwiIgVFpBjQDFiVzXFmpkD2eRPuiRQROR2oDazP1iizV167fmVYvnlCU9U4EbkHmI6rIfWJqq4QkTu86UNxNd46AGuBo7g7vFwrwH1+BigPfOA9scRpLm61O8B9zlMC2WdVXSUi04ClQAIwXFVTrP6dGwR4nl8ARorIMlx23GOqmmu7lRGRcUAroIKIbAGeBQpB3rx+BcOavjLGGJMn5KcsR2OMMXmYJWjGGGPyBEvQjDHG5AmWoBljjMkTLEEzxhiTJ1iCls95rc3H+P1VT2Pew5mwvZEissHb1mIRaR7EOoaLSB3v83+TTfs91Bi99SQel+Vei+1l0pk/SkQ6BLGdSiLyjfe5lYgcEJElIrJKRJ4NYn0dE1ueF5HOicfJGx4oIldkdJ0pbGOkpNNDgdfEVsCvf3j7/k0A86XY4ryIvC4ilwe6PZM3WYJmjqlqlN/fxmzY5qOqGgU8DnyY0YVVtZ+qrvQG/5ts2kWhhwf8e1zq4RqEvTud+aNw7wBl1EPAR37Dv6jq+bjWTG4UkcYZWZmqTlHVwd5gZ6CO37RnVHVGEDHmJCOBdimMfxf3fTL5mCVoJgkRKSEiP3pPT8tE5JSW6r2nitl+TzCXeOPbiMgcb9mJIlIinc3NBmp6yz7krWu5iDzgjSsuIt+K689quYh098bPEpEmIjIYKOrFMcabdtj7P97/icl7qugiIhEi8pqILBDXZ9TtARyWOXiNvIpIU3H9xi3x/tf2WqoYCHT3Yunuxf6Jt50lKR1HTxdgWvKRXhNVi4Czvae/uV68X4lIWS+W+0RkpTc+2hvXR0TeE5GLgI7Aa15MZyc+WYlIexGZ4HdsWonI197nDJ1DEXnG28flIjJMJEnjmDd6x2i5iDT15g/0uKQotRbnVfVvoLyI/Ccj6zN5TLj7r7G/8P4B8bgGXGOAr3Ctx5TyplXAtTqQ+AL+Ye//w8CT3ucIoKQ372yguDf+MeCZFLY3Eq//MaArMA/XaO4yoDium48VwPm4i/1HfsuW9v7PApr4x+Q3T2KM1wKjvM+Fca2QFwX6A09544sAC4EaKcR52G//JgLtvOFSQEHv8xXAF97nPsB7fsu/BNzofS6DazOxeLJt1AAW+Q23Ar7xPpcHNgJ1ca17XOqNHwi87X3eBhRJ3EbyOPyPtf+wd443+Z2r/wE3BnkOy/mN/xS4xu8cfeR9bonXh1dqxyXZvjfBtWSS2ne2Oin0CYZ70u0S7t+U/YXvL980fWVSdUxd9h8AIlIIeElEWuKaSKoMnA7s8FtmAfCJN+8kVY0RkUtx2Vu/eTfphXFPNil5TUSeAnbhWvhvDXyl7qkEEfkSuAT35PK6iLyCu9j9koH9+g4YIiJFcFlUs1X1mIi0ARr4lQGVBmoBG5ItX1REYnAXz0XAD37zjxKRWriWzAulsv02QEcRecQbjgSqkbT9xEreMfB3iYgswR37wbgGZ8uoamIP06NwCSy4hG6MiEwCJqUSxynUNRs1DbhGRD4HrgIGABk5h4kuE5EBQDGgHO5m5Gtv2jhve7NFpJS4csjUjot/fAuBfoHuj59/gDOCWM7kEZagmeR64Xr3bayqJ0VkI+6i4+NdoFriLoSfishrwD7gB1W9IYBtPKqqnycOSCoVFVR1tVeG1AF4WUS+V9WBgeyEqsaKyCxcFyLd8S6uuDb97lXV6ems4piqRolIaeAbXBnaEFz7gDNV9VpxFWhmpbK84J4W/kprGyQ7trgytKt9K3HbT81VuKefjsDTIlI3jXmTG4/bp73AAlU95GUXBnoOEZFI4APc0/JmEXmOpPuTvF09JZXjIq7x4FBF4o6pyaesDM0kVxr4x0vMLgPOTD6DiJzpzfMR8DGuW/i5wMUiklgmVkxEzglwm7OBzt4yxXHZhb+IyBnAUVX9DHjd205yJ70nxZRE4xpovQTXiC3e/zsTlxGRc7xtpkhVDwD3AY94y5QGtnqT+/jNegiX9ZpoOnBvYpmSiJyfwupX454AU+Vtf5945ZTATcDPIlIAqKqqM3FPV2Vw2bX+ksfkbxbueN6GS9wg4+cwMfHa7ZW1Ja/5mFjm2QLX8vsBAjsuwToHyLUNLpvQWYJmkhsDNBGRhbintT9TmKcVEONljXUB3lHVXbgL/DgRWYq7OJ4byAZVdTGuXGY+rkxtuKouAeoD872svyeBF1NYfBiwVLxKIcl8j3uCmaGqJ7xxw4GVwGJxVb8/JJ2cCi+WP3BdlLyKe1r8DVe+lmgmUCexUgjuSa6QF9tybzj5eo8A6xITkDTcjMumXYqrTTnQ2/Zn4lqSXwK8par7ky0XDTzqVb44O9m243FPnu29/2T0HHrb+whX/jkJlxXtb5+41yiG4rKWIYDjIq7Cz/CUtimuxfk5QG0R2SIit3rjC+EqGC1MLV6T91lr+8aEkYhci8vefSrcseRm3nFspKpPhzsWEz5WhmZMGKnqVyJSPtxx5AEFgTfCHYQJL3tCM8YYkydYGZoxxpg8wRI0Y4wxeYIlaMYYY/IES9CMMcbkCZagGWOMyRP+DwHawlSw1VxKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Receiver Operation Curve (ROC) for best MLP model \n",
    "best_mlp_roc = plot_roc_curve(best_mlp, X_test, y_test)\n",
    "\n",
    "# Add ROC for Dummy Classifier model\n",
    "dummy_roc = plot_roc_curve(dummy_model, X_test, y_test, ax=best_mlp_roc.ax_)\n",
    "\n",
    "# Add ROC for best SVM model \n",
    "best_svm_roc = plot_roc_curve(best_svm, X_test, y_test, ax=best_mlp_roc.ax_)\n",
    "\n",
    "# Add optimal threshold for best MLP model\n",
    "plt.scatter(mlp_FPR[mlp_ix], mlp_TPR[mlp_ix], marker='o', color='blue')\n",
    "\n",
    "# Add optimal threshold for best SVM model\n",
    "plt.scatter(svm_FPR[svm_ix], svm_TPR[svm_ix], marker='o', color='green')\n",
    "\n",
    "# Add title\n",
    "plt.title(\"ROC curve for best SVM model, best MLP model and dummy classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code is based on https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Recall=0.778, Best Precision=0.600\n"
     ]
    }
   ],
   "source": [
    "# Obtain precision, recall and threshold for best SVM model\n",
    "svm_precision, svm_recall, svm_prthresholds = precision_recall_curve(y_test, best_svm_y_pred_class)\n",
    "\n",
    "# Calculate F1 score for the best SVM model\n",
    "svm_fscore = (2 * svm_precision * svm_recall) / (svm_precision + svm_recall)\n",
    "\n",
    "# Determine the best recall and precision at largest F1 score for best MLP model\n",
    "svmf_ix = np.argmax(svm_fscore)\n",
    "print('Best Recall=%.3f, Best Precision=%.3f' % (svm_recall[svmf_ix],svm_precision[svmf_ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Recall=0.889, Best Precision=0.578\n"
     ]
    }
   ],
   "source": [
    "# Obtain precision, recall and threshold for best MLP model\n",
    "mlp_precision, mlp_recall, mlp_prthresholds = precision_recall_curve(y_test, best_mlp_y_pred_class)\n",
    "\n",
    "# Calculate F1 score for best MLP model\n",
    "mlp_fscore = (2 * mlp_precision * mlp_recall) / (mlp_precision + mlp_recall)\n",
    "\n",
    "# Determine the best recall and precision at largest F1 score for best MLP model\n",
    "mlpf_ix = np.argmax(mlp_fscore)\n",
    "print('Best Recall=%.3f, Best Precision=%.3f' % (mlp_recall[mlpf_ix],mlp_precision[mlpf_ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Precision-Recall Curve for best MLP model\n",
    "best_mlp_prc = plot_precision_recall_curve(best_mlp, X_test, y_test)\n",
    "\n",
    "# Add Precision-Recall Curve for Dummy Classifier model\n",
    "dummy_prc = plot_precision_recall_curve(dummy_model, X_test, y_test, ax=best_mlp_prc.ax_)\n",
    "\n",
    "# Add Precision-Recall Curve for best SVM model \n",
    "best_svm_prc = plot_precision_recall_curve(best_svm, X_test, y_test, ax=best_mlp_prc.ax_)\n",
    "\n",
    "# Add optimal threshold for best SMV model\n",
    "plt.scatter(svm_recall[svmf_ix], svm_precision[svmf_ix], marker='o', color='green')\n",
    "\n",
    "# Add optimal threshold for best MLP model\n",
    "plt.scatter(mlp_recall[mlpf_ix], mlp_precision[mlpf_ix], marker='o', color='blue')\n",
    "\n",
    "# Add title\n",
    "plt.title(\"Precision-recall curve for best SVM model, best MLP model and dummy classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results, Findings and Evaluation\n",
    "\n",
    "### Model Selection\n",
    "\n",
    "For SVM, applying RBF kernel, relatively large C of 100 and moderate gamma of 0.02 yielded the highest AUC. The choice of kernel appeared to have strongest impact on AUC, as all RBF kernel SVMs showed higher AUCs than linear or third degree polynomial kernel SVMs. Increasing C slightly increased the AUC for RBF and polynomial SVMs, as this decreased the margin and increased the complexity of the decision boundary, which resulted in higher variance and lower bias [11]. Increasing gamma, which determines how far the influence of each training example, showed mixed impact on AUCs for third degree polynomial and RBF SVMs.\n",
    "\n",
    "For MLP, the combination of 8 neurons in a single hidden layer, relatively large batch size of 64, high learning rate of 1, small dropout rate of 0.2 and small momentum of 0.3 yielded the highest AUC. The architecture appeared to show the highest impact on AUC. Increasing the number of hidden neurons from 3 to 5 appeared to correlate with increase in AUC. As the model complexity increased, the variance increased and the bias reduced. Nonetheless, adding more hidden neurons or a second hidden layer resulted in little or no increase in AUCs, as the models started to become too complex and overfitted. Further investigation is needed to determine the influence of each of the parameters optimizer momentum, learning rate, dropout rate and batch size on AUC. Two models with two hidden layers and optimizer momentum of 0.9 lacked discriminative power between the two target classes (AUC of 0.5), which reflected the steps taken by stochastic gradient descend algorithm were so large that the minimum loss could not be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm comparison\n",
    "\n",
    "When constructing the final model, all training data were used for SVM, whereas for MLP, only 80% of the training data were used, as 20% of the data was withheld for validation in Early Stopping. Both final MLP and SVM models showed relatively high AUC scores of 0.878 and 0.889 respectively on training data and slightly lower AUCs on the test data. The stratified 5-fold cross validation AUCs for SVM (0.851) and MLP (0.844) obtained previously were between the AUCs on training and test data for the final models. MLP achieved a marginally higher AUC of 0.831 than SVM (0.820) on the test data, whereas SVM showed slightly better performance (0.740) than MLP (0.734). \n",
    "\n",
    "The higher AUC scores on training data than on the test data for both algorithms indicated both MLP and SVM were slightly overfitted with relatively high variance and low bias. When compared to MLP, SVM showed more prominent overfitting, higher variance and lower bias. The generalizability of these models can be increased by reducing the model complexity or by providing more data for training. Model complexity can be reduced by using a simpler kernel or a smaller regularization parameter C for SVM, and using fewer hidden neurons, increasing the dropout rate and increasing the batch size for MLP [12].\n",
    "\n",
    "SVM required significantly less computation time for Randomized Search. Two-layer and three-layer MLP required 66.8 times and 85.9 times longer computation time than SVM respectively. As we expected, the repeated, iterative search for minimal loss in MLP required significantly longer time than SVM’s approach in maximizing the margin of the decision boundary.\n",
    "The ROC and confusion matrices revealed SVM displayed a slightly higher sensitivity (also known as true positive rate or recall) of 72% than MLP’s 65%. This indicated SVM exhibited slightly better capability in making positive diagnosis for diabetes, particularly for this case where incorrectly classifying diabetes patients as non-diabetic may cause serious complications. Nonetheless, the specificity (=1- true negative rate) for MLP 89% was significantly higher than SVM’s 78%. Considering diabetes occurs in a relatively small proportion of population (8.5% in 2014 [1]), in countries where medical resources are inadequate, MLP would be more suitable than SVM, as there is a high cost associated with incorrect classification of a large number of non- diabetes patients.\n",
    "The precision-recall curves revealed both SVM and MLP attained precision of 60% and 58%, indicating they were capable of making correct positive diagnosis out of all positive predictions made respectively, at the imbalanced diabetes to non-diabetes class ratio of 268:500 [13].\n",
    "\n",
    "The use of SMOTE introduced bias towards the minority diabetic class during training. This may have a particularly significant impact on SVM when the synthesized data were close to the decision boundary. Such impact can be lessened by combining SMOTE with some undersampling of the majority non-diabetic class instead of solely applying SMOTE on the minority class, so that fewer synthetic data would be required [10]. The bias would have less influence on MLP as the training data was passed into the neural network in batches and for multiple epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Both MLP and SVM exhibited high capability in diagnosing diabetes. The differences between the performance of the two algorithms were subtle, as reflected by the similarity in AUCs and accuracies on test or training data. MLP’s higher specificity compared to SVM makes MLP more suitable for real-life situation, where diabetes only occurs in a small proportion of population and there is a high cost associated with the incorrect classification of a large number of non-diabetes patients. There is, however, small trade-offs in sensitivity. Furthermore, significantly longer computation time and larger efforts in terms of architecture and hyperparameter optimization would be required for training MLP when compared to SVM. Further investigation should be made into developing ensemble models such as bagging, which is expected to have lower variance and higher generalizability [14]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "1. Who.int. 2021. Diabetes. [online] Available at: <https://www.who.int/news-room/fact-sheets/detail/diabetes/> [Accessed 12 April 2021].\n",
    "2. Gardner, M. and Dorling, S., 1998. Artificial neural networks (the multilayer perceptron)—a review of applications in the atmospheric sciences. Atmospheric Environment, 32(14-15), pp.2627-2636.\n",
    "3. Garbin, C., Zhu, X. and Marques, O., 2020. Dropout vs. batch normalization: an empirical study of their impact to deep learning. Multimedia Tools and Applications, 79(19-20), pp.12777-12815.\n",
    "4. Prechelt, L., 1998. Automatic early stopping using cross validation: quantifying the criteria. Neural Networks, 11(4), pp.761-767.\n",
    "5. Fukumizu, K. and Amari, S., 2000. Local minima and plateaus in hierarchical structures of multilayer perceptrons. Neural Networks, 13(3), pp.317-327.\n",
    "6. CS229 Lecture notes by Andrew Ng. 2021. [online] Available at: <https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf> [Accessed 12 April 2021].\n",
    "7. Ebenezer Obaloluwa Olaniyi, K., 2021. Onset Diabetes Diagnosis Using Artificial Neural Network. [online] Ijser.org. Available at: <https://www.ijser.org/paper/Onset-Diabetes-Diagnosis-Using-Artificial-Neural-Network.html> [Accessed 12 April 2021].\n",
    "8. van Gestel, T., Suykens, J., Baesens, B., Viaene, S., Vanthienen, J., Dedene, G., de Moor, B. and Vandewalle, J., 2004. Benchmarking Least Squares Support Vector Machine Classifiers. Machine Learning, 54(1), pp.5-32.\n",
    "9. Kaggle.com. 2021. Pima Indians Diabetes Database. [online] Available at: <https://www.kaggle.com/uciml/pima-indians-diabetes-database> [Accessed 12 April 2021].\n",
    "10. Chawla, N., Bowyer, K., Hall, L. and Kegelmeyer, W., 2002. SMOTE: Synthetic Minority Over-sampling Technique. Journal of Artificial Intelligence Research, 16, pp.321-357.\n",
    "11. Valentini, G. and Dietterich, T., 2002. Bias—Variance Analysis and Ensembles of SVM. Multiple Classifier Systems, pp.222-231.\n",
    "12. Garbin, C., Zhu, X. and Marques, O., 2020. Dropout vs. batch normalization: an empirical study of their impact to deep learning. Multimedia Tools and Applications, 79(19-20), pp.12777-12815.\n",
    "13. Saito, T. and Rehmsmeier, M., 2015. The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Datasets. PLOS ONE, 10(3), p.e0118432.\n",
    "14. Wang, H., Zheng, B., Yoon, S. and Ko, H., 2018. A support vector machine-based ensemble algorithm for breast cancer diagnosis. European Journal of Operational Research, 267(2), pp.687-699.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
